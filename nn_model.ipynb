{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting utilities\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as K\n",
    "from tensorflow.keras.callbacks import History, ModelCheckpoint\n",
    "\n",
    "# data-science & processing tools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics\n",
    "import h5py\n",
    "import functools\n",
    "import itertools as it\n",
    "from tqdm.notebook import tqdm\n",
    "import pygmnormalize as gmn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('raw_data.tsv', sep='\\t', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_ID = df['Gene ID']\n",
    "gene_names = df['Gene Name']\n",
    "\n",
    "df.drop('Gene ID', axis=1, inplace=True)\n",
    "df.drop('Gene Name', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_df = gmn.total_count_normalization(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = normal_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65217, 322)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54914, 322)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## indices where values are greater than zero\n",
    "idx2 = np.where(X.any(axis=1))[0]\n",
    "newX = X[idx2]\n",
    "newX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5637, 322)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get rows where a value is greater than 0.0001\n",
    "rows = np.unique(np.where(newX > 0.0001)[0])\n",
    "newerX = newX[rows]\n",
    "newerX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = gene_names[idx2].values[rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(322, 5637)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "by_patient = newerX.T\n",
    "by_patient.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = open('classifications.txt', 'r').read()\n",
    "classes = eval(classes)\n",
    "y = np.array(list(classes.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 2, 0, 0, 0, 0, 2, 2, 0, 0,\n",
       "       0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 2, 2, 2, 2, 0, 2, 2, 0, 2, 2, 0, 2,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0,\n",
       "       2, 0, 0, 0, 0, 2, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 2, 2, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0,\n",
       "       0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_enc = LabelEncoder()\n",
    "labels = label_enc.fit_transform(y)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = labels.reshape(len(labels), 1)\n",
    "one_hot = enc.fit_transform(labels)\n",
    "one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(by_patient, one_hot, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(215, 5637)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = K.Sequential()\n",
    "model.add(K.layers.Dense(units=10, activation='relu', input_shape=(5637,), \n",
    "                         kernel_regularizer=K.regularizers.l2(l=0.001)))\n",
    "model.add(K.layers.Dropout(rate=0.001))\n",
    "model.add(K.layers.Dense(units=200, activation='relu', kernel_regularizer=K.regularizers.l2(l=0.001)))\n",
    "model.add(K.layers.Dense(units=3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_67 (Dense)             (None, 10)                56380     \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 200)               2200      \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 3)                 603       \n",
      "=================================================================\n",
      "Total params: 59,183\n",
      "Trainable params: 59,183\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = History()\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'], callbacks=[history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 172 samples, validate on 43 samples\n",
      "Epoch 1/100\n",
      "172/172 [==============================] - 1s 8ms/sample - loss: 0.3918 - accuracy: 0.8353 - val_loss: 0.3743 - val_accuracy: 0.8450\n",
      "Epoch 2/100\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.3948 - accuracy: 0.8295 - val_loss: 0.3846 - val_accuracy: 0.8527\n",
      "Epoch 3/100\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 0.3861 - accuracy: 0.8391 - val_loss: 0.3755 - val_accuracy: 0.8450\n",
      "Epoch 4/100\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.3840 - accuracy: 0.8450 - val_loss: 0.3842 - val_accuracy: 0.8527\n",
      "Epoch 5/100\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 0.3886 - accuracy: 0.8391 - val_loss: 0.3692 - val_accuracy: 0.8450\n",
      "Epoch 6/100\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.3860 - accuracy: 0.8314 - val_loss: 0.3812 - val_accuracy: 0.8450\n",
      "Epoch 7/100\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 0.3817 - accuracy: 0.8353 - val_loss: 0.3695 - val_accuracy: 0.8372\n",
      "Epoch 8/100\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 0.3955 - accuracy: 0.8333 - val_loss: 0.3983 - val_accuracy: 0.8527\n",
      "Epoch 9/100\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.3917 - accuracy: 0.8295 - val_loss: 0.3835 - val_accuracy: 0.8527\n",
      "Epoch 10/100\n",
      "172/172 [==============================] - 0s 942us/sample - loss: 0.3821 - accuracy: 0.8411 - val_loss: 0.3788 - val_accuracy: 0.8450\n",
      "Epoch 11/100\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.3915 - accuracy: 0.8295 - val_loss: 0.3830 - val_accuracy: 0.8450\n",
      "Epoch 12/100\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.3859 - accuracy: 0.8391 - val_loss: 0.3733 - val_accuracy: 0.8450\n",
      "Epoch 13/100\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 0.3894 - accuracy: 0.8391 - val_loss: 0.3927 - val_accuracy: 0.8527\n",
      "Epoch 14/100\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 0.3806 - accuracy: 0.8411 - val_loss: 0.3699 - val_accuracy: 0.8372\n",
      "Epoch 15/100\n",
      "172/172 [==============================] - 0s 861us/sample - loss: 0.3901 - accuracy: 0.8333 - val_loss: 0.3715 - val_accuracy: 0.8295\n",
      "Epoch 16/100\n",
      "172/172 [==============================] - 0s 882us/sample - loss: 0.3892 - accuracy: 0.8391 - val_loss: 0.3708 - val_accuracy: 0.8372\n",
      "Epoch 17/100\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 0.3935 - accuracy: 0.8275 - val_loss: 0.4085 - val_accuracy: 0.8450\n",
      "Epoch 18/100\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 0.3879 - accuracy: 0.8391 - val_loss: 0.3809 - val_accuracy: 0.8450\n",
      "Epoch 19/100\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.3796 - accuracy: 0.8411 - val_loss: 0.3750 - val_accuracy: 0.8450\n",
      "Epoch 20/100\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 0.3812 - accuracy: 0.8430 - val_loss: 0.3733 - val_accuracy: 0.8372\n",
      "Epoch 21/100\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.3853 - accuracy: 0.8314 - val_loss: 0.3779 - val_accuracy: 0.8372\n",
      "Epoch 22/100\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.4173 - accuracy: 0.8159 - val_loss: 0.4728 - val_accuracy: 0.7907\n",
      "Epoch 23/100\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 0.3855 - accuracy: 0.8353 - val_loss: 0.3760 - val_accuracy: 0.8217\n",
      "Epoch 24/100\n",
      "172/172 [==============================] - 0s 942us/sample - loss: 0.3773 - accuracy: 0.8450 - val_loss: 0.3776 - val_accuracy: 0.8372\n",
      "Epoch 25/100\n",
      "172/172 [==============================] - 0s 987us/sample - loss: 0.4020 - accuracy: 0.8275 - val_loss: 0.4073 - val_accuracy: 0.8527\n",
      "Epoch 26/100\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.3887 - accuracy: 0.8295 - val_loss: 0.3903 - val_accuracy: 0.8527\n",
      "Epoch 27/100\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.4036 - accuracy: 0.8295 - val_loss: 0.3769 - val_accuracy: 0.8372\n",
      "Epoch 28/100\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.3831 - accuracy: 0.8372 - val_loss: 0.3790 - val_accuracy: 0.8372\n",
      "Epoch 29/100\n",
      "172/172 [==============================] - 0s 928us/sample - loss: 0.3833 - accuracy: 0.8430 - val_loss: 0.3771 - val_accuracy: 0.8217\n",
      "Epoch 30/100\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.3891 - accuracy: 0.8430 - val_loss: 0.3796 - val_accuracy: 0.8372\n",
      "Epoch 31/100\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.3856 - accuracy: 0.8372 - val_loss: 0.3919 - val_accuracy: 0.8527\n",
      "Epoch 32/100\n",
      "172/172 [==============================] - 0s 952us/sample - loss: 0.3788 - accuracy: 0.8411 - val_loss: 0.3784 - val_accuracy: 0.8450\n",
      "Epoch 33/100\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.3799 - accuracy: 0.8353 - val_loss: 0.4195 - val_accuracy: 0.8372\n",
      "Epoch 34/100\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.3891 - accuracy: 0.8411 - val_loss: 0.3777 - val_accuracy: 0.8372\n",
      "Epoch 35/100\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 0.3813 - accuracy: 0.8333 - val_loss: 0.3971 - val_accuracy: 0.8527\n",
      "Epoch 36/100\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.3951 - accuracy: 0.8372 - val_loss: 0.3822 - val_accuracy: 0.8140\n",
      "Epoch 37/100\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.3824 - accuracy: 0.8314 - val_loss: 0.3930 - val_accuracy: 0.8527\n",
      "Epoch 38/100\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 0.3861 - accuracy: 0.8411 - val_loss: 0.4041 - val_accuracy: 0.8527\n",
      "Epoch 39/100\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.3878 - accuracy: 0.8353 - val_loss: 0.3801 - val_accuracy: 0.8372\n",
      "Epoch 40/100\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 0.3794 - accuracy: 0.8295 - val_loss: 0.4235 - val_accuracy: 0.8295\n",
      "Epoch 41/100\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.3939 - accuracy: 0.8256 - val_loss: 0.3866 - val_accuracy: 0.8450\n",
      "Epoch 42/100\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 0.3779 - accuracy: 0.8372 - val_loss: 0.3804 - val_accuracy: 0.8450\n",
      "Epoch 43/100\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.3804 - accuracy: 0.8411 - val_loss: 0.3836 - val_accuracy: 0.8372\n",
      "Epoch 44/100\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.3789 - accuracy: 0.8391 - val_loss: 0.3824 - val_accuracy: 0.8372\n",
      "Epoch 45/100\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 0.3843 - accuracy: 0.8372 - val_loss: 0.3947 - val_accuracy: 0.8527\n",
      "Epoch 46/100\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.3790 - accuracy: 0.8391 - val_loss: 0.3809 - val_accuracy: 0.8372\n",
      "Epoch 47/100\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.3859 - accuracy: 0.8314 - val_loss: 0.3993 - val_accuracy: 0.8527\n",
      "Epoch 48/100\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.3792 - accuracy: 0.8353 - val_loss: 0.3950 - val_accuracy: 0.8527\n",
      "Epoch 49/100\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 0.3824 - accuracy: 0.8372 - val_loss: 0.3778 - val_accuracy: 0.8295\n",
      "Epoch 50/100\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.3831 - accuracy: 0.8372 - val_loss: 0.3795 - val_accuracy: 0.8450\n",
      "Epoch 51/100\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.3786 - accuracy: 0.8391 - val_loss: 0.3861 - val_accuracy: 0.8450\n",
      "Epoch 52/100\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.3934 - accuracy: 0.8372 - val_loss: 0.3791 - val_accuracy: 0.8372\n",
      "Epoch 53/100\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.3968 - accuracy: 0.8353 - val_loss: 0.3961 - val_accuracy: 0.7984\n",
      "Epoch 54/100\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.4462 - accuracy: 0.8159 - val_loss: 0.4618 - val_accuracy: 0.8140\n",
      "Epoch 55/100\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.3851 - accuracy: 0.8372 - val_loss: 0.3788 - val_accuracy: 0.8450\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 964us/sample - loss: 0.3900 - accuracy: 0.8333 - val_loss: 0.3911 - val_accuracy: 0.8062\n",
      "Epoch 57/100\n",
      "172/172 [==============================] - 0s 980us/sample - loss: 0.3819 - accuracy: 0.8391 - val_loss: 0.4093 - val_accuracy: 0.8450\n",
      "Epoch 58/100\n",
      "172/172 [==============================] - 0s 986us/sample - loss: 0.3850 - accuracy: 0.8372 - val_loss: 0.3872 - val_accuracy: 0.8450\n",
      "Epoch 59/100\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.3792 - accuracy: 0.8391 - val_loss: 0.4033 - val_accuracy: 0.8450\n",
      "Epoch 60/100\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.3830 - accuracy: 0.8314 - val_loss: 0.3819 - val_accuracy: 0.8372\n",
      "Epoch 61/100\n",
      "172/172 [==============================] - 0s 994us/sample - loss: 0.3775 - accuracy: 0.8411 - val_loss: 0.3854 - val_accuracy: 0.8450\n",
      "Epoch 62/100\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.3856 - accuracy: 0.8353 - val_loss: 0.4130 - val_accuracy: 0.8372\n",
      "Epoch 63/100\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.3881 - accuracy: 0.8333 - val_loss: 0.4067 - val_accuracy: 0.8450\n",
      "Epoch 64/100\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.3876 - accuracy: 0.8333 - val_loss: 0.3809 - val_accuracy: 0.8295\n",
      "Epoch 65/100\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.3748 - accuracy: 0.8411 - val_loss: 0.3826 - val_accuracy: 0.8450\n",
      "Epoch 66/100\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.3746 - accuracy: 0.8372 - val_loss: 0.3844 - val_accuracy: 0.8372\n",
      "Epoch 67/100\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.3736 - accuracy: 0.8411 - val_loss: 0.3805 - val_accuracy: 0.8295\n",
      "Epoch 68/100\n",
      "172/172 [==============================] - 0s 985us/sample - loss: 0.3749 - accuracy: 0.8295 - val_loss: 0.4576 - val_accuracy: 0.8217\n",
      "Epoch 69/100\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4019 - accuracy: 0.8372 - val_loss: 0.3839 - val_accuracy: 0.8217\n",
      "Epoch 70/100\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.3956 - accuracy: 0.8295 - val_loss: 0.4086 - val_accuracy: 0.7984\n",
      "Epoch 71/100\n",
      "172/172 [==============================] - 0s 978us/sample - loss: 0.4143 - accuracy: 0.8256 - val_loss: 0.3907 - val_accuracy: 0.8450\n",
      "Epoch 72/100\n",
      "172/172 [==============================] - 0s 986us/sample - loss: 0.3741 - accuracy: 0.8333 - val_loss: 0.3945 - val_accuracy: 0.8527\n",
      "Epoch 73/100\n",
      "172/172 [==============================] - 0s 998us/sample - loss: 0.3858 - accuracy: 0.8353 - val_loss: 0.3836 - val_accuracy: 0.8450\n",
      "Epoch 74/100\n",
      "172/172 [==============================] - 0s 990us/sample - loss: 0.3724 - accuracy: 0.8391 - val_loss: 0.4012 - val_accuracy: 0.8450\n",
      "Epoch 75/100\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 0.3850 - accuracy: 0.8333 - val_loss: 0.3824 - val_accuracy: 0.8217\n",
      "Epoch 76/100\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.3747 - accuracy: 0.8333 - val_loss: 0.3832 - val_accuracy: 0.8450\n",
      "Epoch 77/100\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 0.3750 - accuracy: 0.8353 - val_loss: 0.4099 - val_accuracy: 0.8450\n",
      "Epoch 78/100\n",
      "172/172 [==============================] - 0s 974us/sample - loss: 0.3759 - accuracy: 0.8411 - val_loss: 0.3865 - val_accuracy: 0.8140\n",
      "Epoch 79/100\n",
      "172/172 [==============================] - 0s 970us/sample - loss: 0.3745 - accuracy: 0.8333 - val_loss: 0.3957 - val_accuracy: 0.8527\n",
      "Epoch 80/100\n",
      "172/172 [==============================] - 0s 951us/sample - loss: 0.3774 - accuracy: 0.8372 - val_loss: 0.3838 - val_accuracy: 0.8450\n",
      "Epoch 81/100\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.3711 - accuracy: 0.8430 - val_loss: 0.3814 - val_accuracy: 0.8450\n",
      "Epoch 82/100\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.3749 - accuracy: 0.8314 - val_loss: 0.4115 - val_accuracy: 0.8450\n",
      "Epoch 83/100\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 0.3750 - accuracy: 0.8372 - val_loss: 0.3839 - val_accuracy: 0.8450\n",
      "Epoch 84/100\n",
      "172/172 [==============================] - 0s 969us/sample - loss: 0.3709 - accuracy: 0.8391 - val_loss: 0.3819 - val_accuracy: 0.8450\n",
      "Epoch 85/100\n",
      "172/172 [==============================] - 0s 946us/sample - loss: 0.3921 - accuracy: 0.8256 - val_loss: 0.4018 - val_accuracy: 0.8450\n",
      "Epoch 86/100\n",
      "172/172 [==============================] - 0s 937us/sample - loss: 0.3719 - accuracy: 0.8353 - val_loss: 0.3889 - val_accuracy: 0.8450\n",
      "Epoch 87/100\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.3810 - accuracy: 0.8391 - val_loss: 0.3948 - val_accuracy: 0.8527\n",
      "Epoch 88/100\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.4202 - accuracy: 0.8314 - val_loss: 0.3956 - val_accuracy: 0.8062\n",
      "Epoch 89/100\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.3824 - accuracy: 0.8430 - val_loss: 0.3808 - val_accuracy: 0.8450\n",
      "Epoch 90/100\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 0.3923 - accuracy: 0.8256 - val_loss: 0.3848 - val_accuracy: 0.8372\n",
      "Epoch 91/100\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.3763 - accuracy: 0.8391 - val_loss: 0.3929 - val_accuracy: 0.8527\n",
      "Epoch 92/100\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.3778 - accuracy: 0.8333 - val_loss: 0.4005 - val_accuracy: 0.8450\n",
      "Epoch 93/100\n",
      "172/172 [==============================] - 0s 962us/sample - loss: 0.3716 - accuracy: 0.8391 - val_loss: 0.3876 - val_accuracy: 0.8450\n",
      "Epoch 94/100\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.3706 - accuracy: 0.8450 - val_loss: 0.3827 - val_accuracy: 0.8295\n",
      "Epoch 95/100\n",
      "172/172 [==============================] - 0s 976us/sample - loss: 0.3749 - accuracy: 0.8314 - val_loss: 0.3826 - val_accuracy: 0.8295\n",
      "Epoch 96/100\n",
      "172/172 [==============================] - 0s 996us/sample - loss: 0.3737 - accuracy: 0.8488 - val_loss: 0.3811 - val_accuracy: 0.8295\n",
      "Epoch 97/100\n",
      "172/172 [==============================] - 0s 956us/sample - loss: 0.3815 - accuracy: 0.8275 - val_loss: 0.4026 - val_accuracy: 0.8450\n",
      "Epoch 98/100\n",
      "172/172 [==============================] - 0s 978us/sample - loss: 0.3791 - accuracy: 0.8450 - val_loss: 0.3963 - val_accuracy: 0.8450\n",
      "Epoch 99/100\n",
      "172/172 [==============================] - 0s 958us/sample - loss: 0.3825 - accuracy: 0.8275 - val_loss: 0.4079 - val_accuracy: 0.8450\n",
      "Epoch 100/100\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.3851 - accuracy: 0.8372 - val_loss: 0.3874 - val_accuracy: 0.8140\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, y_train, epochs=100, batch_size=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Loss: 0.36916357763977936\n"
     ]
    }
   ],
   "source": [
    "print('Best Loss: {}'.format(min(hist.history['val_loss'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 0.8068535923957825\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Model accuracy: {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(dropout_rate=0.001, \n",
    "                 input_shape=(5637,), \n",
    "                 reg_coeff=0.001,\n",
    "                 reg_type='l2',\n",
    "                 activation='relu',\n",
    "                 num_epochs=300,\n",
    "                 units=200,\n",
    "                 num_layers=2):\n",
    "    model = K.Sequential()\n",
    "    if reg_type == 'l2':\n",
    "        reg = K.regularizers.l2(l=reg_coeff)\n",
    "    elif reg_type == 'l1':\n",
    "        reg = K.regularizers.l1(l=reg_coeff)\n",
    "    model.add(K.layers.Dense(units=units, activation=activation, input_shape=input_shape, \n",
    "                             kernel_regularizer=reg))\n",
    "    model.add(K.layers.Dropout(rate=dropout_rate))\n",
    "#     model.add(K.layers.Dense(units=units, activation=activation, kernel_regularizer=reg))\n",
    "\n",
    "    for i in range(num_layers-1):\n",
    "        model.add(K.layers.Dense(units=units, activation=activation, kernel_regularizer=reg))\n",
    "        model.add(K.layers.Dropout(rate=dropout_rate))\n",
    "    \n",
    "    model.add(K.layers.Dense(units=3, activation='softmax'))\n",
    "    history = History()\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'], callbacks=[history])\n",
    "    \n",
    "    hist = model.fit(X_train, y_train, epochs=num_epochs, batch_size=10, validation_split=0.2)\n",
    "    \n",
    "    best_loss = min(hist.history['val_loss'])\n",
    "    \n",
    "    return best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(dropout_rates, \n",
    "                reg_coeffs,\n",
    "                reg_types,\n",
    "                pbars,\n",
    "                num_epochs,\n",
    "                activations=['relu'],\n",
    "                units=[200],\n",
    "                num_layers=[2]):\n",
    "    \"\"\"performs a grid hyperparameter search with loss as the metric\n",
    "    \n",
    "    perform a grid search over different hyper parameter configurations\n",
    "    to determing the optimal configuration for the cnn\n",
    "    \n",
    "    Arguments:\n",
    "      dropout_rates: a list of dropout_rates to test\n",
    "      reg_coeffs: a list or L2 lambda terms to test\n",
    "      learning_rates: a list of learning rates to test\n",
    "      pbars: a list of `tqdm` progress bar objects to use for displaying\n",
    "        grid search and training progress\n",
    "        * len(pbars) == 3\n",
    "      verbose: (False)flag to print grid search parameters and epoch loss on \n",
    "        each respective iteration\n",
    "      **kwargs: any additional valid keyword arguments for passing to\n",
    "        `cnn_train` \n",
    "        \n",
    "    Returns:\n",
    "      losses_df: a `pd.DataFrame` table of the grid search results\n",
    "        * len(losses_df) == (len(dropout_rates) * len(reg_coeffs) \n",
    "                             * len(learning_rates))\n",
    "    \"\"\"\n",
    "    losses = []\n",
    "    hyperparam_combos = list(\n",
    "        it.product(dropout_rates, reg_coeffs, reg_types, activations, units, num_layers))\n",
    "    \n",
    "    pbars[0].reset(len(hyperparam_combos))\n",
    "    pbars[0].set_description('Grid Search')\n",
    "    for dropout_rate, reg_coeff, reg_type, activation, units, num_layers in hyperparam_combos:\n",
    "        tf.print('Beginning training for dr={:.3f}, l_lambda={:.1e}, reg_type={}, act: {}'.format(dropout_rate, \n",
    "                                                                                             reg_coeff, reg_type,\n",
    "                                                                                             activation))\n",
    "        \n",
    "        best_loss = create_model(dropout_rate=dropout_rate, \n",
    "                                 input_shape=(5637,), \n",
    "                                 reg_coeff=reg_coeff, \n",
    "                                 reg_type=reg_type,\n",
    "                                 activation=activation,\n",
    "                                 num_epochs=num_epochs,\n",
    "                                 units=units,\n",
    "                                 num_layers=num_layers)\n",
    "        losses.append([dropout_rate, \n",
    "                       reg_type,\n",
    "                       reg_coeff,\n",
    "                       activation,\n",
    "                       units,\n",
    "                       num_layers,\n",
    "                       best_loss])\n",
    "        \n",
    "        pbars[0].update()\n",
    "    \n",
    "#     return losses\n",
    "        \n",
    "    losses_df = pd.DataFrame(losses, \n",
    "                             columns=['dropout rate',\n",
    "                                      'reg type',\n",
    "                                      'lambda',\n",
    "                                      'activation',\n",
    "                                      'units',\n",
    "                                      'num_layers',\n",
    "                                      'validation loss'])                                              \n",
    "    return losses_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6af637580cc142438746fd3b90aeb10d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=1.0), HTML(value='')), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0656433b314742a89e493e2ac4a8e7b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=1.0), HTML(value='')), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b013d2f21314c078d828253c640c0bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=1.0), HTML(value='')), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training for dr=0.001, l_lambda=1.0e-03, reg_type=l2\n",
      "Train on 172 samples, validate on 43 samples\n",
      "Epoch 1/200\n",
      "172/172 [==============================] - 1s 8ms/sample - loss: 0.6485 - accuracy: 0.6667 - val_loss: 0.6182 - val_accuracy: 0.6667\n",
      "Epoch 2/200\n",
      "172/172 [==============================] - 0s 838us/sample - loss: 0.5972 - accuracy: 0.6667 - val_loss: 0.5646 - val_accuracy: 0.6667\n",
      "Epoch 3/200\n",
      "172/172 [==============================] - 0s 833us/sample - loss: 0.5447 - accuracy: 0.7500 - val_loss: 0.5221 - val_accuracy: 0.7829\n",
      "Epoch 4/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 0.5187 - accuracy: 0.7791 - val_loss: 0.5112 - val_accuracy: 0.7829\n",
      "Epoch 5/200\n",
      "172/172 [==============================] - 0s 858us/sample - loss: 0.5171 - accuracy: 0.7791 - val_loss: 0.5081 - val_accuracy: 0.7829\n",
      "Epoch 6/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 0.5135 - accuracy: 0.7791 - val_loss: 0.5070 - val_accuracy: 0.7829\n",
      "Epoch 7/200\n",
      "172/172 [==============================] - 0s 997us/sample - loss: 0.5128 - accuracy: 0.7791 - val_loss: 0.5060 - val_accuracy: 0.7829\n",
      "Epoch 8/200\n",
      "172/172 [==============================] - 0s 958us/sample - loss: 0.5133 - accuracy: 0.7791 - val_loss: 0.5045 - val_accuracy: 0.7829\n",
      "Epoch 9/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5118 - accuracy: 0.7791 - val_loss: 0.5039 - val_accuracy: 0.7829\n",
      "Epoch 10/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5113 - accuracy: 0.7791 - val_loss: 0.5036 - val_accuracy: 0.7829\n",
      "Epoch 11/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.5108 - accuracy: 0.7791 - val_loss: 0.5031 - val_accuracy: 0.7829\n",
      "Epoch 12/200\n",
      "172/172 [==============================] - 0s 837us/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5028 - val_accuracy: 0.7829\n",
      "Epoch 13/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5026 - val_accuracy: 0.7829\n",
      "Epoch 14/200\n",
      "172/172 [==============================] - 0s 818us/sample - loss: 0.5108 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 15/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 16/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 17/200\n",
      "172/172 [==============================] - 0s 802us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 18/200\n",
      "172/172 [==============================] - 0s 815us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5014 - val_accuracy: 0.7829\n",
      "Epoch 19/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5011 - val_accuracy: 0.7829\n",
      "Epoch 20/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5086 - accuracy: 0.7791 - val_loss: 0.5011 - val_accuracy: 0.7829\n",
      "Epoch 21/200\n",
      "172/172 [==============================] - 0s 845us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5011 - val_accuracy: 0.7829\n",
      "Epoch 22/200\n",
      "172/172 [==============================] - 0s 800us/sample - loss: 0.5085 - accuracy: 0.7791 - val_loss: 0.5012 - val_accuracy: 0.7829\n",
      "Epoch 23/200\n",
      "172/172 [==============================] - 0s 818us/sample - loss: 0.5083 - accuracy: 0.7791 - val_loss: 0.5006 - val_accuracy: 0.7829\n",
      "Epoch 24/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.5082 - accuracy: 0.7791 - val_loss: 0.5008 - val_accuracy: 0.7829\n",
      "Epoch 25/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5004 - val_accuracy: 0.7829\n",
      "Epoch 26/200\n",
      "172/172 [==============================] - 0s 826us/sample - loss: 0.5080 - accuracy: 0.7791 - val_loss: 0.5007 - val_accuracy: 0.7829\n",
      "Epoch 27/200\n",
      "172/172 [==============================] - 0s 984us/sample - loss: 0.5084 - accuracy: 0.7791 - val_loss: 0.5004 - val_accuracy: 0.7829\n",
      "Epoch 28/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5084 - accuracy: 0.7791 - val_loss: 0.5001 - val_accuracy: 0.7829\n",
      "Epoch 29/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5009 - val_accuracy: 0.7829\n",
      "Epoch 30/200\n",
      "172/172 [==============================] - 0s 999us/sample - loss: 0.5077 - accuracy: 0.7791 - val_loss: 0.5003 - val_accuracy: 0.7829\n",
      "Epoch 31/200\n",
      "172/172 [==============================] - 0s 964us/sample - loss: 0.5080 - accuracy: 0.7791 - val_loss: 0.4999 - val_accuracy: 0.7829\n",
      "Epoch 32/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.5083 - accuracy: 0.7791 - val_loss: 0.4997 - val_accuracy: 0.7829\n",
      "Epoch 33/200\n",
      "172/172 [==============================] - 0s 999us/sample - loss: 0.5081 - accuracy: 0.7791 - val_loss: 0.5008 - val_accuracy: 0.7829\n",
      "Epoch 34/200\n",
      "172/172 [==============================] - 0s 994us/sample - loss: 0.5079 - accuracy: 0.7791 - val_loss: 0.4997 - val_accuracy: 0.7829\n",
      "Epoch 35/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5075 - accuracy: 0.7791 - val_loss: 0.4995 - val_accuracy: 0.7829\n",
      "Epoch 36/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5071 - accuracy: 0.7791 - val_loss: 0.4992 - val_accuracy: 0.7829\n",
      "Epoch 37/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5078 - accuracy: 0.7791 - val_loss: 0.4992 - val_accuracy: 0.7829\n",
      "Epoch 38/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5079 - accuracy: 0.7791 - val_loss: 0.4989 - val_accuracy: 0.7829\n",
      "Epoch 39/200\n",
      "172/172 [==============================] - 0s 989us/sample - loss: 0.5063 - accuracy: 0.7791 - val_loss: 0.4986 - val_accuracy: 0.7829\n",
      "Epoch 40/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 0.5069 - accuracy: 0.7791 - val_loss: 0.4981 - val_accuracy: 0.7829\n",
      "Epoch 41/200\n",
      "172/172 [==============================] - 0s 955us/sample - loss: 0.5063 - accuracy: 0.7791 - val_loss: 0.4995 - val_accuracy: 0.7829\n",
      "Epoch 42/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 0.5062 - accuracy: 0.7791 - val_loss: 0.4977 - val_accuracy: 0.7829\n",
      "Epoch 43/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 0.5056 - accuracy: 0.7791 - val_loss: 0.4976 - val_accuracy: 0.7829\n",
      "Epoch 44/200\n",
      "172/172 [==============================] - 0s 956us/sample - loss: 0.5057 - accuracy: 0.7791 - val_loss: 0.4972 - val_accuracy: 0.7829\n",
      "Epoch 45/200\n",
      "172/172 [==============================] - 0s 977us/sample - loss: 0.5055 - accuracy: 0.7791 - val_loss: 0.4970 - val_accuracy: 0.7829\n",
      "Epoch 46/200\n",
      "172/172 [==============================] - 0s 865us/sample - loss: 0.5058 - accuracy: 0.7791 - val_loss: 0.4980 - val_accuracy: 0.7829\n",
      "Epoch 47/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.5069 - accuracy: 0.7791 - val_loss: 0.4967 - val_accuracy: 0.7829\n",
      "Epoch 48/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5059 - accuracy: 0.7791 - val_loss: 0.4963 - val_accuracy: 0.7829\n",
      "Epoch 49/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5062 - accuracy: 0.7791 - val_loss: 0.4975 - val_accuracy: 0.7829\n",
      "Epoch 50/200\n",
      "172/172 [==============================] - 0s 996us/sample - loss: 0.5061 - accuracy: 0.7791 - val_loss: 0.4966 - val_accuracy: 0.7829\n",
      "Epoch 51/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5046 - accuracy: 0.7791 - val_loss: 0.4959 - val_accuracy: 0.7829\n",
      "Epoch 52/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5034 - accuracy: 0.7791 - val_loss: 0.4952 - val_accuracy: 0.7829\n",
      "Epoch 53/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.5035 - accuracy: 0.7791 - val_loss: 0.4958 - val_accuracy: 0.7829\n",
      "Epoch 54/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.5041 - accuracy: 0.7791 - val_loss: 0.4949 - val_accuracy: 0.7829\n",
      "Epoch 55/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5019 - accuracy: 0.7791 - val_loss: 0.4944 - val_accuracy: 0.7829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5037 - accuracy: 0.7791 - val_loss: 0.4943 - val_accuracy: 0.7829\n",
      "Epoch 57/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5018 - accuracy: 0.7791 - val_loss: 0.4947 - val_accuracy: 0.7829\n",
      "Epoch 58/200\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 0.5025 - accuracy: 0.7791 - val_loss: 0.4938 - val_accuracy: 0.7829\n",
      "Epoch 59/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.5026 - accuracy: 0.7791 - val_loss: 0.4928 - val_accuracy: 0.7829\n",
      "Epoch 60/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5011 - accuracy: 0.7791 - val_loss: 0.4921 - val_accuracy: 0.7829\n",
      "Epoch 61/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5011 - accuracy: 0.7791 - val_loss: 0.4923 - val_accuracy: 0.7829\n",
      "Epoch 62/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5010 - accuracy: 0.7791 - val_loss: 0.4925 - val_accuracy: 0.7829\n",
      "Epoch 63/200\n",
      "172/172 [==============================] - 0s 972us/sample - loss: 0.5000 - accuracy: 0.7791 - val_loss: 0.4908 - val_accuracy: 0.7829\n",
      "Epoch 64/200\n",
      "172/172 [==============================] - 0s 994us/sample - loss: 0.5003 - accuracy: 0.7791 - val_loss: 0.4899 - val_accuracy: 0.7829\n",
      "Epoch 65/200\n",
      "172/172 [==============================] - 0s 989us/sample - loss: 0.4982 - accuracy: 0.7791 - val_loss: 0.4894 - val_accuracy: 0.7829\n",
      "Epoch 66/200\n",
      "172/172 [==============================] - 0s 949us/sample - loss: 0.4980 - accuracy: 0.7791 - val_loss: 0.4883 - val_accuracy: 0.7829\n",
      "Epoch 67/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.4995 - accuracy: 0.7791 - val_loss: 0.4875 - val_accuracy: 0.7829\n",
      "Epoch 68/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4978 - accuracy: 0.7791 - val_loss: 0.4868 - val_accuracy: 0.7829\n",
      "Epoch 69/200\n",
      "172/172 [==============================] - 0s 945us/sample - loss: 0.4984 - accuracy: 0.7791 - val_loss: 0.4874 - val_accuracy: 0.7829\n",
      "Epoch 70/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.4961 - accuracy: 0.7791 - val_loss: 0.4847 - val_accuracy: 0.7829\n",
      "Epoch 71/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.4981 - accuracy: 0.7791 - val_loss: 0.4860 - val_accuracy: 0.7829\n",
      "Epoch 72/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.4941 - accuracy: 0.7791 - val_loss: 0.4824 - val_accuracy: 0.7829\n",
      "Epoch 73/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4981 - accuracy: 0.7791 - val_loss: 0.4826 - val_accuracy: 0.7829\n",
      "Epoch 74/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4964 - accuracy: 0.7771 - val_loss: 0.4817 - val_accuracy: 0.7829\n",
      "Epoch 75/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.4961 - accuracy: 0.7791 - val_loss: 0.4801 - val_accuracy: 0.7829\n",
      "Epoch 76/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.4955 - accuracy: 0.7791 - val_loss: 0.4798 - val_accuracy: 0.7829\n",
      "Epoch 77/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 0.4931 - accuracy: 0.7810 - val_loss: 0.4811 - val_accuracy: 0.7907\n",
      "Epoch 78/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 0.4950 - accuracy: 0.7791 - val_loss: 0.4777 - val_accuracy: 0.7829\n",
      "Epoch 79/200\n",
      "172/172 [==============================] - 0s 958us/sample - loss: 0.4946 - accuracy: 0.7888 - val_loss: 0.4805 - val_accuracy: 0.7984\n",
      "Epoch 80/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.4847 - accuracy: 0.7810 - val_loss: 0.4753 - val_accuracy: 0.7829\n",
      "Epoch 81/200\n",
      "172/172 [==============================] - 0s 858us/sample - loss: 0.4878 - accuracy: 0.7791 - val_loss: 0.4765 - val_accuracy: 0.7984\n",
      "Epoch 82/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 0.4995 - accuracy: 0.8023 - val_loss: 0.4756 - val_accuracy: 0.7984\n",
      "Epoch 83/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.4841 - accuracy: 0.7849 - val_loss: 0.4726 - val_accuracy: 0.7984\n",
      "Epoch 84/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.4819 - accuracy: 0.7829 - val_loss: 0.4741 - val_accuracy: 0.7984\n",
      "Epoch 85/200\n",
      "172/172 [==============================] - 0s 859us/sample - loss: 0.4810 - accuracy: 0.7868 - val_loss: 0.4711 - val_accuracy: 0.8062\n",
      "Epoch 86/200\n",
      "172/172 [==============================] - 0s 856us/sample - loss: 0.4832 - accuracy: 0.7829 - val_loss: 0.4706 - val_accuracy: 0.7984\n",
      "Epoch 87/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.4824 - accuracy: 0.7829 - val_loss: 0.4692 - val_accuracy: 0.7984\n",
      "Epoch 88/200\n",
      "172/172 [==============================] - 0s 859us/sample - loss: 0.4780 - accuracy: 0.7849 - val_loss: 0.4681 - val_accuracy: 0.7984\n",
      "Epoch 89/200\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 0.4782 - accuracy: 0.7888 - val_loss: 0.4681 - val_accuracy: 0.7984\n",
      "Epoch 90/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.4751 - accuracy: 0.7907 - val_loss: 0.4674 - val_accuracy: 0.7984\n",
      "Epoch 91/200\n",
      "172/172 [==============================] - 0s 864us/sample - loss: 0.4751 - accuracy: 0.7926 - val_loss: 0.4677 - val_accuracy: 0.7984\n",
      "Epoch 92/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.4744 - accuracy: 0.7965 - val_loss: 0.4647 - val_accuracy: 0.7907\n",
      "Epoch 93/200\n",
      "172/172 [==============================] - 0s 857us/sample - loss: 0.4732 - accuracy: 0.7849 - val_loss: 0.4627 - val_accuracy: 0.7907\n",
      "Epoch 94/200\n",
      "172/172 [==============================] - 0s 857us/sample - loss: 0.4876 - accuracy: 0.8004 - val_loss: 0.4638 - val_accuracy: 0.7984\n",
      "Epoch 95/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 0.4737 - accuracy: 0.7907 - val_loss: 0.4614 - val_accuracy: 0.7984\n",
      "Epoch 96/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.4764 - accuracy: 0.7849 - val_loss: 0.4641 - val_accuracy: 0.7907\n",
      "Epoch 97/200\n",
      "172/172 [==============================] - 0s 862us/sample - loss: 0.4695 - accuracy: 0.7946 - val_loss: 0.4638 - val_accuracy: 0.7907\n",
      "Epoch 98/200\n",
      "172/172 [==============================] - 0s 848us/sample - loss: 0.4708 - accuracy: 0.7926 - val_loss: 0.4622 - val_accuracy: 0.7907\n",
      "Epoch 99/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 0.4713 - accuracy: 0.7829 - val_loss: 0.4613 - val_accuracy: 0.7907\n",
      "Epoch 100/200\n",
      "172/172 [==============================] - 0s 854us/sample - loss: 0.4742 - accuracy: 0.8081 - val_loss: 0.4598 - val_accuracy: 0.7907\n",
      "Epoch 101/200\n",
      "172/172 [==============================] - 0s 862us/sample - loss: 0.4682 - accuracy: 0.7907 - val_loss: 0.4581 - val_accuracy: 0.7984\n",
      "Epoch 102/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.4658 - accuracy: 0.8062 - val_loss: 0.4664 - val_accuracy: 0.8062\n",
      "Epoch 103/200\n",
      "172/172 [==============================] - 0s 860us/sample - loss: 0.4662 - accuracy: 0.8023 - val_loss: 0.4575 - val_accuracy: 0.7907\n",
      "Epoch 104/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 0.4669 - accuracy: 0.8159 - val_loss: 0.4603 - val_accuracy: 0.7984\n",
      "Epoch 105/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.4692 - accuracy: 0.7849 - val_loss: 0.4553 - val_accuracy: 0.7907\n",
      "Epoch 106/200\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 0.4621 - accuracy: 0.8023 - val_loss: 0.4610 - val_accuracy: 0.8062\n",
      "Epoch 107/200\n",
      "172/172 [==============================] - 0s 858us/sample - loss: 0.4645 - accuracy: 0.7926 - val_loss: 0.4560 - val_accuracy: 0.7984\n",
      "Epoch 108/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.4612 - accuracy: 0.8004 - val_loss: 0.4584 - val_accuracy: 0.8062\n",
      "Epoch 109/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 0.4605 - accuracy: 0.8140 - val_loss: 0.4552 - val_accuracy: 0.7984\n",
      "Epoch 110/200\n",
      "172/172 [==============================] - 0s 864us/sample - loss: 0.4624 - accuracy: 0.7984 - val_loss: 0.4596 - val_accuracy: 0.8062\n",
      "Epoch 111/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 855us/sample - loss: 0.4585 - accuracy: 0.8101 - val_loss: 0.4517 - val_accuracy: 0.7907\n",
      "Epoch 112/200\n",
      "172/172 [==============================] - 0s 865us/sample - loss: 0.4617 - accuracy: 0.8081 - val_loss: 0.4525 - val_accuracy: 0.7984\n",
      "Epoch 113/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 0.4596 - accuracy: 0.8081 - val_loss: 0.4559 - val_accuracy: 0.8062\n",
      "Epoch 114/200\n",
      "172/172 [==============================] - 0s 853us/sample - loss: 0.4567 - accuracy: 0.8140 - val_loss: 0.4549 - val_accuracy: 0.8062\n",
      "Epoch 115/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.4572 - accuracy: 0.8043 - val_loss: 0.4567 - val_accuracy: 0.8062\n",
      "Epoch 116/200\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 0.4572 - accuracy: 0.8120 - val_loss: 0.4555 - val_accuracy: 0.8062\n",
      "Epoch 117/200\n",
      "172/172 [==============================] - 0s 862us/sample - loss: 0.4596 - accuracy: 0.8120 - val_loss: 0.4569 - val_accuracy: 0.8062\n",
      "Epoch 118/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 0.4554 - accuracy: 0.8140 - val_loss: 0.4496 - val_accuracy: 0.7984\n",
      "Epoch 119/200\n",
      "172/172 [==============================] - 0s 856us/sample - loss: 0.4538 - accuracy: 0.8140 - val_loss: 0.4558 - val_accuracy: 0.8062\n",
      "Epoch 120/200\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 0.4568 - accuracy: 0.8178 - val_loss: 0.4483 - val_accuracy: 0.7984\n",
      "Epoch 121/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 0.4522 - accuracy: 0.8178 - val_loss: 0.4547 - val_accuracy: 0.8062\n",
      "Epoch 122/200\n",
      "172/172 [==============================] - 0s 865us/sample - loss: 0.4626 - accuracy: 0.8101 - val_loss: 0.4466 - val_accuracy: 0.7984\n",
      "Epoch 123/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 0.4511 - accuracy: 0.8120 - val_loss: 0.4515 - val_accuracy: 0.8062\n",
      "Epoch 124/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.4525 - accuracy: 0.8178 - val_loss: 0.4522 - val_accuracy: 0.8062\n",
      "Epoch 125/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 0.4587 - accuracy: 0.8101 - val_loss: 0.4552 - val_accuracy: 0.8217\n",
      "Epoch 126/200\n",
      "172/172 [==============================] - 0s 858us/sample - loss: 0.4548 - accuracy: 0.8178 - val_loss: 0.4460 - val_accuracy: 0.8062\n",
      "Epoch 127/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.4511 - accuracy: 0.8236 - val_loss: 0.4470 - val_accuracy: 0.8062\n",
      "Epoch 128/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 0.4575 - accuracy: 0.7984 - val_loss: 0.4479 - val_accuracy: 0.8062\n",
      "Epoch 129/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 0.4490 - accuracy: 0.8198 - val_loss: 0.4466 - val_accuracy: 0.8062\n",
      "Epoch 130/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.4504 - accuracy: 0.8198 - val_loss: 0.4430 - val_accuracy: 0.8062\n",
      "Epoch 131/200\n",
      "172/172 [==============================] - 0s 854us/sample - loss: 0.4508 - accuracy: 0.8159 - val_loss: 0.4429 - val_accuracy: 0.8062\n",
      "Epoch 132/200\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 0.4502 - accuracy: 0.8159 - val_loss: 0.4433 - val_accuracy: 0.8062\n",
      "Epoch 133/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.4471 - accuracy: 0.8081 - val_loss: 0.4461 - val_accuracy: 0.8062\n",
      "Epoch 134/200\n",
      "172/172 [==============================] - 0s 882us/sample - loss: 0.4525 - accuracy: 0.8217 - val_loss: 0.4440 - val_accuracy: 0.8062\n",
      "Epoch 135/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.4455 - accuracy: 0.8236 - val_loss: 0.4456 - val_accuracy: 0.8062\n",
      "Epoch 136/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 0.4444 - accuracy: 0.8140 - val_loss: 0.4422 - val_accuracy: 0.8062\n",
      "Epoch 137/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.4459 - accuracy: 0.8178 - val_loss: 0.4455 - val_accuracy: 0.8140\n",
      "Epoch 138/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.4458 - accuracy: 0.8275 - val_loss: 0.4403 - val_accuracy: 0.8062\n",
      "Epoch 139/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.4445 - accuracy: 0.8159 - val_loss: 0.4438 - val_accuracy: 0.8062\n",
      "Epoch 140/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.4425 - accuracy: 0.8217 - val_loss: 0.4431 - val_accuracy: 0.8062\n",
      "Epoch 141/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.4425 - accuracy: 0.8198 - val_loss: 0.4399 - val_accuracy: 0.8062\n",
      "Epoch 142/200\n",
      "172/172 [==============================] - 0s 958us/sample - loss: 0.4452 - accuracy: 0.8217 - val_loss: 0.4431 - val_accuracy: 0.8140\n",
      "Epoch 143/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4496 - accuracy: 0.8140 - val_loss: 0.4454 - val_accuracy: 0.8295\n",
      "Epoch 144/200\n",
      "172/172 [==============================] - 0s 962us/sample - loss: 0.4420 - accuracy: 0.8236 - val_loss: 0.4372 - val_accuracy: 0.8062\n",
      "Epoch 145/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4494 - accuracy: 0.8101 - val_loss: 0.4434 - val_accuracy: 0.8217\n",
      "Epoch 146/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4426 - accuracy: 0.8198 - val_loss: 0.4406 - val_accuracy: 0.8062\n",
      "Epoch 147/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.4416 - accuracy: 0.8198 - val_loss: 0.4371 - val_accuracy: 0.8062\n",
      "Epoch 148/200\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 0.4451 - accuracy: 0.8198 - val_loss: 0.4371 - val_accuracy: 0.8062\n",
      "Epoch 149/200\n",
      "172/172 [==============================] - 0s 956us/sample - loss: 0.4426 - accuracy: 0.8217 - val_loss: 0.4392 - val_accuracy: 0.8062\n",
      "Epoch 150/200\n",
      "172/172 [==============================] - 0s 941us/sample - loss: 0.4388 - accuracy: 0.8198 - val_loss: 0.4382 - val_accuracy: 0.8062\n",
      "Epoch 151/200\n",
      "172/172 [==============================] - 0s 976us/sample - loss: 0.4450 - accuracy: 0.8140 - val_loss: 0.4365 - val_accuracy: 0.8062\n",
      "Epoch 152/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4385 - accuracy: 0.8217 - val_loss: 0.4430 - val_accuracy: 0.8372\n",
      "Epoch 153/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4424 - accuracy: 0.8217 - val_loss: 0.4402 - val_accuracy: 0.8217\n",
      "Epoch 154/200\n",
      "172/172 [==============================] - 0s 954us/sample - loss: 0.4416 - accuracy: 0.8217 - val_loss: 0.4392 - val_accuracy: 0.8217\n",
      "Epoch 155/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4414 - accuracy: 0.8275 - val_loss: 0.4353 - val_accuracy: 0.8062\n",
      "Epoch 156/200\n",
      "172/172 [==============================] - 0s 940us/sample - loss: 0.4384 - accuracy: 0.8159 - val_loss: 0.4379 - val_accuracy: 0.8217\n",
      "Epoch 157/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4387 - accuracy: 0.8217 - val_loss: 0.4392 - val_accuracy: 0.8295\n",
      "Epoch 158/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.4418 - accuracy: 0.8314 - val_loss: 0.4326 - val_accuracy: 0.8062\n",
      "Epoch 159/200\n",
      "172/172 [==============================] - 0s 964us/sample - loss: 0.4393 - accuracy: 0.8178 - val_loss: 0.4431 - val_accuracy: 0.8372\n",
      "Epoch 160/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4409 - accuracy: 0.8217 - val_loss: 0.4329 - val_accuracy: 0.8062\n",
      "Epoch 161/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 0.4370 - accuracy: 0.8236 - val_loss: 0.4377 - val_accuracy: 0.8372\n",
      "Epoch 162/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4366 - accuracy: 0.8372 - val_loss: 0.4313 - val_accuracy: 0.7984\n",
      "Epoch 163/200\n",
      "172/172 [==============================] - 0s 954us/sample - loss: 0.4486 - accuracy: 0.8178 - val_loss: 0.4356 - val_accuracy: 0.8140\n",
      "Epoch 164/200\n",
      "172/172 [==============================] - 0s 971us/sample - loss: 0.4399 - accuracy: 0.8140 - val_loss: 0.4421 - val_accuracy: 0.8372\n",
      "Epoch 165/200\n",
      "172/172 [==============================] - 0s 979us/sample - loss: 0.4353 - accuracy: 0.8275 - val_loss: 0.4312 - val_accuracy: 0.8062\n",
      "Epoch 166/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 985us/sample - loss: 0.4357 - accuracy: 0.8256 - val_loss: 0.4371 - val_accuracy: 0.8295\n",
      "Epoch 167/200\n",
      "172/172 [==============================] - 0s 963us/sample - loss: 0.4340 - accuracy: 0.8256 - val_loss: 0.4341 - val_accuracy: 0.8140\n",
      "Epoch 168/200\n",
      "172/172 [==============================] - 0s 930us/sample - loss: 0.4360 - accuracy: 0.8178 - val_loss: 0.4325 - val_accuracy: 0.8062\n",
      "Epoch 169/200\n",
      "172/172 [==============================] - 0s 964us/sample - loss: 0.4355 - accuracy: 0.8217 - val_loss: 0.4320 - val_accuracy: 0.8062\n",
      "Epoch 170/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.4355 - accuracy: 0.8198 - val_loss: 0.4304 - val_accuracy: 0.8062\n",
      "Epoch 171/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 0.4385 - accuracy: 0.8081 - val_loss: 0.4346 - val_accuracy: 0.8372\n",
      "Epoch 172/200\n",
      "172/172 [==============================] - 0s 975us/sample - loss: 0.4328 - accuracy: 0.8236 - val_loss: 0.4310 - val_accuracy: 0.8140\n",
      "Epoch 173/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 0.4329 - accuracy: 0.8275 - val_loss: 0.4318 - val_accuracy: 0.8140\n",
      "Epoch 174/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4311 - accuracy: 0.8198 - val_loss: 0.4346 - val_accuracy: 0.8372\n",
      "Epoch 175/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.4348 - accuracy: 0.8333 - val_loss: 0.4294 - val_accuracy: 0.8062\n",
      "Epoch 176/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 0.4330 - accuracy: 0.8236 - val_loss: 0.4307 - val_accuracy: 0.8140\n",
      "Epoch 177/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.4320 - accuracy: 0.8217 - val_loss: 0.4328 - val_accuracy: 0.8295\n",
      "Epoch 178/200\n",
      "172/172 [==============================] - 0s 954us/sample - loss: 0.4302 - accuracy: 0.8236 - val_loss: 0.4286 - val_accuracy: 0.8062\n",
      "Epoch 179/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.4320 - accuracy: 0.8256 - val_loss: 0.4328 - val_accuracy: 0.8372\n",
      "Epoch 180/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.4318 - accuracy: 0.8275 - val_loss: 0.4303 - val_accuracy: 0.8140\n",
      "Epoch 181/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.4329 - accuracy: 0.8217 - val_loss: 0.4298 - val_accuracy: 0.8140\n",
      "Epoch 182/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.4289 - accuracy: 0.8314 - val_loss: 0.4323 - val_accuracy: 0.8372\n",
      "Epoch 183/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.4306 - accuracy: 0.8295 - val_loss: 0.4289 - val_accuracy: 0.8140\n",
      "Epoch 184/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.4368 - accuracy: 0.8256 - val_loss: 0.4276 - val_accuracy: 0.8062\n",
      "Epoch 185/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.4296 - accuracy: 0.8198 - val_loss: 0.4313 - val_accuracy: 0.8372\n",
      "Epoch 186/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 0.4303 - accuracy: 0.8217 - val_loss: 0.4395 - val_accuracy: 0.8372\n",
      "Epoch 187/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 0.4335 - accuracy: 0.8411 - val_loss: 0.4302 - val_accuracy: 0.7984\n",
      "Epoch 188/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.4688 - accuracy: 0.8004 - val_loss: 0.4423 - val_accuracy: 0.8372\n",
      "Epoch 189/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.4239 - accuracy: 0.8314 - val_loss: 0.4268 - val_accuracy: 0.7907\n",
      "Epoch 190/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.4303 - accuracy: 0.8198 - val_loss: 0.4310 - val_accuracy: 0.8295\n",
      "Epoch 191/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.4300 - accuracy: 0.8217 - val_loss: 0.4304 - val_accuracy: 0.8372\n",
      "Epoch 192/200\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 0.4271 - accuracy: 0.8295 - val_loss: 0.4310 - val_accuracy: 0.8372\n",
      "Epoch 193/200\n",
      "172/172 [==============================] - 0s 882us/sample - loss: 0.4308 - accuracy: 0.8217 - val_loss: 0.4343 - val_accuracy: 0.8372\n",
      "Epoch 194/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.4416 - accuracy: 0.8217 - val_loss: 0.4275 - val_accuracy: 0.8140\n",
      "Epoch 195/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.4269 - accuracy: 0.8275 - val_loss: 0.4283 - val_accuracy: 0.8217\n",
      "Epoch 196/200\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 0.4267 - accuracy: 0.8236 - val_loss: 0.4294 - val_accuracy: 0.8372\n",
      "Epoch 197/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.4351 - accuracy: 0.8236 - val_loss: 0.4291 - val_accuracy: 0.8372\n",
      "Epoch 198/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 0.4243 - accuracy: 0.8256 - val_loss: 0.4293 - val_accuracy: 0.8372\n",
      "Epoch 199/200\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 0.4267 - accuracy: 0.8314 - val_loss: 0.4262 - val_accuracy: 0.8140\n",
      "Epoch 200/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.4253 - accuracy: 0.8275 - val_loss: 0.4275 - val_accuracy: 0.8295\n",
      "Beginning training for dr=0.001, l_lambda=1.0e-03, reg_type=l1\n",
      "Train on 172 samples, validate on 43 samples\n",
      "Epoch 1/200\n",
      "172/172 [==============================] - 1s 8ms/sample - loss: 1.3309 - accuracy: 0.6667 - val_loss: 0.9623 - val_accuracy: 0.6667\n",
      "Epoch 2/200\n",
      "172/172 [==============================] - 0s 842us/sample - loss: 0.8236 - accuracy: 0.6667 - val_loss: 0.7371 - val_accuracy: 0.6667\n",
      "Epoch 3/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.6856 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.7829\n",
      "Epoch 4/200\n",
      "172/172 [==============================] - 0s 882us/sample - loss: 0.6133 - accuracy: 0.7791 - val_loss: 0.5824 - val_accuracy: 0.7829\n",
      "Epoch 5/200\n",
      "172/172 [==============================] - 0s 864us/sample - loss: 0.5799 - accuracy: 0.7791 - val_loss: 0.5551 - val_accuracy: 0.7829\n",
      "Epoch 6/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 0.5543 - accuracy: 0.7791 - val_loss: 0.5409 - val_accuracy: 0.7829\n",
      "Epoch 7/200\n",
      "172/172 [==============================] - 0s 854us/sample - loss: 0.5421 - accuracy: 0.7791 - val_loss: 0.5302 - val_accuracy: 0.7829\n",
      "Epoch 8/200\n",
      "172/172 [==============================] - 0s 844us/sample - loss: 0.5319 - accuracy: 0.7791 - val_loss: 0.5215 - val_accuracy: 0.7829\n",
      "Epoch 9/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 0.5250 - accuracy: 0.7791 - val_loss: 0.5166 - val_accuracy: 0.7829\n",
      "Epoch 10/200\n",
      "172/172 [==============================] - 0s 848us/sample - loss: 0.5226 - accuracy: 0.7791 - val_loss: 0.5148 - val_accuracy: 0.7829\n",
      "Epoch 11/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 0.5207 - accuracy: 0.7791 - val_loss: 0.5134 - val_accuracy: 0.7829\n",
      "Epoch 12/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.5201 - accuracy: 0.7791 - val_loss: 0.5126 - val_accuracy: 0.7829\n",
      "Epoch 13/200\n",
      "172/172 [==============================] - 0s 973us/sample - loss: 0.5189 - accuracy: 0.7791 - val_loss: 0.5118 - val_accuracy: 0.7829\n",
      "Epoch 14/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.5183 - accuracy: 0.7791 - val_loss: 0.5112 - val_accuracy: 0.7829\n",
      "Epoch 15/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.5185 - accuracy: 0.7791 - val_loss: 0.5111 - val_accuracy: 0.7829\n",
      "Epoch 16/200\n",
      "172/172 [==============================] - 0s 951us/sample - loss: 0.5175 - accuracy: 0.7791 - val_loss: 0.5104 - val_accuracy: 0.7829\n",
      "Epoch 17/200\n",
      "172/172 [==============================] - 0s 966us/sample - loss: 0.5171 - accuracy: 0.7791 - val_loss: 0.5102 - val_accuracy: 0.7829\n",
      "Epoch 18/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.5172 - accuracy: 0.7791 - val_loss: 0.5096 - val_accuracy: 0.7829\n",
      "Epoch 19/200\n",
      "172/172 [==============================] - 0s 963us/sample - loss: 0.5169 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 20/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 933us/sample - loss: 0.5174 - accuracy: 0.7791 - val_loss: 0.5097 - val_accuracy: 0.7829\n",
      "Epoch 21/200\n",
      "172/172 [==============================] - 0s 999us/sample - loss: 0.5169 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 22/200\n",
      "172/172 [==============================] - 0s 967us/sample - loss: 0.5175 - accuracy: 0.7791 - val_loss: 0.5105 - val_accuracy: 0.7829\n",
      "Epoch 23/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5177 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 24/200\n",
      "172/172 [==============================] - 0s 995us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 25/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 26/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 27/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 28/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 29/200\n",
      "172/172 [==============================] - 0s 969us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 30/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5177 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 31/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 32/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 33/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5085 - val_accuracy: 0.7829\n",
      "Epoch 34/200\n",
      "172/172 [==============================] - 0s 981us/sample - loss: 0.5158 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 35/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 36/200\n",
      "172/172 [==============================] - 0s 946us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 37/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 38/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.5158 - accuracy: 0.7791 - val_loss: 0.5085 - val_accuracy: 0.7829\n",
      "Epoch 39/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5084 - val_accuracy: 0.7829\n",
      "Epoch 40/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5085 - val_accuracy: 0.7829\n",
      "Epoch 41/200\n",
      "172/172 [==============================] - 0s 964us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5084 - val_accuracy: 0.7829\n",
      "Epoch 42/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5169 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 43/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5085 - val_accuracy: 0.7829\n",
      "Epoch 44/200\n",
      "172/172 [==============================] - 0s 940us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 45/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5085 - val_accuracy: 0.7829\n",
      "Epoch 46/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 47/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 48/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5157 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 49/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5097 - val_accuracy: 0.7829\n",
      "Epoch 50/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 51/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 0.5157 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 52/200\n",
      "172/172 [==============================] - 0s 850us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 53/200\n",
      "172/172 [==============================] - 0s 856us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 54/200\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 0.5156 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 55/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 0.5174 - accuracy: 0.7791 - val_loss: 0.5098 - val_accuracy: 0.7829\n",
      "Epoch 56/200\n",
      "172/172 [==============================] - 0s 861us/sample - loss: 0.5168 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 57/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 0.5157 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 58/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 59/200\n",
      "172/172 [==============================] - 0s 941us/sample - loss: 0.5190 - accuracy: 0.7791 - val_loss: 0.5098 - val_accuracy: 0.7829\n",
      "Epoch 60/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.5170 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 61/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5097 - val_accuracy: 0.7829\n",
      "Epoch 62/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 63/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 64/200\n",
      "172/172 [==============================] - 0s 856us/sample - loss: 0.5158 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 65/200\n",
      "172/172 [==============================] - 0s 858us/sample - loss: 0.5168 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 66/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.5170 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 67/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 68/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5085 - val_accuracy: 0.7829\n",
      "Epoch 69/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 0.5158 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 70/200\n",
      "172/172 [==============================] - 0s 882us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5085 - val_accuracy: 0.7829\n",
      "Epoch 71/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 72/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 73/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.5155 - accuracy: 0.7791 - val_loss: 0.5085 - val_accuracy: 0.7829\n",
      "Epoch 74/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.5158 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 75/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 906us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 76/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 77/200\n",
      "172/172 [==============================] - 0s 882us/sample - loss: 0.5176 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 78/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.5187 - accuracy: 0.7791 - val_loss: 0.5098 - val_accuracy: 0.7829\n",
      "Epoch 79/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.5177 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 80/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 81/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 82/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 0.5157 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 83/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 84/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 0.5156 - accuracy: 0.7791 - val_loss: 0.5084 - val_accuracy: 0.7829\n",
      "Epoch 85/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 86/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 87/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5085 - val_accuracy: 0.7829\n",
      "Epoch 88/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 89/200\n",
      "172/172 [==============================] - 0s 854us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 90/200\n",
      "172/172 [==============================] - 0s 869us/sample - loss: 0.5158 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 91/200\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 92/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 93/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 94/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5084 - val_accuracy: 0.7829\n",
      "Epoch 95/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 96/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5158 - accuracy: 0.7791 - val_loss: 0.5085 - val_accuracy: 0.7829\n",
      "Epoch 97/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 98/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5085 - val_accuracy: 0.7829\n",
      "Epoch 99/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.5157 - accuracy: 0.7791 - val_loss: 0.5085 - val_accuracy: 0.7829\n",
      "Epoch 100/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.5157 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 101/200\n",
      "172/172 [==============================] - 0s 946us/sample - loss: 0.5157 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 102/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 0.5157 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 103/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 104/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5169 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 105/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.5157 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 106/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5101 - val_accuracy: 0.7829\n",
      "Epoch 107/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5098 - val_accuracy: 0.7829\n",
      "Epoch 108/200\n",
      "172/172 [==============================] - 0s 974us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 109/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 110/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.5158 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 111/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.5158 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 112/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.5157 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 113/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.5153 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 114/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.5170 - accuracy: 0.7791 - val_loss: 0.5102 - val_accuracy: 0.7829\n",
      "Epoch 115/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 116/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.5157 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 117/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 118/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.5157 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 119/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 0.5168 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 120/200\n",
      "172/172 [==============================] - 0s 856us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 121/200\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 122/200\n",
      "172/172 [==============================] - 0s 853us/sample - loss: 0.5158 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 123/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 124/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 0.5157 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 125/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 126/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 127/200\n",
      "172/172 [==============================] - 0s 857us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 128/200\n",
      "172/172 [==============================] - 0s 850us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 129/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 130/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 871us/sample - loss: 0.5157 - accuracy: 0.7791 - val_loss: 0.5083 - val_accuracy: 0.7829\n",
      "Epoch 131/200\n",
      "172/172 [==============================] - 0s 850us/sample - loss: 0.5156 - accuracy: 0.7791 - val_loss: 0.5083 - val_accuracy: 0.7829\n",
      "Epoch 132/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 0.5157 - accuracy: 0.7791 - val_loss: 0.5083 - val_accuracy: 0.7829\n",
      "Epoch 133/200\n",
      "172/172 [==============================] - 0s 859us/sample - loss: 0.5157 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 134/200\n",
      "172/172 [==============================] - 0s 857us/sample - loss: 0.5155 - accuracy: 0.7791 - val_loss: 0.5084 - val_accuracy: 0.7829\n",
      "Epoch 135/200\n",
      "172/172 [==============================] - 0s 865us/sample - loss: 0.5158 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 136/200\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 0.5157 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 137/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 138/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.5157 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 139/200\n",
      "172/172 [==============================] - 0s 862us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 140/200\n",
      "172/172 [==============================] - 0s 854us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 141/200\n",
      "172/172 [==============================] - 0s 859us/sample - loss: 0.5157 - accuracy: 0.7791 - val_loss: 0.5085 - val_accuracy: 0.7829\n",
      "Epoch 142/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5169 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 143/200\n",
      "172/172 [==============================] - 0s 854us/sample - loss: 0.5170 - accuracy: 0.7791 - val_loss: 0.5085 - val_accuracy: 0.7829\n",
      "Epoch 144/200\n",
      "172/172 [==============================] - 0s 850us/sample - loss: 0.5156 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 145/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 0.5155 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 146/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 147/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 148/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 149/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 150/200\n",
      "172/172 [==============================] - 0s 869us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 151/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.5186 - accuracy: 0.7791 - val_loss: 0.5105 - val_accuracy: 0.7829\n",
      "Epoch 152/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 153/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 154/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 155/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.5157 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 156/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.5156 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 157/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 158/200\n",
      "172/172 [==============================] - 0s 945us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 159/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.5157 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 160/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.5156 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 161/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.5156 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 162/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5173 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 163/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5168 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 164/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 0.5189 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 165/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 166/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 167/200\n",
      "172/172 [==============================] - 0s 970us/sample - loss: 0.5157 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 168/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.5169 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 169/200\n",
      "172/172 [==============================] - 0s 858us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 170/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5098 - val_accuracy: 0.7829\n",
      "Epoch 171/200\n",
      "172/172 [==============================] - 0s 860us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5096 - val_accuracy: 0.7829\n",
      "Epoch 172/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 173/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.5170 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 174/200\n",
      "172/172 [==============================] - 0s 865us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 175/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 176/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5085 - val_accuracy: 0.7829\n",
      "Epoch 177/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.5158 - accuracy: 0.7791 - val_loss: 0.5083 - val_accuracy: 0.7829\n",
      "Epoch 178/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.5158 - accuracy: 0.7791 - val_loss: 0.5082 - val_accuracy: 0.7829\n",
      "Epoch 179/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5083 - val_accuracy: 0.7829\n",
      "Epoch 180/200\n",
      "172/172 [==============================] - 0s 858us/sample - loss: 0.5158 - accuracy: 0.7791 - val_loss: 0.5084 - val_accuracy: 0.7829\n",
      "Epoch 181/200\n",
      "172/172 [==============================] - 0s 854us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 182/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.5156 - accuracy: 0.7791 - val_loss: 0.5085 - val_accuracy: 0.7829\n",
      "Epoch 183/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.5155 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 184/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 185/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 871us/sample - loss: 0.5157 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 186/200\n",
      "172/172 [==============================] - 0s 869us/sample - loss: 0.5157 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 187/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5085 - val_accuracy: 0.7829\n",
      "Epoch 188/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.5156 - accuracy: 0.7791 - val_loss: 0.5085 - val_accuracy: 0.7829\n",
      "Epoch 189/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 190/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 191/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 192/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 193/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.5155 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 194/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 195/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.5157 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 196/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.5158 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 197/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.5156 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 198/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.5155 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 199/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.5158 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 200/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Beginning training for dr=0.001, l_lambda=1.0e-02, reg_type=l2\n",
      "Train on 172 samples, validate on 43 samples\n",
      "Epoch 1/200\n",
      "172/172 [==============================] - 1s 8ms/sample - loss: 0.8743 - accuracy: 0.6667 - val_loss: 0.7534 - val_accuracy: 0.6667\n",
      "Epoch 2/200\n",
      "172/172 [==============================] - 0s 802us/sample - loss: 0.7054 - accuracy: 0.6667 - val_loss: 0.6550 - val_accuracy: 0.6667\n",
      "Epoch 3/200\n",
      "172/172 [==============================] - 0s 823us/sample - loss: 0.6274 - accuracy: 0.6938 - val_loss: 0.5868 - val_accuracy: 0.7829\n",
      "Epoch 4/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5724 - accuracy: 0.7791 - val_loss: 0.5502 - val_accuracy: 0.7829\n",
      "Epoch 5/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.5474 - accuracy: 0.7791 - val_loss: 0.5333 - val_accuracy: 0.7829\n",
      "Epoch 6/200\n",
      "172/172 [==============================] - 0s 833us/sample - loss: 0.5349 - accuracy: 0.7791 - val_loss: 0.5226 - val_accuracy: 0.7829\n",
      "Epoch 7/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 0.5261 - accuracy: 0.7791 - val_loss: 0.5160 - val_accuracy: 0.7829\n",
      "Epoch 8/200\n",
      "172/172 [==============================] - 0s 837us/sample - loss: 0.5201 - accuracy: 0.7791 - val_loss: 0.5112 - val_accuracy: 0.7829\n",
      "Epoch 9/200\n",
      "172/172 [==============================] - 0s 834us/sample - loss: 0.5171 - accuracy: 0.7791 - val_loss: 0.5083 - val_accuracy: 0.7829\n",
      "Epoch 10/200\n",
      "172/172 [==============================] - 0s 843us/sample - loss: 0.5134 - accuracy: 0.7791 - val_loss: 0.5058 - val_accuracy: 0.7829\n",
      "Epoch 11/200\n",
      "172/172 [==============================] - 0s 842us/sample - loss: 0.5113 - accuracy: 0.7791 - val_loss: 0.5047 - val_accuracy: 0.7829\n",
      "Epoch 12/200\n",
      "172/172 [==============================] - 0s 823us/sample - loss: 0.5106 - accuracy: 0.7791 - val_loss: 0.5033 - val_accuracy: 0.7829\n",
      "Epoch 13/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.5105 - accuracy: 0.7791 - val_loss: 0.5030 - val_accuracy: 0.7829\n",
      "Epoch 14/200\n",
      "172/172 [==============================] - 0s 840us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 15/200\n",
      "172/172 [==============================] - 0s 843us/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 16/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 17/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 18/200\n",
      "172/172 [==============================] - 0s 837us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 19/200\n",
      "172/172 [==============================] - 0s 839us/sample - loss: 0.5109 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 20/200\n",
      "172/172 [==============================] - 0s 840us/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 21/200\n",
      "172/172 [==============================] - 0s 854us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 22/200\n",
      "172/172 [==============================] - 0s 829us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 23/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 24/200\n",
      "172/172 [==============================] - 0s 835us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 25/200\n",
      "172/172 [==============================] - 0s 853us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 26/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 27/200\n",
      "172/172 [==============================] - 0s 999us/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 28/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 29/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 30/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 31/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 32/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 33/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 34/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5033 - val_accuracy: 0.7829\n",
      "Epoch 35/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5026 - val_accuracy: 0.7829\n",
      "Epoch 36/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 37/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 38/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 39/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 41/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 42/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 43/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 44/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 45/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 46/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 47/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 48/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 49/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 50/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.5102 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 51/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 52/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 53/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 54/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 55/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 56/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 57/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 58/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 59/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 60/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 61/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 62/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 63/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 64/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 65/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 66/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 67/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 68/200\n",
      "172/172 [==============================] - 0s 854us/sample - loss: 0.5086 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 69/200\n",
      "172/172 [==============================] - 0s 857us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 70/200\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 71/200\n",
      "172/172 [==============================] - 0s 857us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 72/200\n",
      "172/172 [==============================] - 0s 854us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5028 - val_accuracy: 0.7829\n",
      "Epoch 73/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.5110 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 74/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 75/200\n",
      "172/172 [==============================] - 0s 845us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5029 - val_accuracy: 0.7829\n",
      "Epoch 76/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 77/200\n",
      "172/172 [==============================] - 0s 857us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 78/200\n",
      "172/172 [==============================] - 0s 858us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 79/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 80/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 81/200\n",
      "172/172 [==============================] - 0s 860us/sample - loss: 0.5086 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 82/200\n",
      "172/172 [==============================] - 0s 994us/sample - loss: 0.5102 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 83/200\n",
      "172/172 [==============================] - 0s 949us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 84/200\n",
      "172/172 [==============================] - 0s 978us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 85/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5083 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 86/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 87/200\n",
      "172/172 [==============================] - 0s 928us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 88/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 89/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 90/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 91/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 92/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 93/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 94/200\n",
      "172/172 [==============================] - 0s 955us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 95/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 927us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 96/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 97/200\n",
      "172/172 [==============================] - 0s 944us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 98/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 99/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 100/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 101/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 102/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5030 - val_accuracy: 0.7829\n",
      "Epoch 103/200\n",
      "172/172 [==============================] - 0s 984us/sample - loss: 0.5108 - accuracy: 0.7791 - val_loss: 0.5035 - val_accuracy: 0.7829\n",
      "Epoch 104/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.5110 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 105/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 106/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 107/200\n",
      "172/172 [==============================] - 0s 995us/sample - loss: 0.5084 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 108/200\n",
      "172/172 [==============================] - 0s 942us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 109/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 110/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 111/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 112/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 113/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 114/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 115/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 116/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 117/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 118/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 119/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 120/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 121/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 122/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 123/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 124/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 125/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 126/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.5086 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 127/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 128/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 129/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 130/200\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 131/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 132/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 133/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 134/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 135/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 136/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 137/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 138/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.5086 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 139/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 140/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 141/200\n",
      "172/172 [==============================] - 0s 942us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 142/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 143/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 144/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 145/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 146/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 147/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5028 - val_accuracy: 0.7829\n",
      "Epoch 148/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 149/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 150/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 904us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 151/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 152/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 153/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 154/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 155/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 0.5083 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 156/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 157/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 158/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 159/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 160/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 161/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 162/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 163/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 164/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 165/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 166/200\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 167/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 168/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 169/200\n",
      "172/172 [==============================] - 0s 869us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 170/200\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 171/200\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 172/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5030 - val_accuracy: 0.7829\n",
      "Epoch 173/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5031 - val_accuracy: 0.7829\n",
      "Epoch 174/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 175/200\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 176/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 177/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 0.5105 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 178/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 179/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 180/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 181/200\n",
      "172/172 [==============================] - 0s 944us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 182/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 183/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 184/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 185/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 186/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 187/200\n",
      "172/172 [==============================] - 0s 937us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 188/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5026 - val_accuracy: 0.7829\n",
      "Epoch 189/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5028 - val_accuracy: 0.7829\n",
      "Epoch 190/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5029 - val_accuracy: 0.7829\n",
      "Epoch 191/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 192/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 193/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 194/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 195/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 196/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 197/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 198/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 199/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 200/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Beginning training for dr=0.001, l_lambda=1.0e-02, reg_type=l1\n",
      "Train on 172 samples, validate on 43 samples\n",
      "Epoch 1/200\n",
      "172/172 [==============================] - 1s 8ms/sample - loss: 7.6691 - accuracy: 0.6667 - val_loss: 4.1303 - val_accuracy: 0.6667\n",
      "Epoch 2/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 2.8637 - accuracy: 0.6667 - val_loss: 2.1759 - val_accuracy: 0.6667\n",
      "Epoch 3/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 1.8075 - accuracy: 0.6705 - val_loss: 1.4845 - val_accuracy: 0.7829\n",
      "Epoch 4/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 904us/sample - loss: 1.3282 - accuracy: 0.7791 - val_loss: 1.1598 - val_accuracy: 0.7829\n",
      "Epoch 5/200\n",
      "172/172 [==============================] - 0s 865us/sample - loss: 1.0644 - accuracy: 0.7791 - val_loss: 0.9478 - val_accuracy: 0.7829\n",
      "Epoch 6/200\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 0.8783 - accuracy: 0.7791 - val_loss: 0.7928 - val_accuracy: 0.7829\n",
      "Epoch 7/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.7462 - accuracy: 0.7791 - val_loss: 0.6862 - val_accuracy: 0.7829\n",
      "Epoch 8/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.6567 - accuracy: 0.7791 - val_loss: 0.6152 - val_accuracy: 0.7829\n",
      "Epoch 9/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.6041 - accuracy: 0.7791 - val_loss: 0.5836 - val_accuracy: 0.7829\n",
      "Epoch 10/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.5869 - accuracy: 0.7791 - val_loss: 0.5781 - val_accuracy: 0.7829\n",
      "Epoch 11/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.5840 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 12/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 0.5838 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 13/200\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5779 - val_accuracy: 0.7829\n",
      "Epoch 14/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 0.5833 - accuracy: 0.7791 - val_loss: 0.5772 - val_accuracy: 0.7829\n",
      "Epoch 15/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5772 - val_accuracy: 0.7829\n",
      "Epoch 16/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5833 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 17/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 18/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 19/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 20/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 21/200\n",
      "172/172 [==============================] - 0s 882us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 22/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 23/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5770 - val_accuracy: 0.7829\n",
      "Epoch 24/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.5838 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 25/200\n",
      "172/172 [==============================] - 0s 958us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5772 - val_accuracy: 0.7829\n",
      "Epoch 26/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5835 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 27/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 28/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 29/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5768 - val_accuracy: 0.7829\n",
      "Epoch 30/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 31/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.5834 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 32/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5751 - val_accuracy: 0.7829\n",
      "Epoch 33/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 34/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 35/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5776 - val_accuracy: 0.7829\n",
      "Epoch 36/200\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 37/200\n",
      "172/172 [==============================] - 0s 958us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 38/200\n",
      "172/172 [==============================] - 0s 988us/sample - loss: 0.5832 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 39/200\n",
      "172/172 [==============================] - 0s 946us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 40/200\n",
      "172/172 [==============================] - 0s 946us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 41/200\n",
      "172/172 [==============================] - 0s 942us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 42/200\n",
      "172/172 [==============================] - 0s 945us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 43/200\n",
      "172/172 [==============================] - 0s 941us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5767 - val_accuracy: 0.7829\n",
      "Epoch 44/200\n",
      "172/172 [==============================] - 0s 965us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 45/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.5835 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 46/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 47/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 48/200\n",
      "172/172 [==============================] - 0s 930us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 49/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.5819 - accuracy: 0.7791 - val_loss: 0.5768 - val_accuracy: 0.7829\n",
      "Epoch 50/200\n",
      "172/172 [==============================] - 0s 976us/sample - loss: 0.5834 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 51/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.5836 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 52/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5752 - val_accuracy: 0.7829\n",
      "Epoch 53/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5768 - val_accuracy: 0.7829\n",
      "Epoch 54/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5832 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 55/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 56/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.5874 - accuracy: 0.7791 - val_loss: 0.5775 - val_accuracy: 0.7829\n",
      "Epoch 57/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 58/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 943us/sample - loss: 0.5832 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 60/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 61/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 0.5842 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 62/200\n",
      "172/172 [==============================] - 0s 952us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5749 - val_accuracy: 0.7829\n",
      "Epoch 63/200\n",
      "172/172 [==============================] - 0s 937us/sample - loss: 0.5832 - accuracy: 0.7791 - val_loss: 0.5775 - val_accuracy: 0.7829\n",
      "Epoch 64/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.5835 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 65/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5767 - val_accuracy: 0.7829\n",
      "Epoch 66/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5751 - val_accuracy: 0.7829\n",
      "Epoch 67/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 0.5836 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 68/200\n",
      "172/172 [==============================] - 0s 949us/sample - loss: 0.5839 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 69/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 70/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 71/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 72/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 73/200\n",
      "172/172 [==============================] - 0s 943us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 74/200\n",
      "172/172 [==============================] - 0s 949us/sample - loss: 0.5835 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 75/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 76/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5832 - accuracy: 0.7791 - val_loss: 0.5748 - val_accuracy: 0.7829\n",
      "Epoch 77/200\n",
      "172/172 [==============================] - 0s 983us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 78/200\n",
      "172/172 [==============================] - 0s 967us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 79/200\n",
      "172/172 [==============================] - 0s 943us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 80/200\n",
      "172/172 [==============================] - 0s 937us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5750 - val_accuracy: 0.7829\n",
      "Epoch 81/200\n",
      "172/172 [==============================] - 0s 968us/sample - loss: 0.5834 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 82/200\n",
      "172/172 [==============================] - 0s 983us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5751 - val_accuracy: 0.7829\n",
      "Epoch 83/200\n",
      "172/172 [==============================] - 0s 969us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5767 - val_accuracy: 0.7829\n",
      "Epoch 84/200\n",
      "172/172 [==============================] - 0s 970us/sample - loss: 0.5833 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 85/200\n",
      "172/172 [==============================] - 0s 966us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 86/200\n",
      "172/172 [==============================] - 0s 959us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 87/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 88/200\n",
      "172/172 [==============================] - 0s 984us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 89/200\n",
      "172/172 [==============================] - 0s 963us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5752 - val_accuracy: 0.7829\n",
      "Epoch 90/200\n",
      "172/172 [==============================] - 0s 983us/sample - loss: 0.5835 - accuracy: 0.7791 - val_loss: 0.5752 - val_accuracy: 0.7829\n",
      "Epoch 91/200\n",
      "172/172 [==============================] - 0s 959us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5769 - val_accuracy: 0.7829\n",
      "Epoch 92/200\n",
      "172/172 [==============================] - 0s 971us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 93/200\n",
      "172/172 [==============================] - 0s 980us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5769 - val_accuracy: 0.7829\n",
      "Epoch 94/200\n",
      "172/172 [==============================] - 0s 970us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 95/200\n",
      "172/172 [==============================] - 0s 967us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5773 - val_accuracy: 0.7829\n",
      "Epoch 96/200\n",
      "172/172 [==============================] - 0s 998us/sample - loss: 0.5834 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 97/200\n",
      "172/172 [==============================] - 0s 968us/sample - loss: 0.5818 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 98/200\n",
      "172/172 [==============================] - 0s 972us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 99/200\n",
      "172/172 [==============================] - 0s 989us/sample - loss: 0.5850 - accuracy: 0.7791 - val_loss: 0.5770 - val_accuracy: 0.7829\n",
      "Epoch 100/200\n",
      "172/172 [==============================] - 0s 998us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 101/200\n",
      "172/172 [==============================] - 0s 974us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 102/200\n",
      "172/172 [==============================] - 0s 966us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 103/200\n",
      "172/172 [==============================] - 0s 965us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 104/200\n",
      "172/172 [==============================] - 0s 967us/sample - loss: 0.5842 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 105/200\n",
      "172/172 [==============================] - 0s 974us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5779 - val_accuracy: 0.7829\n",
      "Epoch 106/200\n",
      "172/172 [==============================] - 0s 981us/sample - loss: 0.5842 - accuracy: 0.7791 - val_loss: 0.5751 - val_accuracy: 0.7829\n",
      "Epoch 107/200\n",
      "172/172 [==============================] - 0s 974us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 108/200\n",
      "172/172 [==============================] - 0s 981us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 109/200\n",
      "172/172 [==============================] - 0s 969us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 110/200\n",
      "172/172 [==============================] - 0s 977us/sample - loss: 0.5835 - accuracy: 0.7791 - val_loss: 0.5750 - val_accuracy: 0.7829\n",
      "Epoch 111/200\n",
      "172/172 [==============================] - 0s 992us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 112/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 113/200\n",
      "172/172 [==============================] - 0s 968us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5767 - val_accuracy: 0.7829\n",
      "Epoch 114/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 974us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 115/200\n",
      "172/172 [==============================] - 0s 979us/sample - loss: 0.5836 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 116/200\n",
      "172/172 [==============================] - 0s 970us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 117/200\n",
      "172/172 [==============================] - 0s 964us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 118/200\n",
      "172/172 [==============================] - 0s 981us/sample - loss: 0.5839 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 119/200\n",
      "172/172 [==============================] - 0s 963us/sample - loss: 0.5837 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 120/200\n",
      "172/172 [==============================] - 0s 962us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5752 - val_accuracy: 0.7829\n",
      "Epoch 121/200\n",
      "172/172 [==============================] - 0s 987us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 122/200\n",
      "172/172 [==============================] - 0s 967us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5751 - val_accuracy: 0.7829\n",
      "Epoch 123/200\n",
      "172/172 [==============================] - 0s 966us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 124/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5832 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 125/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5819 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 126/200\n",
      "172/172 [==============================] - 0s 969us/sample - loss: 0.5834 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 127/200\n",
      "172/172 [==============================] - 0s 979us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5768 - val_accuracy: 0.7829\n",
      "Epoch 128/200\n",
      "172/172 [==============================] - 0s 982us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 129/200\n",
      "172/172 [==============================] - 0s 971us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 130/200\n",
      "172/172 [==============================] - 0s 972us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 131/200\n",
      "172/172 [==============================] - 0s 974us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 132/200\n",
      "172/172 [==============================] - 0s 978us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5747 - val_accuracy: 0.7829\n",
      "Epoch 133/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5775 - val_accuracy: 0.7829\n",
      "Epoch 134/200\n",
      "172/172 [==============================] - 0s 963us/sample - loss: 0.5834 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 135/200\n",
      "172/172 [==============================] - 0s 956us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5771 - val_accuracy: 0.7829\n",
      "Epoch 136/200\n",
      "172/172 [==============================] - 0s 959us/sample - loss: 0.5832 - accuracy: 0.7791 - val_loss: 0.5751 - val_accuracy: 0.7829\n",
      "Epoch 137/200\n",
      "172/172 [==============================] - 0s 993us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 138/200\n",
      "172/172 [==============================] - 0s 941us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 139/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 140/200\n",
      "172/172 [==============================] - 0s 963us/sample - loss: 0.5835 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 141/200\n",
      "172/172 [==============================] - 0s 943us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 142/200\n",
      "172/172 [==============================] - 0s 942us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 143/200\n",
      "172/172 [==============================] - 0s 954us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 144/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 0.5834 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 145/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.5834 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 146/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 147/200\n",
      "172/172 [==============================] - 0s 989us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5771 - val_accuracy: 0.7829\n",
      "Epoch 148/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.5834 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 149/200\n",
      "172/172 [==============================] - 0s 963us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 150/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 151/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 152/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 153/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 0.5817 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 154/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 155/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5767 - val_accuracy: 0.7829\n",
      "Epoch 156/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 157/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 158/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 159/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 160/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5750 - val_accuracy: 0.7829\n",
      "Epoch 161/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5768 - val_accuracy: 0.7829\n",
      "Epoch 162/200\n",
      "172/172 [==============================] - 0s 956us/sample - loss: 0.5835 - accuracy: 0.7791 - val_loss: 0.5751 - val_accuracy: 0.7829\n",
      "Epoch 163/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.5839 - accuracy: 0.7791 - val_loss: 0.5771 - val_accuracy: 0.7829\n",
      "Epoch 164/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5751 - val_accuracy: 0.7829\n",
      "Epoch 165/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 166/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 167/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 168/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 169/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 899us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 170/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.5820 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 171/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.5852 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 172/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.5832 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 173/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 174/200\n",
      "172/172 [==============================] - 0s 943us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5751 - val_accuracy: 0.7829\n",
      "Epoch 175/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5774 - val_accuracy: 0.7829\n",
      "Epoch 176/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.5836 - accuracy: 0.7791 - val_loss: 0.5751 - val_accuracy: 0.7829\n",
      "Epoch 177/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.5818 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 178/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 179/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 180/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.5832 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 181/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 182/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 183/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5772 - val_accuracy: 0.7829\n",
      "Epoch 184/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 185/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 186/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 187/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.5833 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 188/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 189/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5769 - val_accuracy: 0.7829\n",
      "Epoch 190/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 191/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 192/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 193/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5769 - val_accuracy: 0.7829\n",
      "Epoch 194/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 195/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5767 - val_accuracy: 0.7829\n",
      "Epoch 196/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 0.5842 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 197/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 198/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.5834 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 199/200\n",
      "172/172 [==============================] - 0s 940us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 200/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 0.5835 - accuracy: 0.7791 - val_loss: 0.5769 - val_accuracy: 0.7829\n",
      "Beginning training for dr=0.001, l_lambda=1.0e-01, reg_type=l2\n",
      "Train on 172 samples, validate on 43 samples\n",
      "Epoch 1/200\n",
      "172/172 [==============================] - 1s 9ms/sample - loss: 3.2737 - accuracy: 0.6667 - val_loss: 2.2254 - val_accuracy: 0.6667\n",
      "Epoch 2/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 1.8684 - accuracy: 0.6667 - val_loss: 1.5635 - val_accuracy: 0.6667\n",
      "Epoch 3/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 1.3996 - accuracy: 0.6705 - val_loss: 1.2221 - val_accuracy: 0.7829\n",
      "Epoch 4/200\n",
      "172/172 [==============================] - 0s 944us/sample - loss: 1.1046 - accuracy: 0.7791 - val_loss: 0.9792 - val_accuracy: 0.7829\n",
      "Epoch 5/200\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 0.9037 - accuracy: 0.7791 - val_loss: 0.8190 - val_accuracy: 0.7829\n",
      "Epoch 6/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.7732 - accuracy: 0.7791 - val_loss: 0.7122 - val_accuracy: 0.7829\n",
      "Epoch 7/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 0.6830 - accuracy: 0.7791 - val_loss: 0.6397 - val_accuracy: 0.7829\n",
      "Epoch 8/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.6219 - accuracy: 0.7791 - val_loss: 0.5910 - val_accuracy: 0.7829\n",
      "Epoch 9/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5584 - val_accuracy: 0.7829\n",
      "Epoch 10/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5544 - accuracy: 0.7791 - val_loss: 0.5368 - val_accuracy: 0.7829\n",
      "Epoch 11/200\n",
      "172/172 [==============================] - 0s 991us/sample - loss: 0.5375 - accuracy: 0.7791 - val_loss: 0.5233 - val_accuracy: 0.7829\n",
      "Epoch 12/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.5274 - accuracy: 0.7791 - val_loss: 0.5158 - val_accuracy: 0.7829\n",
      "Epoch 13/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.5195 - accuracy: 0.7791 - val_loss: 0.5096 - val_accuracy: 0.7829\n",
      "Epoch 14/200\n",
      "172/172 [==============================] - 0s 942us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5068 - val_accuracy: 0.7829\n",
      "Epoch 15/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5120 - accuracy: 0.7791 - val_loss: 0.5047 - val_accuracy: 0.7829\n",
      "Epoch 16/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 0.5136 - accuracy: 0.7791 - val_loss: 0.5038 - val_accuracy: 0.7829\n",
      "Epoch 17/200\n",
      "172/172 [==============================] - 0s 943us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5028 - val_accuracy: 0.7829\n",
      "Epoch 18/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 19/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5030 - val_accuracy: 0.7829\n",
      "Epoch 20/200\n",
      "172/172 [==============================] - 0s 942us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5028 - val_accuracy: 0.7829\n",
      "Epoch 21/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 22/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 23/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 980us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 24/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 25/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 26/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 27/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 28/200\n",
      "172/172 [==============================] - 0s 956us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 29/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 30/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 31/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.5086 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 32/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 33/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 34/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 35/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 36/200\n",
      "172/172 [==============================] - 0s 964us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 37/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 38/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 39/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 40/200\n",
      "172/172 [==============================] - 0s 948us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 41/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 42/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 43/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 44/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 45/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 46/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 47/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 48/200\n",
      "172/172 [==============================] - 0s 984us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 49/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 50/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 51/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 52/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 53/200\n",
      "172/172 [==============================] - 0s 953us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 54/200\n",
      "172/172 [==============================] - 0s 943us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 55/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 56/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 57/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 58/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 59/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 60/200\n",
      "172/172 [==============================] - 0s 986us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 61/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 62/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 63/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 64/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 65/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 66/200\n",
      "172/172 [==============================] - 0s 956us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 67/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 68/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 69/200\n",
      "172/172 [==============================] - 0s 928us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 70/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 71/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 72/200\n",
      "172/172 [==============================] - 0s 972us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5026 - val_accuracy: 0.7829\n",
      "Epoch 73/200\n",
      "172/172 [==============================] - 0s 944us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 74/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 75/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 76/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 77/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 78/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 968us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 79/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 80/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 81/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 82/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 83/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 0.5105 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 84/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 85/200\n",
      "172/172 [==============================] - 0s 986us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 86/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 87/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 88/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 89/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 90/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 91/200\n",
      "172/172 [==============================] - 0s 968us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 92/200\n",
      "172/172 [==============================] - 0s 942us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 93/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 94/200\n",
      "172/172 [==============================] - 0s 941us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 95/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 96/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 97/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 98/200\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 99/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5032 - val_accuracy: 0.7829\n",
      "Epoch 100/200\n",
      "172/172 [==============================] - 0s 952us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5030 - val_accuracy: 0.7829\n",
      "Epoch 101/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 102/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 103/200\n",
      "172/172 [==============================] - 0s 981us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 104/200\n",
      "172/172 [==============================] - 0s 944us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 105/200\n",
      "172/172 [==============================] - 0s 940us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 106/200\n",
      "172/172 [==============================] - 0s 964us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 107/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 108/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 109/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 110/200\n",
      "172/172 [==============================] - 0s 970us/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 111/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 112/200\n",
      "172/172 [==============================] - 0s 944us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 113/200\n",
      "172/172 [==============================] - 0s 966us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 114/200\n",
      "172/172 [==============================] - 0s 973us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 115/200\n",
      "172/172 [==============================] - 0s 992us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 116/200\n",
      "172/172 [==============================] - 0s 975us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 117/200\n",
      "172/172 [==============================] - 0s 956us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 118/200\n",
      "172/172 [==============================] - 0s 988us/sample - loss: 0.5113 - accuracy: 0.7791 - val_loss: 0.5029 - val_accuracy: 0.7829\n",
      "Epoch 119/200\n",
      "172/172 [==============================] - 0s 963us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 120/200\n",
      "172/172 [==============================] - 0s 963us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 121/200\n",
      "172/172 [==============================] - 0s 970us/sample - loss: 0.5085 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 122/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 123/200\n",
      "172/172 [==============================] - 0s 962us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 124/200\n",
      "172/172 [==============================] - 0s 978us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 125/200\n",
      "172/172 [==============================] - 0s 963us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 126/200\n",
      "172/172 [==============================] - 0s 967us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 127/200\n",
      "172/172 [==============================] - 0s 978us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 128/200\n",
      "172/172 [==============================] - 0s 986us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 129/200\n",
      "172/172 [==============================] - 0s 975us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 130/200\n",
      "172/172 [==============================] - 0s 972us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 131/200\n",
      "172/172 [==============================] - 0s 976us/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 132/200\n",
      "172/172 [==============================] - 0s 976us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 133/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 969us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 134/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 135/200\n",
      "172/172 [==============================] - 0s 961us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 136/200\n",
      "172/172 [==============================] - 0s 953us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 137/200\n",
      "172/172 [==============================] - 0s 975us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 138/200\n",
      "172/172 [==============================] - 0s 961us/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 139/200\n",
      "172/172 [==============================] - 0s 958us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 140/200\n",
      "172/172 [==============================] - 0s 977us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 141/200\n",
      "172/172 [==============================] - 0s 952us/sample - loss: 0.5108 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 142/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 143/200\n",
      "172/172 [==============================] - 0s 970us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 144/200\n",
      "172/172 [==============================] - 0s 941us/sample - loss: 0.5084 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 145/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.5106 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 146/200\n",
      "172/172 [==============================] - 0s 980us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5028 - val_accuracy: 0.7829\n",
      "Epoch 147/200\n",
      "172/172 [==============================] - 0s 964us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 148/200\n",
      "172/172 [==============================] - 0s 941us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 149/200\n",
      "172/172 [==============================] - 0s 941us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 150/200\n",
      "172/172 [==============================] - 0s 986us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 151/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 152/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 153/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 154/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.5086 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 155/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 0.5086 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 156/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 0.5110 - accuracy: 0.7791 - val_loss: 0.5028 - val_accuracy: 0.7829\n",
      "Epoch 157/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 158/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 159/200\n",
      "172/172 [==============================] - 0s 937us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 160/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 161/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 162/200\n",
      "172/172 [==============================] - 0s 955us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 163/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 164/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 165/200\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 166/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 167/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 168/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 169/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 170/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 171/200\n",
      "172/172 [==============================] - 0s 947us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 172/200\n",
      "172/172 [==============================] - 0s 952us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 173/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 174/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 175/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 176/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 177/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 178/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 179/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.5086 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 180/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5029 - val_accuracy: 0.7829\n",
      "Epoch 181/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 182/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 183/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 184/200\n",
      "172/172 [==============================] - 0s 940us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 185/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 186/200\n",
      "172/172 [==============================] - 0s 961us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 187/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 0.5084 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 188/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 911us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 189/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 190/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 191/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.5086 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 192/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 193/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 194/200\n",
      "172/172 [==============================] - 0s 943us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 195/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 196/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 0.5085 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 197/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 198/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 199/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 200/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Beginning training for dr=0.001, l_lambda=1.0e-01, reg_type=l1\n",
      "Train on 172 samples, validate on 43 samples\n",
      "Epoch 1/200\n",
      "172/172 [==============================] - 2s 9ms/sample - loss: 71.3987 - accuracy: 0.6667 - val_loss: 35.9936 - val_accuracy: 0.6667\n",
      "Epoch 2/200\n",
      "172/172 [==============================] - 0s 860us/sample - loss: 23.4522 - accuracy: 0.6667 - val_loss: 16.7858 - val_accuracy: 0.6667\n",
      "Epoch 3/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 13.2069 - accuracy: 0.7132 - val_loss: 10.1956 - val_accuracy: 0.7829\n",
      "Epoch 4/200\n",
      "172/172 [==============================] - 0s 865us/sample - loss: 8.6766 - accuracy: 0.7791 - val_loss: 7.1458 - val_accuracy: 0.7829\n",
      "Epoch 5/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 6.1923 - accuracy: 0.7791 - val_loss: 5.1519 - val_accuracy: 0.7829\n",
      "Epoch 6/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 4.4225 - accuracy: 0.7791 - val_loss: 3.6018 - val_accuracy: 0.7829\n",
      "Epoch 7/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 3.0620 - accuracy: 0.7791 - val_loss: 2.4859 - val_accuracy: 0.7829\n",
      "Epoch 8/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 2.0891 - accuracy: 0.7791 - val_loss: 1.6924 - val_accuracy: 0.7829\n",
      "Epoch 9/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 1.4981 - accuracy: 0.7791 - val_loss: 1.3317 - val_accuracy: 0.7829\n",
      "Epoch 10/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 1.2960 - accuracy: 0.7791 - val_loss: 1.2606 - val_accuracy: 0.7829\n",
      "Epoch 11/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 1.2587 - accuracy: 0.7791 - val_loss: 1.2493 - val_accuracy: 0.7829\n",
      "Epoch 12/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 1.2514 - accuracy: 0.7791 - val_loss: 1.2404 - val_accuracy: 0.7829\n",
      "Epoch 13/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 1.2430 - accuracy: 0.7791 - val_loss: 1.2448 - val_accuracy: 0.7829\n",
      "Epoch 14/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 1.2445 - accuracy: 0.7791 - val_loss: 1.2510 - val_accuracy: 0.7829\n",
      "Epoch 15/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 1.2460 - accuracy: 0.7791 - val_loss: 1.2508 - val_accuracy: 0.7829\n",
      "Epoch 16/200\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 1.2446 - accuracy: 0.7791 - val_loss: 1.2433 - val_accuracy: 0.7829\n",
      "Epoch 17/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 1.2472 - accuracy: 0.7791 - val_loss: 1.2379 - val_accuracy: 0.7829\n",
      "Epoch 18/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 1.2426 - accuracy: 0.7791 - val_loss: 1.2464 - val_accuracy: 0.7829\n",
      "Epoch 19/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 1.2455 - accuracy: 0.7791 - val_loss: 1.2443 - val_accuracy: 0.7829\n",
      "Epoch 20/200\n",
      "172/172 [==============================] - 0s 869us/sample - loss: 1.2454 - accuracy: 0.7791 - val_loss: 1.2354 - val_accuracy: 0.7829\n",
      "Epoch 21/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 1.2438 - accuracy: 0.7791 - val_loss: 1.2526 - val_accuracy: 0.7829\n",
      "Epoch 22/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 1.2453 - accuracy: 0.7791 - val_loss: 1.2396 - val_accuracy: 0.7829\n",
      "Epoch 23/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 1.2437 - accuracy: 0.7791 - val_loss: 1.2489 - val_accuracy: 0.7829\n",
      "Epoch 24/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 1.2463 - accuracy: 0.7791 - val_loss: 1.2434 - val_accuracy: 0.7829\n",
      "Epoch 25/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 1.2397 - accuracy: 0.7791 - val_loss: 1.2486 - val_accuracy: 0.7829\n",
      "Epoch 26/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 1.2484 - accuracy: 0.7791 - val_loss: 1.2407 - val_accuracy: 0.7829\n",
      "Epoch 27/200\n",
      "172/172 [==============================] - 0s 974us/sample - loss: 1.2424 - accuracy: 0.7791 - val_loss: 1.2417 - val_accuracy: 0.7829\n",
      "Epoch 28/200\n",
      "172/172 [==============================] - 0s 984us/sample - loss: 1.2465 - accuracy: 0.7791 - val_loss: 1.2404 - val_accuracy: 0.7829\n",
      "Epoch 29/200\n",
      "172/172 [==============================] - 0s 947us/sample - loss: 1.2443 - accuracy: 0.7791 - val_loss: 1.2465 - val_accuracy: 0.7829\n",
      "Epoch 30/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 1.2411 - accuracy: 0.7791 - val_loss: 1.2457 - val_accuracy: 0.7829\n",
      "Epoch 31/200\n",
      "172/172 [==============================] - 0s 999us/sample - loss: 1.2486 - accuracy: 0.7791 - val_loss: 1.2391 - val_accuracy: 0.7829\n",
      "Epoch 32/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 1.2456 - accuracy: 0.7791 - val_loss: 1.2388 - val_accuracy: 0.7829\n",
      "Epoch 33/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 1.2418 - accuracy: 0.7791 - val_loss: 1.2447 - val_accuracy: 0.7829\n",
      "Epoch 34/200\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 1.2476 - accuracy: 0.7791 - val_loss: 1.2418 - val_accuracy: 0.7829\n",
      "Epoch 35/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 1.2411 - accuracy: 0.7791 - val_loss: 1.2599 - val_accuracy: 0.7829\n",
      "Epoch 36/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 1.2474 - accuracy: 0.7791 - val_loss: 1.2405 - val_accuracy: 0.7829\n",
      "Epoch 37/200\n",
      "172/172 [==============================] - 0s 930us/sample - loss: 1.2458 - accuracy: 0.7791 - val_loss: 1.2472 - val_accuracy: 0.7829\n",
      "Epoch 38/200\n",
      "172/172 [==============================] - 0s 930us/sample - loss: 1.2451 - accuracy: 0.7791 - val_loss: 1.2383 - val_accuracy: 0.7829\n",
      "Epoch 39/200\n",
      "172/172 [==============================] - 0s 949us/sample - loss: 1.2442 - accuracy: 0.7791 - val_loss: 1.2492 - val_accuracy: 0.7829\n",
      "Epoch 40/200\n",
      "172/172 [==============================] - 0s 968us/sample - loss: 1.2465 - accuracy: 0.7791 - val_loss: 1.2394 - val_accuracy: 0.7829\n",
      "Epoch 41/200\n",
      "172/172 [==============================] - 0s 953us/sample - loss: 1.2434 - accuracy: 0.7791 - val_loss: 1.2396 - val_accuracy: 0.7829\n",
      "Epoch 42/200\n",
      "172/172 [==============================] - 0s 951us/sample - loss: 1.2451 - accuracy: 0.7791 - val_loss: 1.2420 - val_accuracy: 0.7829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/200\n",
      "172/172 [==============================] - 0s 988us/sample - loss: 1.2446 - accuracy: 0.7791 - val_loss: 1.2465 - val_accuracy: 0.7829\n",
      "Epoch 44/200\n",
      "172/172 [==============================] - 0s 965us/sample - loss: 1.2448 - accuracy: 0.7791 - val_loss: 1.2515 - val_accuracy: 0.7829\n",
      "Epoch 45/200\n",
      "172/172 [==============================] - 0s 941us/sample - loss: 1.2448 - accuracy: 0.7791 - val_loss: 1.2394 - val_accuracy: 0.7829\n",
      "Epoch 46/200\n",
      "172/172 [==============================] - 0s 948us/sample - loss: 1.2428 - accuracy: 0.7791 - val_loss: 1.2461 - val_accuracy: 0.7829\n",
      "Epoch 47/200\n",
      "172/172 [==============================] - 0s 949us/sample - loss: 1.2460 - accuracy: 0.7791 - val_loss: 1.2440 - val_accuracy: 0.7829\n",
      "Epoch 48/200\n",
      "172/172 [==============================] - 0s 949us/sample - loss: 1.2447 - accuracy: 0.7791 - val_loss: 1.2321 - val_accuracy: 0.7829\n",
      "Epoch 49/200\n",
      "172/172 [==============================] - 0s 952us/sample - loss: 1.2444 - accuracy: 0.7791 - val_loss: 1.2556 - val_accuracy: 0.7829\n",
      "Epoch 50/200\n",
      "172/172 [==============================] - 0s 954us/sample - loss: 1.2440 - accuracy: 0.7791 - val_loss: 1.2414 - val_accuracy: 0.7829\n",
      "Epoch 51/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 1.2468 - accuracy: 0.7791 - val_loss: 1.2459 - val_accuracy: 0.7829\n",
      "Epoch 52/200\n",
      "172/172 [==============================] - 0s 986us/sample - loss: 1.2455 - accuracy: 0.7791 - val_loss: 1.2406 - val_accuracy: 0.7829\n",
      "Epoch 53/200\n",
      "172/172 [==============================] - 0s 971us/sample - loss: 1.2407 - accuracy: 0.7791 - val_loss: 1.2487 - val_accuracy: 0.7829\n",
      "Epoch 54/200\n",
      "172/172 [==============================] - 0s 995us/sample - loss: 1.2499 - accuracy: 0.7791 - val_loss: 1.2431 - val_accuracy: 0.7829\n",
      "Epoch 55/200\n",
      "172/172 [==============================] - 0s 993us/sample - loss: 1.2390 - accuracy: 0.7791 - val_loss: 1.2439 - val_accuracy: 0.7829\n",
      "Epoch 56/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2482 - accuracy: 0.7791 - val_loss: 1.2460 - val_accuracy: 0.7829\n",
      "Epoch 57/200\n",
      "172/172 [==============================] - 0s 977us/sample - loss: 1.2461 - accuracy: 0.7791 - val_loss: 1.2472 - val_accuracy: 0.7829\n",
      "Epoch 58/200\n",
      "172/172 [==============================] - 0s 980us/sample - loss: 1.2398 - accuracy: 0.7791 - val_loss: 1.2466 - val_accuracy: 0.7829\n",
      "Epoch 59/200\n",
      "172/172 [==============================] - 0s 991us/sample - loss: 1.2497 - accuracy: 0.7791 - val_loss: 1.2429 - val_accuracy: 0.7829\n",
      "Epoch 60/200\n",
      "172/172 [==============================] - 0s 977us/sample - loss: 1.2432 - accuracy: 0.7791 - val_loss: 1.2384 - val_accuracy: 0.7829\n",
      "Epoch 61/200\n",
      "172/172 [==============================] - 0s 973us/sample - loss: 1.2452 - accuracy: 0.7791 - val_loss: 1.2415 - val_accuracy: 0.7829\n",
      "Epoch 62/200\n",
      "172/172 [==============================] - 0s 987us/sample - loss: 1.2452 - accuracy: 0.7791 - val_loss: 1.2355 - val_accuracy: 0.7829\n",
      "Epoch 63/200\n",
      "172/172 [==============================] - 0s 984us/sample - loss: 1.2424 - accuracy: 0.7791 - val_loss: 1.2607 - val_accuracy: 0.7829\n",
      "Epoch 64/200\n",
      "172/172 [==============================] - 0s 972us/sample - loss: 1.2470 - accuracy: 0.7791 - val_loss: 1.2416 - val_accuracy: 0.7829\n",
      "Epoch 65/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2403 - accuracy: 0.7791 - val_loss: 1.2499 - val_accuracy: 0.7829\n",
      "Epoch 66/200\n",
      "172/172 [==============================] - 0s 996us/sample - loss: 1.2491 - accuracy: 0.7791 - val_loss: 1.2387 - val_accuracy: 0.7829\n",
      "Epoch 67/200\n",
      "172/172 [==============================] - 0s 976us/sample - loss: 1.2412 - accuracy: 0.7791 - val_loss: 1.2448 - val_accuracy: 0.7829\n",
      "Epoch 68/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2489 - accuracy: 0.7791 - val_loss: 1.2366 - val_accuracy: 0.7829\n",
      "Epoch 69/200\n",
      "172/172 [==============================] - 0s 971us/sample - loss: 1.2420 - accuracy: 0.7791 - val_loss: 1.2442 - val_accuracy: 0.7829\n",
      "Epoch 70/200\n",
      "172/172 [==============================] - 0s 967us/sample - loss: 1.2430 - accuracy: 0.7791 - val_loss: 1.2472 - val_accuracy: 0.7829\n",
      "Epoch 71/200\n",
      "172/172 [==============================] - 0s 980us/sample - loss: 1.2494 - accuracy: 0.7791 - val_loss: 1.2436 - val_accuracy: 0.7829\n",
      "Epoch 72/200\n",
      "172/172 [==============================] - 0s 979us/sample - loss: 1.2426 - accuracy: 0.7791 - val_loss: 1.2450 - val_accuracy: 0.7829\n",
      "Epoch 73/200\n",
      "172/172 [==============================] - 0s 977us/sample - loss: 1.2446 - accuracy: 0.7791 - val_loss: 1.2432 - val_accuracy: 0.7829\n",
      "Epoch 74/200\n",
      "172/172 [==============================] - 0s 989us/sample - loss: 1.2445 - accuracy: 0.7791 - val_loss: 1.2486 - val_accuracy: 0.7829\n",
      "Epoch 75/200\n",
      "172/172 [==============================] - 0s 973us/sample - loss: 1.2411 - accuracy: 0.7791 - val_loss: 1.2443 - val_accuracy: 0.7829\n",
      "Epoch 76/200\n",
      "172/172 [==============================] - 0s 980us/sample - loss: 1.2494 - accuracy: 0.7791 - val_loss: 1.2344 - val_accuracy: 0.7829\n",
      "Epoch 77/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2429 - accuracy: 0.7791 - val_loss: 1.2535 - val_accuracy: 0.7829\n",
      "Epoch 78/200\n",
      "172/172 [==============================] - 0s 967us/sample - loss: 1.2435 - accuracy: 0.7791 - val_loss: 1.2417 - val_accuracy: 0.7829\n",
      "Epoch 79/200\n",
      "172/172 [==============================] - 0s 982us/sample - loss: 1.2460 - accuracy: 0.7791 - val_loss: 1.2497 - val_accuracy: 0.7829\n",
      "Epoch 80/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2453 - accuracy: 0.7791 - val_loss: 1.2375 - val_accuracy: 0.7829\n",
      "Epoch 81/200\n",
      "172/172 [==============================] - 0s 994us/sample - loss: 1.2439 - accuracy: 0.7791 - val_loss: 1.2391 - val_accuracy: 0.7829\n",
      "Epoch 82/200\n",
      "172/172 [==============================] - 0s 972us/sample - loss: 1.2487 - accuracy: 0.7791 - val_loss: 1.2375 - val_accuracy: 0.7829\n",
      "Epoch 83/200\n",
      "172/172 [==============================] - 0s 988us/sample - loss: 1.2433 - accuracy: 0.7791 - val_loss: 1.2471 - val_accuracy: 0.7829\n",
      "Epoch 84/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2443 - accuracy: 0.7791 - val_loss: 1.2477 - val_accuracy: 0.7829\n",
      "Epoch 85/200\n",
      "172/172 [==============================] - 0s 991us/sample - loss: 1.2433 - accuracy: 0.7791 - val_loss: 1.2503 - val_accuracy: 0.7829\n",
      "Epoch 86/200\n",
      "172/172 [==============================] - 0s 989us/sample - loss: 1.2449 - accuracy: 0.7791 - val_loss: 1.2484 - val_accuracy: 0.7829\n",
      "Epoch 87/200\n",
      "172/172 [==============================] - 0s 982us/sample - loss: 1.2466 - accuracy: 0.7791 - val_loss: 1.2378 - val_accuracy: 0.7829\n",
      "Epoch 88/200\n",
      "172/172 [==============================] - 0s 937us/sample - loss: 1.2446 - accuracy: 0.7791 - val_loss: 1.2455 - val_accuracy: 0.7829\n",
      "Epoch 89/200\n",
      "172/172 [==============================] - 0s 973us/sample - loss: 1.2467 - accuracy: 0.7791 - val_loss: 1.2424 - val_accuracy: 0.7829\n",
      "Epoch 90/200\n",
      "172/172 [==============================] - 0s 952us/sample - loss: 1.2416 - accuracy: 0.7791 - val_loss: 1.2367 - val_accuracy: 0.7829\n",
      "Epoch 91/200\n",
      "172/172 [==============================] - 0s 941us/sample - loss: 1.2463 - accuracy: 0.7791 - val_loss: 1.2565 - val_accuracy: 0.7829\n",
      "Epoch 92/200\n",
      "172/172 [==============================] - 0s 968us/sample - loss: 1.2459 - accuracy: 0.7791 - val_loss: 1.2385 - val_accuracy: 0.7829\n",
      "Epoch 93/200\n",
      "172/172 [==============================] - 0s 989us/sample - loss: 1.2424 - accuracy: 0.7791 - val_loss: 1.2455 - val_accuracy: 0.7829\n",
      "Epoch 94/200\n",
      "172/172 [==============================] - 0s 972us/sample - loss: 1.2460 - accuracy: 0.7791 - val_loss: 1.2420 - val_accuracy: 0.7829\n",
      "Epoch 95/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 1.2410 - accuracy: 0.7791 - val_loss: 1.2515 - val_accuracy: 0.7829\n",
      "Epoch 96/200\n",
      "172/172 [==============================] - 0s 942us/sample - loss: 1.2508 - accuracy: 0.7791 - val_loss: 1.2363 - val_accuracy: 0.7829\n",
      "Epoch 97/200\n",
      "172/172 [==============================] - 0s 953us/sample - loss: 1.2383 - accuracy: 0.7791 - val_loss: 1.2414 - val_accuracy: 0.7829\n",
      "Epoch 98/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2466 - accuracy: 0.7791 - val_loss: 1.2458 - val_accuracy: 0.7829\n",
      "Epoch 99/200\n",
      "172/172 [==============================] - 0s 987us/sample - loss: 1.2484 - accuracy: 0.7791 - val_loss: 1.2443 - val_accuracy: 0.7829\n",
      "Epoch 100/200\n",
      "172/172 [==============================] - 0s 945us/sample - loss: 1.2431 - accuracy: 0.7791 - val_loss: 1.2484 - val_accuracy: 0.7829\n",
      "Epoch 101/200\n",
      "172/172 [==============================] - 0s 968us/sample - loss: 1.2490 - accuracy: 0.7791 - val_loss: 1.2381 - val_accuracy: 0.7829\n",
      "Epoch 102/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 1.2423 - accuracy: 0.7791 - val_loss: 1.2448 - val_accuracy: 0.7829\n",
      "Epoch 103/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 1.2451 - accuracy: 0.7791 - val_loss: 1.2466 - val_accuracy: 0.7829\n",
      "Epoch 104/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 1.2452 - accuracy: 0.7791 - val_loss: 1.2374 - val_accuracy: 0.7829\n",
      "Epoch 105/200\n",
      "172/172 [==============================] - 0s 958us/sample - loss: 1.2415 - accuracy: 0.7791 - val_loss: 1.2617 - val_accuracy: 0.7829\n",
      "Epoch 106/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 1.2470 - accuracy: 0.7791 - val_loss: 1.2388 - val_accuracy: 0.7829\n",
      "Epoch 107/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 1.2423 - accuracy: 0.7791 - val_loss: 1.2499 - val_accuracy: 0.7829\n",
      "Epoch 108/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 1.2483 - accuracy: 0.7791 - val_loss: 1.2371 - val_accuracy: 0.7829\n",
      "Epoch 109/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 1.2420 - accuracy: 0.7791 - val_loss: 1.2448 - val_accuracy: 0.7829\n",
      "Epoch 110/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 1.2462 - accuracy: 0.7791 - val_loss: 1.2369 - val_accuracy: 0.7829\n",
      "Epoch 111/200\n",
      "172/172 [==============================] - 0s 946us/sample - loss: 1.2435 - accuracy: 0.7791 - val_loss: 1.2417 - val_accuracy: 0.7829\n",
      "Epoch 112/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 1.2460 - accuracy: 0.7791 - val_loss: 1.2425 - val_accuracy: 0.7829\n",
      "Epoch 113/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 1.2447 - accuracy: 0.7791 - val_loss: 1.2444 - val_accuracy: 0.7829\n",
      "Epoch 114/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 1.2412 - accuracy: 0.7791 - val_loss: 1.2519 - val_accuracy: 0.7829\n",
      "Epoch 115/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 1.2474 - accuracy: 0.7791 - val_loss: 1.2427 - val_accuracy: 0.7829\n",
      "Epoch 116/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 1.2456 - accuracy: 0.7791 - val_loss: 1.2435 - val_accuracy: 0.7829\n",
      "Epoch 117/200\n",
      "172/172 [==============================] - 0s 973us/sample - loss: 1.2432 - accuracy: 0.7791 - val_loss: 1.2461 - val_accuracy: 0.7829\n",
      "Epoch 118/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 1.2467 - accuracy: 0.7791 - val_loss: 1.2373 - val_accuracy: 0.7829\n",
      "Epoch 119/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 1.2452 - accuracy: 0.7791 - val_loss: 1.2571 - val_accuracy: 0.7829\n",
      "Epoch 120/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 1.2462 - accuracy: 0.7791 - val_loss: 1.2411 - val_accuracy: 0.7829\n",
      "Epoch 121/200\n",
      "172/172 [==============================] - 0s 944us/sample - loss: 1.2450 - accuracy: 0.7791 - val_loss: 1.2427 - val_accuracy: 0.7829\n",
      "Epoch 122/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 1.2458 - accuracy: 0.7791 - val_loss: 1.2419 - val_accuracy: 0.7829\n",
      "Epoch 123/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 1.2431 - accuracy: 0.7791 - val_loss: 1.2428 - val_accuracy: 0.7829\n",
      "Epoch 124/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 1.2475 - accuracy: 0.7791 - val_loss: 1.2447 - val_accuracy: 0.7829\n",
      "Epoch 125/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 1.2404 - accuracy: 0.7791 - val_loss: 1.2459 - val_accuracy: 0.7829\n",
      "Epoch 126/200\n",
      "172/172 [==============================] - 0s 955us/sample - loss: 1.2450 - accuracy: 0.7791 - val_loss: 1.2422 - val_accuracy: 0.7829\n",
      "Epoch 127/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 1.2466 - accuracy: 0.7791 - val_loss: 1.2484 - val_accuracy: 0.7829\n",
      "Epoch 128/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 1.2442 - accuracy: 0.7791 - val_loss: 1.2460 - val_accuracy: 0.7829\n",
      "Epoch 129/200\n",
      "172/172 [==============================] - 0s 952us/sample - loss: 1.2459 - accuracy: 0.7791 - val_loss: 1.2399 - val_accuracy: 0.7829\n",
      "Epoch 130/200\n",
      "172/172 [==============================] - 0s 948us/sample - loss: 1.2418 - accuracy: 0.7791 - val_loss: 1.2452 - val_accuracy: 0.7829\n",
      "Epoch 131/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 1.2481 - accuracy: 0.7791 - val_loss: 1.2403 - val_accuracy: 0.7829\n",
      "Epoch 132/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 1.2464 - accuracy: 0.7791 - val_loss: 1.2326 - val_accuracy: 0.7829\n",
      "Epoch 133/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 1.2420 - accuracy: 0.7791 - val_loss: 1.2574 - val_accuracy: 0.7829\n",
      "Epoch 134/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 1.2456 - accuracy: 0.7791 - val_loss: 1.2456 - val_accuracy: 0.7829\n",
      "Epoch 135/200\n",
      "172/172 [==============================] - 0s 930us/sample - loss: 1.2423 - accuracy: 0.7791 - val_loss: 1.2528 - val_accuracy: 0.7829\n",
      "Epoch 136/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 1.2472 - accuracy: 0.7791 - val_loss: 1.2356 - val_accuracy: 0.7829\n",
      "Epoch 137/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 1.2430 - accuracy: 0.7791 - val_loss: 1.2478 - val_accuracy: 0.7829\n",
      "Epoch 138/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 1.2486 - accuracy: 0.7791 - val_loss: 1.2366 - val_accuracy: 0.7829\n",
      "Epoch 139/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 1.2411 - accuracy: 0.7791 - val_loss: 1.2471 - val_accuracy: 0.7829\n",
      "Epoch 140/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 1.2477 - accuracy: 0.7791 - val_loss: 1.2461 - val_accuracy: 0.7829\n",
      "Epoch 141/200\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 1.2466 - accuracy: 0.7791 - val_loss: 1.2404 - val_accuracy: 0.7829\n",
      "Epoch 142/200\n",
      "172/172 [==============================] - 0s 971us/sample - loss: 1.2407 - accuracy: 0.7791 - val_loss: 1.2439 - val_accuracy: 0.7829\n",
      "Epoch 143/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 1.2474 - accuracy: 0.7791 - val_loss: 1.2428 - val_accuracy: 0.7829\n",
      "Epoch 144/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 1.2461 - accuracy: 0.7791 - val_loss: 1.2447 - val_accuracy: 0.7829\n",
      "Epoch 145/200\n",
      "172/172 [==============================] - 0s 948us/sample - loss: 1.2410 - accuracy: 0.7791 - val_loss: 1.2449 - val_accuracy: 0.7829\n",
      "Epoch 146/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 1.2465 - accuracy: 0.7791 - val_loss: 1.2339 - val_accuracy: 0.7829\n",
      "Epoch 147/200\n",
      "172/172 [==============================] - 0s 955us/sample - loss: 1.2437 - accuracy: 0.7791 - val_loss: 1.2551 - val_accuracy: 0.7829\n",
      "Epoch 148/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 1.2442 - accuracy: 0.7791 - val_loss: 1.2379 - val_accuracy: 0.7829\n",
      "Epoch 149/200\n",
      "172/172 [==============================] - 0s 930us/sample - loss: 1.2448 - accuracy: 0.7791 - val_loss: 1.2487 - val_accuracy: 0.7829\n",
      "Epoch 150/200\n",
      "172/172 [==============================] - 0s 973us/sample - loss: 1.2439 - accuracy: 0.7791 - val_loss: 1.2401 - val_accuracy: 0.7829\n",
      "Epoch 151/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 1.2446 - accuracy: 0.7791 - val_loss: 1.2415 - val_accuracy: 0.7829\n",
      "Epoch 152/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 1.2493 - accuracy: 0.7791 - val_loss: 1.2375 - val_accuracy: 0.7829\n",
      "Epoch 153/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 922us/sample - loss: 1.2396 - accuracy: 0.7791 - val_loss: 1.2414 - val_accuracy: 0.7829\n",
      "Epoch 154/200\n",
      "172/172 [==============================] - 0s 975us/sample - loss: 1.2458 - accuracy: 0.7791 - val_loss: 1.2519 - val_accuracy: 0.7829\n",
      "Epoch 155/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 1.2466 - accuracy: 0.7791 - val_loss: 1.2473 - val_accuracy: 0.7829\n",
      "Epoch 156/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 1.2445 - accuracy: 0.7791 - val_loss: 1.2480 - val_accuracy: 0.7829\n",
      "Epoch 157/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 1.2461 - accuracy: 0.7791 - val_loss: 1.2378 - val_accuracy: 0.7829\n",
      "Epoch 158/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 1.2422 - accuracy: 0.7791 - val_loss: 1.2451 - val_accuracy: 0.7829\n",
      "Epoch 159/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 1.2468 - accuracy: 0.7791 - val_loss: 1.2424 - val_accuracy: 0.7829\n",
      "Epoch 160/200\n",
      "172/172 [==============================] - 0s 944us/sample - loss: 1.2444 - accuracy: 0.7791 - val_loss: 1.2321 - val_accuracy: 0.7829\n",
      "Epoch 161/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 1.2437 - accuracy: 0.7791 - val_loss: 1.2567 - val_accuracy: 0.7829\n",
      "Epoch 162/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 1.2449 - accuracy: 0.7791 - val_loss: 1.2404 - val_accuracy: 0.7829\n",
      "Epoch 163/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 1.2427 - accuracy: 0.7791 - val_loss: 1.2500 - val_accuracy: 0.7829\n",
      "Epoch 164/200\n",
      "172/172 [==============================] - 0s 954us/sample - loss: 1.2489 - accuracy: 0.7791 - val_loss: 1.2411 - val_accuracy: 0.7829\n",
      "Epoch 165/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 1.2389 - accuracy: 0.7791 - val_loss: 1.2426 - val_accuracy: 0.7829\n",
      "Epoch 166/200\n",
      "172/172 [==============================] - 0s 954us/sample - loss: 1.2500 - accuracy: 0.7791 - val_loss: 1.2428 - val_accuracy: 0.7829\n",
      "Epoch 167/200\n",
      "172/172 [==============================] - 0s 948us/sample - loss: 1.2428 - accuracy: 0.7791 - val_loss: 1.2432 - val_accuracy: 0.7829\n",
      "Epoch 168/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 1.2434 - accuracy: 0.7791 - val_loss: 1.2407 - val_accuracy: 0.7829\n",
      "Epoch 169/200\n",
      "172/172 [==============================] - 0s 928us/sample - loss: 1.2470 - accuracy: 0.7791 - val_loss: 1.2477 - val_accuracy: 0.7829\n",
      "Epoch 170/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 1.2416 - accuracy: 0.7791 - val_loss: 1.2425 - val_accuracy: 0.7829\n",
      "Epoch 171/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 1.2488 - accuracy: 0.7791 - val_loss: 1.2397 - val_accuracy: 0.7829\n",
      "Epoch 172/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 1.2430 - accuracy: 0.7791 - val_loss: 1.2433 - val_accuracy: 0.7829\n",
      "Epoch 173/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 1.2465 - accuracy: 0.7791 - val_loss: 1.2447 - val_accuracy: 0.7829\n",
      "Epoch 174/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 1.2453 - accuracy: 0.7791 - val_loss: 1.2392 - val_accuracy: 0.7829\n",
      "Epoch 175/200\n",
      "172/172 [==============================] - 0s 970us/sample - loss: 1.2409 - accuracy: 0.7791 - val_loss: 1.2605 - val_accuracy: 0.7829\n",
      "Epoch 176/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 1.2499 - accuracy: 0.7791 - val_loss: 1.2406 - val_accuracy: 0.7829\n",
      "Epoch 177/200\n",
      "172/172 [==============================] - 0s 946us/sample - loss: 1.2420 - accuracy: 0.7791 - val_loss: 1.2465 - val_accuracy: 0.7829\n",
      "Epoch 178/200\n",
      "172/172 [==============================] - 0s 964us/sample - loss: 1.2455 - accuracy: 0.7791 - val_loss: 1.2405 - val_accuracy: 0.7829\n",
      "Epoch 179/200\n",
      "172/172 [==============================] - 0s 983us/sample - loss: 1.2457 - accuracy: 0.7791 - val_loss: 1.2460 - val_accuracy: 0.7829\n",
      "Epoch 180/200\n",
      "172/172 [==============================] - 0s 963us/sample - loss: 1.2455 - accuracy: 0.7791 - val_loss: 1.2344 - val_accuracy: 0.7829\n",
      "Epoch 181/200\n",
      "172/172 [==============================] - 0s 941us/sample - loss: 1.2432 - accuracy: 0.7791 - val_loss: 1.2385 - val_accuracy: 0.7829\n",
      "Epoch 182/200\n",
      "172/172 [==============================] - 0s 943us/sample - loss: 1.2447 - accuracy: 0.7791 - val_loss: 1.2428 - val_accuracy: 0.7829\n",
      "Epoch 183/200\n",
      "172/172 [==============================] - 0s 953us/sample - loss: 1.2459 - accuracy: 0.7791 - val_loss: 1.2499 - val_accuracy: 0.7829\n",
      "Epoch 184/200\n",
      "172/172 [==============================] - 0s 944us/sample - loss: 1.2437 - accuracy: 0.7791 - val_loss: 1.2493 - val_accuracy: 0.7829\n",
      "Epoch 185/200\n",
      "172/172 [==============================] - 0s 962us/sample - loss: 1.2441 - accuracy: 0.7791 - val_loss: 1.2425 - val_accuracy: 0.7829\n",
      "Epoch 186/200\n",
      "172/172 [==============================] - 0s 948us/sample - loss: 1.2450 - accuracy: 0.7791 - val_loss: 1.2436 - val_accuracy: 0.7829\n",
      "Epoch 187/200\n",
      "172/172 [==============================] - 0s 980us/sample - loss: 1.2436 - accuracy: 0.7791 - val_loss: 1.2405 - val_accuracy: 0.7829\n",
      "Epoch 188/200\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 1.2467 - accuracy: 0.7791 - val_loss: 1.2367 - val_accuracy: 0.7829\n",
      "Epoch 189/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 1.2432 - accuracy: 0.7791 - val_loss: 1.2574 - val_accuracy: 0.7829\n",
      "Epoch 190/200\n",
      "172/172 [==============================] - 0s 943us/sample - loss: 1.2421 - accuracy: 0.7791 - val_loss: 1.2399 - val_accuracy: 0.7829\n",
      "Epoch 191/200\n",
      "172/172 [==============================] - 0s 998us/sample - loss: 1.2461 - accuracy: 0.7791 - val_loss: 1.2456 - val_accuracy: 0.7829\n",
      "Epoch 192/200\n",
      "172/172 [==============================] - 0s 944us/sample - loss: 1.2478 - accuracy: 0.7791 - val_loss: 1.2361 - val_accuracy: 0.7829\n",
      "Epoch 193/200\n",
      "172/172 [==============================] - 0s 940us/sample - loss: 1.2403 - accuracy: 0.7791 - val_loss: 1.2479 - val_accuracy: 0.7829\n",
      "Epoch 194/200\n",
      "172/172 [==============================] - 0s 953us/sample - loss: 1.2471 - accuracy: 0.7791 - val_loss: 1.2437 - val_accuracy: 0.7829\n",
      "Epoch 195/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 1.2399 - accuracy: 0.7791 - val_loss: 1.2478 - val_accuracy: 0.7829\n",
      "Epoch 196/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 1.2482 - accuracy: 0.7791 - val_loss: 1.2426 - val_accuracy: 0.7829\n",
      "Epoch 197/200\n",
      "172/172 [==============================] - 0s 968us/sample - loss: 1.2436 - accuracy: 0.7791 - val_loss: 1.2424 - val_accuracy: 0.7829\n",
      "Epoch 198/200\n",
      "172/172 [==============================] - 0s 953us/sample - loss: 1.2435 - accuracy: 0.7791 - val_loss: 1.2464 - val_accuracy: 0.7829\n",
      "Epoch 199/200\n",
      "172/172 [==============================] - 0s 971us/sample - loss: 1.2476 - accuracy: 0.7791 - val_loss: 1.2389 - val_accuracy: 0.7829\n",
      "Epoch 200/200\n",
      "172/172 [==============================] - 0s 968us/sample - loss: 1.2415 - accuracy: 0.7791 - val_loss: 1.2459 - val_accuracy: 0.7829\n",
      "Beginning training for dr=0.010, l_lambda=1.0e-03, reg_type=l2\n",
      "Train on 172 samples, validate on 43 samples\n",
      "Epoch 1/200\n",
      "172/172 [==============================] - 1s 9ms/sample - loss: 0.6506 - accuracy: 0.6667 - val_loss: 0.6190 - val_accuracy: 0.6667\n",
      "Epoch 2/200\n",
      "172/172 [==============================] - 0s 980us/sample - loss: 0.5977 - accuracy: 0.6667 - val_loss: 0.5703 - val_accuracy: 0.6667\n",
      "Epoch 3/200\n",
      "172/172 [==============================] - 0s 998us/sample - loss: 0.5516 - accuracy: 0.7267 - val_loss: 0.5260 - val_accuracy: 0.7829\n",
      "Epoch 4/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.5218 - accuracy: 0.7791 - val_loss: 0.5112 - val_accuracy: 0.7829\n",
      "Epoch 5/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5180 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 6/200\n",
      "172/172 [==============================] - 0s 943us/sample - loss: 0.5145 - accuracy: 0.7791 - val_loss: 0.5068 - val_accuracy: 0.7829\n",
      "Epoch 7/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 931us/sample - loss: 0.5132 - accuracy: 0.7791 - val_loss: 0.5058 - val_accuracy: 0.7829\n",
      "Epoch 8/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.5123 - accuracy: 0.7791 - val_loss: 0.5048 - val_accuracy: 0.7829\n",
      "Epoch 9/200\n",
      "172/172 [==============================] - 0s 944us/sample - loss: 0.5118 - accuracy: 0.7791 - val_loss: 0.5040 - val_accuracy: 0.7829\n",
      "Epoch 10/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.5106 - accuracy: 0.7791 - val_loss: 0.5038 - val_accuracy: 0.7829\n",
      "Epoch 11/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 0.5117 - accuracy: 0.7791 - val_loss: 0.5036 - val_accuracy: 0.7829\n",
      "Epoch 12/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5108 - accuracy: 0.7791 - val_loss: 0.5032 - val_accuracy: 0.7829\n",
      "Epoch 13/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.5116 - accuracy: 0.7791 - val_loss: 0.5029 - val_accuracy: 0.7829\n",
      "Epoch 14/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 15/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.5102 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 16/200\n",
      "172/172 [==============================] - 0s 882us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 17/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5107 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 18/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.5085 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 19/200\n",
      "172/172 [==============================] - 0s 882us/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 20/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5014 - val_accuracy: 0.7829\n",
      "Epoch 21/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5013 - val_accuracy: 0.7829\n",
      "Epoch 22/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 0.5085 - accuracy: 0.7791 - val_loss: 0.5014 - val_accuracy: 0.7829\n",
      "Epoch 23/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 0.5102 - accuracy: 0.7791 - val_loss: 0.5013 - val_accuracy: 0.7829\n",
      "Epoch 24/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.5082 - accuracy: 0.7791 - val_loss: 0.5006 - val_accuracy: 0.7829\n",
      "Epoch 25/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 0.5085 - accuracy: 0.7791 - val_loss: 0.5006 - val_accuracy: 0.7829\n",
      "Epoch 26/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5006 - val_accuracy: 0.7829\n",
      "Epoch 27/200\n",
      "172/172 [==============================] - 0s 948us/sample - loss: 0.5081 - accuracy: 0.7791 - val_loss: 0.5007 - val_accuracy: 0.7829\n",
      "Epoch 28/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.5082 - accuracy: 0.7791 - val_loss: 0.5009 - val_accuracy: 0.7829\n",
      "Epoch 29/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.5083 - accuracy: 0.7791 - val_loss: 0.5000 - val_accuracy: 0.7829\n",
      "Epoch 30/200\n",
      "172/172 [==============================] - 0s 941us/sample - loss: 0.5075 - accuracy: 0.7791 - val_loss: 0.5004 - val_accuracy: 0.7829\n",
      "Epoch 31/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.5073 - accuracy: 0.7791 - val_loss: 0.5000 - val_accuracy: 0.7829\n",
      "Epoch 32/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 0.5084 - accuracy: 0.7791 - val_loss: 0.4998 - val_accuracy: 0.7829\n",
      "Epoch 33/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.5085 - accuracy: 0.7791 - val_loss: 0.4997 - val_accuracy: 0.7829\n",
      "Epoch 34/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.4997 - val_accuracy: 0.7829\n",
      "Epoch 35/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.5067 - accuracy: 0.7791 - val_loss: 0.5004 - val_accuracy: 0.7829\n",
      "Epoch 36/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5067 - accuracy: 0.7791 - val_loss: 0.4995 - val_accuracy: 0.7829\n",
      "Epoch 37/200\n",
      "172/172 [==============================] - 0s 882us/sample - loss: 0.5082 - accuracy: 0.7791 - val_loss: 0.4992 - val_accuracy: 0.7829\n",
      "Epoch 38/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.5076 - accuracy: 0.7791 - val_loss: 0.5001 - val_accuracy: 0.7829\n",
      "Epoch 39/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.5082 - accuracy: 0.7791 - val_loss: 0.4993 - val_accuracy: 0.7829\n",
      "Epoch 40/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.5070 - accuracy: 0.7791 - val_loss: 0.4991 - val_accuracy: 0.7829\n",
      "Epoch 41/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.5070 - accuracy: 0.7791 - val_loss: 0.4989 - val_accuracy: 0.7829\n",
      "Epoch 42/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 0.5071 - accuracy: 0.7791 - val_loss: 0.4983 - val_accuracy: 0.7829\n",
      "Epoch 43/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.5077 - accuracy: 0.7791 - val_loss: 0.4986 - val_accuracy: 0.7829\n",
      "Epoch 44/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.5052 - accuracy: 0.7791 - val_loss: 0.4978 - val_accuracy: 0.7829\n",
      "Epoch 45/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.5055 - accuracy: 0.7791 - val_loss: 0.4977 - val_accuracy: 0.7829\n",
      "Epoch 46/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.5056 - accuracy: 0.7791 - val_loss: 0.4978 - val_accuracy: 0.7829\n",
      "Epoch 47/200\n",
      "172/172 [==============================] - 0s 865us/sample - loss: 0.5054 - accuracy: 0.7791 - val_loss: 0.4975 - val_accuracy: 0.7829\n",
      "Epoch 48/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5048 - accuracy: 0.7791 - val_loss: 0.4975 - val_accuracy: 0.7829\n",
      "Epoch 49/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.5052 - accuracy: 0.7791 - val_loss: 0.4970 - val_accuracy: 0.7829\n",
      "Epoch 50/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.5061 - accuracy: 0.7791 - val_loss: 0.4970 - val_accuracy: 0.7829\n",
      "Epoch 51/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.5055 - accuracy: 0.7791 - val_loss: 0.4976 - val_accuracy: 0.7829\n",
      "Epoch 52/200\n",
      "172/172 [==============================] - 0s 945us/sample - loss: 0.5042 - accuracy: 0.7791 - val_loss: 0.4960 - val_accuracy: 0.7829\n",
      "Epoch 53/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.5046 - accuracy: 0.7791 - val_loss: 0.4959 - val_accuracy: 0.7829\n",
      "Epoch 54/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 0.5046 - accuracy: 0.7791 - val_loss: 0.4955 - val_accuracy: 0.7829\n",
      "Epoch 55/200\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 0.5040 - accuracy: 0.7791 - val_loss: 0.4952 - val_accuracy: 0.7829\n",
      "Epoch 56/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 0.5053 - accuracy: 0.7791 - val_loss: 0.4949 - val_accuracy: 0.7829\n",
      "Epoch 57/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5055 - accuracy: 0.7791 - val_loss: 0.4943 - val_accuracy: 0.7829\n",
      "Epoch 58/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 0.5032 - accuracy: 0.7791 - val_loss: 0.4942 - val_accuracy: 0.7829\n",
      "Epoch 59/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 0.5024 - accuracy: 0.7791 - val_loss: 0.4934 - val_accuracy: 0.7829\n",
      "Epoch 60/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 0.5056 - accuracy: 0.7791 - val_loss: 0.4932 - val_accuracy: 0.7829\n",
      "Epoch 61/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 0.5029 - accuracy: 0.7791 - val_loss: 0.4933 - val_accuracy: 0.7829\n",
      "Epoch 62/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 921us/sample - loss: 0.5028 - accuracy: 0.7791 - val_loss: 0.4925 - val_accuracy: 0.7829\n",
      "Epoch 63/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.5043 - accuracy: 0.7791 - val_loss: 0.4919 - val_accuracy: 0.7829\n",
      "Epoch 64/200\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 0.5022 - accuracy: 0.7791 - val_loss: 0.4913 - val_accuracy: 0.7829\n",
      "Epoch 65/200\n",
      "172/172 [==============================] - 0s 981us/sample - loss: 0.5030 - accuracy: 0.7791 - val_loss: 0.4907 - val_accuracy: 0.7829\n",
      "Epoch 66/200\n",
      "172/172 [==============================] - 0s 940us/sample - loss: 0.5006 - accuracy: 0.7791 - val_loss: 0.4904 - val_accuracy: 0.7829\n",
      "Epoch 67/200\n",
      "172/172 [==============================] - 0s 928us/sample - loss: 0.4998 - accuracy: 0.7791 - val_loss: 0.4894 - val_accuracy: 0.7829\n",
      "Epoch 68/200\n",
      "172/172 [==============================] - 0s 966us/sample - loss: 0.4981 - accuracy: 0.7791 - val_loss: 0.4897 - val_accuracy: 0.7829\n",
      "Epoch 69/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4988 - accuracy: 0.7791 - val_loss: 0.4890 - val_accuracy: 0.7829\n",
      "Epoch 70/200\n",
      "172/172 [==============================] - 0s 994us/sample - loss: 0.4975 - accuracy: 0.7791 - val_loss: 0.4871 - val_accuracy: 0.7829\n",
      "Epoch 71/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5008 - accuracy: 0.7791 - val_loss: 0.4867 - val_accuracy: 0.7829\n",
      "Epoch 72/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.4955 - accuracy: 0.7791 - val_loss: 0.4869 - val_accuracy: 0.7829\n",
      "Epoch 73/200\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 0.4954 - accuracy: 0.7791 - val_loss: 0.4852 - val_accuracy: 0.7829\n",
      "Epoch 74/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 0.4946 - accuracy: 0.7791 - val_loss: 0.4835 - val_accuracy: 0.7829\n",
      "Epoch 75/200\n",
      "172/172 [==============================] - 0s 945us/sample - loss: 0.4938 - accuracy: 0.7791 - val_loss: 0.4826 - val_accuracy: 0.7829\n",
      "Epoch 76/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.4941 - accuracy: 0.7791 - val_loss: 0.4811 - val_accuracy: 0.7829\n",
      "Epoch 77/200\n",
      "172/172 [==============================] - 0s 981us/sample - loss: 0.4946 - accuracy: 0.7810 - val_loss: 0.4822 - val_accuracy: 0.7829\n",
      "Epoch 78/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 0.4924 - accuracy: 0.7791 - val_loss: 0.4789 - val_accuracy: 0.7829\n",
      "Epoch 79/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.4972 - accuracy: 0.7829 - val_loss: 0.4787 - val_accuracy: 0.7829\n",
      "Epoch 80/200\n",
      "172/172 [==============================] - 0s 951us/sample - loss: 0.4944 - accuracy: 0.7791 - val_loss: 0.4773 - val_accuracy: 0.7829\n",
      "Epoch 81/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 0.4872 - accuracy: 0.7791 - val_loss: 0.4781 - val_accuracy: 0.7907\n",
      "Epoch 82/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 0.4876 - accuracy: 0.7810 - val_loss: 0.4758 - val_accuracy: 0.7907\n",
      "Epoch 83/200\n",
      "172/172 [==============================] - 0s 949us/sample - loss: 0.4880 - accuracy: 0.7771 - val_loss: 0.4759 - val_accuracy: 0.7907\n",
      "Epoch 84/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.4852 - accuracy: 0.7829 - val_loss: 0.4745 - val_accuracy: 0.7907\n",
      "Epoch 85/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 0.4836 - accuracy: 0.7849 - val_loss: 0.4725 - val_accuracy: 0.7984\n",
      "Epoch 86/200\n",
      "172/172 [==============================] - 0s 948us/sample - loss: 0.4816 - accuracy: 0.7868 - val_loss: 0.4722 - val_accuracy: 0.8062\n",
      "Epoch 87/200\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 0.4795 - accuracy: 0.7810 - val_loss: 0.4692 - val_accuracy: 0.7984\n",
      "Epoch 88/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 0.4832 - accuracy: 0.7868 - val_loss: 0.4682 - val_accuracy: 0.8062\n",
      "Epoch 89/200\n",
      "172/172 [==============================] - 0s 992us/sample - loss: 0.4830 - accuracy: 0.7810 - val_loss: 0.4708 - val_accuracy: 0.7907\n",
      "Epoch 90/200\n",
      "172/172 [==============================] - 0s 979us/sample - loss: 0.4801 - accuracy: 0.7888 - val_loss: 0.4673 - val_accuracy: 0.8062\n",
      "Epoch 91/200\n",
      "172/172 [==============================] - 0s 959us/sample - loss: 0.4759 - accuracy: 0.7849 - val_loss: 0.4663 - val_accuracy: 0.7907\n",
      "Epoch 92/200\n",
      "172/172 [==============================] - 0s 969us/sample - loss: 0.4775 - accuracy: 0.7984 - val_loss: 0.4648 - val_accuracy: 0.7907\n",
      "Epoch 93/200\n",
      "172/172 [==============================] - 0s 961us/sample - loss: 0.4722 - accuracy: 0.7868 - val_loss: 0.4634 - val_accuracy: 0.7907\n",
      "Epoch 94/200\n",
      "172/172 [==============================] - 0s 966us/sample - loss: 0.4705 - accuracy: 0.7926 - val_loss: 0.4647 - val_accuracy: 0.7984\n",
      "Epoch 95/200\n",
      "172/172 [==============================] - 0s 974us/sample - loss: 0.4717 - accuracy: 0.7907 - val_loss: 0.4618 - val_accuracy: 0.7984\n",
      "Epoch 96/200\n",
      "172/172 [==============================] - 0s 979us/sample - loss: 0.4725 - accuracy: 0.7888 - val_loss: 0.4637 - val_accuracy: 0.7907\n",
      "Epoch 97/200\n",
      "172/172 [==============================] - 0s 954us/sample - loss: 0.4713 - accuracy: 0.7926 - val_loss: 0.4614 - val_accuracy: 0.7907\n",
      "Epoch 98/200\n",
      "172/172 [==============================] - 0s 970us/sample - loss: 0.4686 - accuracy: 0.7888 - val_loss: 0.4624 - val_accuracy: 0.7984\n",
      "Epoch 99/200\n",
      "172/172 [==============================] - 0s 955us/sample - loss: 0.4676 - accuracy: 0.8004 - val_loss: 0.4572 - val_accuracy: 0.7984\n",
      "Epoch 100/200\n",
      "172/172 [==============================] - 0s 969us/sample - loss: 0.4692 - accuracy: 0.7849 - val_loss: 0.4675 - val_accuracy: 0.8062\n",
      "Epoch 101/200\n",
      "172/172 [==============================] - 0s 974us/sample - loss: 0.4643 - accuracy: 0.8004 - val_loss: 0.4557 - val_accuracy: 0.7984\n",
      "Epoch 102/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4660 - accuracy: 0.8101 - val_loss: 0.4625 - val_accuracy: 0.8062\n",
      "Epoch 103/200\n",
      "172/172 [==============================] - 0s 954us/sample - loss: 0.4653 - accuracy: 0.8004 - val_loss: 0.4574 - val_accuracy: 0.7984\n",
      "Epoch 104/200\n",
      "172/172 [==============================] - 0s 957us/sample - loss: 0.4639 - accuracy: 0.8101 - val_loss: 0.4613 - val_accuracy: 0.8062\n",
      "Epoch 105/200\n",
      "172/172 [==============================] - 0s 979us/sample - loss: 0.4788 - accuracy: 0.7868 - val_loss: 0.4609 - val_accuracy: 0.8062\n",
      "Epoch 106/200\n",
      "172/172 [==============================] - 0s 952us/sample - loss: 0.4995 - accuracy: 0.8043 - val_loss: 0.4533 - val_accuracy: 0.7984\n",
      "Epoch 107/200\n",
      "172/172 [==============================] - 0s 951us/sample - loss: 0.4643 - accuracy: 0.7946 - val_loss: 0.4564 - val_accuracy: 0.7984\n",
      "Epoch 108/200\n",
      "172/172 [==============================] - 0s 991us/sample - loss: 0.4709 - accuracy: 0.7926 - val_loss: 0.4644 - val_accuracy: 0.8062\n",
      "Epoch 109/200\n",
      "172/172 [==============================] - 0s 956us/sample - loss: 0.4620 - accuracy: 0.8140 - val_loss: 0.4562 - val_accuracy: 0.8062\n",
      "Epoch 110/200\n",
      "172/172 [==============================] - 0s 961us/sample - loss: 0.4665 - accuracy: 0.7946 - val_loss: 0.4507 - val_accuracy: 0.7984\n",
      "Epoch 111/200\n",
      "172/172 [==============================] - 0s 975us/sample - loss: 0.4571 - accuracy: 0.8062 - val_loss: 0.4561 - val_accuracy: 0.8062\n",
      "Epoch 112/200\n",
      "172/172 [==============================] - 0s 957us/sample - loss: 0.4582 - accuracy: 0.8004 - val_loss: 0.4516 - val_accuracy: 0.7984\n",
      "Epoch 113/200\n",
      "172/172 [==============================] - 0s 958us/sample - loss: 0.4597 - accuracy: 0.8081 - val_loss: 0.4514 - val_accuracy: 0.7984\n",
      "Epoch 114/200\n",
      "172/172 [==============================] - 0s 991us/sample - loss: 0.4617 - accuracy: 0.7946 - val_loss: 0.4553 - val_accuracy: 0.8062\n",
      "Epoch 115/200\n",
      "172/172 [==============================] - 0s 968us/sample - loss: 0.4596 - accuracy: 0.8043 - val_loss: 0.4525 - val_accuracy: 0.8062\n",
      "Epoch 116/200\n",
      "172/172 [==============================] - 0s 968us/sample - loss: 0.4586 - accuracy: 0.8140 - val_loss: 0.4506 - val_accuracy: 0.8062\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 969us/sample - loss: 0.4553 - accuracy: 0.8140 - val_loss: 0.4482 - val_accuracy: 0.7984\n",
      "Epoch 118/200\n",
      "172/172 [==============================] - 0s 961us/sample - loss: 0.4541 - accuracy: 0.8120 - val_loss: 0.4534 - val_accuracy: 0.8062\n",
      "Epoch 119/200\n",
      "172/172 [==============================] - 0s 956us/sample - loss: 0.4564 - accuracy: 0.8159 - val_loss: 0.4485 - val_accuracy: 0.8062\n",
      "Epoch 120/200\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 0.4517 - accuracy: 0.8159 - val_loss: 0.4498 - val_accuracy: 0.8062\n",
      "Epoch 121/200\n",
      "172/172 [==============================] - 0s 928us/sample - loss: 0.4525 - accuracy: 0.8140 - val_loss: 0.4471 - val_accuracy: 0.8062\n",
      "Epoch 122/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 0.4540 - accuracy: 0.8198 - val_loss: 0.4490 - val_accuracy: 0.8062\n",
      "Epoch 123/200\n",
      "172/172 [==============================] - 0s 966us/sample - loss: 0.4512 - accuracy: 0.8140 - val_loss: 0.4450 - val_accuracy: 0.7984\n",
      "Epoch 124/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 0.4555 - accuracy: 0.8081 - val_loss: 0.4580 - val_accuracy: 0.8295\n",
      "Epoch 125/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 0.4569 - accuracy: 0.8081 - val_loss: 0.4467 - val_accuracy: 0.8062\n",
      "Epoch 126/200\n",
      "172/172 [==============================] - 0s 955us/sample - loss: 0.4539 - accuracy: 0.8198 - val_loss: 0.4456 - val_accuracy: 0.8062\n",
      "Epoch 127/200\n",
      "172/172 [==============================] - 0s 957us/sample - loss: 0.4508 - accuracy: 0.8081 - val_loss: 0.4476 - val_accuracy: 0.8062\n",
      "Epoch 128/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.4497 - accuracy: 0.8236 - val_loss: 0.4463 - val_accuracy: 0.8062\n",
      "Epoch 129/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 0.4490 - accuracy: 0.8178 - val_loss: 0.4436 - val_accuracy: 0.8062\n",
      "Epoch 130/200\n",
      "172/172 [==============================] - 0s 947us/sample - loss: 0.4504 - accuracy: 0.8140 - val_loss: 0.4428 - val_accuracy: 0.8062\n",
      "Epoch 131/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.4461 - accuracy: 0.8159 - val_loss: 0.4472 - val_accuracy: 0.8140\n",
      "Epoch 132/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 0.4459 - accuracy: 0.8178 - val_loss: 0.4441 - val_accuracy: 0.8062\n",
      "Epoch 133/200\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 0.4441 - accuracy: 0.8217 - val_loss: 0.4469 - val_accuracy: 0.8140\n",
      "Epoch 134/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 0.4435 - accuracy: 0.8140 - val_loss: 0.4405 - val_accuracy: 0.7984\n",
      "Epoch 135/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.4467 - accuracy: 0.8120 - val_loss: 0.4431 - val_accuracy: 0.8062\n",
      "Epoch 136/200\n",
      "172/172 [==============================] - 0s 972us/sample - loss: 0.4472 - accuracy: 0.8120 - val_loss: 0.4478 - val_accuracy: 0.8295\n",
      "Epoch 137/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.4513 - accuracy: 0.8295 - val_loss: 0.4395 - val_accuracy: 0.8062\n",
      "Epoch 138/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.4439 - accuracy: 0.8140 - val_loss: 0.4476 - val_accuracy: 0.8295\n",
      "Epoch 139/200\n",
      "172/172 [==============================] - 0s 946us/sample - loss: 0.4491 - accuracy: 0.8159 - val_loss: 0.4418 - val_accuracy: 0.8062\n",
      "Epoch 140/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.4413 - accuracy: 0.8198 - val_loss: 0.4414 - val_accuracy: 0.8062\n",
      "Epoch 141/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.4371 - accuracy: 0.8198 - val_loss: 0.4394 - val_accuracy: 0.8062\n",
      "Epoch 142/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 0.4411 - accuracy: 0.8236 - val_loss: 0.4448 - val_accuracy: 0.8295\n",
      "Epoch 143/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.4414 - accuracy: 0.8275 - val_loss: 0.4388 - val_accuracy: 0.8062\n",
      "Epoch 144/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.4461 - accuracy: 0.8178 - val_loss: 0.4419 - val_accuracy: 0.8140\n",
      "Epoch 145/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.4434 - accuracy: 0.8198 - val_loss: 0.4364 - val_accuracy: 0.7984\n",
      "Epoch 146/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.4369 - accuracy: 0.8275 - val_loss: 0.4411 - val_accuracy: 0.8217\n",
      "Epoch 147/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.4421 - accuracy: 0.8198 - val_loss: 0.4380 - val_accuracy: 0.8140\n",
      "Epoch 148/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 0.4397 - accuracy: 0.8198 - val_loss: 0.4364 - val_accuracy: 0.8062\n",
      "Epoch 149/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.4425 - accuracy: 0.8217 - val_loss: 0.4360 - val_accuracy: 0.8062\n",
      "Epoch 150/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.4482 - accuracy: 0.7984 - val_loss: 0.4481 - val_accuracy: 0.8372\n",
      "Epoch 151/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.4449 - accuracy: 0.8198 - val_loss: 0.4349 - val_accuracy: 0.7984\n",
      "Epoch 152/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.4372 - accuracy: 0.8236 - val_loss: 0.4424 - val_accuracy: 0.8372\n",
      "Epoch 153/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 0.4395 - accuracy: 0.8236 - val_loss: 0.4349 - val_accuracy: 0.7984\n",
      "Epoch 154/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.4386 - accuracy: 0.8198 - val_loss: 0.4354 - val_accuracy: 0.8062\n",
      "Epoch 155/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.4423 - accuracy: 0.8295 - val_loss: 0.4357 - val_accuracy: 0.8140\n",
      "Epoch 156/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.4355 - accuracy: 0.8217 - val_loss: 0.4380 - val_accuracy: 0.8295\n",
      "Epoch 157/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 0.4363 - accuracy: 0.8217 - val_loss: 0.4394 - val_accuracy: 0.8372\n",
      "Epoch 158/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.4421 - accuracy: 0.8275 - val_loss: 0.4360 - val_accuracy: 0.8295\n",
      "Epoch 159/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.4366 - accuracy: 0.8236 - val_loss: 0.4336 - val_accuracy: 0.8062\n",
      "Epoch 160/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.4389 - accuracy: 0.8217 - val_loss: 0.4332 - val_accuracy: 0.8140\n",
      "Epoch 161/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.4349 - accuracy: 0.8198 - val_loss: 0.4381 - val_accuracy: 0.8372\n",
      "Epoch 162/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.4353 - accuracy: 0.8275 - val_loss: 0.4345 - val_accuracy: 0.8295\n",
      "Epoch 163/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.4393 - accuracy: 0.8217 - val_loss: 0.4374 - val_accuracy: 0.8372\n",
      "Epoch 164/200\n",
      "172/172 [==============================] - 0s 968us/sample - loss: 0.4373 - accuracy: 0.8178 - val_loss: 0.4389 - val_accuracy: 0.8372\n",
      "Epoch 165/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 0.4398 - accuracy: 0.8178 - val_loss: 0.4325 - val_accuracy: 0.8140\n",
      "Epoch 166/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.4341 - accuracy: 0.8295 - val_loss: 0.4329 - val_accuracy: 0.8295\n",
      "Epoch 167/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 0.4361 - accuracy: 0.8178 - val_loss: 0.4356 - val_accuracy: 0.8372\n",
      "Epoch 168/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 0.4378 - accuracy: 0.8314 - val_loss: 0.4304 - val_accuracy: 0.7984\n",
      "Epoch 169/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.4382 - accuracy: 0.8178 - val_loss: 0.4436 - val_accuracy: 0.8295\n",
      "Epoch 170/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 0.4327 - accuracy: 0.8217 - val_loss: 0.4289 - val_accuracy: 0.8062\n",
      "Epoch 171/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.4346 - accuracy: 0.8256 - val_loss: 0.4359 - val_accuracy: 0.8372\n",
      "Epoch 172/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 904us/sample - loss: 0.4340 - accuracy: 0.8236 - val_loss: 0.4306 - val_accuracy: 0.8140\n",
      "Epoch 173/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.4368 - accuracy: 0.8198 - val_loss: 0.4425 - val_accuracy: 0.8295\n",
      "Epoch 174/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.4318 - accuracy: 0.8275 - val_loss: 0.4312 - val_accuracy: 0.8217\n",
      "Epoch 175/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 0.4333 - accuracy: 0.8198 - val_loss: 0.4329 - val_accuracy: 0.8295\n",
      "Epoch 176/200\n",
      "172/172 [==============================] - 0s 940us/sample - loss: 0.4312 - accuracy: 0.8256 - val_loss: 0.4317 - val_accuracy: 0.8295\n",
      "Epoch 177/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 0.4341 - accuracy: 0.8178 - val_loss: 0.4313 - val_accuracy: 0.8295\n",
      "Epoch 178/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.4295 - accuracy: 0.8256 - val_loss: 0.4301 - val_accuracy: 0.8140\n",
      "Epoch 179/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.4405 - accuracy: 0.8140 - val_loss: 0.4445 - val_accuracy: 0.8217\n",
      "Epoch 180/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.4292 - accuracy: 0.8198 - val_loss: 0.4279 - val_accuracy: 0.7984\n",
      "Epoch 181/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.4373 - accuracy: 0.8043 - val_loss: 0.4441 - val_accuracy: 0.8217\n",
      "Epoch 182/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.4302 - accuracy: 0.8236 - val_loss: 0.4289 - val_accuracy: 0.8140\n",
      "Epoch 183/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.4305 - accuracy: 0.8314 - val_loss: 0.4278 - val_accuracy: 0.7984\n",
      "Epoch 184/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.4433 - accuracy: 0.8101 - val_loss: 0.4432 - val_accuracy: 0.8140\n",
      "Epoch 185/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.4305 - accuracy: 0.8314 - val_loss: 0.4277 - val_accuracy: 0.8062\n",
      "Epoch 186/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.4293 - accuracy: 0.8275 - val_loss: 0.4277 - val_accuracy: 0.7984\n",
      "Epoch 187/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.4267 - accuracy: 0.8159 - val_loss: 0.4304 - val_accuracy: 0.8372\n",
      "Epoch 188/200\n",
      "172/172 [==============================] - 0s 942us/sample - loss: 0.4278 - accuracy: 0.8217 - val_loss: 0.4271 - val_accuracy: 0.8140\n",
      "Epoch 189/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 0.4261 - accuracy: 0.8295 - val_loss: 0.4384 - val_accuracy: 0.8295\n",
      "Epoch 190/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.4279 - accuracy: 0.8295 - val_loss: 0.4275 - val_accuracy: 0.8140\n",
      "Epoch 191/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 0.4279 - accuracy: 0.8256 - val_loss: 0.4321 - val_accuracy: 0.8372\n",
      "Epoch 192/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.4340 - accuracy: 0.8217 - val_loss: 0.4268 - val_accuracy: 0.8140\n",
      "Epoch 193/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.4316 - accuracy: 0.8256 - val_loss: 0.4270 - val_accuracy: 0.8140\n",
      "Epoch 194/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.4263 - accuracy: 0.8256 - val_loss: 0.4281 - val_accuracy: 0.8372\n",
      "Epoch 195/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.4301 - accuracy: 0.8178 - val_loss: 0.4294 - val_accuracy: 0.8372\n",
      "Epoch 196/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.4257 - accuracy: 0.8256 - val_loss: 0.4265 - val_accuracy: 0.8217\n",
      "Epoch 197/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.4302 - accuracy: 0.8217 - val_loss: 0.4276 - val_accuracy: 0.8372\n",
      "Epoch 198/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.4512 - accuracy: 0.8217 - val_loss: 0.4246 - val_accuracy: 0.8062\n",
      "Epoch 199/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 0.4280 - accuracy: 0.8275 - val_loss: 0.4270 - val_accuracy: 0.8372\n",
      "Epoch 200/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.4280 - accuracy: 0.8256 - val_loss: 0.4264 - val_accuracy: 0.8372\n",
      "Beginning training for dr=0.010, l_lambda=1.0e-03, reg_type=l1\n",
      "Train on 172 samples, validate on 43 samples\n",
      "Epoch 1/200\n",
      "172/172 [==============================] - 2s 10ms/sample - loss: 1.3289 - accuracy: 0.6667 - val_loss: 0.9566 - val_accuracy: 0.6667\n",
      "Epoch 2/200\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 0.8165 - accuracy: 0.6667 - val_loss: 0.7236 - val_accuracy: 0.6667\n",
      "Epoch 3/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.6723 - accuracy: 0.7248 - val_loss: 0.6209 - val_accuracy: 0.7829\n",
      "Epoch 4/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 0.6013 - accuracy: 0.7791 - val_loss: 0.5731 - val_accuracy: 0.7829\n",
      "Epoch 5/200\n",
      "172/172 [==============================] - 0s 945us/sample - loss: 0.5679 - accuracy: 0.7791 - val_loss: 0.5511 - val_accuracy: 0.7829\n",
      "Epoch 6/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.5498 - accuracy: 0.7791 - val_loss: 0.5359 - val_accuracy: 0.7829\n",
      "Epoch 7/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.5373 - accuracy: 0.7791 - val_loss: 0.5255 - val_accuracy: 0.7829\n",
      "Epoch 8/200\n",
      "172/172 [==============================] - 0s 951us/sample - loss: 0.5274 - accuracy: 0.7791 - val_loss: 0.5172 - val_accuracy: 0.7829\n",
      "Epoch 9/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 0.5241 - accuracy: 0.7791 - val_loss: 0.5142 - val_accuracy: 0.7829\n",
      "Epoch 10/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.5186 - accuracy: 0.7791 - val_loss: 0.5113 - val_accuracy: 0.7829\n",
      "Epoch 11/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5171 - accuracy: 0.7791 - val_loss: 0.5107 - val_accuracy: 0.7829\n",
      "Epoch 12/200\n",
      "172/172 [==============================] - 0s 957us/sample - loss: 0.5179 - accuracy: 0.7791 - val_loss: 0.5101 - val_accuracy: 0.7829\n",
      "Epoch 13/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.5180 - accuracy: 0.7791 - val_loss: 0.5103 - val_accuracy: 0.7829\n",
      "Epoch 14/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.5170 - accuracy: 0.7791 - val_loss: 0.5097 - val_accuracy: 0.7829\n",
      "Epoch 15/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5099 - val_accuracy: 0.7829\n",
      "Epoch 16/200\n",
      "172/172 [==============================] - 0s 970us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 17/200\n",
      "172/172 [==============================] - 0s 954us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 18/200\n",
      "172/172 [==============================] - 0s 943us/sample - loss: 0.5170 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 19/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 20/200\n",
      "172/172 [==============================] - 0s 940us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 21/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 22/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 0.5168 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 23/200\n",
      "172/172 [==============================] - 0s 968us/sample - loss: 0.5168 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 24/200\n",
      "172/172 [==============================] - 0s 967us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 25/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 26/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 948us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 27/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 28/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.5174 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 29/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 30/200\n",
      "172/172 [==============================] - 0s 949us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 31/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 32/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 33/200\n",
      "172/172 [==============================] - 0s 937us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 34/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 35/200\n",
      "172/172 [==============================] - 0s 976us/sample - loss: 0.5170 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 36/200\n",
      "172/172 [==============================] - 0s 986us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 37/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 38/200\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 39/200\n",
      "172/172 [==============================] - 0s 951us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5097 - val_accuracy: 0.7829\n",
      "Epoch 40/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 0.5169 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 41/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 42/200\n",
      "172/172 [==============================] - 0s 952us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 43/200\n",
      "172/172 [==============================] - 0s 949us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 44/200\n",
      "172/172 [==============================] - 0s 937us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5098 - val_accuracy: 0.7829\n",
      "Epoch 45/200\n",
      "172/172 [==============================] - 0s 930us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 46/200\n",
      "172/172 [==============================] - 0s 947us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 47/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 48/200\n",
      "172/172 [==============================] - 0s 989us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 49/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 50/200\n",
      "172/172 [==============================] - 0s 978us/sample - loss: 0.5168 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 51/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 52/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.5172 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 53/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 54/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 55/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 56/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 57/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.5180 - accuracy: 0.7791 - val_loss: 0.5099 - val_accuracy: 0.7829\n",
      "Epoch 58/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.5174 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 59/200\n",
      "172/172 [==============================] - 0s 869us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 60/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 61/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.5174 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 62/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 0.5172 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 63/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 64/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 65/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5085 - val_accuracy: 0.7829\n",
      "Epoch 66/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 67/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.5172 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 68/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 69/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 70/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 71/200\n",
      "172/172 [==============================] - 0s 928us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 72/200\n",
      "172/172 [==============================] - 0s 954us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 73/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 74/200\n",
      "172/172 [==============================] - 0s 949us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5100 - val_accuracy: 0.7829\n",
      "Epoch 75/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5097 - val_accuracy: 0.7829\n",
      "Epoch 76/200\n",
      "172/172 [==============================] - 0s 956us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 77/200\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 78/200\n",
      "172/172 [==============================] - 0s 937us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 79/200\n",
      "172/172 [==============================] - 0s 955us/sample - loss: 0.5178 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 80/200\n",
      "172/172 [==============================] - 0s 949us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 956us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 82/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 0.5168 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 83/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 84/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 85/200\n",
      "172/172 [==============================] - 0s 989us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 86/200\n",
      "172/172 [==============================] - 0s 941us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 87/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 88/200\n",
      "172/172 [==============================] - 0s 947us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 89/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 90/200\n",
      "172/172 [==============================] - 0s 937us/sample - loss: 0.5169 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 91/200\n",
      "172/172 [==============================] - 0s 962us/sample - loss: 0.5157 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 92/200\n",
      "172/172 [==============================] - 0s 943us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 93/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 94/200\n",
      "172/172 [==============================] - 0s 966us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 95/200\n",
      "172/172 [==============================] - 0s 962us/sample - loss: 0.5168 - accuracy: 0.7791 - val_loss: 0.5096 - val_accuracy: 0.7829\n",
      "Epoch 96/200\n",
      "172/172 [==============================] - 0s 958us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 97/200\n",
      "172/172 [==============================] - 0s 973us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 98/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 99/200\n",
      "172/172 [==============================] - 0s 996us/sample - loss: 0.5174 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 100/200\n",
      "172/172 [==============================] - 0s 983us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 101/200\n",
      "172/172 [==============================] - 0s 969us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 102/200\n",
      "172/172 [==============================] - 0s 963us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 103/200\n",
      "172/172 [==============================] - 0s 960us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 104/200\n",
      "172/172 [==============================] - 0s 987us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 105/200\n",
      "172/172 [==============================] - 0s 972us/sample - loss: 0.5170 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 106/200\n",
      "172/172 [==============================] - 0s 972us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 107/200\n",
      "172/172 [==============================] - 0s 963us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 108/200\n",
      "172/172 [==============================] - 0s 965us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 109/200\n",
      "172/172 [==============================] - 0s 978us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 110/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 111/200\n",
      "172/172 [==============================] - 0s 981us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 112/200\n",
      "172/172 [==============================] - 0s 956us/sample - loss: 0.5156 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 113/200\n",
      "172/172 [==============================] - 0s 977us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 114/200\n",
      "172/172 [==============================] - 0s 991us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 115/200\n",
      "172/172 [==============================] - 0s 967us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 116/200\n",
      "172/172 [==============================] - 0s 977us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 117/200\n",
      "172/172 [==============================] - 0s 969us/sample - loss: 0.5158 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 118/200\n",
      "172/172 [==============================] - 0s 960us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 119/200\n",
      "172/172 [==============================] - 0s 984us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 120/200\n",
      "172/172 [==============================] - 0s 968us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 121/200\n",
      "172/172 [==============================] - 0s 957us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 122/200\n",
      "172/172 [==============================] - 0s 992us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 123/200\n",
      "172/172 [==============================] - 0s 999us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 124/200\n",
      "172/172 [==============================] - 0s 974us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 125/200\n",
      "172/172 [==============================] - 0s 945us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 126/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.5172 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 127/200\n",
      "172/172 [==============================] - 0s 940us/sample - loss: 0.5168 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 128/200\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 129/200\n",
      "172/172 [==============================] - 0s 956us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 130/200\n",
      "172/172 [==============================] - 0s 940us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 131/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 132/200\n",
      "172/172 [==============================] - 0s 941us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 133/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 134/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 135/200\n",
      "172/172 [==============================] - 0s 992us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 136/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 934us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 137/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 138/200\n",
      "172/172 [==============================] - 0s 945us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 139/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 140/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 0.5157 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 141/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 142/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 143/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.5158 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 144/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 0.5177 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 145/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5171 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 146/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 147/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5097 - val_accuracy: 0.7829\n",
      "Epoch 148/200\n",
      "172/172 [==============================] - 0s 940us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 149/200\n",
      "172/172 [==============================] - 0s 941us/sample - loss: 0.5156 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 150/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 151/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 152/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 153/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 154/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 155/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 156/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.5170 - accuracy: 0.7791 - val_loss: 0.5098 - val_accuracy: 0.7829\n",
      "Epoch 157/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 158/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 159/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 160/200\n",
      "172/172 [==============================] - 0s 969us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 161/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 162/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 163/200\n",
      "172/172 [==============================] - 0s 943us/sample - loss: 0.5158 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 164/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 165/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 166/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 167/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 168/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.5175 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 169/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 170/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 171/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 172/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 0.5173 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 173/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5085 - val_accuracy: 0.7829\n",
      "Epoch 174/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 175/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 0.5158 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 176/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 177/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5097 - val_accuracy: 0.7829\n",
      "Epoch 178/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 179/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 180/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 181/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.5157 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 182/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 183/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 184/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 185/200\n",
      "172/172 [==============================] - 0s 962us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 186/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 187/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 188/200\n",
      "172/172 [==============================] - 0s 928us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 189/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 190/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 191/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 932us/sample - loss: 0.5158 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 192/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 193/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.5177 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 194/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 195/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 196/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 197/200\n",
      "172/172 [==============================] - 0s 937us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 198/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 199/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 200/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Beginning training for dr=0.010, l_lambda=1.0e-02, reg_type=l2\n",
      "Train on 172 samples, validate on 43 samples\n",
      "Epoch 1/200\n",
      "172/172 [==============================] - 1s 9ms/sample - loss: 0.8855 - accuracy: 0.6667 - val_loss: 0.7628 - val_accuracy: 0.6667\n",
      "Epoch 2/200\n",
      "172/172 [==============================] - 0s 956us/sample - loss: 0.7104 - accuracy: 0.6667 - val_loss: 0.6582 - val_accuracy: 0.6667\n",
      "Epoch 3/200\n",
      "172/172 [==============================] - 0s 945us/sample - loss: 0.6287 - accuracy: 0.7151 - val_loss: 0.5906 - val_accuracy: 0.7829\n",
      "Epoch 4/200\n",
      "172/172 [==============================] - 0s 963us/sample - loss: 0.5758 - accuracy: 0.7791 - val_loss: 0.5542 - val_accuracy: 0.7829\n",
      "Epoch 5/200\n",
      "172/172 [==============================] - 0s 967us/sample - loss: 0.5548 - accuracy: 0.7791 - val_loss: 0.5358 - val_accuracy: 0.7829\n",
      "Epoch 6/200\n",
      "172/172 [==============================] - 0s 956us/sample - loss: 0.5369 - accuracy: 0.7791 - val_loss: 0.5244 - val_accuracy: 0.7829\n",
      "Epoch 7/200\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 0.5262 - accuracy: 0.7791 - val_loss: 0.5170 - val_accuracy: 0.7829\n",
      "Epoch 8/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.5209 - accuracy: 0.7791 - val_loss: 0.5116 - val_accuracy: 0.7829\n",
      "Epoch 9/200\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 0.5168 - accuracy: 0.7791 - val_loss: 0.5081 - val_accuracy: 0.7829\n",
      "Epoch 10/200\n",
      "172/172 [==============================] - 0s 960us/sample - loss: 0.5139 - accuracy: 0.7791 - val_loss: 0.5058 - val_accuracy: 0.7829\n",
      "Epoch 11/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.5131 - accuracy: 0.7791 - val_loss: 0.5047 - val_accuracy: 0.7829\n",
      "Epoch 12/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.5121 - accuracy: 0.7791 - val_loss: 0.5038 - val_accuracy: 0.7829\n",
      "Epoch 13/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5030 - val_accuracy: 0.7829\n",
      "Epoch 14/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5029 - val_accuracy: 0.7829\n",
      "Epoch 15/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 16/200\n",
      "172/172 [==============================] - 0s 970us/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5035 - val_accuracy: 0.7829\n",
      "Epoch 17/200\n",
      "172/172 [==============================] - 0s 928us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 18/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 19/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 20/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.5105 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 21/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 22/200\n",
      "172/172 [==============================] - 0s 984us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 23/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 24/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 25/200\n",
      "172/172 [==============================] - 0s 937us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 26/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 27/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 28/200\n",
      "172/172 [==============================] - 0s 992us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 29/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.5104 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 30/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 31/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 32/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 33/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 34/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 35/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5107 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 36/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 37/200\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 38/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 39/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 40/200\n",
      "172/172 [==============================] - 0s 947us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 41/200\n",
      "172/172 [==============================] - 0s 943us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5014 - val_accuracy: 0.7829\n",
      "Epoch 42/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.5106 - accuracy: 0.7791 - val_loss: 0.5026 - val_accuracy: 0.7829\n",
      "Epoch 43/200\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 44/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 45/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/200\n",
      "172/172 [==============================] - 0s 990us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 47/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 48/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 49/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 50/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5014 - val_accuracy: 0.7829\n",
      "Epoch 51/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5014 - val_accuracy: 0.7829\n",
      "Epoch 52/200\n",
      "172/172 [==============================] - 0s 979us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 53/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 54/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.5107 - accuracy: 0.7791 - val_loss: 0.5031 - val_accuracy: 0.7829\n",
      "Epoch 55/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.5118 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 56/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5026 - val_accuracy: 0.7829\n",
      "Epoch 57/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5026 - val_accuracy: 0.7829\n",
      "Epoch 58/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 59/200\n",
      "172/172 [==============================] - 0s 951us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 60/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 61/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5102 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 62/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 63/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 64/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 65/200\n",
      "172/172 [==============================] - 0s 972us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5029 - val_accuracy: 0.7829\n",
      "Epoch 66/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 67/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 68/200\n",
      "172/172 [==============================] - 0s 937us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 69/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 70/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 71/200\n",
      "172/172 [==============================] - 0s 974us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 72/200\n",
      "172/172 [==============================] - 0s 955us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 73/200\n",
      "172/172 [==============================] - 0s 937us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 74/200\n",
      "172/172 [==============================] - 0s 992us/sample - loss: 0.5085 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 75/200\n",
      "172/172 [==============================] - 0s 940us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5028 - val_accuracy: 0.7829\n",
      "Epoch 76/200\n",
      "172/172 [==============================] - 0s 937us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 77/200\n",
      "172/172 [==============================] - 0s 966us/sample - loss: 0.5113 - accuracy: 0.7791 - val_loss: 0.5030 - val_accuracy: 0.7829\n",
      "Epoch 78/200\n",
      "172/172 [==============================] - 0s 949us/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 79/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 80/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.5105 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 81/200\n",
      "172/172 [==============================] - 0s 940us/sample - loss: 0.5086 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 82/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5028 - val_accuracy: 0.7829\n",
      "Epoch 83/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5028 - val_accuracy: 0.7829\n",
      "Epoch 84/200\n",
      "172/172 [==============================] - 0s 979us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5031 - val_accuracy: 0.7829\n",
      "Epoch 85/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5029 - val_accuracy: 0.7829\n",
      "Epoch 86/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 87/200\n",
      "172/172 [==============================] - 0s 995us/sample - loss: 0.5086 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 88/200\n",
      "172/172 [==============================] - 0s 953us/sample - loss: 0.5106 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 89/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 90/200\n",
      "172/172 [==============================] - 0s 970us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 91/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 92/200\n",
      "172/172 [==============================] - 0s 937us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 93/200\n",
      "172/172 [==============================] - 0s 982us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 94/200\n",
      "172/172 [==============================] - 0s 960us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 95/200\n",
      "172/172 [==============================] - 0s 946us/sample - loss: 0.5110 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 96/200\n",
      "172/172 [==============================] - 0s 999us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 97/200\n",
      "172/172 [==============================] - 0s 990us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 98/200\n",
      "172/172 [==============================] - 0s 958us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 99/200\n",
      "172/172 [==============================] - 0s 975us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 100/200\n",
      "172/172 [==============================] - 0s 953us/sample - loss: 0.5104 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 101/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 970us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 102/200\n",
      "172/172 [==============================] - 0s 969us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 103/200\n",
      "172/172 [==============================] - 0s 975us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 104/200\n",
      "172/172 [==============================] - 0s 952us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 105/200\n",
      "172/172 [==============================] - 0s 952us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 106/200\n",
      "172/172 [==============================] - 0s 958us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 107/200\n",
      "172/172 [==============================] - 0s 965us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 108/200\n",
      "172/172 [==============================] - 0s 959us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 109/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 110/200\n",
      "172/172 [==============================] - 0s 963us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 111/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5014 - val_accuracy: 0.7829\n",
      "Epoch 112/200\n",
      "172/172 [==============================] - 0s 969us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 113/200\n",
      "172/172 [==============================] - 0s 953us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 114/200\n",
      "172/172 [==============================] - 0s 963us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 115/200\n",
      "172/172 [==============================] - 0s 978us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 116/200\n",
      "172/172 [==============================] - 0s 962us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 117/200\n",
      "172/172 [==============================] - 0s 960us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 118/200\n",
      "172/172 [==============================] - 0s 986us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 119/200\n",
      "172/172 [==============================] - 0s 953us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 120/200\n",
      "172/172 [==============================] - 0s 956us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 121/200\n",
      "172/172 [==============================] - 0s 975us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 122/200\n",
      "172/172 [==============================] - 0s 966us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 123/200\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 124/200\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 125/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.5105 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 126/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 127/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 128/200\n",
      "172/172 [==============================] - 0s 952us/sample - loss: 0.5086 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 129/200\n",
      "172/172 [==============================] - 0s 945us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 130/200\n",
      "172/172 [==============================] - 0s 930us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 131/200\n",
      "172/172 [==============================] - 0s 928us/sample - loss: 0.5104 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 132/200\n",
      "172/172 [==============================] - 0s 940us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 133/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 134/200\n",
      "172/172 [==============================] - 0s 987us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 135/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 136/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 137/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 138/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 139/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.5083 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 140/200\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 141/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 142/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 143/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 144/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 145/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 146/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 147/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 148/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5030 - val_accuracy: 0.7829\n",
      "Epoch 149/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 150/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 151/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 152/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5026 - val_accuracy: 0.7829\n",
      "Epoch 153/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 154/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 155/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 156/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 911us/sample - loss: 0.5129 - accuracy: 0.7791 - val_loss: 0.5036 - val_accuracy: 0.7829\n",
      "Epoch 157/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 158/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 159/200\n",
      "172/172 [==============================] - 0s 949us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 160/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 161/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 162/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 163/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 164/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 165/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 166/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 167/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5014 - val_accuracy: 0.7829\n",
      "Epoch 168/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5014 - val_accuracy: 0.7829\n",
      "Epoch 169/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 170/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 171/200\n",
      "172/172 [==============================] - 0s 958us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 172/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 173/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 174/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 175/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 176/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 177/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.5105 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 178/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 179/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 180/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 181/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5013 - val_accuracy: 0.7829\n",
      "Epoch 182/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 183/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 184/200\n",
      "172/172 [==============================] - 0s 941us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 185/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 186/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 187/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 188/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 189/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 190/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 191/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 192/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5105 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 193/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 194/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 195/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.5085 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 196/200\n",
      "172/172 [==============================] - 0s 958us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 197/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 198/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.5086 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 199/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 200/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Beginning training for dr=0.010, l_lambda=1.0e-02, reg_type=l1\n",
      "Train on 172 samples, validate on 43 samples\n",
      "Epoch 1/200\n",
      "172/172 [==============================] - 2s 9ms/sample - loss: 7.6852 - accuracy: 0.6667 - val_loss: 4.1354 - val_accuracy: 0.6667\n",
      "Epoch 2/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 2.8682 - accuracy: 0.6667 - val_loss: 2.1813 - val_accuracy: 0.6667\n",
      "Epoch 3/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.8089 - accuracy: 0.6822 - val_loss: 1.4877 - val_accuracy: 0.7829\n",
      "Epoch 4/200\n",
      "172/172 [==============================] - 0s 963us/sample - loss: 1.3314 - accuracy: 0.7791 - val_loss: 1.1632 - val_accuracy: 0.7829\n",
      "Epoch 5/200\n",
      "172/172 [==============================] - 0s 952us/sample - loss: 1.0714 - accuracy: 0.7791 - val_loss: 0.9580 - val_accuracy: 0.7829\n",
      "Epoch 6/200\n",
      "172/172 [==============================] - 0s 946us/sample - loss: 0.8904 - accuracy: 0.7791 - val_loss: 0.8052 - val_accuracy: 0.7829\n",
      "Epoch 7/200\n",
      "172/172 [==============================] - 0s 959us/sample - loss: 0.7585 - accuracy: 0.7791 - val_loss: 0.6955 - val_accuracy: 0.7829\n",
      "Epoch 8/200\n",
      "172/172 [==============================] - 0s 972us/sample - loss: 0.6622 - accuracy: 0.7791 - val_loss: 0.6188 - val_accuracy: 0.7829\n",
      "Epoch 9/200\n",
      "172/172 [==============================] - 0s 993us/sample - loss: 0.6056 - accuracy: 0.7791 - val_loss: 0.5848 - val_accuracy: 0.7829\n",
      "Epoch 10/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 969us/sample - loss: 0.5875 - accuracy: 0.7791 - val_loss: 0.5781 - val_accuracy: 0.7829\n",
      "Epoch 11/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 0.5845 - accuracy: 0.7791 - val_loss: 0.5767 - val_accuracy: 0.7829\n",
      "Epoch 12/200\n",
      "172/172 [==============================] - 0s 930us/sample - loss: 0.5838 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 13/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 14/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 15/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5769 - val_accuracy: 0.7829\n",
      "Epoch 16/200\n",
      "172/172 [==============================] - 0s 947us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 17/200\n",
      "172/172 [==============================] - 0s 946us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 18/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 19/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 20/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 21/200\n",
      "172/172 [==============================] - 0s 995us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5768 - val_accuracy: 0.7829\n",
      "Epoch 22/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 23/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5772 - val_accuracy: 0.7829\n",
      "Epoch 24/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 25/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5775 - val_accuracy: 0.7829\n",
      "Epoch 26/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 0.5836 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 27/200\n",
      "172/172 [==============================] - 0s 953us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5771 - val_accuracy: 0.7829\n",
      "Epoch 28/200\n",
      "172/172 [==============================] - 0s 968us/sample - loss: 0.5834 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 29/200\n",
      "172/172 [==============================] - 0s 928us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 30/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.5818 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 31/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 32/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 33/200\n",
      "172/172 [==============================] - 0s 997us/sample - loss: 0.5820 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 34/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 35/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5781 - val_accuracy: 0.7829\n",
      "Epoch 36/200\n",
      "172/172 [==============================] - 0s 937us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 37/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5768 - val_accuracy: 0.7829\n",
      "Epoch 38/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 39/200\n",
      "172/172 [==============================] - 0s 945us/sample - loss: 0.5819 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 40/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 41/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 42/200\n",
      "172/172 [==============================] - 0s 940us/sample - loss: 0.5832 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 43/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5775 - val_accuracy: 0.7829\n",
      "Epoch 44/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 45/200\n",
      "172/172 [==============================] - 0s 981us/sample - loss: 0.5841 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 46/200\n",
      "172/172 [==============================] - 0s 947us/sample - loss: 0.5820 - accuracy: 0.7791 - val_loss: 0.5771 - val_accuracy: 0.7829\n",
      "Epoch 47/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 48/200\n",
      "172/172 [==============================] - 0s 953us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 49/200\n",
      "172/172 [==============================] - 0s 960us/sample - loss: 0.5820 - accuracy: 0.7791 - val_loss: 0.5767 - val_accuracy: 0.7829\n",
      "Epoch 50/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.5849 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 51/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.5835 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 52/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 53/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5769 - val_accuracy: 0.7829\n",
      "Epoch 54/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 55/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 0.5833 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 56/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 57/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5767 - val_accuracy: 0.7829\n",
      "Epoch 58/200\n",
      "172/172 [==============================] - 0s 960us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 59/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 60/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 61/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 0.5818 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 62/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 63/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.5817 - accuracy: 0.7791 - val_loss: 0.5777 - val_accuracy: 0.7829\n",
      "Epoch 64/200\n",
      "172/172 [==============================] - 0s 944us/sample - loss: 0.5834 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 65/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 939us/sample - loss: 0.5816 - accuracy: 0.7791 - val_loss: 0.5768 - val_accuracy: 0.7829\n",
      "Epoch 66/200\n",
      "172/172 [==============================] - 0s 957us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 67/200\n",
      "172/172 [==============================] - 0s 954us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 68/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 69/200\n",
      "172/172 [==============================] - 0s 944us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 70/200\n",
      "172/172 [==============================] - 0s 980us/sample - loss: 0.5818 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 71/200\n",
      "172/172 [==============================] - 0s 953us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 72/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 0.5818 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 73/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 74/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 0.5819 - accuracy: 0.7791 - val_loss: 0.5768 - val_accuracy: 0.7829\n",
      "Epoch 75/200\n",
      "172/172 [==============================] - 0s 928us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 76/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.5834 - accuracy: 0.7791 - val_loss: 0.5770 - val_accuracy: 0.7829\n",
      "Epoch 77/200\n",
      "172/172 [==============================] - 0s 945us/sample - loss: 0.5832 - accuracy: 0.7791 - val_loss: 0.5785 - val_accuracy: 0.7829\n",
      "Epoch 78/200\n",
      "172/172 [==============================] - 0s 942us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5767 - val_accuracy: 0.7829\n",
      "Epoch 79/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5773 - val_accuracy: 0.7829\n",
      "Epoch 80/200\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 81/200\n",
      "172/172 [==============================] - 0s 940us/sample - loss: 0.5842 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 82/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 83/200\n",
      "172/172 [==============================] - 0s 976us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5771 - val_accuracy: 0.7829\n",
      "Epoch 84/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 85/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 86/200\n",
      "172/172 [==============================] - 0s 952us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 87/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 88/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 0.5819 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 89/200\n",
      "172/172 [==============================] - 0s 964us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 90/200\n",
      "172/172 [==============================] - 0s 976us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 91/200\n",
      "172/172 [==============================] - 0s 960us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5777 - val_accuracy: 0.7829\n",
      "Epoch 92/200\n",
      "172/172 [==============================] - 0s 981us/sample - loss: 0.5832 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 93/200\n",
      "172/172 [==============================] - 0s 954us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5770 - val_accuracy: 0.7829\n",
      "Epoch 94/200\n",
      "172/172 [==============================] - 0s 960us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 95/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5773 - val_accuracy: 0.7829\n",
      "Epoch 96/200\n",
      "172/172 [==============================] - 0s 982us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 97/200\n",
      "172/172 [==============================] - 0s 959us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 98/200\n",
      "172/172 [==============================] - 0s 965us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 99/200\n",
      "172/172 [==============================] - 0s 961us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 100/200\n",
      "172/172 [==============================] - 0s 968us/sample - loss: 0.5820 - accuracy: 0.7791 - val_loss: 0.5769 - val_accuracy: 0.7829\n",
      "Epoch 101/200\n",
      "172/172 [==============================] - 0s 991us/sample - loss: 0.5834 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 102/200\n",
      "172/172 [==============================] - 0s 985us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 103/200\n",
      "172/172 [==============================] - 0s 958us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 104/200\n",
      "172/172 [==============================] - 0s 980us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 105/200\n",
      "172/172 [==============================] - 0s 963us/sample - loss: 0.5817 - accuracy: 0.7791 - val_loss: 0.5779 - val_accuracy: 0.7829\n",
      "Epoch 106/200\n",
      "172/172 [==============================] - 0s 973us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 107/200\n",
      "172/172 [==============================] - 0s 964us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5776 - val_accuracy: 0.7829\n",
      "Epoch 108/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5833 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 109/200\n",
      "172/172 [==============================] - 0s 958us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 110/200\n",
      "172/172 [==============================] - 0s 959us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5752 - val_accuracy: 0.7829\n",
      "Epoch 111/200\n",
      "172/172 [==============================] - 0s 986us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 112/200\n",
      "172/172 [==============================] - 0s 964us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 113/200\n",
      "172/172 [==============================] - 0s 963us/sample - loss: 0.5820 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 114/200\n",
      "172/172 [==============================] - 0s 993us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 115/200\n",
      "172/172 [==============================] - 0s 960us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 116/200\n",
      "172/172 [==============================] - 0s 959us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 117/200\n",
      "172/172 [==============================] - 0s 982us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 118/200\n",
      "172/172 [==============================] - 0s 965us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 119/200\n",
      "172/172 [==============================] - 0s 953us/sample - loss: 0.5858 - accuracy: 0.7791 - val_loss: 0.5768 - val_accuracy: 0.7829\n",
      "Epoch 120/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 991us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 121/200\n",
      "172/172 [==============================] - 0s 954us/sample - loss: 0.5832 - accuracy: 0.7791 - val_loss: 0.5774 - val_accuracy: 0.7829\n",
      "Epoch 122/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.5834 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 123/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 124/200\n",
      "172/172 [==============================] - 0s 988us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5769 - val_accuracy: 0.7829\n",
      "Epoch 125/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 0.5817 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 126/200\n",
      "172/172 [==============================] - 0s 943us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 127/200\n",
      "172/172 [==============================] - 0s 943us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5769 - val_accuracy: 0.7829\n",
      "Epoch 128/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 129/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 130/200\n",
      "172/172 [==============================] - 0s 941us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 131/200\n",
      "172/172 [==============================] - 0s 937us/sample - loss: 0.5844 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 132/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.5844 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 133/200\n",
      "172/172 [==============================] - 0s 986us/sample - loss: 0.5819 - accuracy: 0.7791 - val_loss: 0.5772 - val_accuracy: 0.7829\n",
      "Epoch 134/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.5837 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 135/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.5832 - accuracy: 0.7791 - val_loss: 0.5777 - val_accuracy: 0.7829\n",
      "Epoch 136/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5748 - val_accuracy: 0.7829\n",
      "Epoch 137/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 138/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 139/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 140/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 141/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5752 - val_accuracy: 0.7829\n",
      "Epoch 142/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 0.5818 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 143/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 0.5851 - accuracy: 0.7791 - val_loss: 0.5772 - val_accuracy: 0.7829\n",
      "Epoch 144/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.5819 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 145/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 146/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5751 - val_accuracy: 0.7829\n",
      "Epoch 147/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.5851 - accuracy: 0.7791 - val_loss: 0.5782 - val_accuracy: 0.7829\n",
      "Epoch 148/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 149/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 150/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 151/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 152/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.5832 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 153/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 154/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 155/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.5820 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 156/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 157/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 158/200\n",
      "172/172 [==============================] - 0s 973us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 159/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 160/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 161/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 0.5819 - accuracy: 0.7791 - val_loss: 0.5768 - val_accuracy: 0.7829\n",
      "Epoch 162/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 163/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.5820 - accuracy: 0.7791 - val_loss: 0.5772 - val_accuracy: 0.7829\n",
      "Epoch 164/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 165/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.5817 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 166/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 167/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.5834 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 168/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 169/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5767 - val_accuracy: 0.7829\n",
      "Epoch 170/200\n",
      "172/172 [==============================] - 0s 942us/sample - loss: 0.5818 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 171/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 0.5835 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 172/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 173/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 174/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5832 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 175/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5782 - val_accuracy: 0.7829\n",
      "Epoch 176/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 177/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5768 - val_accuracy: 0.7829\n",
      "Epoch 178/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 179/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 180/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 181/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 0.5819 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 182/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 183/200\n",
      "172/172 [==============================] - 0s 988us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5767 - val_accuracy: 0.7829\n",
      "Epoch 184/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 185/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 186/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 187/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 188/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5752 - val_accuracy: 0.7829\n",
      "Epoch 189/200\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 0.5834 - accuracy: 0.7791 - val_loss: 0.5772 - val_accuracy: 0.7829\n",
      "Epoch 190/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 191/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.5833 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 192/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 193/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.5818 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 194/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 195/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5817 - accuracy: 0.7791 - val_loss: 0.5770 - val_accuracy: 0.7829\n",
      "Epoch 196/200\n",
      "172/172 [==============================] - 0s 958us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 197/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 198/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.5819 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 199/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 200/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 0.5820 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Beginning training for dr=0.010, l_lambda=1.0e-01, reg_type=l2\n",
      "Train on 172 samples, validate on 43 samples\n",
      "Epoch 1/200\n",
      "172/172 [==============================] - 2s 10ms/sample - loss: 3.2958 - accuracy: 0.6667 - val_loss: 2.2412 - val_accuracy: 0.6667\n",
      "Epoch 2/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 1.8795 - accuracy: 0.6667 - val_loss: 1.5656 - val_accuracy: 0.6667\n",
      "Epoch 3/200\n",
      "172/172 [==============================] - 0s 954us/sample - loss: 1.4001 - accuracy: 0.6996 - val_loss: 1.2160 - val_accuracy: 0.7829\n",
      "Epoch 4/200\n",
      "172/172 [==============================] - 0s 946us/sample - loss: 1.0999 - accuracy: 0.7791 - val_loss: 0.9732 - val_accuracy: 0.7829\n",
      "Epoch 5/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 0.9015 - accuracy: 0.7791 - val_loss: 0.8145 - val_accuracy: 0.7829\n",
      "Epoch 6/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.7700 - accuracy: 0.7791 - val_loss: 0.7084 - val_accuracy: 0.7829\n",
      "Epoch 7/200\n",
      "172/172 [==============================] - 0s 937us/sample - loss: 0.6811 - accuracy: 0.7791 - val_loss: 0.6354 - val_accuracy: 0.7829\n",
      "Epoch 8/200\n",
      "172/172 [==============================] - 0s 940us/sample - loss: 0.6189 - accuracy: 0.7791 - val_loss: 0.5872 - val_accuracy: 0.7829\n",
      "Epoch 9/200\n",
      "172/172 [==============================] - 0s 964us/sample - loss: 0.5786 - accuracy: 0.7791 - val_loss: 0.5554 - val_accuracy: 0.7829\n",
      "Epoch 10/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.5518 - accuracy: 0.7791 - val_loss: 0.5357 - val_accuracy: 0.7829\n",
      "Epoch 11/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.5359 - accuracy: 0.7791 - val_loss: 0.5225 - val_accuracy: 0.7829\n",
      "Epoch 12/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.5250 - accuracy: 0.7791 - val_loss: 0.5136 - val_accuracy: 0.7829\n",
      "Epoch 13/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.5191 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 14/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.5142 - accuracy: 0.7791 - val_loss: 0.5056 - val_accuracy: 0.7829\n",
      "Epoch 15/200\n",
      "172/172 [==============================] - 0s 967us/sample - loss: 0.5123 - accuracy: 0.7791 - val_loss: 0.5038 - val_accuracy: 0.7829\n",
      "Epoch 16/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5032 - val_accuracy: 0.7829\n",
      "Epoch 17/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5026 - val_accuracy: 0.7829\n",
      "Epoch 18/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 19/200\n",
      "172/172 [==============================] - 0s 952us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 20/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5026 - val_accuracy: 0.7829\n",
      "Epoch 21/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 22/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 23/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 24/200\n",
      "172/172 [==============================] - 0s 970us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 25/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 26/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5033 - val_accuracy: 0.7829\n",
      "Epoch 27/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 28/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.5104 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 29/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 889us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 30/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 31/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 32/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 33/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 34/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 35/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 36/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 37/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 38/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 39/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 40/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 41/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 42/200\n",
      "172/172 [==============================] - 0s 869us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 43/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 0.5085 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 44/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 45/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 46/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 47/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 48/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 49/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 50/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 51/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 52/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 53/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 54/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 55/200\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 56/200\n",
      "172/172 [==============================] - 0s 991us/sample - loss: 0.5105 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 57/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 58/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 59/200\n",
      "172/172 [==============================] - 0s 949us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 60/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 61/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 0.5086 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 62/200\n",
      "172/172 [==============================] - 0s 946us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 63/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 64/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 65/200\n",
      "172/172 [==============================] - 0s 943us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 66/200\n",
      "172/172 [==============================] - 0s 944us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 67/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 68/200\n",
      "172/172 [==============================] - 0s 958us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 69/200\n",
      "172/172 [==============================] - 0s 947us/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5028 - val_accuracy: 0.7829\n",
      "Epoch 70/200\n",
      "172/172 [==============================] - 0s 941us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 71/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 72/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 73/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 74/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 75/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 76/200\n",
      "172/172 [==============================] - 0s 958us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 77/200\n",
      "172/172 [==============================] - 0s 955us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 78/200\n",
      "172/172 [==============================] - 0s 975us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 79/200\n",
      "172/172 [==============================] - 0s 957us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 80/200\n",
      "172/172 [==============================] - 0s 963us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 81/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 82/200\n",
      "172/172 [==============================] - 0s 947us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 83/200\n",
      "172/172 [==============================] - 0s 952us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 84/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 970us/sample - loss: 0.5102 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 85/200\n",
      "172/172 [==============================] - 0s 949us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 86/200\n",
      "172/172 [==============================] - 0s 947us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 87/200\n",
      "172/172 [==============================] - 0s 963us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 88/200\n",
      "172/172 [==============================] - 0s 954us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 89/200\n",
      "172/172 [==============================] - 0s 948us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 90/200\n",
      "172/172 [==============================] - 0s 991us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 91/200\n",
      "172/172 [==============================] - 0s 957us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 92/200\n",
      "172/172 [==============================] - 0s 966us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 93/200\n",
      "172/172 [==============================] - 0s 973us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 94/200\n",
      "172/172 [==============================] - 0s 977us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 95/200\n",
      "172/172 [==============================] - 0s 964us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 96/200\n",
      "172/172 [==============================] - 0s 974us/sample - loss: 0.5116 - accuracy: 0.7791 - val_loss: 0.5029 - val_accuracy: 0.7829\n",
      "Epoch 97/200\n",
      "172/172 [==============================] - 0s 953us/sample - loss: 0.5102 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 98/200\n",
      "172/172 [==============================] - 0s 957us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 99/200\n",
      "172/172 [==============================] - 0s 952us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 100/200\n",
      "172/172 [==============================] - 0s 979us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 101/200\n",
      "172/172 [==============================] - 0s 969us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 102/200\n",
      "172/172 [==============================] - 0s 978us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 103/200\n",
      "172/172 [==============================] - 0s 955us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 104/200\n",
      "172/172 [==============================] - 0s 944us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 105/200\n",
      "172/172 [==============================] - 0s 949us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 106/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 107/200\n",
      "172/172 [==============================] - 0s 962us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 108/200\n",
      "172/172 [==============================] - 0s 941us/sample - loss: 0.5086 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 109/200\n",
      "172/172 [==============================] - 0s 966us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 110/200\n",
      "172/172 [==============================] - 0s 955us/sample - loss: 0.5117 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 111/200\n",
      "172/172 [==============================] - 0s 967us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 112/200\n",
      "172/172 [==============================] - 0s 946us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 113/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 114/200\n",
      "172/172 [==============================] - 0s 942us/sample - loss: 0.5104 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 115/200\n",
      "172/172 [==============================] - 0s 948us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 116/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.5105 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 117/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 118/200\n",
      "172/172 [==============================] - 0s 943us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 119/200\n",
      "172/172 [==============================] - 0s 966us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 120/200\n",
      "172/172 [==============================] - 0s 928us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 121/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 122/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 123/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 124/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.5104 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 125/200\n",
      "172/172 [==============================] - 0s 942us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 126/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 127/200\n",
      "172/172 [==============================] - 0s 928us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 128/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 129/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 130/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 131/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 132/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 133/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 134/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 135/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 0.5086 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 136/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 137/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 138/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.5111 - accuracy: 0.7791 - val_loss: 0.5026 - val_accuracy: 0.7829\n",
      "Epoch 139/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 925us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 140/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 141/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 142/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 143/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 144/200\n",
      "172/172 [==============================] - 0s 942us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 145/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 146/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 147/200\n",
      "172/172 [==============================] - 0s 963us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 148/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 149/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 150/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 151/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 152/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 153/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 154/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 155/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 156/200\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 157/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 158/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 159/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 160/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 161/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 162/200\n",
      "172/172 [==============================] - 0s 957us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 163/200\n",
      "172/172 [==============================] - 0s 930us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 164/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 165/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 166/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 167/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 168/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 169/200\n",
      "172/172 [==============================] - 0s 952us/sample - loss: 0.5106 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 170/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 171/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 172/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.5086 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 173/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 174/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 175/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5086 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 176/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 177/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 178/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 179/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 180/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 181/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 182/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 183/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 184/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5034 - val_accuracy: 0.7829\n",
      "Epoch 185/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 0.5109 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 186/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5026 - val_accuracy: 0.7829\n",
      "Epoch 187/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 188/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 189/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.5110 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 190/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.5086 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 191/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 192/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.5108 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 193/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 194/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 947us/sample - loss: 0.5102 - accuracy: 0.7791 - val_loss: 0.5026 - val_accuracy: 0.7829\n",
      "Epoch 195/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.5113 - accuracy: 0.7791 - val_loss: 0.5036 - val_accuracy: 0.7829\n",
      "Epoch 196/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 197/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 198/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 199/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 200/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Beginning training for dr=0.010, l_lambda=1.0e-01, reg_type=l1\n",
      "Train on 172 samples, validate on 43 samples\n",
      "Epoch 1/200\n",
      "172/172 [==============================] - 1s 9ms/sample - loss: 71.1577 - accuracy: 0.6667 - val_loss: 35.9008 - val_accuracy: 0.6667\n",
      "Epoch 2/200\n",
      "172/172 [==============================] - 0s 979us/sample - loss: 23.4134 - accuracy: 0.6667 - val_loss: 16.7729 - val_accuracy: 0.6667\n",
      "Epoch 3/200\n",
      "172/172 [==============================] - 0s 951us/sample - loss: 13.2230 - accuracy: 0.6705 - val_loss: 10.2515 - val_accuracy: 0.7829\n",
      "Epoch 4/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 8.7326 - accuracy: 0.7791 - val_loss: 7.1843 - val_accuracy: 0.7829\n",
      "Epoch 5/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 6.2190 - accuracy: 0.7791 - val_loss: 5.1515 - val_accuracy: 0.7829\n",
      "Epoch 6/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 4.4194 - accuracy: 0.7791 - val_loss: 3.5797 - val_accuracy: 0.7829\n",
      "Epoch 7/200\n",
      "172/172 [==============================] - 0s 947us/sample - loss: 3.0376 - accuracy: 0.7791 - val_loss: 2.4582 - val_accuracy: 0.7829\n",
      "Epoch 8/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 2.0650 - accuracy: 0.7791 - val_loss: 1.6761 - val_accuracy: 0.7829\n",
      "Epoch 9/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 1.4849 - accuracy: 0.7791 - val_loss: 1.3264 - val_accuracy: 0.7829\n",
      "Epoch 10/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 1.2963 - accuracy: 0.7791 - val_loss: 1.2587 - val_accuracy: 0.7829\n",
      "Epoch 11/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 1.2562 - accuracy: 0.7791 - val_loss: 1.2477 - val_accuracy: 0.7829\n",
      "Epoch 12/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 1.2495 - accuracy: 0.7791 - val_loss: 1.2394 - val_accuracy: 0.7829\n",
      "Epoch 13/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 1.2403 - accuracy: 0.7791 - val_loss: 1.2491 - val_accuracy: 0.7829\n",
      "Epoch 14/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 1.2434 - accuracy: 0.7791 - val_loss: 1.2458 - val_accuracy: 0.7829\n",
      "Epoch 15/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 1.2442 - accuracy: 0.7791 - val_loss: 1.2536 - val_accuracy: 0.7829\n",
      "Epoch 16/200\n",
      "172/172 [==============================] - 0s 941us/sample - loss: 1.2435 - accuracy: 0.7791 - val_loss: 1.2411 - val_accuracy: 0.7829\n",
      "Epoch 17/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 1.2437 - accuracy: 0.7791 - val_loss: 1.2417 - val_accuracy: 0.7829\n",
      "Epoch 18/200\n",
      "172/172 [==============================] - 0s 957us/sample - loss: 1.2414 - accuracy: 0.7791 - val_loss: 1.2454 - val_accuracy: 0.7829\n",
      "Epoch 19/200\n",
      "172/172 [==============================] - 0s 988us/sample - loss: 1.2446 - accuracy: 0.7791 - val_loss: 1.2429 - val_accuracy: 0.7829\n",
      "Epoch 20/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 1.2435 - accuracy: 0.7791 - val_loss: 1.2323 - val_accuracy: 0.7829\n",
      "Epoch 21/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 1.2427 - accuracy: 0.7791 - val_loss: 1.2476 - val_accuracy: 0.7829\n",
      "Epoch 22/200\n",
      "172/172 [==============================] - 0s 943us/sample - loss: 1.2433 - accuracy: 0.7791 - val_loss: 1.2419 - val_accuracy: 0.7829\n",
      "Epoch 23/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 1.2429 - accuracy: 0.7791 - val_loss: 1.2537 - val_accuracy: 0.7829\n",
      "Epoch 24/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 1.2455 - accuracy: 0.7791 - val_loss: 1.2407 - val_accuracy: 0.7829\n",
      "Epoch 25/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 1.2388 - accuracy: 0.7791 - val_loss: 1.2477 - val_accuracy: 0.7829\n",
      "Epoch 26/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 1.2488 - accuracy: 0.7791 - val_loss: 1.2342 - val_accuracy: 0.7829\n",
      "Epoch 27/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 1.2409 - accuracy: 0.7791 - val_loss: 1.2475 - val_accuracy: 0.7829\n",
      "Epoch 28/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 1.2448 - accuracy: 0.7791 - val_loss: 1.2414 - val_accuracy: 0.7829\n",
      "Epoch 29/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 1.2432 - accuracy: 0.7791 - val_loss: 1.2478 - val_accuracy: 0.7829\n",
      "Epoch 30/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 1.2407 - accuracy: 0.7791 - val_loss: 1.2430 - val_accuracy: 0.7829\n",
      "Epoch 31/200\n",
      "172/172 [==============================] - 0s 973us/sample - loss: 1.2484 - accuracy: 0.7791 - val_loss: 1.2398 - val_accuracy: 0.7829\n",
      "Epoch 32/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 1.2428 - accuracy: 0.7791 - val_loss: 1.2376 - val_accuracy: 0.7829\n",
      "Epoch 33/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 1.2406 - accuracy: 0.7791 - val_loss: 1.2446 - val_accuracy: 0.7829\n",
      "Epoch 34/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 1.2456 - accuracy: 0.7791 - val_loss: 1.2411 - val_accuracy: 0.7829\n",
      "Epoch 35/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 1.2402 - accuracy: 0.7791 - val_loss: 1.2588 - val_accuracy: 0.7829\n",
      "Epoch 36/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 1.2457 - accuracy: 0.7791 - val_loss: 1.2390 - val_accuracy: 0.7829\n",
      "Epoch 37/200\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 1.2428 - accuracy: 0.7791 - val_loss: 1.2471 - val_accuracy: 0.7829\n",
      "Epoch 38/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 1.2439 - accuracy: 0.7791 - val_loss: 1.2365 - val_accuracy: 0.7829\n",
      "Epoch 39/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 1.2412 - accuracy: 0.7791 - val_loss: 1.2479 - val_accuracy: 0.7829\n",
      "Epoch 40/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 1.2461 - accuracy: 0.7791 - val_loss: 1.2331 - val_accuracy: 0.7829\n",
      "Epoch 41/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 1.2417 - accuracy: 0.7791 - val_loss: 1.2390 - val_accuracy: 0.7829\n",
      "Epoch 42/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 1.2436 - accuracy: 0.7791 - val_loss: 1.2390 - val_accuracy: 0.7829\n",
      "Epoch 43/200\n",
      "172/172 [==============================] - 0s 944us/sample - loss: 1.2426 - accuracy: 0.7791 - val_loss: 1.2498 - val_accuracy: 0.7829\n",
      "Epoch 44/200\n",
      "172/172 [==============================] - 0s 941us/sample - loss: 1.2434 - accuracy: 0.7791 - val_loss: 1.2463 - val_accuracy: 0.7829\n",
      "Epoch 45/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 1.2428 - accuracy: 0.7791 - val_loss: 1.2395 - val_accuracy: 0.7829\n",
      "Epoch 46/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 1.2423 - accuracy: 0.7791 - val_loss: 1.2404 - val_accuracy: 0.7829\n",
      "Epoch 47/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 1.2450 - accuracy: 0.7791 - val_loss: 1.2474 - val_accuracy: 0.7829\n",
      "Epoch 48/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 1.2436 - accuracy: 0.7791 - val_loss: 1.2353 - val_accuracy: 0.7829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 1.2418 - accuracy: 0.7791 - val_loss: 1.2524 - val_accuracy: 0.7829\n",
      "Epoch 50/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 1.2429 - accuracy: 0.7791 - val_loss: 1.2421 - val_accuracy: 0.7829\n",
      "Epoch 51/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 1.2450 - accuracy: 0.7791 - val_loss: 1.2465 - val_accuracy: 0.7829\n",
      "Epoch 52/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 1.2455 - accuracy: 0.7791 - val_loss: 1.2387 - val_accuracy: 0.7829\n",
      "Epoch 53/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 1.2385 - accuracy: 0.7791 - val_loss: 1.2476 - val_accuracy: 0.7829\n",
      "Epoch 54/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 1.2476 - accuracy: 0.7791 - val_loss: 1.2369 - val_accuracy: 0.7829\n",
      "Epoch 55/200\n",
      "172/172 [==============================] - 0s 945us/sample - loss: 1.2383 - accuracy: 0.7791 - val_loss: 1.2465 - val_accuracy: 0.7829\n",
      "Epoch 56/200\n",
      "172/172 [==============================] - 0s 970us/sample - loss: 1.2453 - accuracy: 0.7791 - val_loss: 1.2420 - val_accuracy: 0.7829\n",
      "Epoch 57/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 1.2444 - accuracy: 0.7791 - val_loss: 1.2496 - val_accuracy: 0.7829\n",
      "Epoch 58/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 1.2412 - accuracy: 0.7791 - val_loss: 1.2464 - val_accuracy: 0.7829\n",
      "Epoch 59/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 1.2475 - accuracy: 0.7791 - val_loss: 1.2420 - val_accuracy: 0.7829\n",
      "Epoch 60/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 1.2421 - accuracy: 0.7791 - val_loss: 1.2370 - val_accuracy: 0.7829\n",
      "Epoch 61/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 1.2442 - accuracy: 0.7791 - val_loss: 1.2397 - val_accuracy: 0.7829\n",
      "Epoch 62/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 1.2432 - accuracy: 0.7791 - val_loss: 1.2350 - val_accuracy: 0.7829\n",
      "Epoch 63/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 1.2407 - accuracy: 0.7791 - val_loss: 1.2597 - val_accuracy: 0.7829\n",
      "Epoch 64/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 1.2473 - accuracy: 0.7791 - val_loss: 1.2412 - val_accuracy: 0.7829\n",
      "Epoch 65/200\n",
      "172/172 [==============================] - 0s 945us/sample - loss: 1.2401 - accuracy: 0.7791 - val_loss: 1.2472 - val_accuracy: 0.7829\n",
      "Epoch 66/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 1.2475 - accuracy: 0.7791 - val_loss: 1.2338 - val_accuracy: 0.7829\n",
      "Epoch 67/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 1.2396 - accuracy: 0.7791 - val_loss: 1.2481 - val_accuracy: 0.7829\n",
      "Epoch 68/200\n",
      "172/172 [==============================] - 0s 946us/sample - loss: 1.2473 - accuracy: 0.7791 - val_loss: 1.2354 - val_accuracy: 0.7829\n",
      "Epoch 69/200\n",
      "172/172 [==============================] - 0s 941us/sample - loss: 1.2411 - accuracy: 0.7791 - val_loss: 1.2439 - val_accuracy: 0.7829\n",
      "Epoch 70/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 1.2418 - accuracy: 0.7791 - val_loss: 1.2423 - val_accuracy: 0.7829\n",
      "Epoch 71/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 1.2484 - accuracy: 0.7791 - val_loss: 1.2457 - val_accuracy: 0.7829\n",
      "Epoch 72/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 1.2416 - accuracy: 0.7791 - val_loss: 1.2433 - val_accuracy: 0.7829\n",
      "Epoch 73/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 1.2437 - accuracy: 0.7791 - val_loss: 1.2439 - val_accuracy: 0.7829\n",
      "Epoch 74/200\n",
      "172/172 [==============================] - 0s 946us/sample - loss: 1.2429 - accuracy: 0.7791 - val_loss: 1.2432 - val_accuracy: 0.7829\n",
      "Epoch 75/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 1.2399 - accuracy: 0.7791 - val_loss: 1.2459 - val_accuracy: 0.7829\n",
      "Epoch 76/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 1.2488 - accuracy: 0.7791 - val_loss: 1.2330 - val_accuracy: 0.7829\n",
      "Epoch 77/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 1.2405 - accuracy: 0.7791 - val_loss: 1.2527 - val_accuracy: 0.7829\n",
      "Epoch 78/200\n",
      "172/172 [==============================] - 0s 968us/sample - loss: 1.2432 - accuracy: 0.7791 - val_loss: 1.2435 - val_accuracy: 0.7829\n",
      "Epoch 79/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 1.2431 - accuracy: 0.7791 - val_loss: 1.2482 - val_accuracy: 0.7829\n",
      "Epoch 80/200\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 1.2441 - accuracy: 0.7791 - val_loss: 1.2362 - val_accuracy: 0.7829\n",
      "Epoch 81/200\n",
      "172/172 [==============================] - 0s 959us/sample - loss: 1.2422 - accuracy: 0.7791 - val_loss: 1.2401 - val_accuracy: 0.7829\n",
      "Epoch 82/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 1.2453 - accuracy: 0.7791 - val_loss: 1.2365 - val_accuracy: 0.7829\n",
      "Epoch 83/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 1.2418 - accuracy: 0.7791 - val_loss: 1.2504 - val_accuracy: 0.7829\n",
      "Epoch 84/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 1.2435 - accuracy: 0.7791 - val_loss: 1.2430 - val_accuracy: 0.7829\n",
      "Epoch 85/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 1.2410 - accuracy: 0.7791 - val_loss: 1.2500 - val_accuracy: 0.7829\n",
      "Epoch 86/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 1.2447 - accuracy: 0.7791 - val_loss: 1.2447 - val_accuracy: 0.7829\n",
      "Epoch 87/200\n",
      "172/172 [==============================] - 0s 941us/sample - loss: 1.2440 - accuracy: 0.7791 - val_loss: 1.2432 - val_accuracy: 0.7829\n",
      "Epoch 88/200\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 1.2425 - accuracy: 0.7791 - val_loss: 1.2442 - val_accuracy: 0.7829\n",
      "Epoch 89/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 1.2441 - accuracy: 0.7791 - val_loss: 1.2403 - val_accuracy: 0.7829\n",
      "Epoch 90/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 1.2402 - accuracy: 0.7791 - val_loss: 1.2358 - val_accuracy: 0.7829\n",
      "Epoch 91/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 1.2450 - accuracy: 0.7791 - val_loss: 1.2541 - val_accuracy: 0.7829\n",
      "Epoch 92/200\n",
      "172/172 [==============================] - 0s 945us/sample - loss: 1.2446 - accuracy: 0.7791 - val_loss: 1.2384 - val_accuracy: 0.7829\n",
      "Epoch 93/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2410 - accuracy: 0.7791 - val_loss: 1.2486 - val_accuracy: 0.7829\n",
      "Epoch 94/200\n",
      "172/172 [==============================] - 0s 946us/sample - loss: 1.2452 - accuracy: 0.7791 - val_loss: 1.2377 - val_accuracy: 0.7829\n",
      "Epoch 95/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 1.2389 - accuracy: 0.7791 - val_loss: 1.2521 - val_accuracy: 0.7829\n",
      "Epoch 96/200\n",
      "172/172 [==============================] - 0s 954us/sample - loss: 1.2494 - accuracy: 0.7791 - val_loss: 1.2315 - val_accuracy: 0.7829\n",
      "Epoch 97/200\n",
      "172/172 [==============================] - 0s 944us/sample - loss: 1.2382 - accuracy: 0.7791 - val_loss: 1.2428 - val_accuracy: 0.7829\n",
      "Epoch 98/200\n",
      "172/172 [==============================] - 0s 953us/sample - loss: 1.2451 - accuracy: 0.7791 - val_loss: 1.2435 - val_accuracy: 0.7829\n",
      "Epoch 99/200\n",
      "172/172 [==============================] - 0s 965us/sample - loss: 1.2454 - accuracy: 0.7791 - val_loss: 1.2455 - val_accuracy: 0.7829\n",
      "Epoch 100/200\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 1.2406 - accuracy: 0.7791 - val_loss: 1.2460 - val_accuracy: 0.7829\n",
      "Epoch 101/200\n",
      "172/172 [==============================] - 0s 943us/sample - loss: 1.2475 - accuracy: 0.7791 - val_loss: 1.2372 - val_accuracy: 0.7829\n",
      "Epoch 102/200\n",
      "172/172 [==============================] - 0s 963us/sample - loss: 1.2421 - accuracy: 0.7791 - val_loss: 1.2426 - val_accuracy: 0.7829\n",
      "Epoch 103/200\n",
      "172/172 [==============================] - 0s 949us/sample - loss: 1.2436 - accuracy: 0.7791 - val_loss: 1.2490 - val_accuracy: 0.7829\n",
      "Epoch 104/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 939us/sample - loss: 1.2438 - accuracy: 0.7791 - val_loss: 1.2357 - val_accuracy: 0.7829\n",
      "Epoch 105/200\n",
      "172/172 [==============================] - 0s 972us/sample - loss: 1.2394 - accuracy: 0.7791 - val_loss: 1.2583 - val_accuracy: 0.7829\n",
      "Epoch 106/200\n",
      "172/172 [==============================] - 0s 964us/sample - loss: 1.2460 - accuracy: 0.7791 - val_loss: 1.2358 - val_accuracy: 0.7829\n",
      "Epoch 107/200\n",
      "172/172 [==============================] - 0s 949us/sample - loss: 1.2401 - accuracy: 0.7791 - val_loss: 1.2520 - val_accuracy: 0.7829\n",
      "Epoch 108/200\n",
      "172/172 [==============================] - 0s 946us/sample - loss: 1.2463 - accuracy: 0.7791 - val_loss: 1.2373 - val_accuracy: 0.7829\n",
      "Epoch 109/200\n",
      "172/172 [==============================] - 0s 942us/sample - loss: 1.2405 - accuracy: 0.7791 - val_loss: 1.2440 - val_accuracy: 0.7829\n",
      "Epoch 110/200\n",
      "172/172 [==============================] - 0s 940us/sample - loss: 1.2450 - accuracy: 0.7791 - val_loss: 1.2331 - val_accuracy: 0.7829\n",
      "Epoch 111/200\n",
      "172/172 [==============================] - 0s 943us/sample - loss: 1.2432 - accuracy: 0.7791 - val_loss: 1.2434 - val_accuracy: 0.7829\n",
      "Epoch 112/200\n",
      "172/172 [==============================] - 0s 960us/sample - loss: 1.2439 - accuracy: 0.7791 - val_loss: 1.2417 - val_accuracy: 0.7829\n",
      "Epoch 113/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 1.2427 - accuracy: 0.7791 - val_loss: 1.2486 - val_accuracy: 0.7829\n",
      "Epoch 114/200\n",
      "172/172 [==============================] - 0s 943us/sample - loss: 1.2407 - accuracy: 0.7791 - val_loss: 1.2476 - val_accuracy: 0.7829\n",
      "Epoch 115/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 1.2456 - accuracy: 0.7791 - val_loss: 1.2454 - val_accuracy: 0.7829\n",
      "Epoch 116/200\n",
      "172/172 [==============================] - 0s 956us/sample - loss: 1.2442 - accuracy: 0.7791 - val_loss: 1.2398 - val_accuracy: 0.7829\n",
      "Epoch 117/200\n",
      "172/172 [==============================] - 0s 983us/sample - loss: 1.2410 - accuracy: 0.7791 - val_loss: 1.2443 - val_accuracy: 0.7829\n",
      "Epoch 118/200\n",
      "172/172 [==============================] - 0s 980us/sample - loss: 1.2449 - accuracy: 0.7791 - val_loss: 1.2386 - val_accuracy: 0.7829\n",
      "Epoch 119/200\n",
      "172/172 [==============================] - 0s 954us/sample - loss: 1.2431 - accuracy: 0.7791 - val_loss: 1.2538 - val_accuracy: 0.7829\n",
      "Epoch 120/200\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 1.2444 - accuracy: 0.7791 - val_loss: 1.2378 - val_accuracy: 0.7829\n",
      "Epoch 121/200\n",
      "172/172 [==============================] - 0s 974us/sample - loss: 1.2430 - accuracy: 0.7791 - val_loss: 1.2412 - val_accuracy: 0.7829\n",
      "Epoch 122/200\n",
      "172/172 [==============================] - 0s 962us/sample - loss: 1.2440 - accuracy: 0.7791 - val_loss: 1.2397 - val_accuracy: 0.7829\n",
      "Epoch 123/200\n",
      "172/172 [==============================] - 0s 973us/sample - loss: 1.2416 - accuracy: 0.7791 - val_loss: 1.2461 - val_accuracy: 0.7829\n",
      "Epoch 124/200\n",
      "172/172 [==============================] - 0s 985us/sample - loss: 1.2463 - accuracy: 0.7791 - val_loss: 1.2382 - val_accuracy: 0.7829\n",
      "Epoch 125/200\n",
      "172/172 [==============================] - 0s 965us/sample - loss: 1.2389 - accuracy: 0.7791 - val_loss: 1.2471 - val_accuracy: 0.7829\n",
      "Epoch 126/200\n",
      "172/172 [==============================] - 0s 971us/sample - loss: 1.2447 - accuracy: 0.7791 - val_loss: 1.2403 - val_accuracy: 0.7829\n",
      "Epoch 127/200\n",
      "172/172 [==============================] - 0s 997us/sample - loss: 1.2442 - accuracy: 0.7791 - val_loss: 1.2546 - val_accuracy: 0.7829\n",
      "Epoch 128/200\n",
      "172/172 [==============================] - 0s 961us/sample - loss: 1.2427 - accuracy: 0.7791 - val_loss: 1.2458 - val_accuracy: 0.7829\n",
      "Epoch 129/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2444 - accuracy: 0.7791 - val_loss: 1.2376 - val_accuracy: 0.7829\n",
      "Epoch 130/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2408 - accuracy: 0.7791 - val_loss: 1.2407 - val_accuracy: 0.7829\n",
      "Epoch 131/200\n",
      "172/172 [==============================] - 0s 995us/sample - loss: 1.2460 - accuracy: 0.7791 - val_loss: 1.2400 - val_accuracy: 0.7829\n",
      "Epoch 132/200\n",
      "172/172 [==============================] - 0s 964us/sample - loss: 1.2452 - accuracy: 0.7791 - val_loss: 1.2368 - val_accuracy: 0.7829\n",
      "Epoch 133/200\n",
      "172/172 [==============================] - 0s 973us/sample - loss: 1.2399 - accuracy: 0.7791 - val_loss: 1.2559 - val_accuracy: 0.7829\n",
      "Epoch 134/200\n",
      "172/172 [==============================] - 0s 981us/sample - loss: 1.2438 - accuracy: 0.7791 - val_loss: 1.2435 - val_accuracy: 0.7829\n",
      "Epoch 135/200\n",
      "172/172 [==============================] - 0s 979us/sample - loss: 1.2408 - accuracy: 0.7791 - val_loss: 1.2530 - val_accuracy: 0.7829\n",
      "Epoch 136/200\n",
      "172/172 [==============================] - 0s 986us/sample - loss: 1.2473 - accuracy: 0.7791 - val_loss: 1.2317 - val_accuracy: 0.7829\n",
      "Epoch 137/200\n",
      "172/172 [==============================] - 0s 977us/sample - loss: 1.2404 - accuracy: 0.7791 - val_loss: 1.2465 - val_accuracy: 0.7829\n",
      "Epoch 138/200\n",
      "172/172 [==============================] - 0s 979us/sample - loss: 1.2457 - accuracy: 0.7791 - val_loss: 1.2360 - val_accuracy: 0.7829\n",
      "Epoch 139/200\n",
      "172/172 [==============================] - 0s 978us/sample - loss: 1.2401 - accuracy: 0.7791 - val_loss: 1.2472 - val_accuracy: 0.7829\n",
      "Epoch 140/200\n",
      "172/172 [==============================] - 0s 974us/sample - loss: 1.2443 - accuracy: 0.7791 - val_loss: 1.2401 - val_accuracy: 0.7829\n",
      "Epoch 141/200\n",
      "172/172 [==============================] - 0s 991us/sample - loss: 1.2460 - accuracy: 0.7791 - val_loss: 1.2398 - val_accuracy: 0.7829\n",
      "Epoch 142/200\n",
      "172/172 [==============================] - 0s 982us/sample - loss: 1.2406 - accuracy: 0.7791 - val_loss: 1.2425 - val_accuracy: 0.7829\n",
      "Epoch 143/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2450 - accuracy: 0.7791 - val_loss: 1.2462 - val_accuracy: 0.7829\n",
      "Epoch 144/200\n",
      "172/172 [==============================] - 0s 975us/sample - loss: 1.2443 - accuracy: 0.7791 - val_loss: 1.2425 - val_accuracy: 0.7829\n",
      "Epoch 145/200\n",
      "172/172 [==============================] - 0s 971us/sample - loss: 1.2397 - accuracy: 0.7791 - val_loss: 1.2447 - val_accuracy: 0.7829\n",
      "Epoch 146/200\n",
      "172/172 [==============================] - 0s 994us/sample - loss: 1.2453 - accuracy: 0.7791 - val_loss: 1.2343 - val_accuracy: 0.7829\n",
      "Epoch 147/200\n",
      "172/172 [==============================] - 0s 968us/sample - loss: 1.2422 - accuracy: 0.7791 - val_loss: 1.2588 - val_accuracy: 0.7829\n",
      "Epoch 148/200\n",
      "172/172 [==============================] - 0s 960us/sample - loss: 1.2439 - accuracy: 0.7791 - val_loss: 1.2397 - val_accuracy: 0.7829\n",
      "Epoch 149/200\n",
      "172/172 [==============================] - 0s 963us/sample - loss: 1.2425 - accuracy: 0.7791 - val_loss: 1.2474 - val_accuracy: 0.7829\n",
      "Epoch 150/200\n",
      "172/172 [==============================] - 0s 954us/sample - loss: 1.2433 - accuracy: 0.7791 - val_loss: 1.2373 - val_accuracy: 0.7829\n",
      "Epoch 151/200\n",
      "172/172 [==============================] - 0s 944us/sample - loss: 1.2432 - accuracy: 0.7791 - val_loss: 1.2413 - val_accuracy: 0.7829\n",
      "Epoch 152/200\n",
      "172/172 [==============================] - 0s 941us/sample - loss: 1.2469 - accuracy: 0.7791 - val_loss: 1.2350 - val_accuracy: 0.7829\n",
      "Epoch 153/200\n",
      "172/172 [==============================] - 0s 953us/sample - loss: 1.2389 - accuracy: 0.7791 - val_loss: 1.2459 - val_accuracy: 0.7829\n",
      "Epoch 154/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 1.2454 - accuracy: 0.7791 - val_loss: 1.2464 - val_accuracy: 0.7829\n",
      "Epoch 155/200\n",
      "172/172 [==============================] - 0s 999us/sample - loss: 1.2425 - accuracy: 0.7791 - val_loss: 1.2513 - val_accuracy: 0.7829\n",
      "Epoch 156/200\n",
      "172/172 [==============================] - 0s 947us/sample - loss: 1.2428 - accuracy: 0.7791 - val_loss: 1.2428 - val_accuracy: 0.7829\n",
      "Epoch 157/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 1.2449 - accuracy: 0.7791 - val_loss: 1.2397 - val_accuracy: 0.7829\n",
      "Epoch 158/200\n",
      "172/172 [==============================] - 0s 967us/sample - loss: 1.2413 - accuracy: 0.7791 - val_loss: 1.2437 - val_accuracy: 0.7829\n",
      "Epoch 159/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 952us/sample - loss: 1.2452 - accuracy: 0.7791 - val_loss: 1.2418 - val_accuracy: 0.7829\n",
      "Epoch 160/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 1.2431 - accuracy: 0.7791 - val_loss: 1.2335 - val_accuracy: 0.7829\n",
      "Epoch 161/200\n",
      "172/172 [==============================] - 0s 954us/sample - loss: 1.2418 - accuracy: 0.7791 - val_loss: 1.2527 - val_accuracy: 0.7829\n",
      "Epoch 162/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 1.2437 - accuracy: 0.7791 - val_loss: 1.2389 - val_accuracy: 0.7829\n",
      "Epoch 163/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 1.2411 - accuracy: 0.7791 - val_loss: 1.2516 - val_accuracy: 0.7829\n",
      "Epoch 164/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 1.2476 - accuracy: 0.7791 - val_loss: 1.2385 - val_accuracy: 0.7829\n",
      "Epoch 165/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 1.2380 - accuracy: 0.7791 - val_loss: 1.2439 - val_accuracy: 0.7829\n",
      "Epoch 166/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 1.2480 - accuracy: 0.7791 - val_loss: 1.2403 - val_accuracy: 0.7829\n",
      "Epoch 167/200\n",
      "172/172 [==============================] - 0s 930us/sample - loss: 1.2410 - accuracy: 0.7791 - val_loss: 1.2481 - val_accuracy: 0.7829\n",
      "Epoch 168/200\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 1.2421 - accuracy: 0.7791 - val_loss: 1.2412 - val_accuracy: 0.7829\n",
      "Epoch 169/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 1.2454 - accuracy: 0.7791 - val_loss: 1.2482 - val_accuracy: 0.7829\n",
      "Epoch 170/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 1.2399 - accuracy: 0.7791 - val_loss: 1.2392 - val_accuracy: 0.7829\n",
      "Epoch 171/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 1.2475 - accuracy: 0.7791 - val_loss: 1.2401 - val_accuracy: 0.7829\n",
      "Epoch 172/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 1.2414 - accuracy: 0.7791 - val_loss: 1.2413 - val_accuracy: 0.7829\n",
      "Epoch 173/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 1.2420 - accuracy: 0.7791 - val_loss: 1.2431 - val_accuracy: 0.7829\n",
      "Epoch 174/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 1.2445 - accuracy: 0.7791 - val_loss: 1.2356 - val_accuracy: 0.7829\n",
      "Epoch 175/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 1.2392 - accuracy: 0.7791 - val_loss: 1.2580 - val_accuracy: 0.7829\n",
      "Epoch 176/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 1.2482 - accuracy: 0.7791 - val_loss: 1.2364 - val_accuracy: 0.7829\n",
      "Epoch 177/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 1.2400 - accuracy: 0.7791 - val_loss: 1.2480 - val_accuracy: 0.7829\n",
      "Epoch 178/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 1.2445 - accuracy: 0.7791 - val_loss: 1.2406 - val_accuracy: 0.7829\n",
      "Epoch 179/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 1.2428 - accuracy: 0.7791 - val_loss: 1.2456 - val_accuracy: 0.7829\n",
      "Epoch 180/200\n",
      "172/172 [==============================] - 0s 975us/sample - loss: 1.2455 - accuracy: 0.7791 - val_loss: 1.2319 - val_accuracy: 0.7829\n",
      "Epoch 181/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 1.2424 - accuracy: 0.7791 - val_loss: 1.2403 - val_accuracy: 0.7829\n",
      "Epoch 182/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 1.2428 - accuracy: 0.7791 - val_loss: 1.2427 - val_accuracy: 0.7829\n",
      "Epoch 183/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 1.2438 - accuracy: 0.7791 - val_loss: 1.2561 - val_accuracy: 0.7829\n",
      "Epoch 184/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 1.2428 - accuracy: 0.7791 - val_loss: 1.2468 - val_accuracy: 0.7829\n",
      "Epoch 185/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 1.2423 - accuracy: 0.7791 - val_loss: 1.2408 - val_accuracy: 0.7829\n",
      "Epoch 186/200\n",
      "172/172 [==============================] - 0s 963us/sample - loss: 1.2457 - accuracy: 0.7791 - val_loss: 1.2401 - val_accuracy: 0.7829\n",
      "Epoch 187/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 1.2433 - accuracy: 0.7791 - val_loss: 1.2436 - val_accuracy: 0.7829\n",
      "Epoch 188/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 1.2445 - accuracy: 0.7791 - val_loss: 1.2394 - val_accuracy: 0.7829\n",
      "Epoch 189/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 1.2423 - accuracy: 0.7791 - val_loss: 1.2536 - val_accuracy: 0.7829\n",
      "Epoch 190/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 1.2421 - accuracy: 0.7791 - val_loss: 1.2377 - val_accuracy: 0.7829\n",
      "Epoch 191/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 1.2451 - accuracy: 0.7791 - val_loss: 1.2449 - val_accuracy: 0.7829\n",
      "Epoch 192/200\n",
      "172/172 [==============================] - 0s 955us/sample - loss: 1.2458 - accuracy: 0.7791 - val_loss: 1.2359 - val_accuracy: 0.7829\n",
      "Epoch 193/200\n",
      "172/172 [==============================] - 0s 947us/sample - loss: 1.2387 - accuracy: 0.7791 - val_loss: 1.2481 - val_accuracy: 0.7829\n",
      "Epoch 194/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 1.2464 - accuracy: 0.7791 - val_loss: 1.2380 - val_accuracy: 0.7829\n",
      "Epoch 195/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 1.2385 - accuracy: 0.7791 - val_loss: 1.2495 - val_accuracy: 0.7829\n",
      "Epoch 196/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 1.2473 - accuracy: 0.7791 - val_loss: 1.2383 - val_accuracy: 0.7829\n",
      "Epoch 197/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 1.2417 - accuracy: 0.7791 - val_loss: 1.2452 - val_accuracy: 0.7829\n",
      "Epoch 198/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 1.2421 - accuracy: 0.7791 - val_loss: 1.2456 - val_accuracy: 0.7829\n",
      "Epoch 199/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 1.2470 - accuracy: 0.7791 - val_loss: 1.2393 - val_accuracy: 0.7829\n",
      "Epoch 200/200\n",
      "172/172 [==============================] - 0s 957us/sample - loss: 1.2412 - accuracy: 0.7791 - val_loss: 1.2449 - val_accuracy: 0.7829\n",
      "Beginning training for dr=0.100, l_lambda=1.0e-03, reg_type=l2\n",
      "Train on 172 samples, validate on 43 samples\n",
      "Epoch 1/200\n",
      "172/172 [==============================] - 1s 8ms/sample - loss: 0.6491 - accuracy: 0.6667 - val_loss: 0.6203 - val_accuracy: 0.6667\n",
      "Epoch 2/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5978 - accuracy: 0.6667 - val_loss: 0.5668 - val_accuracy: 0.6667\n",
      "Epoch 3/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 0.5499 - accuracy: 0.7267 - val_loss: 0.5251 - val_accuracy: 0.7829\n",
      "Epoch 4/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 0.5213 - accuracy: 0.7791 - val_loss: 0.5102 - val_accuracy: 0.7829\n",
      "Epoch 5/200\n",
      "172/172 [==============================] - 0s 940us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5077 - val_accuracy: 0.7829\n",
      "Epoch 6/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 0.5176 - accuracy: 0.7791 - val_loss: 0.5067 - val_accuracy: 0.7829\n",
      "Epoch 7/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.5126 - accuracy: 0.7791 - val_loss: 0.5054 - val_accuracy: 0.7829\n",
      "Epoch 8/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.5121 - accuracy: 0.7791 - val_loss: 0.5047 - val_accuracy: 0.7829\n",
      "Epoch 9/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.5136 - accuracy: 0.7791 - val_loss: 0.5039 - val_accuracy: 0.7829\n",
      "Epoch 10/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.5119 - accuracy: 0.7791 - val_loss: 0.5036 - val_accuracy: 0.7829\n",
      "Epoch 11/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 0.5142 - accuracy: 0.7791 - val_loss: 0.5036 - val_accuracy: 0.7829\n",
      "Epoch 12/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.5147 - accuracy: 0.7791 - val_loss: 0.5035 - val_accuracy: 0.7829\n",
      "Epoch 13/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 914us/sample - loss: 0.5118 - accuracy: 0.7791 - val_loss: 0.5028 - val_accuracy: 0.7829\n",
      "Epoch 14/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5126 - accuracy: 0.7791 - val_loss: 0.5033 - val_accuracy: 0.7829\n",
      "Epoch 15/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.5116 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 16/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 17/200\n",
      "172/172 [==============================] - 0s 974us/sample - loss: 0.5110 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 18/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 19/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 20/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 21/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.5105 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 22/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5013 - val_accuracy: 0.7829\n",
      "Epoch 23/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 0.5085 - accuracy: 0.7791 - val_loss: 0.5014 - val_accuracy: 0.7829\n",
      "Epoch 24/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 25/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5009 - val_accuracy: 0.7829\n",
      "Epoch 26/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5008 - val_accuracy: 0.7829\n",
      "Epoch 27/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.5109 - accuracy: 0.7791 - val_loss: 0.5012 - val_accuracy: 0.7829\n",
      "Epoch 28/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.5081 - accuracy: 0.7791 - val_loss: 0.5004 - val_accuracy: 0.7829\n",
      "Epoch 29/200\n",
      "172/172 [==============================] - 0s 977us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5007 - val_accuracy: 0.7829\n",
      "Epoch 30/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5003 - val_accuracy: 0.7829\n",
      "Epoch 31/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.5082 - accuracy: 0.7791 - val_loss: 0.5004 - val_accuracy: 0.7829\n",
      "Epoch 32/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.4999 - val_accuracy: 0.7829\n",
      "Epoch 33/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.5083 - accuracy: 0.7791 - val_loss: 0.5009 - val_accuracy: 0.7829\n",
      "Epoch 34/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 0.5079 - accuracy: 0.7791 - val_loss: 0.5001 - val_accuracy: 0.7829\n",
      "Epoch 35/200\n",
      "172/172 [==============================] - 0s 930us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.4998 - val_accuracy: 0.7829\n",
      "Epoch 36/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 0.5076 - accuracy: 0.7791 - val_loss: 0.4996 - val_accuracy: 0.7829\n",
      "Epoch 37/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.4992 - val_accuracy: 0.7829\n",
      "Epoch 38/200\n",
      "172/172 [==============================] - 0s 955us/sample - loss: 0.5079 - accuracy: 0.7791 - val_loss: 0.4991 - val_accuracy: 0.7829\n",
      "Epoch 39/200\n",
      "172/172 [==============================] - 0s 940us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.4999 - val_accuracy: 0.7829\n",
      "Epoch 40/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.5061 - accuracy: 0.7791 - val_loss: 0.4988 - val_accuracy: 0.7829\n",
      "Epoch 41/200\n",
      "172/172 [==============================] - 0s 983us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.4988 - val_accuracy: 0.7829\n",
      "Epoch 42/200\n",
      "172/172 [==============================] - 0s 970us/sample - loss: 0.5078 - accuracy: 0.7791 - val_loss: 0.5002 - val_accuracy: 0.7829\n",
      "Epoch 43/200\n",
      "172/172 [==============================] - 0s 957us/sample - loss: 0.5073 - accuracy: 0.7791 - val_loss: 0.4983 - val_accuracy: 0.7829\n",
      "Epoch 44/200\n",
      "172/172 [==============================] - 0s 951us/sample - loss: 0.5070 - accuracy: 0.7791 - val_loss: 0.4982 - val_accuracy: 0.7829\n",
      "Epoch 45/200\n",
      "172/172 [==============================] - 0s 944us/sample - loss: 0.5071 - accuracy: 0.7791 - val_loss: 0.4979 - val_accuracy: 0.7829\n",
      "Epoch 46/200\n",
      "172/172 [==============================] - 0s 962us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.4978 - val_accuracy: 0.7829\n",
      "Epoch 47/200\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 0.5053 - accuracy: 0.7791 - val_loss: 0.4977 - val_accuracy: 0.7829\n",
      "Epoch 48/200\n",
      "172/172 [==============================] - 0s 943us/sample - loss: 0.5052 - accuracy: 0.7791 - val_loss: 0.4982 - val_accuracy: 0.7829\n",
      "Epoch 49/200\n",
      "172/172 [==============================] - 0s 945us/sample - loss: 0.5057 - accuracy: 0.7791 - val_loss: 0.4981 - val_accuracy: 0.7829\n",
      "Epoch 50/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.5045 - accuracy: 0.7791 - val_loss: 0.4974 - val_accuracy: 0.7829\n",
      "Epoch 51/200\n",
      "172/172 [==============================] - 0s 947us/sample - loss: 0.5069 - accuracy: 0.7791 - val_loss: 0.4971 - val_accuracy: 0.7829\n",
      "Epoch 52/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.5068 - accuracy: 0.7791 - val_loss: 0.4968 - val_accuracy: 0.7829\n",
      "Epoch 53/200\n",
      "172/172 [==============================] - 0s 975us/sample - loss: 0.5058 - accuracy: 0.7791 - val_loss: 0.4969 - val_accuracy: 0.7829\n",
      "Epoch 54/200\n",
      "172/172 [==============================] - 0s 995us/sample - loss: 0.5041 - accuracy: 0.7791 - val_loss: 0.4962 - val_accuracy: 0.7829\n",
      "Epoch 55/200\n",
      "172/172 [==============================] - 0s 943us/sample - loss: 0.5073 - accuracy: 0.7791 - val_loss: 0.4961 - val_accuracy: 0.7829\n",
      "Epoch 56/200\n",
      "172/172 [==============================] - 0s 957us/sample - loss: 0.5043 - accuracy: 0.7791 - val_loss: 0.4961 - val_accuracy: 0.7829\n",
      "Epoch 57/200\n",
      "172/172 [==============================] - 0s 978us/sample - loss: 0.5069 - accuracy: 0.7791 - val_loss: 0.4961 - val_accuracy: 0.7829\n",
      "Epoch 58/200\n",
      "172/172 [==============================] - 0s 954us/sample - loss: 0.5073 - accuracy: 0.7791 - val_loss: 0.4952 - val_accuracy: 0.7829\n",
      "Epoch 59/200\n",
      "172/172 [==============================] - 0s 961us/sample - loss: 0.5057 - accuracy: 0.7791 - val_loss: 0.4958 - val_accuracy: 0.7829\n",
      "Epoch 60/200\n",
      "172/172 [==============================] - 0s 981us/sample - loss: 0.5043 - accuracy: 0.7791 - val_loss: 0.4950 - val_accuracy: 0.7829\n",
      "Epoch 61/200\n",
      "172/172 [==============================] - 0s 970us/sample - loss: 0.5047 - accuracy: 0.7791 - val_loss: 0.4951 - val_accuracy: 0.7829\n",
      "Epoch 62/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 0.5034 - accuracy: 0.7791 - val_loss: 0.4939 - val_accuracy: 0.7829\n",
      "Epoch 63/200\n",
      "172/172 [==============================] - 0s 988us/sample - loss: 0.5022 - accuracy: 0.7791 - val_loss: 0.4929 - val_accuracy: 0.7829\n",
      "Epoch 64/200\n",
      "172/172 [==============================] - 0s 972us/sample - loss: 0.5011 - accuracy: 0.7791 - val_loss: 0.4932 - val_accuracy: 0.7829\n",
      "Epoch 65/200\n",
      "172/172 [==============================] - 0s 964us/sample - loss: 0.5018 - accuracy: 0.7791 - val_loss: 0.4925 - val_accuracy: 0.7829\n",
      "Epoch 66/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5050 - accuracy: 0.7791 - val_loss: 0.4911 - val_accuracy: 0.7829\n",
      "Epoch 67/200\n",
      "172/172 [==============================] - 0s 979us/sample - loss: 0.4983 - accuracy: 0.7791 - val_loss: 0.4912 - val_accuracy: 0.7829\n",
      "Epoch 68/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 965us/sample - loss: 0.4980 - accuracy: 0.7791 - val_loss: 0.4910 - val_accuracy: 0.7829\n",
      "Epoch 69/200\n",
      "172/172 [==============================] - 0s 985us/sample - loss: 0.4988 - accuracy: 0.7791 - val_loss: 0.4906 - val_accuracy: 0.7829\n",
      "Epoch 70/200\n",
      "172/172 [==============================] - 0s 973us/sample - loss: 0.5023 - accuracy: 0.7791 - val_loss: 0.4916 - val_accuracy: 0.7829\n",
      "Epoch 71/200\n",
      "172/172 [==============================] - 0s 976us/sample - loss: 0.5008 - accuracy: 0.7791 - val_loss: 0.4881 - val_accuracy: 0.7829\n",
      "Epoch 72/200\n",
      "172/172 [==============================] - 0s 982us/sample - loss: 0.5058 - accuracy: 0.7791 - val_loss: 0.4905 - val_accuracy: 0.7829\n",
      "Epoch 73/200\n",
      "172/172 [==============================] - 0s 965us/sample - loss: 0.4994 - accuracy: 0.7791 - val_loss: 0.4873 - val_accuracy: 0.7829\n",
      "Epoch 74/200\n",
      "172/172 [==============================] - 0s 965us/sample - loss: 0.4983 - accuracy: 0.7791 - val_loss: 0.4895 - val_accuracy: 0.7829\n",
      "Epoch 75/200\n",
      "172/172 [==============================] - 0s 983us/sample - loss: 0.4987 - accuracy: 0.7791 - val_loss: 0.4859 - val_accuracy: 0.7829\n",
      "Epoch 76/200\n",
      "172/172 [==============================] - 0s 961us/sample - loss: 0.4966 - accuracy: 0.7791 - val_loss: 0.4857 - val_accuracy: 0.7829\n",
      "Epoch 77/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 0.4943 - accuracy: 0.7791 - val_loss: 0.4861 - val_accuracy: 0.7829\n",
      "Epoch 78/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4947 - accuracy: 0.7791 - val_loss: 0.4835 - val_accuracy: 0.7829\n",
      "Epoch 79/200\n",
      "172/172 [==============================] - 0s 987us/sample - loss: 0.4925 - accuracy: 0.7791 - val_loss: 0.4834 - val_accuracy: 0.7829\n",
      "Epoch 80/200\n",
      "172/172 [==============================] - 0s 968us/sample - loss: 0.4926 - accuracy: 0.7791 - val_loss: 0.4816 - val_accuracy: 0.7829\n",
      "Epoch 81/200\n",
      "172/172 [==============================] - 0s 968us/sample - loss: 0.4920 - accuracy: 0.7791 - val_loss: 0.4831 - val_accuracy: 0.7829\n",
      "Epoch 82/200\n",
      "172/172 [==============================] - 0s 967us/sample - loss: 0.4888 - accuracy: 0.7791 - val_loss: 0.4797 - val_accuracy: 0.7829\n",
      "Epoch 83/200\n",
      "172/172 [==============================] - 0s 981us/sample - loss: 0.4925 - accuracy: 0.7791 - val_loss: 0.4785 - val_accuracy: 0.7829\n",
      "Epoch 84/200\n",
      "172/172 [==============================] - 0s 952us/sample - loss: 0.4982 - accuracy: 0.7791 - val_loss: 0.4805 - val_accuracy: 0.7829\n",
      "Epoch 85/200\n",
      "172/172 [==============================] - 0s 987us/sample - loss: 0.4899 - accuracy: 0.7791 - val_loss: 0.4779 - val_accuracy: 0.7829\n",
      "Epoch 86/200\n",
      "172/172 [==============================] - 0s 968us/sample - loss: 0.4923 - accuracy: 0.7791 - val_loss: 0.4759 - val_accuracy: 0.7829\n",
      "Epoch 87/200\n",
      "172/172 [==============================] - 0s 947us/sample - loss: 0.4843 - accuracy: 0.7791 - val_loss: 0.4784 - val_accuracy: 0.7829\n",
      "Epoch 88/200\n",
      "172/172 [==============================] - 0s 962us/sample - loss: 0.4836 - accuracy: 0.7868 - val_loss: 0.4735 - val_accuracy: 0.7829\n",
      "Epoch 89/200\n",
      "172/172 [==============================] - 0s 975us/sample - loss: 0.4846 - accuracy: 0.7810 - val_loss: 0.4757 - val_accuracy: 0.8062\n",
      "Epoch 90/200\n",
      "172/172 [==============================] - 0s 970us/sample - loss: 0.4844 - accuracy: 0.7829 - val_loss: 0.4736 - val_accuracy: 0.8062\n",
      "Epoch 91/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4831 - accuracy: 0.7849 - val_loss: 0.4716 - val_accuracy: 0.7984\n",
      "Epoch 92/200\n",
      "172/172 [==============================] - 0s 962us/sample - loss: 0.4759 - accuracy: 0.7849 - val_loss: 0.4716 - val_accuracy: 0.8062\n",
      "Epoch 93/200\n",
      "172/172 [==============================] - 0s 958us/sample - loss: 0.4786 - accuracy: 0.7868 - val_loss: 0.4693 - val_accuracy: 0.8062\n",
      "Epoch 94/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4880 - accuracy: 0.7984 - val_loss: 0.4707 - val_accuracy: 0.7984\n",
      "Epoch 95/200\n",
      "172/172 [==============================] - 0s 982us/sample - loss: 0.4801 - accuracy: 0.7829 - val_loss: 0.4678 - val_accuracy: 0.8062\n",
      "Epoch 96/200\n",
      "172/172 [==============================] - 0s 928us/sample - loss: 0.4821 - accuracy: 0.7829 - val_loss: 0.4711 - val_accuracy: 0.7984\n",
      "Epoch 97/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.4768 - accuracy: 0.7984 - val_loss: 0.4684 - val_accuracy: 0.7984\n",
      "Epoch 98/200\n",
      "172/172 [==============================] - 0s 979us/sample - loss: 0.4769 - accuracy: 0.7849 - val_loss: 0.4644 - val_accuracy: 0.7984\n",
      "Epoch 99/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 0.4739 - accuracy: 0.7868 - val_loss: 0.4667 - val_accuracy: 0.7984\n",
      "Epoch 100/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.4770 - accuracy: 0.8081 - val_loss: 0.4640 - val_accuracy: 0.7984\n",
      "Epoch 101/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 0.4859 - accuracy: 0.7791 - val_loss: 0.4723 - val_accuracy: 0.8062\n",
      "Epoch 102/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.4684 - accuracy: 0.7907 - val_loss: 0.4627 - val_accuracy: 0.7984\n",
      "Epoch 103/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.4705 - accuracy: 0.7907 - val_loss: 0.4655 - val_accuracy: 0.7984\n",
      "Epoch 104/200\n",
      "172/172 [==============================] - 0s 945us/sample - loss: 0.4732 - accuracy: 0.8101 - val_loss: 0.4615 - val_accuracy: 0.7907\n",
      "Epoch 105/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.4762 - accuracy: 0.7849 - val_loss: 0.4637 - val_accuracy: 0.7984\n",
      "Epoch 106/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.4767 - accuracy: 0.8062 - val_loss: 0.4642 - val_accuracy: 0.7984\n",
      "Epoch 107/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.4704 - accuracy: 0.8004 - val_loss: 0.4651 - val_accuracy: 0.7984\n",
      "Epoch 108/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.4666 - accuracy: 0.8101 - val_loss: 0.4594 - val_accuracy: 0.7984\n",
      "Epoch 109/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 0.4737 - accuracy: 0.7907 - val_loss: 0.4634 - val_accuracy: 0.7984\n",
      "Epoch 110/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.4660 - accuracy: 0.7965 - val_loss: 0.4627 - val_accuracy: 0.8062\n",
      "Epoch 111/200\n",
      "172/172 [==============================] - 0s 930us/sample - loss: 0.4668 - accuracy: 0.8140 - val_loss: 0.4573 - val_accuracy: 0.7907\n",
      "Epoch 112/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.4669 - accuracy: 0.7907 - val_loss: 0.4600 - val_accuracy: 0.7984\n",
      "Epoch 113/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4641 - accuracy: 0.8198 - val_loss: 0.4591 - val_accuracy: 0.7984\n",
      "Epoch 114/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 0.4712 - accuracy: 0.7907 - val_loss: 0.4610 - val_accuracy: 0.8062\n",
      "Epoch 115/200\n",
      "172/172 [==============================] - 0s 958us/sample - loss: 0.4602 - accuracy: 0.8062 - val_loss: 0.4587 - val_accuracy: 0.8062\n",
      "Epoch 116/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4629 - accuracy: 0.8120 - val_loss: 0.4576 - val_accuracy: 0.8062\n",
      "Epoch 117/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.4686 - accuracy: 0.8023 - val_loss: 0.4587 - val_accuracy: 0.8062\n",
      "Epoch 118/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 0.4591 - accuracy: 0.8043 - val_loss: 0.4555 - val_accuracy: 0.8062\n",
      "Epoch 119/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.4629 - accuracy: 0.8120 - val_loss: 0.4528 - val_accuracy: 0.7984\n",
      "Epoch 120/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.4596 - accuracy: 0.8043 - val_loss: 0.4509 - val_accuracy: 0.7984\n",
      "Epoch 121/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.4578 - accuracy: 0.8043 - val_loss: 0.4573 - val_accuracy: 0.8062\n",
      "Epoch 122/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.4646 - accuracy: 0.8159 - val_loss: 0.4504 - val_accuracy: 0.7907\n",
      "Epoch 123/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 909us/sample - loss: 0.4601 - accuracy: 0.8062 - val_loss: 0.4532 - val_accuracy: 0.8062\n",
      "Epoch 124/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.4630 - accuracy: 0.8178 - val_loss: 0.4496 - val_accuracy: 0.7907\n",
      "Epoch 125/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.4582 - accuracy: 0.7926 - val_loss: 0.4595 - val_accuracy: 0.8140\n",
      "Epoch 126/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.4616 - accuracy: 0.8198 - val_loss: 0.4524 - val_accuracy: 0.8062\n",
      "Epoch 127/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.4566 - accuracy: 0.8023 - val_loss: 0.4555 - val_accuracy: 0.8062\n",
      "Epoch 128/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 0.4598 - accuracy: 0.8043 - val_loss: 0.4570 - val_accuracy: 0.8140\n",
      "Epoch 129/200\n",
      "172/172 [==============================] - 0s 944us/sample - loss: 0.4568 - accuracy: 0.8159 - val_loss: 0.4513 - val_accuracy: 0.8062\n",
      "Epoch 130/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.4636 - accuracy: 0.8217 - val_loss: 0.4484 - val_accuracy: 0.8062\n",
      "Epoch 131/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.4541 - accuracy: 0.8140 - val_loss: 0.4529 - val_accuracy: 0.8140\n",
      "Epoch 132/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.4578 - accuracy: 0.8217 - val_loss: 0.4472 - val_accuracy: 0.8062\n",
      "Epoch 133/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.4468 - accuracy: 0.8236 - val_loss: 0.4492 - val_accuracy: 0.8062\n",
      "Epoch 134/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.4503 - accuracy: 0.8101 - val_loss: 0.4460 - val_accuracy: 0.8062\n",
      "Epoch 135/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.4594 - accuracy: 0.8178 - val_loss: 0.4443 - val_accuracy: 0.8062\n",
      "Epoch 136/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.4633 - accuracy: 0.7946 - val_loss: 0.4490 - val_accuracy: 0.8140\n",
      "Epoch 137/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.4505 - accuracy: 0.8236 - val_loss: 0.4430 - val_accuracy: 0.7907\n",
      "Epoch 138/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 0.4579 - accuracy: 0.8101 - val_loss: 0.4469 - val_accuracy: 0.8062\n",
      "Epoch 139/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.4459 - accuracy: 0.8236 - val_loss: 0.4438 - val_accuracy: 0.7984\n",
      "Epoch 140/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.4450 - accuracy: 0.8178 - val_loss: 0.4492 - val_accuracy: 0.8140\n",
      "Epoch 141/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.4468 - accuracy: 0.8198 - val_loss: 0.4438 - val_accuracy: 0.8062\n",
      "Epoch 142/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.4526 - accuracy: 0.8140 - val_loss: 0.4419 - val_accuracy: 0.7984\n",
      "Epoch 143/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.4536 - accuracy: 0.8023 - val_loss: 0.4415 - val_accuracy: 0.7984\n",
      "Epoch 144/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.4377 - accuracy: 0.8178 - val_loss: 0.4466 - val_accuracy: 0.8140\n",
      "Epoch 145/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.4542 - accuracy: 0.8140 - val_loss: 0.4506 - val_accuracy: 0.8295\n",
      "Epoch 146/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.4475 - accuracy: 0.8295 - val_loss: 0.4416 - val_accuracy: 0.8062\n",
      "Epoch 147/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.4548 - accuracy: 0.8043 - val_loss: 0.4553 - val_accuracy: 0.8372\n",
      "Epoch 148/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.4550 - accuracy: 0.8198 - val_loss: 0.4404 - val_accuracy: 0.7984\n",
      "Epoch 149/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.4618 - accuracy: 0.7907 - val_loss: 0.4564 - val_accuracy: 0.8217\n",
      "Epoch 150/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.4558 - accuracy: 0.8120 - val_loss: 0.4394 - val_accuracy: 0.8062\n",
      "Epoch 151/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 0.4442 - accuracy: 0.8314 - val_loss: 0.4409 - val_accuracy: 0.8062\n",
      "Epoch 152/200\n",
      "172/172 [==============================] - 0s 942us/sample - loss: 0.4554 - accuracy: 0.8023 - val_loss: 0.4424 - val_accuracy: 0.8140\n",
      "Epoch 153/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.4484 - accuracy: 0.8178 - val_loss: 0.4397 - val_accuracy: 0.8062\n",
      "Epoch 154/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4461 - accuracy: 0.8081 - val_loss: 0.4487 - val_accuracy: 0.8372\n",
      "Epoch 155/200\n",
      "172/172 [==============================] - 0s 962us/sample - loss: 0.4483 - accuracy: 0.8140 - val_loss: 0.4395 - val_accuracy: 0.8062\n",
      "Epoch 156/200\n",
      "172/172 [==============================] - 0s 976us/sample - loss: 0.4428 - accuracy: 0.8217 - val_loss: 0.4390 - val_accuracy: 0.8062\n",
      "Epoch 157/200\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 0.4426 - accuracy: 0.8178 - val_loss: 0.4379 - val_accuracy: 0.8062\n",
      "Epoch 158/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 0.4466 - accuracy: 0.8159 - val_loss: 0.4381 - val_accuracy: 0.8062\n",
      "Epoch 159/200\n",
      "172/172 [==============================] - 0s 941us/sample - loss: 0.4473 - accuracy: 0.8159 - val_loss: 0.4439 - val_accuracy: 0.8295\n",
      "Epoch 160/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.4509 - accuracy: 0.8062 - val_loss: 0.4391 - val_accuracy: 0.8140\n",
      "Epoch 161/200\n",
      "172/172 [==============================] - 0s 943us/sample - loss: 0.4427 - accuracy: 0.8275 - val_loss: 0.4400 - val_accuracy: 0.8140\n",
      "Epoch 162/200\n",
      "172/172 [==============================] - 0s 960us/sample - loss: 0.4512 - accuracy: 0.8120 - val_loss: 0.4387 - val_accuracy: 0.8140\n",
      "Epoch 163/200\n",
      "172/172 [==============================] - 0s 963us/sample - loss: 0.4446 - accuracy: 0.8101 - val_loss: 0.4386 - val_accuracy: 0.8140\n",
      "Epoch 164/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.4433 - accuracy: 0.8198 - val_loss: 0.4397 - val_accuracy: 0.8140\n",
      "Epoch 165/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 0.4399 - accuracy: 0.8178 - val_loss: 0.4364 - val_accuracy: 0.8062\n",
      "Epoch 166/200\n",
      "172/172 [==============================] - 0s 961us/sample - loss: 0.4455 - accuracy: 0.8120 - val_loss: 0.4430 - val_accuracy: 0.8372\n",
      "Epoch 167/200\n",
      "172/172 [==============================] - 0s 943us/sample - loss: 0.4410 - accuracy: 0.8295 - val_loss: 0.4342 - val_accuracy: 0.8062\n",
      "Epoch 168/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.4494 - accuracy: 0.8256 - val_loss: 0.4368 - val_accuracy: 0.8140\n",
      "Epoch 169/200\n",
      "172/172 [==============================] - 0s 964us/sample - loss: 0.4482 - accuracy: 0.8101 - val_loss: 0.4371 - val_accuracy: 0.8140\n",
      "Epoch 170/200\n",
      "172/172 [==============================] - 0s 957us/sample - loss: 0.4463 - accuracy: 0.8120 - val_loss: 0.4389 - val_accuracy: 0.8372\n",
      "Epoch 171/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.4432 - accuracy: 0.8256 - val_loss: 0.4332 - val_accuracy: 0.8062\n",
      "Epoch 172/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 0.4406 - accuracy: 0.8217 - val_loss: 0.4389 - val_accuracy: 0.8372\n",
      "Epoch 173/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.4409 - accuracy: 0.8217 - val_loss: 0.4370 - val_accuracy: 0.8217\n",
      "Epoch 174/200\n",
      "172/172 [==============================] - 0s 928us/sample - loss: 0.4415 - accuracy: 0.8217 - val_loss: 0.4483 - val_accuracy: 0.8295\n",
      "Epoch 175/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 0.4438 - accuracy: 0.8217 - val_loss: 0.4341 - val_accuracy: 0.8140\n",
      "Epoch 176/200\n",
      "172/172 [==============================] - 0s 945us/sample - loss: 0.4350 - accuracy: 0.8140 - val_loss: 0.4366 - val_accuracy: 0.8295\n",
      "Epoch 177/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.4407 - accuracy: 0.8256 - val_loss: 0.4344 - val_accuracy: 0.8140\n",
      "Epoch 178/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 972us/sample - loss: 0.4460 - accuracy: 0.8140 - val_loss: 0.4396 - val_accuracy: 0.8372\n",
      "Epoch 179/200\n",
      "172/172 [==============================] - 0s 963us/sample - loss: 0.4404 - accuracy: 0.8275 - val_loss: 0.4315 - val_accuracy: 0.7984\n",
      "Epoch 180/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 0.4406 - accuracy: 0.8178 - val_loss: 0.4344 - val_accuracy: 0.8140\n",
      "Epoch 181/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.4333 - accuracy: 0.8256 - val_loss: 0.4304 - val_accuracy: 0.7984\n",
      "Epoch 182/200\n",
      "172/172 [==============================] - 0s 990us/sample - loss: 0.4417 - accuracy: 0.8140 - val_loss: 0.4353 - val_accuracy: 0.8295\n",
      "Epoch 183/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.4396 - accuracy: 0.8217 - val_loss: 0.4357 - val_accuracy: 0.8372\n",
      "Epoch 184/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.4348 - accuracy: 0.8275 - val_loss: 0.4311 - val_accuracy: 0.7984\n",
      "Epoch 185/200\n",
      "172/172 [==============================] - 0s 941us/sample - loss: 0.4333 - accuracy: 0.8120 - val_loss: 0.4357 - val_accuracy: 0.8372\n",
      "Epoch 186/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.4345 - accuracy: 0.8256 - val_loss: 0.4301 - val_accuracy: 0.7984\n",
      "Epoch 187/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 0.4374 - accuracy: 0.8159 - val_loss: 0.4373 - val_accuracy: 0.8372\n",
      "Epoch 188/200\n",
      "172/172 [==============================] - 0s 946us/sample - loss: 0.4397 - accuracy: 0.8256 - val_loss: 0.4360 - val_accuracy: 0.8372\n",
      "Epoch 189/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.4336 - accuracy: 0.8314 - val_loss: 0.4305 - val_accuracy: 0.8140\n",
      "Epoch 190/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.4287 - accuracy: 0.8275 - val_loss: 0.4327 - val_accuracy: 0.8140\n",
      "Epoch 191/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4336 - accuracy: 0.8236 - val_loss: 0.4294 - val_accuracy: 0.7984\n",
      "Epoch 192/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.4321 - accuracy: 0.8140 - val_loss: 0.4390 - val_accuracy: 0.8372\n",
      "Epoch 193/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.4321 - accuracy: 0.8236 - val_loss: 0.4291 - val_accuracy: 0.7984\n",
      "Epoch 194/200\n",
      "172/172 [==============================] - 0s 954us/sample - loss: 0.4384 - accuracy: 0.8120 - val_loss: 0.4393 - val_accuracy: 0.8372\n",
      "Epoch 195/200\n",
      "172/172 [==============================] - 0s 946us/sample - loss: 0.4274 - accuracy: 0.8314 - val_loss: 0.4304 - val_accuracy: 0.8140\n",
      "Epoch 196/200\n",
      "172/172 [==============================] - 0s 930us/sample - loss: 0.4368 - accuracy: 0.8140 - val_loss: 0.4332 - val_accuracy: 0.8372\n",
      "Epoch 197/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 0.4318 - accuracy: 0.8178 - val_loss: 0.4336 - val_accuracy: 0.8372\n",
      "Epoch 198/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 0.4545 - accuracy: 0.8120 - val_loss: 0.4288 - val_accuracy: 0.7984\n",
      "Epoch 199/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.4320 - accuracy: 0.8159 - val_loss: 0.4345 - val_accuracy: 0.8372\n",
      "Epoch 200/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.4444 - accuracy: 0.8295 - val_loss: 0.4286 - val_accuracy: 0.7907\n",
      "Beginning training for dr=0.100, l_lambda=1.0e-03, reg_type=l1\n",
      "Train on 172 samples, validate on 43 samples\n",
      "Epoch 1/200\n",
      "172/172 [==============================] - 2s 9ms/sample - loss: 1.3260 - accuracy: 0.6667 - val_loss: 0.9497 - val_accuracy: 0.6667\n",
      "Epoch 2/200\n",
      "172/172 [==============================] - 0s 955us/sample - loss: 0.8054 - accuracy: 0.6667 - val_loss: 0.7090 - val_accuracy: 0.6667\n",
      "Epoch 3/200\n",
      "172/172 [==============================] - 0s 984us/sample - loss: 0.6601 - accuracy: 0.7461 - val_loss: 0.6132 - val_accuracy: 0.7829\n",
      "Epoch 4/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5968 - accuracy: 0.7791 - val_loss: 0.5746 - val_accuracy: 0.7829\n",
      "Epoch 5/200\n",
      "172/172 [==============================] - 0s 994us/sample - loss: 0.5711 - accuracy: 0.7791 - val_loss: 0.5541 - val_accuracy: 0.7829\n",
      "Epoch 6/200\n",
      "172/172 [==============================] - 0s 953us/sample - loss: 0.5534 - accuracy: 0.7791 - val_loss: 0.5396 - val_accuracy: 0.7829\n",
      "Epoch 7/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 0.5391 - accuracy: 0.7791 - val_loss: 0.5277 - val_accuracy: 0.7829\n",
      "Epoch 8/200\n",
      "172/172 [==============================] - 0s 942us/sample - loss: 0.5302 - accuracy: 0.7791 - val_loss: 0.5195 - val_accuracy: 0.7829\n",
      "Epoch 9/200\n",
      "172/172 [==============================] - 0s 960us/sample - loss: 0.5237 - accuracy: 0.7791 - val_loss: 0.5145 - val_accuracy: 0.7829\n",
      "Epoch 10/200\n",
      "172/172 [==============================] - 0s 963us/sample - loss: 0.5202 - accuracy: 0.7791 - val_loss: 0.5126 - val_accuracy: 0.7829\n",
      "Epoch 11/200\n",
      "172/172 [==============================] - 0s 956us/sample - loss: 0.5184 - accuracy: 0.7791 - val_loss: 0.5110 - val_accuracy: 0.7829\n",
      "Epoch 12/200\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 0.5183 - accuracy: 0.7791 - val_loss: 0.5102 - val_accuracy: 0.7829\n",
      "Epoch 13/200\n",
      "172/172 [==============================] - 0s 976us/sample - loss: 0.5172 - accuracy: 0.7791 - val_loss: 0.5098 - val_accuracy: 0.7829\n",
      "Epoch 14/200\n",
      "172/172 [==============================] - 0s 943us/sample - loss: 0.5171 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 15/200\n",
      "172/172 [==============================] - 0s 947us/sample - loss: 0.5169 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 16/200\n",
      "172/172 [==============================] - 0s 985us/sample - loss: 0.5171 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 17/200\n",
      "172/172 [==============================] - 0s 980us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 18/200\n",
      "172/172 [==============================] - 0s 952us/sample - loss: 0.5177 - accuracy: 0.7791 - val_loss: 0.5097 - val_accuracy: 0.7829\n",
      "Epoch 19/200\n",
      "172/172 [==============================] - 0s 962us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 20/200\n",
      "172/172 [==============================] - 0s 957us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 21/200\n",
      "172/172 [==============================] - 0s 951us/sample - loss: 0.5175 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 22/200\n",
      "172/172 [==============================] - 0s 966us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 23/200\n",
      "172/172 [==============================] - 0s 955us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 24/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.5170 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 25/200\n",
      "172/172 [==============================] - 0s 947us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 26/200\n",
      "172/172 [==============================] - 0s 992us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 27/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 28/200\n",
      "172/172 [==============================] - 0s 946us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 29/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.5158 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 30/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 31/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 32/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 34/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 35/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5099 - val_accuracy: 0.7829\n",
      "Epoch 36/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.5169 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 37/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 38/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 0.5171 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 39/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.5171 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 40/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 0.5168 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 41/200\n",
      "172/172 [==============================] - 0s 948us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 42/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.5179 - accuracy: 0.7791 - val_loss: 0.5099 - val_accuracy: 0.7829\n",
      "Epoch 43/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.5169 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 44/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 45/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 46/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 47/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 48/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 49/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 50/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 51/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 52/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 53/200\n",
      "172/172 [==============================] - 0s 956us/sample - loss: 0.5157 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 54/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 55/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 56/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 57/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.5190 - accuracy: 0.7791 - val_loss: 0.5103 - val_accuracy: 0.7829\n",
      "Epoch 58/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.5168 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 59/200\n",
      "172/172 [==============================] - 0s 937us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 60/200\n",
      "172/172 [==============================] - 0s 946us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 61/200\n",
      "172/172 [==============================] - 0s 930us/sample - loss: 0.5157 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 62/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 63/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 64/200\n",
      "172/172 [==============================] - 0s 947us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 65/200\n",
      "172/172 [==============================] - 0s 979us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 66/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 67/200\n",
      "172/172 [==============================] - 0s 952us/sample - loss: 0.5168 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 68/200\n",
      "172/172 [==============================] - 0s 981us/sample - loss: 0.5169 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 69/200\n",
      "172/172 [==============================] - 0s 955us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 70/200\n",
      "172/172 [==============================] - 0s 957us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 71/200\n",
      "172/172 [==============================] - 0s 984us/sample - loss: 0.5173 - accuracy: 0.7791 - val_loss: 0.5098 - val_accuracy: 0.7829\n",
      "Epoch 72/200\n",
      "172/172 [==============================] - 0s 952us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 73/200\n",
      "172/172 [==============================] - 0s 949us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 74/200\n",
      "172/172 [==============================] - 0s 972us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 75/200\n",
      "172/172 [==============================] - 0s 964us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 76/200\n",
      "172/172 [==============================] - 0s 954us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 77/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 78/200\n",
      "172/172 [==============================] - 0s 972us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 79/200\n",
      "172/172 [==============================] - 0s 946us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 80/200\n",
      "172/172 [==============================] - 0s 956us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 81/200\n",
      "172/172 [==============================] - 0s 961us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 82/200\n",
      "172/172 [==============================] - 0s 960us/sample - loss: 0.5177 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 83/200\n",
      "172/172 [==============================] - 0s 960us/sample - loss: 0.5175 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 84/200\n",
      "172/172 [==============================] - 0s 958us/sample - loss: 0.5176 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 85/200\n",
      "172/172 [==============================] - 0s 951us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 86/200\n",
      "172/172 [==============================] - 0s 998us/sample - loss: 0.5169 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 87/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5158 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 88/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 984us/sample - loss: 0.5158 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 89/200\n",
      "172/172 [==============================] - 0s 995us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 90/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 91/200\n",
      "172/172 [==============================] - 0s 984us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 92/200\n",
      "172/172 [==============================] - 0s 982us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 93/200\n",
      "172/172 [==============================] - 0s 981us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 94/200\n",
      "172/172 [==============================] - 0s 992us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 95/200\n",
      "172/172 [==============================] - 0s 973us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 96/200\n",
      "172/172 [==============================] - 0s 986us/sample - loss: 0.5158 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 97/200\n",
      "172/172 [==============================] - 0s 983us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 98/200\n",
      "172/172 [==============================] - 0s 989us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 99/200\n",
      "172/172 [==============================] - 0s 981us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 100/200\n",
      "172/172 [==============================] - 0s 983us/sample - loss: 0.5176 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 101/200\n",
      "172/172 [==============================] - 0s 995us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 102/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5176 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 103/200\n",
      "172/172 [==============================] - 0s 975us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 104/200\n",
      "172/172 [==============================] - 0s 977us/sample - loss: 0.5169 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 105/200\n",
      "172/172 [==============================] - 0s 998us/sample - loss: 0.5180 - accuracy: 0.7791 - val_loss: 0.5097 - val_accuracy: 0.7829\n",
      "Epoch 106/200\n",
      "172/172 [==============================] - 0s 982us/sample - loss: 0.5158 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 107/200\n",
      "172/172 [==============================] - 0s 982us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 108/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5099 - val_accuracy: 0.7829\n",
      "Epoch 109/200\n",
      "172/172 [==============================] - 0s 986us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 110/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 111/200\n",
      "172/172 [==============================] - 0s 984us/sample - loss: 0.5169 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 112/200\n",
      "172/172 [==============================] - 0s 989us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 113/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 114/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 115/200\n",
      "172/172 [==============================] - 0s 976us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 116/200\n",
      "172/172 [==============================] - 0s 972us/sample - loss: 0.5173 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 117/200\n",
      "172/172 [==============================] - 0s 995us/sample - loss: 0.5178 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 118/200\n",
      "172/172 [==============================] - 0s 973us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 119/200\n",
      "172/172 [==============================] - 0s 973us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 120/200\n",
      "172/172 [==============================] - 0s 992us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 121/200\n",
      "172/172 [==============================] - 0s 974us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 122/200\n",
      "172/172 [==============================] - 0s 987us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 123/200\n",
      "172/172 [==============================] - 0s 994us/sample - loss: 0.5157 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 124/200\n",
      "172/172 [==============================] - 0s 974us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 125/200\n",
      "172/172 [==============================] - 0s 983us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 126/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 127/200\n",
      "172/172 [==============================] - 0s 964us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 128/200\n",
      "172/172 [==============================] - 0s 954us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5099 - val_accuracy: 0.7829\n",
      "Epoch 129/200\n",
      "172/172 [==============================] - 0s 958us/sample - loss: 0.5172 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 130/200\n",
      "172/172 [==============================] - 0s 954us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 131/200\n",
      "172/172 [==============================] - 0s 943us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 132/200\n",
      "172/172 [==============================] - 0s 965us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 133/200\n",
      "172/172 [==============================] - 0s 975us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 134/200\n",
      "172/172 [==============================] - 0s 961us/sample - loss: 0.5179 - accuracy: 0.7791 - val_loss: 0.5096 - val_accuracy: 0.7829\n",
      "Epoch 135/200\n",
      "172/172 [==============================] - 0s 959us/sample - loss: 0.5178 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 136/200\n",
      "172/172 [==============================] - 0s 960us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 137/200\n",
      "172/172 [==============================] - 0s 953us/sample - loss: 0.5155 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 138/200\n",
      "172/172 [==============================] - 0s 970us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 139/200\n",
      "172/172 [==============================] - 0s 993us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 140/200\n",
      "172/172 [==============================] - 0s 970us/sample - loss: 0.5158 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 141/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.5158 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 142/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 143/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 929us/sample - loss: 0.5155 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 144/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 145/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 146/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 147/200\n",
      "172/172 [==============================] - 0s 984us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 148/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.5172 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 149/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 150/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 151/200\n",
      "172/172 [==============================] - 0s 972us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 152/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 153/200\n",
      "172/172 [==============================] - 0s 928us/sample - loss: 0.5168 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 154/200\n",
      "172/172 [==============================] - 0s 962us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 155/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 156/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.5173 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 157/200\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 158/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.5156 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 159/200\n",
      "172/172 [==============================] - 0s 943us/sample - loss: 0.5158 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 160/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 161/200\n",
      "172/172 [==============================] - 0s 947us/sample - loss: 0.5158 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 162/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 163/200\n",
      "172/172 [==============================] - 0s 983us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 164/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 165/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 166/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 0.5198 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 167/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.5158 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 168/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.5157 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 169/200\n",
      "172/172 [==============================] - 0s 944us/sample - loss: 0.5170 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 170/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 171/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 172/200\n",
      "172/172 [==============================] - 0s 948us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 173/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 174/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 175/200\n",
      "172/172 [==============================] - 0s 961us/sample - loss: 0.5157 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 176/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5085 - val_accuracy: 0.7829\n",
      "Epoch 177/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5085 - val_accuracy: 0.7829\n",
      "Epoch 178/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 179/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 180/200\n",
      "172/172 [==============================] - 0s 928us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5085 - val_accuracy: 0.7829\n",
      "Epoch 181/200\n",
      "172/172 [==============================] - 0s 944us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5084 - val_accuracy: 0.7829\n",
      "Epoch 182/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 183/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 184/200\n",
      "172/172 [==============================] - 0s 941us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 185/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 186/200\n",
      "172/172 [==============================] - 0s 952us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 187/200\n",
      "172/172 [==============================] - 0s 945us/sample - loss: 0.5175 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 188/200\n",
      "172/172 [==============================] - 0s 959us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 189/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 0.5158 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 190/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.5156 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 191/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 192/200\n",
      "172/172 [==============================] - 0s 941us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 193/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 0.5158 - accuracy: 0.7791 - val_loss: 0.5085 - val_accuracy: 0.7829\n",
      "Epoch 194/200\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 195/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 196/200\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 197/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5085 - val_accuracy: 0.7829\n",
      "Epoch 198/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 937us/sample - loss: 0.5178 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 199/200\n",
      "172/172 [==============================] - 0s 951us/sample - loss: 0.5153 - accuracy: 0.7791 - val_loss: 0.5084 - val_accuracy: 0.7829\n",
      "Epoch 200/200\n",
      "172/172 [==============================] - 0s 973us/sample - loss: 0.5191 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Beginning training for dr=0.100, l_lambda=1.0e-02, reg_type=l2\n",
      "Train on 172 samples, validate on 43 samples\n",
      "Epoch 1/200\n",
      "172/172 [==============================] - 1s 9ms/sample - loss: 0.8849 - accuracy: 0.6667 - val_loss: 0.7647 - val_accuracy: 0.6667\n",
      "Epoch 2/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.7140 - accuracy: 0.6667 - val_loss: 0.6616 - val_accuracy: 0.6667\n",
      "Epoch 3/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.6347 - accuracy: 0.6919 - val_loss: 0.6006 - val_accuracy: 0.7829\n",
      "Epoch 4/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5568 - val_accuracy: 0.7829\n",
      "Epoch 5/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.5502 - accuracy: 0.7791 - val_loss: 0.5365 - val_accuracy: 0.7829\n",
      "Epoch 6/200\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 0.5359 - accuracy: 0.7791 - val_loss: 0.5242 - val_accuracy: 0.7829\n",
      "Epoch 7/200\n",
      "172/172 [==============================] - 0s 944us/sample - loss: 0.5269 - accuracy: 0.7791 - val_loss: 0.5163 - val_accuracy: 0.7829\n",
      "Epoch 8/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 0.5209 - accuracy: 0.7791 - val_loss: 0.5114 - val_accuracy: 0.7829\n",
      "Epoch 9/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5084 - val_accuracy: 0.7829\n",
      "Epoch 10/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.5135 - accuracy: 0.7791 - val_loss: 0.5058 - val_accuracy: 0.7829\n",
      "Epoch 11/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.5121 - accuracy: 0.7791 - val_loss: 0.5043 - val_accuracy: 0.7829\n",
      "Epoch 12/200\n",
      "172/172 [==============================] - 0s 992us/sample - loss: 0.5113 - accuracy: 0.7791 - val_loss: 0.5034 - val_accuracy: 0.7829\n",
      "Epoch 13/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 0.5105 - accuracy: 0.7791 - val_loss: 0.5030 - val_accuracy: 0.7829\n",
      "Epoch 14/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.5115 - accuracy: 0.7791 - val_loss: 0.5033 - val_accuracy: 0.7829\n",
      "Epoch 15/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 16/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 17/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 18/200\n",
      "172/172 [==============================] - 0s 955us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 19/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 20/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 21/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 22/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 23/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 24/200\n",
      "172/172 [==============================] - 0s 994us/sample - loss: 0.5107 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 25/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 26/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 27/200\n",
      "172/172 [==============================] - 0s 960us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5030 - val_accuracy: 0.7829\n",
      "Epoch 28/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5026 - val_accuracy: 0.7829\n",
      "Epoch 29/200\n",
      "172/172 [==============================] - 0s 944us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 30/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 31/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 32/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 33/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 34/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.5110 - accuracy: 0.7791 - val_loss: 0.5030 - val_accuracy: 0.7829\n",
      "Epoch 35/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 36/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 37/200\n",
      "172/172 [==============================] - 0s 995us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 38/200\n",
      "172/172 [==============================] - 0s 961us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5014 - val_accuracy: 0.7829\n",
      "Epoch 39/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 40/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 41/200\n",
      "172/172 [==============================] - 0s 946us/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5028 - val_accuracy: 0.7829\n",
      "Epoch 42/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 43/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 44/200\n",
      "172/172 [==============================] - 0s 937us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 45/200\n",
      "172/172 [==============================] - 0s 988us/sample - loss: 0.5104 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 46/200\n",
      "172/172 [==============================] - 0s 930us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 47/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 48/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 49/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 50/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 51/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 52/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 54/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.5102 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 55/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 56/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 57/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 58/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 59/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 60/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 61/200\n",
      "172/172 [==============================] - 0s 928us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 62/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 63/200\n",
      "172/172 [==============================] - 0s 956us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 64/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 65/200\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 66/200\n",
      "172/172 [==============================] - 0s 941us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 67/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.5115 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 68/200\n",
      "172/172 [==============================] - 0s 944us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 69/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 70/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 71/200\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 72/200\n",
      "172/172 [==============================] - 0s 971us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 73/200\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 74/200\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 75/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 76/200\n",
      "172/172 [==============================] - 0s 966us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 77/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 78/200\n",
      "172/172 [==============================] - 0s 984us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 79/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 80/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 81/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 82/200\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 0.5102 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 83/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 84/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 85/200\n",
      "172/172 [==============================] - 0s 948us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 86/200\n",
      "172/172 [==============================] - 0s 928us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 87/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 88/200\n",
      "172/172 [==============================] - 0s 952us/sample - loss: 0.5083 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 89/200\n",
      "172/172 [==============================] - 0s 984us/sample - loss: 0.5118 - accuracy: 0.7791 - val_loss: 0.5042 - val_accuracy: 0.7829\n",
      "Epoch 90/200\n",
      "172/172 [==============================] - 0s 953us/sample - loss: 0.5124 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 91/200\n",
      "172/172 [==============================] - 0s 960us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5029 - val_accuracy: 0.7829\n",
      "Epoch 92/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 93/200\n",
      "172/172 [==============================] - 0s 967us/sample - loss: 0.5104 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 94/200\n",
      "172/172 [==============================] - 0s 945us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5026 - val_accuracy: 0.7829\n",
      "Epoch 95/200\n",
      "172/172 [==============================] - 0s 967us/sample - loss: 0.5110 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 96/200\n",
      "172/172 [==============================] - 0s 947us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5029 - val_accuracy: 0.7829\n",
      "Epoch 97/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5028 - val_accuracy: 0.7829\n",
      "Epoch 98/200\n",
      "172/172 [==============================] - 0s 971us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 99/200\n",
      "172/172 [==============================] - 0s 971us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 100/200\n",
      "172/172 [==============================] - 0s 962us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 101/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 102/200\n",
      "172/172 [==============================] - 0s 978us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 103/200\n",
      "172/172 [==============================] - 0s 952us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 104/200\n",
      "172/172 [==============================] - 0s 965us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 105/200\n",
      "172/172 [==============================] - 0s 980us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 106/200\n",
      "172/172 [==============================] - 0s 990us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 107/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 108/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 950us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 109/200\n",
      "172/172 [==============================] - 0s 991us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 110/200\n",
      "172/172 [==============================] - 0s 964us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 111/200\n",
      "172/172 [==============================] - 0s 963us/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 112/200\n",
      "172/172 [==============================] - 0s 999us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 113/200\n",
      "172/172 [==============================] - 0s 997us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 114/200\n",
      "172/172 [==============================] - 0s 990us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 115/200\n",
      "172/172 [==============================] - 0s 956us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 116/200\n",
      "172/172 [==============================] - 0s 957us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 117/200\n",
      "172/172 [==============================] - 0s 957us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 118/200\n",
      "172/172 [==============================] - 0s 963us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 119/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 120/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 121/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 122/200\n",
      "172/172 [==============================] - 0s 962us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 123/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 124/200\n",
      "172/172 [==============================] - 0s 951us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 125/200\n",
      "172/172 [==============================] - 0s 976us/sample - loss: 0.5104 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 126/200\n",
      "172/172 [==============================] - 0s 928us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 127/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 128/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 129/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 130/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 131/200\n",
      "172/172 [==============================] - 0s 974us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 132/200\n",
      "172/172 [==============================] - 0s 940us/sample - loss: 0.5102 - accuracy: 0.7791 - val_loss: 0.5032 - val_accuracy: 0.7829\n",
      "Epoch 133/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 134/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.5104 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 135/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 136/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 137/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 138/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 139/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 140/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 141/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 142/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 143/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 144/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 145/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 146/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.5105 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 147/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 148/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.5106 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 149/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 150/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 151/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 152/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 153/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 154/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 155/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 156/200\n",
      "172/172 [==============================] - 0s 947us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 157/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 158/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 0.5086 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 159/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 160/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 161/200\n",
      "172/172 [==============================] - 0s 959us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 162/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 163/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 919us/sample - loss: 0.5085 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 164/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.5111 - accuracy: 0.7791 - val_loss: 0.5031 - val_accuracy: 0.7829\n",
      "Epoch 165/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 166/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.5106 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 167/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 168/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.5086 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 169/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 170/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 171/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 172/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 173/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 174/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.5111 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 175/200\n",
      "172/172 [==============================] - 0s 981us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 176/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 177/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 178/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 179/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 180/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 181/200\n",
      "172/172 [==============================] - 0s 951us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 182/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 183/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 184/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 185/200\n",
      "172/172 [==============================] - 0s 971us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 186/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 187/200\n",
      "172/172 [==============================] - 0s 951us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 188/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 189/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 0.5126 - accuracy: 0.7791 - val_loss: 0.5032 - val_accuracy: 0.7829\n",
      "Epoch 190/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 191/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 192/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 193/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 194/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 195/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.5105 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 196/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 197/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 198/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 199/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 200/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5032 - val_accuracy: 0.7829\n",
      "Beginning training for dr=0.100, l_lambda=1.0e-02, reg_type=l1\n",
      "Train on 172 samples, validate on 43 samples\n",
      "Epoch 1/200\n",
      "172/172 [==============================] - 2s 10ms/sample - loss: 7.6998 - accuracy: 0.6667 - val_loss: 4.1444 - val_accuracy: 0.6667\n",
      "Epoch 2/200\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 2.8762 - accuracy: 0.6667 - val_loss: 2.1823 - val_accuracy: 0.6667\n",
      "Epoch 3/200\n",
      "172/172 [==============================] - 0s 964us/sample - loss: 1.8119 - accuracy: 0.6919 - val_loss: 1.4878 - val_accuracy: 0.7829\n",
      "Epoch 4/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.3293 - accuracy: 0.7791 - val_loss: 1.1638 - val_accuracy: 0.7829\n",
      "Epoch 5/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.0679 - accuracy: 0.7791 - val_loss: 0.9577 - val_accuracy: 0.7829\n",
      "Epoch 6/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 0.8917 - accuracy: 0.7791 - val_loss: 0.8033 - val_accuracy: 0.7829\n",
      "Epoch 7/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.7568 - accuracy: 0.7791 - val_loss: 0.6930 - val_accuracy: 0.7829\n",
      "Epoch 8/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.6630 - accuracy: 0.7791 - val_loss: 0.6196 - val_accuracy: 0.7829\n",
      "Epoch 9/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.6086 - accuracy: 0.7791 - val_loss: 0.5853 - val_accuracy: 0.7829\n",
      "Epoch 10/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.5877 - accuracy: 0.7791 - val_loss: 0.5778 - val_accuracy: 0.7829\n",
      "Epoch 11/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 0.5840 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 12/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.5836 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 13/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 14/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 15/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5771 - val_accuracy: 0.7829\n",
      "Epoch 16/200\n",
      "172/172 [==============================] - 0s 953us/sample - loss: 0.5836 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 17/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 18/200\n",
      "172/172 [==============================] - 0s 882us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 19/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 20/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 0.5842 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 21/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 0.5832 - accuracy: 0.7791 - val_loss: 0.5771 - val_accuracy: 0.7829\n",
      "Epoch 22/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 23/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 24/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 25/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5767 - val_accuracy: 0.7829\n",
      "Epoch 26/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 27/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.5820 - accuracy: 0.7791 - val_loss: 0.5768 - val_accuracy: 0.7829\n",
      "Epoch 28/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 29/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 30/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5768 - val_accuracy: 0.7829\n",
      "Epoch 31/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 0.5840 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 32/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 33/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 34/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 35/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5779 - val_accuracy: 0.7829\n",
      "Epoch 36/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.5835 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 37/200\n",
      "172/172 [==============================] - 0s 937us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5768 - val_accuracy: 0.7829\n",
      "Epoch 38/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 39/200\n",
      "172/172 [==============================] - 0s 930us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 40/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 41/200\n",
      "172/172 [==============================] - 0s 955us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 42/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 43/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 44/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5767 - val_accuracy: 0.7829\n",
      "Epoch 45/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 46/200\n",
      "172/172 [==============================] - 0s 930us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 47/200\n",
      "172/172 [==============================] - 0s 947us/sample - loss: 0.5833 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 48/200\n",
      "172/172 [==============================] - 0s 941us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 49/200\n",
      "172/172 [==============================] - 0s 961us/sample - loss: 0.5833 - accuracy: 0.7791 - val_loss: 0.5774 - val_accuracy: 0.7829\n",
      "Epoch 50/200\n",
      "172/172 [==============================] - 0s 937us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 51/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.5834 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 52/200\n",
      "172/172 [==============================] - 0s 945us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 53/200\n",
      "172/172 [==============================] - 0s 984us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 54/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 0.5836 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 55/200\n",
      "172/172 [==============================] - 0s 928us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 56/200\n",
      "172/172 [==============================] - 0s 969us/sample - loss: 0.5833 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 57/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 58/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 59/200\n",
      "172/172 [==============================] - 0s 952us/sample - loss: 0.5832 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 60/200\n",
      "172/172 [==============================] - 0s 946us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 61/200\n",
      "172/172 [==============================] - 0s 930us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 62/200\n",
      "172/172 [==============================] - 0s 955us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5751 - val_accuracy: 0.7829\n",
      "Epoch 63/200\n",
      "172/172 [==============================] - 0s 944us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5775 - val_accuracy: 0.7829\n",
      "Epoch 64/200\n",
      "172/172 [==============================] - 0s 947us/sample - loss: 0.5834 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 65/200\n",
      "172/172 [==============================] - 0s 963us/sample - loss: 0.5850 - accuracy: 0.7791 - val_loss: 0.5772 - val_accuracy: 0.7829\n",
      "Epoch 66/200\n",
      "172/172 [==============================] - 0s 971us/sample - loss: 0.5833 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 67/200\n",
      "172/172 [==============================] - 0s 943us/sample - loss: 0.5836 - accuracy: 0.7791 - val_loss: 0.5771 - val_accuracy: 0.7829\n",
      "Epoch 68/200\n",
      "172/172 [==============================] - 0s 968us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 69/200\n",
      "172/172 [==============================] - 0s 976us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 70/200\n",
      "172/172 [==============================] - 0s 960us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 71/200\n",
      "172/172 [==============================] - 0s 960us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 72/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 987us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 73/200\n",
      "172/172 [==============================] - 0s 963us/sample - loss: 0.5836 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 74/200\n",
      "172/172 [==============================] - 0s 986us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 75/200\n",
      "172/172 [==============================] - 0s 959us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 76/200\n",
      "172/172 [==============================] - 0s 979us/sample - loss: 0.5834 - accuracy: 0.7791 - val_loss: 0.5746 - val_accuracy: 0.7829\n",
      "Epoch 77/200\n",
      "172/172 [==============================] - 0s 978us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5772 - val_accuracy: 0.7829\n",
      "Epoch 78/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 79/200\n",
      "172/172 [==============================] - 0s 959us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5767 - val_accuracy: 0.7829\n",
      "Epoch 80/200\n",
      "172/172 [==============================] - 0s 962us/sample - loss: 0.5832 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 81/200\n",
      "172/172 [==============================] - 0s 980us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 82/200\n",
      "172/172 [==============================] - 0s 959us/sample - loss: 0.5837 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 83/200\n",
      "172/172 [==============================] - 0s 965us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 84/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 85/200\n",
      "172/172 [==============================] - 0s 970us/sample - loss: 0.5833 - accuracy: 0.7791 - val_loss: 0.5767 - val_accuracy: 0.7829\n",
      "Epoch 86/200\n",
      "172/172 [==============================] - 0s 958us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 87/200\n",
      "172/172 [==============================] - 0s 989us/sample - loss: 0.5836 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 88/200\n",
      "172/172 [==============================] - 0s 983us/sample - loss: 0.5833 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 89/200\n",
      "172/172 [==============================] - 0s 965us/sample - loss: 0.5845 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 90/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 91/200\n",
      "172/172 [==============================] - 0s 995us/sample - loss: 0.5832 - accuracy: 0.7791 - val_loss: 0.5770 - val_accuracy: 0.7829\n",
      "Epoch 92/200\n",
      "172/172 [==============================] - 0s 969us/sample - loss: 0.5834 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 93/200\n",
      "172/172 [==============================] - 0s 966us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5767 - val_accuracy: 0.7829\n",
      "Epoch 94/200\n",
      "172/172 [==============================] - 0s 968us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 95/200\n",
      "172/172 [==============================] - 0s 973us/sample - loss: 0.5833 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 96/200\n",
      "172/172 [==============================] - 0s 966us/sample - loss: 0.5837 - accuracy: 0.7791 - val_loss: 0.5748 - val_accuracy: 0.7829\n",
      "Epoch 97/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 98/200\n",
      "172/172 [==============================] - 0s 993us/sample - loss: 0.5837 - accuracy: 0.7791 - val_loss: 0.5767 - val_accuracy: 0.7829\n",
      "Epoch 99/200\n",
      "172/172 [==============================] - 0s 984us/sample - loss: 0.5838 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 100/200\n",
      "172/172 [==============================] - 0s 948us/sample - loss: 0.5837 - accuracy: 0.7791 - val_loss: 0.5777 - val_accuracy: 0.7829\n",
      "Epoch 101/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.5835 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 102/200\n",
      "172/172 [==============================] - 0s 953us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 103/200\n",
      "172/172 [==============================] - 0s 991us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 104/200\n",
      "172/172 [==============================] - 0s 945us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 105/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5778 - val_accuracy: 0.7829\n",
      "Epoch 106/200\n",
      "172/172 [==============================] - 0s 962us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 107/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.5834 - accuracy: 0.7791 - val_loss: 0.5769 - val_accuracy: 0.7829\n",
      "Epoch 108/200\n",
      "172/172 [==============================] - 0s 928us/sample - loss: 0.5832 - accuracy: 0.7791 - val_loss: 0.5752 - val_accuracy: 0.7829\n",
      "Epoch 109/200\n",
      "172/172 [==============================] - 0s 959us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 110/200\n",
      "172/172 [==============================] - 0s 951us/sample - loss: 0.5833 - accuracy: 0.7791 - val_loss: 0.5752 - val_accuracy: 0.7829\n",
      "Epoch 111/200\n",
      "172/172 [==============================] - 0s 968us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 112/200\n",
      "172/172 [==============================] - 0s 945us/sample - loss: 0.5835 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 113/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 114/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5777 - val_accuracy: 0.7829\n",
      "Epoch 115/200\n",
      "172/172 [==============================] - 0s 965us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 116/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 117/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 118/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 119/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5773 - val_accuracy: 0.7829\n",
      "Epoch 120/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 121/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 122/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5832 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 123/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5772 - val_accuracy: 0.7829\n",
      "Epoch 124/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 0.5842 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 125/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5772 - val_accuracy: 0.7829\n",
      "Epoch 126/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5767 - val_accuracy: 0.7829\n",
      "Epoch 127/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 934us/sample - loss: 0.5835 - accuracy: 0.7791 - val_loss: 0.5777 - val_accuracy: 0.7829\n",
      "Epoch 128/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5775 - val_accuracy: 0.7829\n",
      "Epoch 129/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 130/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 131/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 0.5833 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 132/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.5832 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 133/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5779 - val_accuracy: 0.7829\n",
      "Epoch 134/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.5832 - accuracy: 0.7791 - val_loss: 0.5773 - val_accuracy: 0.7829\n",
      "Epoch 135/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5776 - val_accuracy: 0.7829\n",
      "Epoch 136/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5837 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 137/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.5836 - accuracy: 0.7791 - val_loss: 0.5770 - val_accuracy: 0.7829\n",
      "Epoch 138/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 139/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5771 - val_accuracy: 0.7829\n",
      "Epoch 140/200\n",
      "172/172 [==============================] - 0s 963us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 141/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.5835 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 142/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5767 - val_accuracy: 0.7829\n",
      "Epoch 143/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 144/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 145/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 146/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 147/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5778 - val_accuracy: 0.7829\n",
      "Epoch 148/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 149/200\n",
      "172/172 [==============================] - 0s 952us/sample - loss: 0.5833 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 150/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.5832 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 151/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 152/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5752 - val_accuracy: 0.7829\n",
      "Epoch 153/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 154/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 155/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5770 - val_accuracy: 0.7829\n",
      "Epoch 156/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 157/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.5833 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 158/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 159/200\n",
      "172/172 [==============================] - 0s 960us/sample - loss: 0.5838 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 160/200\n",
      "172/172 [==============================] - 0s 952us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 161/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5769 - val_accuracy: 0.7829\n",
      "Epoch 162/200\n",
      "172/172 [==============================] - 0s 953us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 163/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 164/200\n",
      "172/172 [==============================] - 0s 953us/sample - loss: 0.5834 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 165/200\n",
      "172/172 [==============================] - 0s 974us/sample - loss: 0.5819 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 166/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5835 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 167/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 168/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 169/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5767 - val_accuracy: 0.7829\n",
      "Epoch 170/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 171/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.5835 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 172/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5771 - val_accuracy: 0.7829\n",
      "Epoch 173/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 174/200\n",
      "172/172 [==============================] - 0s 940us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 175/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5780 - val_accuracy: 0.7829\n",
      "Epoch 176/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 177/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.5842 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 178/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 179/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 180/200\n",
      "172/172 [==============================] - 0s 951us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5752 - val_accuracy: 0.7829\n",
      "Epoch 181/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 0.5839 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 182/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 945us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 183/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5769 - val_accuracy: 0.7829\n",
      "Epoch 184/200\n",
      "172/172 [==============================] - 0s 956us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 185/200\n",
      "172/172 [==============================] - 0s 937us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 186/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.5836 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 187/200\n",
      "172/172 [==============================] - 0s 956us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 188/200\n",
      "172/172 [==============================] - 0s 953us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 189/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5775 - val_accuracy: 0.7829\n",
      "Epoch 190/200\n",
      "172/172 [==============================] - 0s 994us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 191/200\n",
      "172/172 [==============================] - 0s 984us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 192/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 193/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 194/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 195/200\n",
      "172/172 [==============================] - 0s 940us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5778 - val_accuracy: 0.7829\n",
      "Epoch 196/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5832 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 197/200\n",
      "172/172 [==============================] - 0s 956us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 198/200\n",
      "172/172 [==============================] - 0s 991us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5768 - val_accuracy: 0.7829\n",
      "Epoch 199/200\n",
      "172/172 [==============================] - 0s 949us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 200/200\n",
      "172/172 [==============================] - 0s 971us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Beginning training for dr=0.100, l_lambda=1.0e-01, reg_type=l2\n",
      "Train on 172 samples, validate on 43 samples\n",
      "Epoch 1/200\n",
      "172/172 [==============================] - 2s 9ms/sample - loss: 3.2268 - accuracy: 0.6667 - val_loss: 2.1821 - val_accuracy: 0.6667\n",
      "Epoch 2/200\n",
      "172/172 [==============================] - 0s 930us/sample - loss: 1.8265 - accuracy: 0.6667 - val_loss: 1.5215 - val_accuracy: 0.6667\n",
      "Epoch 3/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.3626 - accuracy: 0.6977 - val_loss: 1.1848 - val_accuracy: 0.7829\n",
      "Epoch 4/200\n",
      "172/172 [==============================] - 0s 965us/sample - loss: 1.0745 - accuracy: 0.7791 - val_loss: 0.9531 - val_accuracy: 0.7829\n",
      "Epoch 5/200\n",
      "172/172 [==============================] - 0s 945us/sample - loss: 0.8860 - accuracy: 0.7791 - val_loss: 0.8030 - val_accuracy: 0.7829\n",
      "Epoch 6/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.7602 - accuracy: 0.7791 - val_loss: 0.7011 - val_accuracy: 0.7829\n",
      "Epoch 7/200\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 0.6740 - accuracy: 0.7791 - val_loss: 0.6318 - val_accuracy: 0.7829\n",
      "Epoch 8/200\n",
      "172/172 [==============================] - 0s 951us/sample - loss: 0.6165 - accuracy: 0.7791 - val_loss: 0.5854 - val_accuracy: 0.7829\n",
      "Epoch 9/200\n",
      "172/172 [==============================] - 0s 952us/sample - loss: 0.5818 - accuracy: 0.7791 - val_loss: 0.5548 - val_accuracy: 0.7829\n",
      "Epoch 10/200\n",
      "172/172 [==============================] - 0s 954us/sample - loss: 0.5509 - accuracy: 0.7791 - val_loss: 0.5347 - val_accuracy: 0.7829\n",
      "Epoch 11/200\n",
      "172/172 [==============================] - 0s 986us/sample - loss: 0.5356 - accuracy: 0.7791 - val_loss: 0.5222 - val_accuracy: 0.7829\n",
      "Epoch 12/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.5254 - accuracy: 0.7791 - val_loss: 0.5138 - val_accuracy: 0.7829\n",
      "Epoch 13/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.5189 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 14/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5055 - val_accuracy: 0.7829\n",
      "Epoch 15/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.5124 - accuracy: 0.7791 - val_loss: 0.5038 - val_accuracy: 0.7829\n",
      "Epoch 16/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.5107 - accuracy: 0.7791 - val_loss: 0.5030 - val_accuracy: 0.7829\n",
      "Epoch 17/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 18/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 19/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 20/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 21/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 22/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 23/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 24/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 25/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 26/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 27/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 28/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 29/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 30/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 0.5085 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 31/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 32/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 33/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 34/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 35/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 36/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 38/200\n",
      "172/172 [==============================] - 0s 882us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 39/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 40/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 41/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.5105 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 42/200\n",
      "172/172 [==============================] - 0s 865us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 43/200\n",
      "172/172 [==============================] - 0s 862us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 44/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 45/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 46/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 47/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 48/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 49/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 50/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 51/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 52/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5028 - val_accuracy: 0.7829\n",
      "Epoch 53/200\n",
      "172/172 [==============================] - 0s 943us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 54/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 55/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 56/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 57/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5029 - val_accuracy: 0.7829\n",
      "Epoch 58/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 59/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 60/200\n",
      "172/172 [==============================] - 0s 949us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 61/200\n",
      "172/172 [==============================] - 0s 984us/sample - loss: 0.5112 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 62/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 63/200\n",
      "172/172 [==============================] - 0s 957us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 64/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 65/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 66/200\n",
      "172/172 [==============================] - 0s 965us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 67/200\n",
      "172/172 [==============================] - 0s 954us/sample - loss: 0.5105 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 68/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 69/200\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 0.5109 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 70/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 71/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 72/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 73/200\n",
      "172/172 [==============================] - 0s 930us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 74/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 75/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 76/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 77/200\n",
      "172/172 [==============================] - 0s 955us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 78/200\n",
      "172/172 [==============================] - 0s 947us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 79/200\n",
      "172/172 [==============================] - 0s 981us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 80/200\n",
      "172/172 [==============================] - 0s 928us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 81/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 82/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 83/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 84/200\n",
      "172/172 [==============================] - 0s 945us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 85/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 86/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 87/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 88/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 89/200\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 90/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 91/200\n",
      "172/172 [==============================] - 0s 987us/sample - loss: 0.5102 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 92/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 964us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 93/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 94/200\n",
      "172/172 [==============================] - 0s 967us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 95/200\n",
      "172/172 [==============================] - 0s 945us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 96/200\n",
      "172/172 [==============================] - 0s 955us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 97/200\n",
      "172/172 [==============================] - 0s 960us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 98/200\n",
      "172/172 [==============================] - 0s 954us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 99/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 100/200\n",
      "172/172 [==============================] - 0s 982us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 101/200\n",
      "172/172 [==============================] - 0s 948us/sample - loss: 0.5113 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 102/200\n",
      "172/172 [==============================] - 0s 953us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 103/200\n",
      "172/172 [==============================] - 0s 974us/sample - loss: 0.5104 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 104/200\n",
      "172/172 [==============================] - 0s 981us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 105/200\n",
      "172/172 [==============================] - 0s 967us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 106/200\n",
      "172/172 [==============================] - 0s 968us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 107/200\n",
      "172/172 [==============================] - 0s 970us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 108/200\n",
      "172/172 [==============================] - 0s 949us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 109/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 110/200\n",
      "172/172 [==============================] - 0s 970us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 111/200\n",
      "172/172 [==============================] - 0s 998us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 112/200\n",
      "172/172 [==============================] - 0s 963us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 113/200\n",
      "172/172 [==============================] - 0s 956us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 114/200\n",
      "172/172 [==============================] - 0s 981us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 115/200\n",
      "172/172 [==============================] - 0s 946us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 116/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 117/200\n",
      "172/172 [==============================] - 0s 947us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 118/200\n",
      "172/172 [==============================] - 0s 942us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5034 - val_accuracy: 0.7829\n",
      "Epoch 119/200\n",
      "172/172 [==============================] - 0s 960us/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 120/200\n",
      "172/172 [==============================] - 0s 954us/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5026 - val_accuracy: 0.7829\n",
      "Epoch 121/200\n",
      "172/172 [==============================] - 0s 954us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 122/200\n",
      "172/172 [==============================] - 0s 959us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 123/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 124/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 125/200\n",
      "172/172 [==============================] - 0s 951us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5032 - val_accuracy: 0.7829\n",
      "Epoch 126/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 0.5108 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 127/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 128/200\n",
      "172/172 [==============================] - 0s 944us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 129/200\n",
      "172/172 [==============================] - 0s 948us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5026 - val_accuracy: 0.7829\n",
      "Epoch 130/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 131/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5028 - val_accuracy: 0.7829\n",
      "Epoch 132/200\n",
      "172/172 [==============================] - 0s 952us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 133/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 134/200\n",
      "172/172 [==============================] - 0s 991us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 135/200\n",
      "172/172 [==============================] - 0s 965us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 136/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.5085 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 137/200\n",
      "172/172 [==============================] - 0s 948us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 138/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 139/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 140/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5031 - val_accuracy: 0.7829\n",
      "Epoch 141/200\n",
      "172/172 [==============================] - 0s 955us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5026 - val_accuracy: 0.7829\n",
      "Epoch 142/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 143/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 144/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 145/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.5107 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 146/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 147/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 931us/sample - loss: 0.5086 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 148/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 149/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 150/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 151/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 152/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 153/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 154/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5031 - val_accuracy: 0.7829\n",
      "Epoch 155/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 156/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 157/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 158/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5105 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 159/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.5086 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 160/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 161/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 162/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.5086 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 163/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 164/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 165/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 166/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 167/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 168/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 169/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 170/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 171/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 172/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 173/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 174/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 175/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 176/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.5102 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 177/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 178/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 179/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 180/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.5102 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 181/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 182/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 183/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5028 - val_accuracy: 0.7829\n",
      "Epoch 184/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 185/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 186/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 187/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 188/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 189/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 190/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 191/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 192/200\n",
      "172/172 [==============================] - 0s 943us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 193/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 194/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 195/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 196/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 197/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 0.5113 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 198/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 199/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 200/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Beginning training for dr=0.100, l_lambda=1.0e-01, reg_type=l1\n",
      "Train on 172 samples, validate on 43 samples\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 1s 8ms/sample - loss: 71.2744 - accuracy: 0.6667 - val_loss: 35.8767 - val_accuracy: 0.6667\n",
      "Epoch 2/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 23.3635 - accuracy: 0.6667 - val_loss: 16.6664 - val_accuracy: 0.6667\n",
      "Epoch 3/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 13.1049 - accuracy: 0.7171 - val_loss: 10.0876 - val_accuracy: 0.7829\n",
      "Epoch 4/200\n",
      "172/172 [==============================] - 0s 967us/sample - loss: 8.5770 - accuracy: 0.7791 - val_loss: 7.0304 - val_accuracy: 0.7829\n",
      "Epoch 5/200\n",
      "172/172 [==============================] - 0s 962us/sample - loss: 6.0735 - accuracy: 0.7791 - val_loss: 5.0261 - val_accuracy: 0.7829\n",
      "Epoch 6/200\n",
      "172/172 [==============================] - 0s 937us/sample - loss: 4.3054 - accuracy: 0.7791 - val_loss: 3.4835 - val_accuracy: 0.7829\n",
      "Epoch 7/200\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 2.9485 - accuracy: 0.7791 - val_loss: 2.3832 - val_accuracy: 0.7829\n",
      "Epoch 8/200\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 2.0083 - accuracy: 0.7791 - val_loss: 1.6383 - val_accuracy: 0.7829\n",
      "Epoch 9/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 1.4646 - accuracy: 0.7791 - val_loss: 1.3161 - val_accuracy: 0.7829\n",
      "Epoch 10/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 1.2893 - accuracy: 0.7791 - val_loss: 1.2598 - val_accuracy: 0.7829\n",
      "Epoch 11/200\n",
      "172/172 [==============================] - 0s 951us/sample - loss: 1.2567 - accuracy: 0.7791 - val_loss: 1.2458 - val_accuracy: 0.7829\n",
      "Epoch 12/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2500 - accuracy: 0.7791 - val_loss: 1.2372 - val_accuracy: 0.7829\n",
      "Epoch 13/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2409 - accuracy: 0.7791 - val_loss: 1.2445 - val_accuracy: 0.7829\n",
      "Epoch 14/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2430 - accuracy: 0.7791 - val_loss: 1.2472 - val_accuracy: 0.7829\n",
      "Epoch 15/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2455 - accuracy: 0.7791 - val_loss: 1.2492 - val_accuracy: 0.7829\n",
      "Epoch 16/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2437 - accuracy: 0.7791 - val_loss: 1.2422 - val_accuracy: 0.7829\n",
      "Epoch 17/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2461 - accuracy: 0.7791 - val_loss: 1.2388 - val_accuracy: 0.7829\n",
      "Epoch 18/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2406 - accuracy: 0.7791 - val_loss: 1.2492 - val_accuracy: 0.7829\n",
      "Epoch 19/200\n",
      "172/172 [==============================] - 0s 972us/sample - loss: 1.2455 - accuracy: 0.7791 - val_loss: 1.2388 - val_accuracy: 0.7829\n",
      "Epoch 20/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 1.2449 - accuracy: 0.7791 - val_loss: 1.2316 - val_accuracy: 0.7829\n",
      "Epoch 21/200\n",
      "172/172 [==============================] - 0s 968us/sample - loss: 1.2441 - accuracy: 0.7791 - val_loss: 1.2475 - val_accuracy: 0.7829\n",
      "Epoch 22/200\n",
      "172/172 [==============================] - 0s 945us/sample - loss: 1.2447 - accuracy: 0.7791 - val_loss: 1.2421 - val_accuracy: 0.7829\n",
      "Epoch 23/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 1.2422 - accuracy: 0.7791 - val_loss: 1.2502 - val_accuracy: 0.7829\n",
      "Epoch 24/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 1.2452 - accuracy: 0.7791 - val_loss: 1.2389 - val_accuracy: 0.7829\n",
      "Epoch 25/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 1.2398 - accuracy: 0.7791 - val_loss: 1.2445 - val_accuracy: 0.7829\n",
      "Epoch 26/200\n",
      "172/172 [==============================] - 0s 942us/sample - loss: 1.2472 - accuracy: 0.7791 - val_loss: 1.2399 - val_accuracy: 0.7829\n",
      "Epoch 27/200\n",
      "172/172 [==============================] - 0s 937us/sample - loss: 1.2404 - accuracy: 0.7791 - val_loss: 1.2436 - val_accuracy: 0.7829\n",
      "Epoch 28/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 1.2466 - accuracy: 0.7791 - val_loss: 1.2414 - val_accuracy: 0.7829\n",
      "Epoch 29/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 1.2421 - accuracy: 0.7791 - val_loss: 1.2446 - val_accuracy: 0.7829\n",
      "Epoch 30/200\n",
      "172/172 [==============================] - 0s 937us/sample - loss: 1.2422 - accuracy: 0.7791 - val_loss: 1.2460 - val_accuracy: 0.7829\n",
      "Epoch 31/200\n",
      "172/172 [==============================] - 0s 954us/sample - loss: 1.2488 - accuracy: 0.7791 - val_loss: 1.2380 - val_accuracy: 0.7829\n",
      "Epoch 32/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 1.2436 - accuracy: 0.7791 - val_loss: 1.2373 - val_accuracy: 0.7829\n",
      "Epoch 33/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 1.2408 - accuracy: 0.7791 - val_loss: 1.2439 - val_accuracy: 0.7829\n",
      "Epoch 34/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 1.2463 - accuracy: 0.7791 - val_loss: 1.2423 - val_accuracy: 0.7829\n",
      "Epoch 35/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 1.2400 - accuracy: 0.7791 - val_loss: 1.2589 - val_accuracy: 0.7829\n",
      "Epoch 36/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 1.2474 - accuracy: 0.7791 - val_loss: 1.2385 - val_accuracy: 0.7829\n",
      "Epoch 37/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 1.2418 - accuracy: 0.7791 - val_loss: 1.2461 - val_accuracy: 0.7829\n",
      "Epoch 38/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 1.2442 - accuracy: 0.7791 - val_loss: 1.2393 - val_accuracy: 0.7829\n",
      "Epoch 39/200\n",
      "172/172 [==============================] - 0s 937us/sample - loss: 1.2412 - accuracy: 0.7791 - val_loss: 1.2458 - val_accuracy: 0.7829\n",
      "Epoch 40/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2469 - accuracy: 0.7791 - val_loss: 1.2371 - val_accuracy: 0.7829\n",
      "Epoch 41/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 1.2425 - accuracy: 0.7791 - val_loss: 1.2364 - val_accuracy: 0.7829\n",
      "Epoch 42/200\n",
      "172/172 [==============================] - 0s 965us/sample - loss: 1.2433 - accuracy: 0.7791 - val_loss: 1.2398 - val_accuracy: 0.7829\n",
      "Epoch 43/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2439 - accuracy: 0.7791 - val_loss: 1.2474 - val_accuracy: 0.7829\n",
      "Epoch 44/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 1.2441 - accuracy: 0.7791 - val_loss: 1.2468 - val_accuracy: 0.7829\n",
      "Epoch 45/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 1.2438 - accuracy: 0.7791 - val_loss: 1.2388 - val_accuracy: 0.7829\n",
      "Epoch 46/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 1.2412 - accuracy: 0.7791 - val_loss: 1.2479 - val_accuracy: 0.7829\n",
      "Epoch 47/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 1.2457 - accuracy: 0.7791 - val_loss: 1.2408 - val_accuracy: 0.7829\n",
      "Epoch 48/200\n",
      "172/172 [==============================] - 0s 944us/sample - loss: 1.2446 - accuracy: 0.7791 - val_loss: 1.2344 - val_accuracy: 0.7829\n",
      "Epoch 49/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2413 - accuracy: 0.7791 - val_loss: 1.2520 - val_accuracy: 0.7829\n",
      "Epoch 50/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2425 - accuracy: 0.7791 - val_loss: 1.2443 - val_accuracy: 0.7829\n",
      "Epoch 51/200\n",
      "172/172 [==============================] - 0s 941us/sample - loss: 1.2451 - accuracy: 0.7791 - val_loss: 1.2444 - val_accuracy: 0.7829\n",
      "Epoch 52/200\n",
      "172/172 [==============================] - 0s 968us/sample - loss: 1.2470 - accuracy: 0.7791 - val_loss: 1.2360 - val_accuracy: 0.7829\n",
      "Epoch 53/200\n",
      "172/172 [==============================] - 0s 941us/sample - loss: 1.2408 - accuracy: 0.7791 - val_loss: 1.2445 - val_accuracy: 0.7829\n",
      "Epoch 54/200\n",
      "172/172 [==============================] - 0s 954us/sample - loss: 1.2474 - accuracy: 0.7791 - val_loss: 1.2409 - val_accuracy: 0.7829\n",
      "Epoch 55/200\n",
      "172/172 [==============================] - 0s 963us/sample - loss: 1.2380 - accuracy: 0.7791 - val_loss: 1.2453 - val_accuracy: 0.7829\n",
      "Epoch 56/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2476 - accuracy: 0.7791 - val_loss: 1.2426 - val_accuracy: 0.7829\n",
      "Epoch 57/200\n",
      "172/172 [==============================] - 0s 967us/sample - loss: 1.2450 - accuracy: 0.7791 - val_loss: 1.2428 - val_accuracy: 0.7829\n",
      "Epoch 58/200\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 1.2392 - accuracy: 0.7791 - val_loss: 1.2467 - val_accuracy: 0.7829\n",
      "Epoch 59/200\n",
      "172/172 [==============================] - 0s 965us/sample - loss: 1.2477 - accuracy: 0.7791 - val_loss: 1.2395 - val_accuracy: 0.7829\n",
      "Epoch 60/200\n",
      "172/172 [==============================] - 0s 956us/sample - loss: 1.2418 - accuracy: 0.7791 - val_loss: 1.2374 - val_accuracy: 0.7829\n",
      "Epoch 61/200\n",
      "172/172 [==============================] - 0s 952us/sample - loss: 1.2452 - accuracy: 0.7791 - val_loss: 1.2351 - val_accuracy: 0.7829\n",
      "Epoch 62/200\n",
      "172/172 [==============================] - 0s 954us/sample - loss: 1.2424 - accuracy: 0.7791 - val_loss: 1.2344 - val_accuracy: 0.7829\n",
      "Epoch 63/200\n",
      "172/172 [==============================] - 0s 975us/sample - loss: 1.2417 - accuracy: 0.7791 - val_loss: 1.2597 - val_accuracy: 0.7829\n",
      "Epoch 64/200\n",
      "172/172 [==============================] - 0s 963us/sample - loss: 1.2460 - accuracy: 0.7791 - val_loss: 1.2400 - val_accuracy: 0.7829\n",
      "Epoch 65/200\n",
      "172/172 [==============================] - 0s 986us/sample - loss: 1.2392 - accuracy: 0.7791 - val_loss: 1.2510 - val_accuracy: 0.7829\n",
      "Epoch 66/200\n",
      "172/172 [==============================] - 0s 966us/sample - loss: 1.2480 - accuracy: 0.7791 - val_loss: 1.2397 - val_accuracy: 0.7829\n",
      "Epoch 67/200\n",
      "172/172 [==============================] - 0s 983us/sample - loss: 1.2390 - accuracy: 0.7791 - val_loss: 1.2431 - val_accuracy: 0.7829\n",
      "Epoch 68/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2478 - accuracy: 0.7791 - val_loss: 1.2360 - val_accuracy: 0.7829\n",
      "Epoch 69/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2404 - accuracy: 0.7791 - val_loss: 1.2408 - val_accuracy: 0.7829\n",
      "Epoch 70/200\n",
      "172/172 [==============================] - 0s 988us/sample - loss: 1.2426 - accuracy: 0.7791 - val_loss: 1.2446 - val_accuracy: 0.7829\n",
      "Epoch 71/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2474 - accuracy: 0.7791 - val_loss: 1.2417 - val_accuracy: 0.7829\n",
      "Epoch 72/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2416 - accuracy: 0.7791 - val_loss: 1.2405 - val_accuracy: 0.7829\n",
      "Epoch 73/200\n",
      "172/172 [==============================] - 0s 967us/sample - loss: 1.2440 - accuracy: 0.7791 - val_loss: 1.2444 - val_accuracy: 0.7829\n",
      "Epoch 74/200\n",
      "172/172 [==============================] - 0s 960us/sample - loss: 1.2427 - accuracy: 0.7791 - val_loss: 1.2461 - val_accuracy: 0.7829\n",
      "Epoch 75/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2410 - accuracy: 0.7791 - val_loss: 1.2421 - val_accuracy: 0.7829\n",
      "Epoch 76/200\n",
      "172/172 [==============================] - 0s 988us/sample - loss: 1.2487 - accuracy: 0.7791 - val_loss: 1.2307 - val_accuracy: 0.7829\n",
      "Epoch 77/200\n",
      "172/172 [==============================] - 0s 987us/sample - loss: 1.2399 - accuracy: 0.7791 - val_loss: 1.2518 - val_accuracy: 0.7829\n",
      "Epoch 78/200\n",
      "172/172 [==============================] - 0s 967us/sample - loss: 1.2434 - accuracy: 0.7791 - val_loss: 1.2437 - val_accuracy: 0.7829\n",
      "Epoch 79/200\n",
      "172/172 [==============================] - 0s 986us/sample - loss: 1.2433 - accuracy: 0.7791 - val_loss: 1.2451 - val_accuracy: 0.7829\n",
      "Epoch 80/200\n",
      "172/172 [==============================] - 0s 963us/sample - loss: 1.2450 - accuracy: 0.7791 - val_loss: 1.2336 - val_accuracy: 0.7829\n",
      "Epoch 81/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2431 - accuracy: 0.7791 - val_loss: 1.2349 - val_accuracy: 0.7829\n",
      "Epoch 82/200\n",
      "172/172 [==============================] - 0s 973us/sample - loss: 1.2445 - accuracy: 0.7791 - val_loss: 1.2390 - val_accuracy: 0.7829\n",
      "Epoch 83/200\n",
      "172/172 [==============================] - 0s 959us/sample - loss: 1.2427 - accuracy: 0.7791 - val_loss: 1.2464 - val_accuracy: 0.7829\n",
      "Epoch 84/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2445 - accuracy: 0.7791 - val_loss: 1.2423 - val_accuracy: 0.7829\n",
      "Epoch 85/200\n",
      "172/172 [==============================] - 0s 971us/sample - loss: 1.2430 - accuracy: 0.7791 - val_loss: 1.2483 - val_accuracy: 0.7829\n",
      "Epoch 86/200\n",
      "172/172 [==============================] - 0s 986us/sample - loss: 1.2435 - accuracy: 0.7791 - val_loss: 1.2481 - val_accuracy: 0.7829\n",
      "Epoch 87/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2457 - accuracy: 0.7791 - val_loss: 1.2394 - val_accuracy: 0.7829\n",
      "Epoch 88/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2431 - accuracy: 0.7791 - val_loss: 1.2472 - val_accuracy: 0.7829\n",
      "Epoch 89/200\n",
      "172/172 [==============================] - 0s 998us/sample - loss: 1.2446 - accuracy: 0.7791 - val_loss: 1.2353 - val_accuracy: 0.7829\n",
      "Epoch 90/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2400 - accuracy: 0.7791 - val_loss: 1.2367 - val_accuracy: 0.7829\n",
      "Epoch 91/200\n",
      "172/172 [==============================] - 0s 994us/sample - loss: 1.2460 - accuracy: 0.7791 - val_loss: 1.2499 - val_accuracy: 0.7829\n",
      "Epoch 92/200\n",
      "172/172 [==============================] - 0s 992us/sample - loss: 1.2456 - accuracy: 0.7791 - val_loss: 1.2372 - val_accuracy: 0.7829\n",
      "Epoch 93/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2412 - accuracy: 0.7791 - val_loss: 1.2456 - val_accuracy: 0.7829\n",
      "Epoch 94/200\n",
      "172/172 [==============================] - 0s 997us/sample - loss: 1.2451 - accuracy: 0.7791 - val_loss: 1.2413 - val_accuracy: 0.7829\n",
      "Epoch 95/200\n",
      "172/172 [==============================] - 0s 965us/sample - loss: 1.2397 - accuracy: 0.7791 - val_loss: 1.2497 - val_accuracy: 0.7829\n",
      "Epoch 96/200\n",
      "172/172 [==============================] - 0s 989us/sample - loss: 1.2498 - accuracy: 0.7791 - val_loss: 1.2329 - val_accuracy: 0.7829\n",
      "Epoch 97/200\n",
      "172/172 [==============================] - 0s 975us/sample - loss: 1.2373 - accuracy: 0.7791 - val_loss: 1.2393 - val_accuracy: 0.7829\n",
      "Epoch 98/200\n",
      "172/172 [==============================] - 0s 966us/sample - loss: 1.2457 - accuracy: 0.7791 - val_loss: 1.2450 - val_accuracy: 0.7829\n",
      "Epoch 99/200\n",
      "172/172 [==============================] - 0s 982us/sample - loss: 1.2459 - accuracy: 0.7791 - val_loss: 1.2436 - val_accuracy: 0.7829\n",
      "Epoch 100/200\n",
      "172/172 [==============================] - 0s 957us/sample - loss: 1.2412 - accuracy: 0.7791 - val_loss: 1.2438 - val_accuracy: 0.7829\n",
      "Epoch 101/200\n",
      "172/172 [==============================] - 0s 961us/sample - loss: 1.2472 - accuracy: 0.7791 - val_loss: 1.2372 - val_accuracy: 0.7829\n",
      "Epoch 102/200\n",
      "172/172 [==============================] - 0s 947us/sample - loss: 1.2410 - accuracy: 0.7791 - val_loss: 1.2424 - val_accuracy: 0.7829\n",
      "Epoch 103/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 1.2445 - accuracy: 0.7791 - val_loss: 1.2428 - val_accuracy: 0.7829\n",
      "Epoch 104/200\n",
      "172/172 [==============================] - 0s 949us/sample - loss: 1.2443 - accuracy: 0.7791 - val_loss: 1.2349 - val_accuracy: 0.7829\n",
      "Epoch 105/200\n",
      "172/172 [==============================] - 0s 953us/sample - loss: 1.2408 - accuracy: 0.7791 - val_loss: 1.2611 - val_accuracy: 0.7829\n",
      "Epoch 106/200\n",
      "172/172 [==============================] - 0s 979us/sample - loss: 1.2454 - accuracy: 0.7791 - val_loss: 1.2421 - val_accuracy: 0.7829\n",
      "Epoch 107/200\n",
      "172/172 [==============================] - 0s 947us/sample - loss: 1.2407 - accuracy: 0.7791 - val_loss: 1.2481 - val_accuracy: 0.7829\n",
      "Epoch 108/200\n",
      "172/172 [==============================] - 0s 972us/sample - loss: 1.2469 - accuracy: 0.7791 - val_loss: 1.2334 - val_accuracy: 0.7829\n",
      "Epoch 109/200\n",
      "172/172 [==============================] - 0s 972us/sample - loss: 1.2415 - accuracy: 0.7791 - val_loss: 1.2417 - val_accuracy: 0.7829\n",
      "Epoch 110/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 1.2442 - accuracy: 0.7791 - val_loss: 1.2378 - val_accuracy: 0.7829\n",
      "Epoch 111/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 955us/sample - loss: 1.2421 - accuracy: 0.7791 - val_loss: 1.2405 - val_accuracy: 0.7829\n",
      "Epoch 112/200\n",
      "172/172 [==============================] - 0s 960us/sample - loss: 1.2450 - accuracy: 0.7791 - val_loss: 1.2377 - val_accuracy: 0.7829\n",
      "Epoch 113/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 1.2427 - accuracy: 0.7791 - val_loss: 1.2432 - val_accuracy: 0.7829\n",
      "Epoch 114/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 1.2412 - accuracy: 0.7791 - val_loss: 1.2510 - val_accuracy: 0.7829\n",
      "Epoch 115/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 1.2461 - accuracy: 0.7791 - val_loss: 1.2433 - val_accuracy: 0.7829\n",
      "Epoch 116/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 1.2437 - accuracy: 0.7791 - val_loss: 1.2432 - val_accuracy: 0.7829\n",
      "Epoch 117/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 1.2421 - accuracy: 0.7791 - val_loss: 1.2414 - val_accuracy: 0.7829\n",
      "Epoch 118/200\n",
      "172/172 [==============================] - 0s 958us/sample - loss: 1.2437 - accuracy: 0.7791 - val_loss: 1.2365 - val_accuracy: 0.7829\n",
      "Epoch 119/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 1.2419 - accuracy: 0.7791 - val_loss: 1.2494 - val_accuracy: 0.7829\n",
      "Epoch 120/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 1.2454 - accuracy: 0.7791 - val_loss: 1.2383 - val_accuracy: 0.7829\n",
      "Epoch 121/200\n",
      "172/172 [==============================] - 0s 930us/sample - loss: 1.2432 - accuracy: 0.7791 - val_loss: 1.2421 - val_accuracy: 0.7829\n",
      "Epoch 122/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 1.2440 - accuracy: 0.7791 - val_loss: 1.2387 - val_accuracy: 0.7829\n",
      "Epoch 123/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 1.2429 - accuracy: 0.7791 - val_loss: 1.2414 - val_accuracy: 0.7829\n",
      "Epoch 124/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 1.2482 - accuracy: 0.7791 - val_loss: 1.2394 - val_accuracy: 0.7829\n",
      "Epoch 125/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 1.2393 - accuracy: 0.7791 - val_loss: 1.2437 - val_accuracy: 0.7829\n",
      "Epoch 126/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 1.2441 - accuracy: 0.7791 - val_loss: 1.2441 - val_accuracy: 0.7829\n",
      "Epoch 127/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 1.2453 - accuracy: 0.7791 - val_loss: 1.2480 - val_accuracy: 0.7829\n",
      "Epoch 128/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 1.2427 - accuracy: 0.7791 - val_loss: 1.2456 - val_accuracy: 0.7829\n",
      "Epoch 129/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 1.2454 - accuracy: 0.7791 - val_loss: 1.2358 - val_accuracy: 0.7829\n",
      "Epoch 130/200\n",
      "172/172 [==============================] - 0s 942us/sample - loss: 1.2396 - accuracy: 0.7791 - val_loss: 1.2443 - val_accuracy: 0.7829\n",
      "Epoch 131/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 1.2477 - accuracy: 0.7791 - val_loss: 1.2363 - val_accuracy: 0.7829\n",
      "Epoch 132/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 1.2444 - accuracy: 0.7791 - val_loss: 1.2327 - val_accuracy: 0.7829\n",
      "Epoch 133/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 1.2404 - accuracy: 0.7791 - val_loss: 1.2556 - val_accuracy: 0.7829\n",
      "Epoch 134/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 1.2438 - accuracy: 0.7791 - val_loss: 1.2447 - val_accuracy: 0.7829\n",
      "Epoch 135/200\n",
      "172/172 [==============================] - 0s 928us/sample - loss: 1.2412 - accuracy: 0.7791 - val_loss: 1.2519 - val_accuracy: 0.7829\n",
      "Epoch 136/200\n",
      "172/172 [==============================] - 0s 942us/sample - loss: 1.2469 - accuracy: 0.7791 - val_loss: 1.2329 - val_accuracy: 0.7829\n",
      "Epoch 137/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 1.2411 - accuracy: 0.7791 - val_loss: 1.2439 - val_accuracy: 0.7829\n",
      "Epoch 138/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 1.2456 - accuracy: 0.7791 - val_loss: 1.2395 - val_accuracy: 0.7829\n",
      "Epoch 139/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 1.2386 - accuracy: 0.7791 - val_loss: 1.2456 - val_accuracy: 0.7829\n",
      "Epoch 140/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 1.2458 - accuracy: 0.7791 - val_loss: 1.2405 - val_accuracy: 0.7829\n",
      "Epoch 141/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 1.2462 - accuracy: 0.7791 - val_loss: 1.2368 - val_accuracy: 0.7829\n",
      "Epoch 142/200\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 1.2396 - accuracy: 0.7791 - val_loss: 1.2425 - val_accuracy: 0.7829\n",
      "Epoch 143/200\n",
      "172/172 [==============================] - 0s 960us/sample - loss: 1.2455 - accuracy: 0.7791 - val_loss: 1.2472 - val_accuracy: 0.7829\n",
      "Epoch 144/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 1.2453 - accuracy: 0.7791 - val_loss: 1.2408 - val_accuracy: 0.7829\n",
      "Epoch 145/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2399 - accuracy: 0.7791 - val_loss: 1.2419 - val_accuracy: 0.7829\n",
      "Epoch 146/200\n",
      "172/172 [==============================] - 0s 947us/sample - loss: 1.2450 - accuracy: 0.7791 - val_loss: 1.2358 - val_accuracy: 0.7829\n",
      "Epoch 147/200\n",
      "172/172 [==============================] - 0s 992us/sample - loss: 1.2430 - accuracy: 0.7791 - val_loss: 1.2527 - val_accuracy: 0.7829\n",
      "Epoch 148/200\n",
      "172/172 [==============================] - 0s 928us/sample - loss: 1.2437 - accuracy: 0.7791 - val_loss: 1.2382 - val_accuracy: 0.7829\n",
      "Epoch 149/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2425 - accuracy: 0.7791 - val_loss: 1.2465 - val_accuracy: 0.7829\n",
      "Epoch 150/200\n",
      "172/172 [==============================] - 0s 985us/sample - loss: 1.2432 - accuracy: 0.7791 - val_loss: 1.2402 - val_accuracy: 0.7829\n",
      "Epoch 151/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 1.2433 - accuracy: 0.7791 - val_loss: 1.2386 - val_accuracy: 0.7829\n",
      "Epoch 152/200\n",
      "172/172 [==============================] - 0s 952us/sample - loss: 1.2482 - accuracy: 0.7791 - val_loss: 1.2339 - val_accuracy: 0.7829\n",
      "Epoch 153/200\n",
      "172/172 [==============================] - 0s 963us/sample - loss: 1.2386 - accuracy: 0.7791 - val_loss: 1.2422 - val_accuracy: 0.7829\n",
      "Epoch 154/200\n",
      "172/172 [==============================] - 0s 943us/sample - loss: 1.2454 - accuracy: 0.7791 - val_loss: 1.2499 - val_accuracy: 0.7829\n",
      "Epoch 155/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2423 - accuracy: 0.7791 - val_loss: 1.2467 - val_accuracy: 0.7829\n",
      "Epoch 156/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 1.2434 - accuracy: 0.7791 - val_loss: 1.2441 - val_accuracy: 0.7829\n",
      "Epoch 157/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 1.2446 - accuracy: 0.7791 - val_loss: 1.2368 - val_accuracy: 0.7829\n",
      "Epoch 158/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2416 - accuracy: 0.7791 - val_loss: 1.2468 - val_accuracy: 0.7829\n",
      "Epoch 159/200\n",
      "172/172 [==============================] - 0s 965us/sample - loss: 1.2449 - accuracy: 0.7791 - val_loss: 1.2362 - val_accuracy: 0.7829\n",
      "Epoch 160/200\n",
      "172/172 [==============================] - 0s 960us/sample - loss: 1.2432 - accuracy: 0.7791 - val_loss: 1.2334 - val_accuracy: 0.7829\n",
      "Epoch 161/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2425 - accuracy: 0.7791 - val_loss: 1.2514 - val_accuracy: 0.7829\n",
      "Epoch 162/200\n",
      "172/172 [==============================] - 0s 956us/sample - loss: 1.2433 - accuracy: 0.7791 - val_loss: 1.2397 - val_accuracy: 0.7829\n",
      "Epoch 163/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 1.2423 - accuracy: 0.7791 - val_loss: 1.2498 - val_accuracy: 0.7829\n",
      "Epoch 164/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 1.2471 - accuracy: 0.7791 - val_loss: 1.2376 - val_accuracy: 0.7829\n",
      "Epoch 165/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 1.2370 - accuracy: 0.7791 - val_loss: 1.2442 - val_accuracy: 0.7829\n",
      "Epoch 166/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 954us/sample - loss: 1.2482 - accuracy: 0.7791 - val_loss: 1.2444 - val_accuracy: 0.7829\n",
      "Epoch 167/200\n",
      "172/172 [==============================] - 0s 974us/sample - loss: 1.2412 - accuracy: 0.7791 - val_loss: 1.2413 - val_accuracy: 0.7829\n",
      "Epoch 168/200\n",
      "172/172 [==============================] - 0s 962us/sample - loss: 1.2441 - accuracy: 0.7791 - val_loss: 1.2408 - val_accuracy: 0.7829\n",
      "Epoch 169/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2458 - accuracy: 0.7791 - val_loss: 1.2443 - val_accuracy: 0.7829\n",
      "Epoch 170/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2403 - accuracy: 0.7791 - val_loss: 1.2430 - val_accuracy: 0.7829\n",
      "Epoch 171/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 1.2482 - accuracy: 0.7791 - val_loss: 1.2410 - val_accuracy: 0.7829\n",
      "Epoch 172/200\n",
      "172/172 [==============================] - 0s 986us/sample - loss: 1.2413 - accuracy: 0.7791 - val_loss: 1.2410 - val_accuracy: 0.7829\n",
      "Epoch 173/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 1.2436 - accuracy: 0.7791 - val_loss: 1.2387 - val_accuracy: 0.7829\n",
      "Epoch 174/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 1.2435 - accuracy: 0.7791 - val_loss: 1.2358 - val_accuracy: 0.7829\n",
      "Epoch 175/200\n",
      "172/172 [==============================] - 0s 964us/sample - loss: 1.2406 - accuracy: 0.7791 - val_loss: 1.2606 - val_accuracy: 0.7829\n",
      "Epoch 176/200\n",
      "172/172 [==============================] - 0s 960us/sample - loss: 1.2483 - accuracy: 0.7791 - val_loss: 1.2381 - val_accuracy: 0.7829\n",
      "Epoch 177/200\n",
      "172/172 [==============================] - 0s 963us/sample - loss: 1.2403 - accuracy: 0.7791 - val_loss: 1.2449 - val_accuracy: 0.7829\n",
      "Epoch 178/200\n",
      "172/172 [==============================] - 0s 983us/sample - loss: 1.2438 - accuracy: 0.7791 - val_loss: 1.2416 - val_accuracy: 0.7829\n",
      "Epoch 179/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2432 - accuracy: 0.7791 - val_loss: 1.2427 - val_accuracy: 0.7829\n",
      "Epoch 180/200\n",
      "172/172 [==============================] - 0s 980us/sample - loss: 1.2456 - accuracy: 0.7791 - val_loss: 1.2319 - val_accuracy: 0.7829\n",
      "Epoch 181/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2423 - accuracy: 0.7791 - val_loss: 1.2359 - val_accuracy: 0.7829\n",
      "Epoch 182/200\n",
      "172/172 [==============================] - 0s 953us/sample - loss: 1.2429 - accuracy: 0.7791 - val_loss: 1.2443 - val_accuracy: 0.7829\n",
      "Epoch 183/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 1.2439 - accuracy: 0.7791 - val_loss: 1.2501 - val_accuracy: 0.7829\n",
      "Epoch 184/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 1.2429 - accuracy: 0.7791 - val_loss: 1.2450 - val_accuracy: 0.7829\n",
      "Epoch 185/200\n",
      "172/172 [==============================] - 0s 967us/sample - loss: 1.2448 - accuracy: 0.7791 - val_loss: 1.2410 - val_accuracy: 0.7829\n",
      "Epoch 186/200\n",
      "172/172 [==============================] - 0s 981us/sample - loss: 1.2440 - accuracy: 0.7791 - val_loss: 1.2432 - val_accuracy: 0.7829\n",
      "Epoch 187/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 1.2418 - accuracy: 0.7791 - val_loss: 1.2398 - val_accuracy: 0.7829\n",
      "Epoch 188/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 1.2449 - accuracy: 0.7791 - val_loss: 1.2358 - val_accuracy: 0.7829\n",
      "Epoch 189/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 1.2431 - accuracy: 0.7791 - val_loss: 1.2527 - val_accuracy: 0.7829\n",
      "Epoch 190/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 1.2428 - accuracy: 0.7791 - val_loss: 1.2406 - val_accuracy: 0.7829\n",
      "Epoch 191/200\n",
      "172/172 [==============================] - 0s 979us/sample - loss: 1.2455 - accuracy: 0.7791 - val_loss: 1.2423 - val_accuracy: 0.7829\n",
      "Epoch 192/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 1.2470 - accuracy: 0.7791 - val_loss: 1.2357 - val_accuracy: 0.7829\n",
      "Epoch 193/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 1.2396 - accuracy: 0.7791 - val_loss: 1.2460 - val_accuracy: 0.7829\n",
      "Epoch 194/200\n",
      "172/172 [==============================] - 0s 985us/sample - loss: 1.2458 - accuracy: 0.7791 - val_loss: 1.2438 - val_accuracy: 0.7829\n",
      "Epoch 195/200\n",
      "172/172 [==============================] - 0s 947us/sample - loss: 1.2400 - accuracy: 0.7791 - val_loss: 1.2450 - val_accuracy: 0.7829\n",
      "Epoch 196/200\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 1.2478 - accuracy: 0.7791 - val_loss: 1.2393 - val_accuracy: 0.7829\n",
      "Epoch 197/200\n",
      "172/172 [==============================] - 0s 976us/sample - loss: 1.2414 - accuracy: 0.7791 - val_loss: 1.2411 - val_accuracy: 0.7829\n",
      "Epoch 198/200\n",
      "172/172 [==============================] - 0s 942us/sample - loss: 1.2427 - accuracy: 0.7791 - val_loss: 1.2503 - val_accuracy: 0.7829\n",
      "Epoch 199/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 1.2470 - accuracy: 0.7791 - val_loss: 1.2351 - val_accuracy: 0.7829\n",
      "Epoch 200/200\n",
      "172/172 [==============================] - 0s 967us/sample - loss: 1.2403 - accuracy: 0.7791 - val_loss: 1.2435 - val_accuracy: 0.7829\n"
     ]
    }
   ],
   "source": [
    "dropout_rates = [0.001, 0.01, 0.1]\n",
    "reg_types = ['l2', 'l1']\n",
    "reg_coeffs = [0.001, 0.01, 0.1]\n",
    "\n",
    "pbar = functools.partial(tqdm, leave=True, ncols='70%')\n",
    "pbars = [pbar() for _ in range(3)]\n",
    "\n",
    "grid_search_df = grid_search(dropout_rates=dropout_rates, reg_coeffs=reg_coeffs,\n",
    "                             reg_types=reg_types, pbars=pbars, num_epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# losses_df = pd.DataFrame(grid_search_df, \n",
    "#                          columns=['dropout rate',\n",
    "#                                   'reg type',\n",
    "#                                   'lambda',\n",
    "#                                   'validation loss'])   \n",
    "# losses_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_cd8b80e2_8db5_11ea_a150_a683e795f3a1row0_col0 {\n",
       "            background-color:  #fecd90;\n",
       "            color:  #000000;\n",
       "        }    #T_cd8b80e2_8db5_11ea_a150_a683e795f3a1row0_col1 {\n",
       "            background-color:  #fea772;\n",
       "            color:  #000000;\n",
       "        }    #T_cd8b80e2_8db5_11ea_a150_a683e795f3a1row0_col2 {\n",
       "            background-color:  #000004;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_cd8b80e2_8db5_11ea_a150_a683e795f3a1row1_col0 {\n",
       "            background-color:  #fecd90;\n",
       "            color:  #000000;\n",
       "        }    #T_cd8b80e2_8db5_11ea_a150_a683e795f3a1row1_col1 {\n",
       "            background-color:  #fea772;\n",
       "            color:  #000000;\n",
       "        }    #T_cd8b80e2_8db5_11ea_a150_a683e795f3a1row1_col2 {\n",
       "            background-color:  #000004;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_cd8b80e2_8db5_11ea_a150_a683e795f3a1row2_col0 {\n",
       "            background-color:  #fecd90;\n",
       "            color:  #000000;\n",
       "        }    #T_cd8b80e2_8db5_11ea_a150_a683e795f3a1row2_col1 {\n",
       "            background-color:  #fea772;\n",
       "            color:  #000000;\n",
       "        }    #T_cd8b80e2_8db5_11ea_a150_a683e795f3a1row2_col2 {\n",
       "            background-color:  #000004;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_cd8b80e2_8db5_11ea_a150_a683e795f3a1row3_col0 {\n",
       "            background-color:  #fcfdbf;\n",
       "            color:  #000000;\n",
       "        }    #T_cd8b80e2_8db5_11ea_a150_a683e795f3a1row3_col1 {\n",
       "            background-color:  #fed194;\n",
       "            color:  #000000;\n",
       "        }    #T_cd8b80e2_8db5_11ea_a150_a683e795f3a1row3_col2 {\n",
       "            background-color:  #fed194;\n",
       "            color:  #000000;\n",
       "        }    #T_cd8b80e2_8db5_11ea_a150_a683e795f3a1row4_col0 {\n",
       "            background-color:  #fcfdbf;\n",
       "            color:  #000000;\n",
       "        }    #T_cd8b80e2_8db5_11ea_a150_a683e795f3a1row4_col1 {\n",
       "            background-color:  #fed194;\n",
       "            color:  #000000;\n",
       "        }    #T_cd8b80e2_8db5_11ea_a150_a683e795f3a1row4_col2 {\n",
       "            background-color:  #fed194;\n",
       "            color:  #000000;\n",
       "        }    #T_cd8b80e2_8db5_11ea_a150_a683e795f3a1row5_col0 {\n",
       "            background-color:  #fcfbbd;\n",
       "            color:  #000000;\n",
       "        }    #T_cd8b80e2_8db5_11ea_a150_a683e795f3a1row5_col1 {\n",
       "            background-color:  #fed194;\n",
       "            color:  #000000;\n",
       "        }    #T_cd8b80e2_8db5_11ea_a150_a683e795f3a1row5_col2 {\n",
       "            background-color:  #fed194;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_cd8b80e2_8db5_11ea_a150_a683e795f3a1\" ><thead>    <tr>        <th class=\"blank\" ></th>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" colspan=3>validation loss</th>    </tr>    <tr>        <th class=\"blank\" ></th>        <th class=\"index_name level1\" >lambda</th>        <th class=\"col_heading level1 col0\" >0.001</th>        <th class=\"col_heading level1 col1\" >0.01</th>        <th class=\"col_heading level1 col2\" >0.1</th>    </tr>    <tr>        <th class=\"index_name level0\" >reg type</th>        <th class=\"index_name level1\" >dropout rate</th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_cd8b80e2_8db5_11ea_a150_a683e795f3a1level0_row0\" class=\"row_heading level0 row0\" rowspan=3>l1</th>\n",
       "                        <th id=\"T_cd8b80e2_8db5_11ea_a150_a683e795f3a1level1_row0\" class=\"row_heading level1 row0\" >0.001</th>\n",
       "                        <td id=\"T_cd8b80e2_8db5_11ea_a150_a683e795f3a1row0_col0\" class=\"data row0 col0\" >0.508</td>\n",
       "                        <td id=\"T_cd8b80e2_8db5_11ea_a150_a683e795f3a1row0_col1\" class=\"data row0 col1\" >0.575</td>\n",
       "                        <td id=\"T_cd8b80e2_8db5_11ea_a150_a683e795f3a1row0_col2\" class=\"data row0 col2\" >1.232</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_cd8b80e2_8db5_11ea_a150_a683e795f3a1level1_row1\" class=\"row_heading level1 row1\" >0.01</th>\n",
       "                        <td id=\"T_cd8b80e2_8db5_11ea_a150_a683e795f3a1row1_col0\" class=\"data row1 col0\" >0.509</td>\n",
       "                        <td id=\"T_cd8b80e2_8db5_11ea_a150_a683e795f3a1row1_col1\" class=\"data row1 col1\" >0.575</td>\n",
       "                        <td id=\"T_cd8b80e2_8db5_11ea_a150_a683e795f3a1row1_col2\" class=\"data row1 col2\" >1.232</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_cd8b80e2_8db5_11ea_a150_a683e795f3a1level1_row2\" class=\"row_heading level1 row2\" >0.1</th>\n",
       "                        <td id=\"T_cd8b80e2_8db5_11ea_a150_a683e795f3a1row2_col0\" class=\"data row2 col0\" >0.508</td>\n",
       "                        <td id=\"T_cd8b80e2_8db5_11ea_a150_a683e795f3a1row2_col1\" class=\"data row2 col1\" >0.575</td>\n",
       "                        <td id=\"T_cd8b80e2_8db5_11ea_a150_a683e795f3a1row2_col2\" class=\"data row2 col2\" >1.231</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cd8b80e2_8db5_11ea_a150_a683e795f3a1level0_row3\" class=\"row_heading level0 row3\" rowspan=3>l2</th>\n",
       "                        <th id=\"T_cd8b80e2_8db5_11ea_a150_a683e795f3a1level1_row3\" class=\"row_heading level1 row3\" >0.001</th>\n",
       "                        <td id=\"T_cd8b80e2_8db5_11ea_a150_a683e795f3a1row3_col0\" class=\"data row3 col0\" >0.426</td>\n",
       "                        <td id=\"T_cd8b80e2_8db5_11ea_a150_a683e795f3a1row3_col1\" class=\"data row3 col1\" >0.502</td>\n",
       "                        <td id=\"T_cd8b80e2_8db5_11ea_a150_a683e795f3a1row3_col2\" class=\"data row3 col2\" >0.502</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_cd8b80e2_8db5_11ea_a150_a683e795f3a1level1_row4\" class=\"row_heading level1 row4\" >0.01</th>\n",
       "                        <td id=\"T_cd8b80e2_8db5_11ea_a150_a683e795f3a1row4_col0\" class=\"data row4 col0\" >0.425</td>\n",
       "                        <td id=\"T_cd8b80e2_8db5_11ea_a150_a683e795f3a1row4_col1\" class=\"data row4 col1\" >0.501</td>\n",
       "                        <td id=\"T_cd8b80e2_8db5_11ea_a150_a683e795f3a1row4_col2\" class=\"data row4 col2\" >0.501</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_cd8b80e2_8db5_11ea_a150_a683e795f3a1level1_row5\" class=\"row_heading level1 row5\" >0.1</th>\n",
       "                        <td id=\"T_cd8b80e2_8db5_11ea_a150_a683e795f3a1row5_col0\" class=\"data row5 col0\" >0.429</td>\n",
       "                        <td id=\"T_cd8b80e2_8db5_11ea_a150_a683e795f3a1row5_col1\" class=\"data row5 col1\" >0.501</td>\n",
       "                        <td id=\"T_cd8b80e2_8db5_11ea_a150_a683e795f3a1row5_col2\" class=\"data row5 col2\" >0.501</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x183c72810>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_pivot = (grid_search_df\n",
    "                     .pivot_table(values=['validation loss'],\n",
    "                                  columns=['lambda'],\n",
    "                                  index=['reg type', 'dropout rate']))\n",
    "grid_search_pivot.style.format('{:.3f}').background_gradient(cmap='magma_r',\n",
    "                                                             axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb423a369441439994e2285426553885",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=1.0), HTML(value='')), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff4b283b5ac74332aa3cee5919a79d28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=1.0), HTML(value='')), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de70bbca85c24dd6a4696ea832b4c263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=1.0), HTML(value='')), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training for dr=0.001, l_lambda=1.0e-03, reg_type=l2, act: relu\n",
      "Train on 172 samples, validate on 43 samples\n",
      "Epoch 1/200\n",
      "172/172 [==============================] - 2s 9ms/sample - loss: 0.6515 - accuracy: 0.6667 - val_loss: 0.6235 - val_accuracy: 0.6667\n",
      "Epoch 2/200\n",
      "172/172 [==============================] - 0s 816us/sample - loss: 0.6062 - accuracy: 0.6667 - val_loss: 0.5765 - val_accuracy: 0.6667\n",
      "Epoch 3/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.5599 - accuracy: 0.6996 - val_loss: 0.5353 - val_accuracy: 0.7829\n",
      "Epoch 4/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.5260 - accuracy: 0.7791 - val_loss: 0.5118 - val_accuracy: 0.7829\n",
      "Epoch 5/200\n",
      "172/172 [==============================] - 0s 837us/sample - loss: 0.5155 - accuracy: 0.7791 - val_loss: 0.5080 - val_accuracy: 0.7829\n",
      "Epoch 6/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.5150 - accuracy: 0.7791 - val_loss: 0.5066 - val_accuracy: 0.7829\n",
      "Epoch 7/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.5121 - accuracy: 0.7791 - val_loss: 0.5052 - val_accuracy: 0.7829\n",
      "Epoch 8/200\n",
      "172/172 [==============================] - 0s 807us/sample - loss: 0.5113 - accuracy: 0.7791 - val_loss: 0.5048 - val_accuracy: 0.7829\n",
      "Epoch 9/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.5123 - accuracy: 0.7791 - val_loss: 0.5041 - val_accuracy: 0.7829\n",
      "Epoch 10/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.5113 - accuracy: 0.7791 - val_loss: 0.5037 - val_accuracy: 0.7829\n",
      "Epoch 11/200\n",
      "172/172 [==============================] - 0s 856us/sample - loss: 0.5113 - accuracy: 0.7791 - val_loss: 0.5030 - val_accuracy: 0.7829\n",
      "Epoch 12/200\n",
      "172/172 [==============================] - 0s 860us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5028 - val_accuracy: 0.7829\n",
      "Epoch 13/200\n",
      "172/172 [==============================] - 0s 945us/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 14/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 15/200\n",
      "172/172 [==============================] - 0s 967us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 16/200\n",
      "172/172 [==============================] - 0s 826us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 17/200\n",
      "172/172 [==============================] - 0s 827us/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 18/200\n",
      "172/172 [==============================] - 0s 838us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 19/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.5086 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 20/200\n",
      "172/172 [==============================] - 0s 864us/sample - loss: 0.5102 - accuracy: 0.7791 - val_loss: 0.5011 - val_accuracy: 0.7829\n",
      "Epoch 21/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.5081 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 22/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 23/200\n",
      "172/172 [==============================] - 0s 832us/sample - loss: 0.5086 - accuracy: 0.7791 - val_loss: 0.5009 - val_accuracy: 0.7829\n",
      "Epoch 24/200\n",
      "172/172 [==============================] - 0s 824us/sample - loss: 0.5085 - accuracy: 0.7791 - val_loss: 0.5008 - val_accuracy: 0.7829\n",
      "Epoch 25/200\n",
      "172/172 [==============================] - 0s 829us/sample - loss: 0.5077 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 26/200\n",
      "172/172 [==============================] - 0s 835us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5009 - val_accuracy: 0.7829\n",
      "Epoch 27/200\n",
      "172/172 [==============================] - 0s 859us/sample - loss: 0.5080 - accuracy: 0.7791 - val_loss: 0.5011 - val_accuracy: 0.7829\n",
      "Epoch 28/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5007 - val_accuracy: 0.7829\n",
      "Epoch 29/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5012 - val_accuracy: 0.7829\n",
      "Epoch 30/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.5078 - accuracy: 0.7791 - val_loss: 0.5010 - val_accuracy: 0.7829\n",
      "Epoch 31/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 0.5078 - accuracy: 0.7791 - val_loss: 0.5005 - val_accuracy: 0.7829\n",
      "Epoch 32/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.5079 - accuracy: 0.7791 - val_loss: 0.5000 - val_accuracy: 0.7829\n",
      "Epoch 33/200\n",
      "172/172 [==============================] - 0s 959us/sample - loss: 0.5079 - accuracy: 0.7791 - val_loss: 0.5000 - val_accuracy: 0.7829\n",
      "Epoch 34/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5074 - accuracy: 0.7791 - val_loss: 0.4996 - val_accuracy: 0.7829\n",
      "Epoch 35/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 0.5071 - accuracy: 0.7791 - val_loss: 0.4997 - val_accuracy: 0.7829\n",
      "Epoch 36/200\n",
      "172/172 [==============================] - 0s 957us/sample - loss: 0.5113 - accuracy: 0.7791 - val_loss: 0.5007 - val_accuracy: 0.7829\n",
      "Epoch 37/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5078 - accuracy: 0.7791 - val_loss: 0.4997 - val_accuracy: 0.7829\n",
      "Epoch 38/200\n",
      "172/172 [==============================] - 0s 958us/sample - loss: 0.5080 - accuracy: 0.7791 - val_loss: 0.4998 - val_accuracy: 0.7829\n",
      "Epoch 39/200\n",
      "172/172 [==============================] - 0s 961us/sample - loss: 0.5086 - accuracy: 0.7791 - val_loss: 0.4995 - val_accuracy: 0.7829\n",
      "Epoch 40/200\n",
      "172/172 [==============================] - 0s 982us/sample - loss: 0.5063 - accuracy: 0.7791 - val_loss: 0.4997 - val_accuracy: 0.7829\n",
      "Epoch 41/200\n",
      "172/172 [==============================] - 0s 930us/sample - loss: 0.5072 - accuracy: 0.7791 - val_loss: 0.4993 - val_accuracy: 0.7829\n",
      "Epoch 42/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.5067 - accuracy: 0.7791 - val_loss: 0.4989 - val_accuracy: 0.7829\n",
      "Epoch 43/200\n",
      "172/172 [==============================] - 0s 944us/sample - loss: 0.5073 - accuracy: 0.7791 - val_loss: 0.4987 - val_accuracy: 0.7829\n",
      "Epoch 44/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5063 - accuracy: 0.7791 - val_loss: 0.4985 - val_accuracy: 0.7829\n",
      "Epoch 45/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.5070 - accuracy: 0.7791 - val_loss: 0.4985 - val_accuracy: 0.7829\n",
      "Epoch 46/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.5061 - accuracy: 0.7791 - val_loss: 0.4990 - val_accuracy: 0.7829\n",
      "Epoch 47/200\n",
      "172/172 [==============================] - 0s 930us/sample - loss: 0.5059 - accuracy: 0.7791 - val_loss: 0.4984 - val_accuracy: 0.7829\n",
      "Epoch 48/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5061 - accuracy: 0.7791 - val_loss: 0.4980 - val_accuracy: 0.7829\n",
      "Epoch 49/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 0.5068 - accuracy: 0.7791 - val_loss: 0.4988 - val_accuracy: 0.7829\n",
      "Epoch 50/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.5068 - accuracy: 0.7791 - val_loss: 0.4976 - val_accuracy: 0.7829\n",
      "Epoch 51/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.5053 - accuracy: 0.7791 - val_loss: 0.4969 - val_accuracy: 0.7829\n",
      "Epoch 52/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.5060 - accuracy: 0.7791 - val_loss: 0.4969 - val_accuracy: 0.7829\n",
      "Epoch 53/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 0.5057 - accuracy: 0.7791 - val_loss: 0.4970 - val_accuracy: 0.7829\n",
      "Epoch 54/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 0.5048 - accuracy: 0.7791 - val_loss: 0.4967 - val_accuracy: 0.7829\n",
      "Epoch 55/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 900us/sample - loss: 0.5055 - accuracy: 0.7791 - val_loss: 0.4963 - val_accuracy: 0.7829\n",
      "Epoch 56/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.5045 - accuracy: 0.7791 - val_loss: 0.4965 - val_accuracy: 0.7829\n",
      "Epoch 57/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.5038 - accuracy: 0.7791 - val_loss: 0.4959 - val_accuracy: 0.7829\n",
      "Epoch 58/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.5048 - accuracy: 0.7791 - val_loss: 0.4959 - val_accuracy: 0.7829\n",
      "Epoch 59/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5069 - accuracy: 0.7791 - val_loss: 0.4956 - val_accuracy: 0.7829\n",
      "Epoch 60/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5046 - accuracy: 0.7791 - val_loss: 0.4953 - val_accuracy: 0.7829\n",
      "Epoch 61/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.5054 - accuracy: 0.7791 - val_loss: 0.4952 - val_accuracy: 0.7829\n",
      "Epoch 62/200\n",
      "172/172 [==============================] - 0s 948us/sample - loss: 0.5040 - accuracy: 0.7791 - val_loss: 0.4949 - val_accuracy: 0.7829\n",
      "Epoch 63/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5028 - accuracy: 0.7791 - val_loss: 0.4946 - val_accuracy: 0.7829\n",
      "Epoch 64/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 0.5033 - accuracy: 0.7791 - val_loss: 0.4946 - val_accuracy: 0.7829\n",
      "Epoch 65/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5031 - accuracy: 0.7791 - val_loss: 0.4941 - val_accuracy: 0.7829\n",
      "Epoch 66/200\n",
      "172/172 [==============================] - 0s 953us/sample - loss: 0.5035 - accuracy: 0.7791 - val_loss: 0.4946 - val_accuracy: 0.7829\n",
      "Epoch 67/200\n",
      "172/172 [==============================] - 0s 928us/sample - loss: 0.5048 - accuracy: 0.7791 - val_loss: 0.4933 - val_accuracy: 0.7829\n",
      "Epoch 68/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 0.5016 - accuracy: 0.7791 - val_loss: 0.4946 - val_accuracy: 0.7829\n",
      "Epoch 69/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5019 - accuracy: 0.7791 - val_loss: 0.4924 - val_accuracy: 0.7829\n",
      "Epoch 70/200\n",
      "172/172 [==============================] - 0s 961us/sample - loss: 0.5014 - accuracy: 0.7791 - val_loss: 0.4920 - val_accuracy: 0.7829\n",
      "Epoch 71/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5020 - accuracy: 0.7791 - val_loss: 0.4930 - val_accuracy: 0.7829\n",
      "Epoch 72/200\n",
      "172/172 [==============================] - 0s 971us/sample - loss: 0.5026 - accuracy: 0.7791 - val_loss: 0.4911 - val_accuracy: 0.7829\n",
      "Epoch 73/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5007 - accuracy: 0.7791 - val_loss: 0.4914 - val_accuracy: 0.7829\n",
      "Epoch 74/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5000 - accuracy: 0.7791 - val_loss: 0.4902 - val_accuracy: 0.7829\n",
      "Epoch 75/200\n",
      "172/172 [==============================] - 0s 979us/sample - loss: 0.4990 - accuracy: 0.7791 - val_loss: 0.4898 - val_accuracy: 0.7829\n",
      "Epoch 76/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 0.5011 - accuracy: 0.7791 - val_loss: 0.4905 - val_accuracy: 0.7829\n",
      "Epoch 77/200\n",
      "172/172 [==============================] - 0s 953us/sample - loss: 0.5071 - accuracy: 0.7791 - val_loss: 0.4887 - val_accuracy: 0.7829\n",
      "Epoch 78/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.4982 - accuracy: 0.7791 - val_loss: 0.4885 - val_accuracy: 0.7829\n",
      "Epoch 79/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5005 - accuracy: 0.7791 - val_loss: 0.4878 - val_accuracy: 0.7829\n",
      "Epoch 80/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.5012 - accuracy: 0.7791 - val_loss: 0.4866 - val_accuracy: 0.7829\n",
      "Epoch 81/200\n",
      "172/172 [==============================] - 0s 948us/sample - loss: 0.4975 - accuracy: 0.7791 - val_loss: 0.4859 - val_accuracy: 0.7829\n",
      "Epoch 82/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.4954 - accuracy: 0.7791 - val_loss: 0.4865 - val_accuracy: 0.7829\n",
      "Epoch 83/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4956 - accuracy: 0.7791 - val_loss: 0.4844 - val_accuracy: 0.7829\n",
      "Epoch 84/200\n",
      "172/172 [==============================] - 0s 978us/sample - loss: 0.4960 - accuracy: 0.7810 - val_loss: 0.4848 - val_accuracy: 0.7829\n",
      "Epoch 85/200\n",
      "172/172 [==============================] - 0s 997us/sample - loss: 0.4985 - accuracy: 0.7791 - val_loss: 0.4824 - val_accuracy: 0.7829\n",
      "Epoch 86/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.4923 - accuracy: 0.7791 - val_loss: 0.4840 - val_accuracy: 0.7907\n",
      "Epoch 87/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4950 - accuracy: 0.7849 - val_loss: 0.4825 - val_accuracy: 0.7907\n",
      "Epoch 88/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4937 - accuracy: 0.7791 - val_loss: 0.4789 - val_accuracy: 0.7829\n",
      "Epoch 89/200\n",
      "172/172 [==============================] - 0s 966us/sample - loss: 0.4902 - accuracy: 0.7771 - val_loss: 0.4803 - val_accuracy: 0.7907\n",
      "Epoch 90/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.4921 - accuracy: 0.7791 - val_loss: 0.4777 - val_accuracy: 0.7907\n",
      "Epoch 91/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.4912 - accuracy: 0.7791 - val_loss: 0.4766 - val_accuracy: 0.7907\n",
      "Epoch 92/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.4875 - accuracy: 0.7791 - val_loss: 0.4763 - val_accuracy: 0.7907\n",
      "Epoch 93/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.4860 - accuracy: 0.7829 - val_loss: 0.4749 - val_accuracy: 0.7907\n",
      "Epoch 94/200\n",
      "172/172 [==============================] - 0s 975us/sample - loss: 0.4849 - accuracy: 0.7810 - val_loss: 0.4738 - val_accuracy: 0.7907\n",
      "Epoch 95/200\n",
      "172/172 [==============================] - 0s 964us/sample - loss: 0.4858 - accuracy: 0.7829 - val_loss: 0.4724 - val_accuracy: 0.7907\n",
      "Epoch 96/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.4841 - accuracy: 0.7829 - val_loss: 0.4728 - val_accuracy: 0.7984\n",
      "Epoch 97/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.4819 - accuracy: 0.7849 - val_loss: 0.4724 - val_accuracy: 0.8062\n",
      "Epoch 98/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.4846 - accuracy: 0.7829 - val_loss: 0.4713 - val_accuracy: 0.8062\n",
      "Epoch 99/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 0.4804 - accuracy: 0.7868 - val_loss: 0.4691 - val_accuracy: 0.7984\n",
      "Epoch 100/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.4879 - accuracy: 0.7849 - val_loss: 0.4698 - val_accuracy: 0.7984\n",
      "Epoch 101/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 0.4849 - accuracy: 0.8081 - val_loss: 0.4735 - val_accuracy: 0.7984\n",
      "Epoch 102/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 0.4795 - accuracy: 0.7868 - val_loss: 0.4659 - val_accuracy: 0.7984\n",
      "Epoch 103/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.4793 - accuracy: 0.7926 - val_loss: 0.4697 - val_accuracy: 0.7984\n",
      "Epoch 104/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.4732 - accuracy: 0.7888 - val_loss: 0.4641 - val_accuracy: 0.8062\n",
      "Epoch 105/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.4798 - accuracy: 0.7849 - val_loss: 0.4675 - val_accuracy: 0.7984\n",
      "Epoch 106/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.4739 - accuracy: 0.7888 - val_loss: 0.4648 - val_accuracy: 0.7984\n",
      "Epoch 107/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.4717 - accuracy: 0.7907 - val_loss: 0.4634 - val_accuracy: 0.7984\n",
      "Epoch 108/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.4721 - accuracy: 0.7888 - val_loss: 0.4609 - val_accuracy: 0.7984\n",
      "Epoch 109/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 0.4718 - accuracy: 0.7907 - val_loss: 0.4613 - val_accuracy: 0.7984\n",
      "Epoch 110/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 902us/sample - loss: 0.4741 - accuracy: 0.7907 - val_loss: 0.4613 - val_accuracy: 0.7984\n",
      "Epoch 111/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.4696 - accuracy: 0.7926 - val_loss: 0.4623 - val_accuracy: 0.7907\n",
      "Epoch 112/200\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 0.4679 - accuracy: 0.7984 - val_loss: 0.4652 - val_accuracy: 0.8062\n",
      "Epoch 113/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.4708 - accuracy: 0.8120 - val_loss: 0.4586 - val_accuracy: 0.7984\n",
      "Epoch 114/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.4678 - accuracy: 0.7907 - val_loss: 0.4636 - val_accuracy: 0.8062\n",
      "Epoch 115/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.4699 - accuracy: 0.8043 - val_loss: 0.4576 - val_accuracy: 0.7907\n",
      "Epoch 116/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 0.4687 - accuracy: 0.7907 - val_loss: 0.4611 - val_accuracy: 0.8062\n",
      "Epoch 117/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.4668 - accuracy: 0.7965 - val_loss: 0.4557 - val_accuracy: 0.7907\n",
      "Epoch 118/200\n",
      "172/172 [==============================] - 0s 869us/sample - loss: 0.4644 - accuracy: 0.8062 - val_loss: 0.4628 - val_accuracy: 0.8062\n",
      "Epoch 119/200\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 0.4635 - accuracy: 0.8120 - val_loss: 0.4557 - val_accuracy: 0.7984\n",
      "Epoch 120/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.4660 - accuracy: 0.7868 - val_loss: 0.4595 - val_accuracy: 0.8062\n",
      "Epoch 121/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 0.4681 - accuracy: 0.8159 - val_loss: 0.4570 - val_accuracy: 0.8062\n",
      "Epoch 122/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.4615 - accuracy: 0.7984 - val_loss: 0.4577 - val_accuracy: 0.8062\n",
      "Epoch 123/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.4610 - accuracy: 0.8140 - val_loss: 0.4577 - val_accuracy: 0.8062\n",
      "Epoch 124/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 0.4621 - accuracy: 0.8023 - val_loss: 0.4528 - val_accuracy: 0.7984\n",
      "Epoch 125/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.4605 - accuracy: 0.8217 - val_loss: 0.4594 - val_accuracy: 0.8062\n",
      "Epoch 126/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 0.4624 - accuracy: 0.7946 - val_loss: 0.4542 - val_accuracy: 0.8062\n",
      "Epoch 127/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.4594 - accuracy: 0.7965 - val_loss: 0.4545 - val_accuracy: 0.8062\n",
      "Epoch 128/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.4580 - accuracy: 0.8140 - val_loss: 0.4556 - val_accuracy: 0.8062\n",
      "Epoch 129/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 0.4566 - accuracy: 0.8140 - val_loss: 0.4515 - val_accuracy: 0.8062\n",
      "Epoch 130/200\n",
      "172/172 [==============================] - 0s 937us/sample - loss: 0.4553 - accuracy: 0.8159 - val_loss: 0.4522 - val_accuracy: 0.8062\n",
      "Epoch 131/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.4560 - accuracy: 0.8004 - val_loss: 0.4506 - val_accuracy: 0.8062\n",
      "Epoch 132/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.4549 - accuracy: 0.8101 - val_loss: 0.4510 - val_accuracy: 0.8062\n",
      "Epoch 133/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.4544 - accuracy: 0.8178 - val_loss: 0.4522 - val_accuracy: 0.8062\n",
      "Epoch 134/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.4601 - accuracy: 0.8023 - val_loss: 0.4547 - val_accuracy: 0.8062\n",
      "Epoch 135/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.4545 - accuracy: 0.8159 - val_loss: 0.4494 - val_accuracy: 0.8062\n",
      "Epoch 136/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 0.4545 - accuracy: 0.8023 - val_loss: 0.4455 - val_accuracy: 0.7984\n",
      "Epoch 137/200\n",
      "172/172 [==============================] - 0s 946us/sample - loss: 0.4581 - accuracy: 0.8140 - val_loss: 0.4535 - val_accuracy: 0.8062\n",
      "Epoch 138/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.4499 - accuracy: 0.8178 - val_loss: 0.4449 - val_accuracy: 0.7907\n",
      "Epoch 139/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 0.4548 - accuracy: 0.8043 - val_loss: 0.4517 - val_accuracy: 0.8062\n",
      "Epoch 140/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.4499 - accuracy: 0.8178 - val_loss: 0.4449 - val_accuracy: 0.8062\n",
      "Epoch 141/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.4529 - accuracy: 0.8043 - val_loss: 0.4464 - val_accuracy: 0.8062\n",
      "Epoch 142/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.4501 - accuracy: 0.8198 - val_loss: 0.4486 - val_accuracy: 0.8062\n",
      "Epoch 143/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.4509 - accuracy: 0.8178 - val_loss: 0.4504 - val_accuracy: 0.8062\n",
      "Epoch 144/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.4494 - accuracy: 0.8217 - val_loss: 0.4458 - val_accuracy: 0.8062\n",
      "Epoch 145/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.4496 - accuracy: 0.8159 - val_loss: 0.4458 - val_accuracy: 0.8062\n",
      "Epoch 146/200\n",
      "172/172 [==============================] - 0s 937us/sample - loss: 0.4492 - accuracy: 0.8217 - val_loss: 0.4439 - val_accuracy: 0.8062\n",
      "Epoch 147/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 0.4507 - accuracy: 0.8081 - val_loss: 0.4448 - val_accuracy: 0.8062\n",
      "Epoch 148/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.4512 - accuracy: 0.8101 - val_loss: 0.4458 - val_accuracy: 0.8062\n",
      "Epoch 149/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.4459 - accuracy: 0.8178 - val_loss: 0.4440 - val_accuracy: 0.8062\n",
      "Epoch 150/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 0.4467 - accuracy: 0.8178 - val_loss: 0.4440 - val_accuracy: 0.8062\n",
      "Epoch 151/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.4469 - accuracy: 0.8159 - val_loss: 0.4429 - val_accuracy: 0.8062\n",
      "Epoch 152/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.4459 - accuracy: 0.8159 - val_loss: 0.4423 - val_accuracy: 0.8062\n",
      "Epoch 153/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 0.4465 - accuracy: 0.8140 - val_loss: 0.4450 - val_accuracy: 0.8062\n",
      "Epoch 154/200\n",
      "172/172 [==============================] - 0s 865us/sample - loss: 0.4431 - accuracy: 0.8236 - val_loss: 0.4392 - val_accuracy: 0.7907\n",
      "Epoch 155/200\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 0.4497 - accuracy: 0.8140 - val_loss: 0.4475 - val_accuracy: 0.8217\n",
      "Epoch 156/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.4451 - accuracy: 0.8178 - val_loss: 0.4429 - val_accuracy: 0.8062\n",
      "Epoch 157/200\n",
      "172/172 [==============================] - 0s 882us/sample - loss: 0.4465 - accuracy: 0.8198 - val_loss: 0.4388 - val_accuracy: 0.8062\n",
      "Epoch 158/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 0.4435 - accuracy: 0.8159 - val_loss: 0.4439 - val_accuracy: 0.8140\n",
      "Epoch 159/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.4446 - accuracy: 0.8217 - val_loss: 0.4437 - val_accuracy: 0.8140\n",
      "Epoch 160/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.4442 - accuracy: 0.8178 - val_loss: 0.4386 - val_accuracy: 0.8062\n",
      "Epoch 161/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.4488 - accuracy: 0.8120 - val_loss: 0.4395 - val_accuracy: 0.8062\n",
      "Epoch 162/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.4492 - accuracy: 0.8217 - val_loss: 0.4404 - val_accuracy: 0.8062\n",
      "Epoch 163/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.4406 - accuracy: 0.8217 - val_loss: 0.4428 - val_accuracy: 0.8217\n",
      "Epoch 164/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.4431 - accuracy: 0.8159 - val_loss: 0.4388 - val_accuracy: 0.8062\n",
      "Epoch 165/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 912us/sample - loss: 0.4408 - accuracy: 0.8217 - val_loss: 0.4410 - val_accuracy: 0.8140\n",
      "Epoch 166/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.4426 - accuracy: 0.8236 - val_loss: 0.4385 - val_accuracy: 0.8062\n",
      "Epoch 167/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.4495 - accuracy: 0.8023 - val_loss: 0.4441 - val_accuracy: 0.8372\n",
      "Epoch 168/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.4420 - accuracy: 0.8140 - val_loss: 0.4376 - val_accuracy: 0.8062\n",
      "Epoch 169/200\n",
      "172/172 [==============================] - 0s 948us/sample - loss: 0.4398 - accuracy: 0.8236 - val_loss: 0.4370 - val_accuracy: 0.8062\n",
      "Epoch 170/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.4382 - accuracy: 0.8217 - val_loss: 0.4388 - val_accuracy: 0.8140\n",
      "Epoch 171/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.4404 - accuracy: 0.8178 - val_loss: 0.4427 - val_accuracy: 0.8372\n",
      "Epoch 172/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 0.4398 - accuracy: 0.8217 - val_loss: 0.4358 - val_accuracy: 0.8062\n",
      "Epoch 173/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.4421 - accuracy: 0.8140 - val_loss: 0.4388 - val_accuracy: 0.8140\n",
      "Epoch 174/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.4422 - accuracy: 0.8236 - val_loss: 0.4355 - val_accuracy: 0.8062\n",
      "Epoch 175/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.4369 - accuracy: 0.8217 - val_loss: 0.4382 - val_accuracy: 0.8140\n",
      "Epoch 176/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.4382 - accuracy: 0.8159 - val_loss: 0.4343 - val_accuracy: 0.8062\n",
      "Epoch 177/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 0.4434 - accuracy: 0.8120 - val_loss: 0.4543 - val_accuracy: 0.8140\n",
      "Epoch 178/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 0.4448 - accuracy: 0.8275 - val_loss: 0.4371 - val_accuracy: 0.8140\n",
      "Epoch 179/200\n",
      "172/172 [==============================] - 0s 865us/sample - loss: 0.4379 - accuracy: 0.8217 - val_loss: 0.4425 - val_accuracy: 0.8372\n",
      "Epoch 180/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 0.4415 - accuracy: 0.8198 - val_loss: 0.4402 - val_accuracy: 0.8372\n",
      "Epoch 181/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.4390 - accuracy: 0.8275 - val_loss: 0.4325 - val_accuracy: 0.8062\n",
      "Epoch 182/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.4528 - accuracy: 0.8043 - val_loss: 0.4414 - val_accuracy: 0.8372\n",
      "Epoch 183/200\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 0.4366 - accuracy: 0.8159 - val_loss: 0.4335 - val_accuracy: 0.8062\n",
      "Epoch 184/200\n",
      "172/172 [==============================] - 0s 861us/sample - loss: 0.4352 - accuracy: 0.8217 - val_loss: 0.4368 - val_accuracy: 0.8295\n",
      "Epoch 185/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.4352 - accuracy: 0.8236 - val_loss: 0.4317 - val_accuracy: 0.8062\n",
      "Epoch 186/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 0.4413 - accuracy: 0.8043 - val_loss: 0.4393 - val_accuracy: 0.8372\n",
      "Epoch 187/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.4407 - accuracy: 0.8275 - val_loss: 0.4308 - val_accuracy: 0.7984\n",
      "Epoch 188/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 0.4477 - accuracy: 0.8101 - val_loss: 0.4341 - val_accuracy: 0.8140\n",
      "Epoch 189/200\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 0.4406 - accuracy: 0.8081 - val_loss: 0.4342 - val_accuracy: 0.8140\n",
      "Epoch 190/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 0.4384 - accuracy: 0.8295 - val_loss: 0.4439 - val_accuracy: 0.8372\n",
      "Epoch 191/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.4445 - accuracy: 0.8314 - val_loss: 0.4320 - val_accuracy: 0.8062\n",
      "Epoch 192/200\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 0.4334 - accuracy: 0.8198 - val_loss: 0.4347 - val_accuracy: 0.8140\n",
      "Epoch 193/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 0.4418 - accuracy: 0.8120 - val_loss: 0.4368 - val_accuracy: 0.8372\n",
      "Epoch 194/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 0.4344 - accuracy: 0.8217 - val_loss: 0.4361 - val_accuracy: 0.8372\n",
      "Epoch 195/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.4331 - accuracy: 0.8236 - val_loss: 0.4339 - val_accuracy: 0.8140\n",
      "Epoch 196/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.4322 - accuracy: 0.8275 - val_loss: 0.4327 - val_accuracy: 0.8140\n",
      "Epoch 197/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.4311 - accuracy: 0.8217 - val_loss: 0.4304 - val_accuracy: 0.8062\n",
      "Epoch 198/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.4332 - accuracy: 0.8178 - val_loss: 0.4424 - val_accuracy: 0.8372\n",
      "Epoch 199/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.4437 - accuracy: 0.8275 - val_loss: 0.4285 - val_accuracy: 0.7907\n",
      "Epoch 200/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.4372 - accuracy: 0.8140 - val_loss: 0.4308 - val_accuracy: 0.8140\n",
      "Beginning training for dr=0.001, l_lambda=1.0e-03, reg_type=l2, act: tanh\n",
      "Train on 172 samples, validate on 43 samples\n",
      "Epoch 1/200\n",
      "172/172 [==============================] - 1s 8ms/sample - loss: 0.6347 - accuracy: 0.6667 - val_loss: 0.5826 - val_accuracy: 0.6667\n",
      "Epoch 2/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 0.5636 - accuracy: 0.7171 - val_loss: 0.5292 - val_accuracy: 0.7829\n",
      "Epoch 3/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 0.5272 - accuracy: 0.7791 - val_loss: 0.5149 - val_accuracy: 0.7829\n",
      "Epoch 4/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.5191 - accuracy: 0.7791 - val_loss: 0.5108 - val_accuracy: 0.7829\n",
      "Epoch 5/200\n",
      "172/172 [==============================] - 0s 869us/sample - loss: 0.5173 - accuracy: 0.7791 - val_loss: 0.5097 - val_accuracy: 0.7829\n",
      "Epoch 6/200\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 0.5172 - accuracy: 0.7791 - val_loss: 0.5081 - val_accuracy: 0.7829\n",
      "Epoch 7/200\n",
      "172/172 [==============================] - 0s 857us/sample - loss: 0.5154 - accuracy: 0.7791 - val_loss: 0.5085 - val_accuracy: 0.7829\n",
      "Epoch 8/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5137 - accuracy: 0.7791 - val_loss: 0.5061 - val_accuracy: 0.7829\n",
      "Epoch 9/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 0.5137 - accuracy: 0.7791 - val_loss: 0.5050 - val_accuracy: 0.7829\n",
      "Epoch 10/200\n",
      "172/172 [==============================] - 0s 864us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5052 - val_accuracy: 0.7829\n",
      "Epoch 11/200\n",
      "172/172 [==============================] - 0s 860us/sample - loss: 0.5142 - accuracy: 0.7791 - val_loss: 0.5034 - val_accuracy: 0.7829\n",
      "Epoch 12/200\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 0.5113 - accuracy: 0.7791 - val_loss: 0.5029 - val_accuracy: 0.7829\n",
      "Epoch 13/200\n",
      "172/172 [==============================] - 0s 860us/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 14/200\n",
      "172/172 [==============================] - 0s 859us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 15/200\n",
      "172/172 [==============================] - 0s 949us/sample - loss: 0.5083 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 16/200\n",
      "172/172 [==============================] - 0s 856us/sample - loss: 0.5080 - accuracy: 0.7791 - val_loss: 0.4994 - val_accuracy: 0.7829\n",
      "Epoch 17/200\n",
      "172/172 [==============================] - 0s 861us/sample - loss: 0.5073 - accuracy: 0.7791 - val_loss: 0.4983 - val_accuracy: 0.7829\n",
      "Epoch 18/200\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 0.5069 - accuracy: 0.7791 - val_loss: 0.4973 - val_accuracy: 0.7829\n",
      "Epoch 19/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 869us/sample - loss: 0.5059 - accuracy: 0.7791 - val_loss: 0.4970 - val_accuracy: 0.7829\n",
      "Epoch 20/200\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 0.5054 - accuracy: 0.7791 - val_loss: 0.4952 - val_accuracy: 0.7829\n",
      "Epoch 21/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.5035 - accuracy: 0.7810 - val_loss: 0.4947 - val_accuracy: 0.7829\n",
      "Epoch 22/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.5026 - accuracy: 0.7810 - val_loss: 0.4931 - val_accuracy: 0.7829\n",
      "Epoch 23/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.5015 - accuracy: 0.7810 - val_loss: 0.4914 - val_accuracy: 0.7829\n",
      "Epoch 24/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.5005 - accuracy: 0.7810 - val_loss: 0.4906 - val_accuracy: 0.7829\n",
      "Epoch 25/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 0.4999 - accuracy: 0.7810 - val_loss: 0.4886 - val_accuracy: 0.7829\n",
      "Epoch 26/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.4992 - accuracy: 0.7810 - val_loss: 0.4865 - val_accuracy: 0.7829\n",
      "Epoch 27/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.4958 - accuracy: 0.7810 - val_loss: 0.4862 - val_accuracy: 0.7829\n",
      "Epoch 28/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.5003 - accuracy: 0.7829 - val_loss: 0.4871 - val_accuracy: 0.7907\n",
      "Epoch 29/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.4957 - accuracy: 0.7791 - val_loss: 0.4819 - val_accuracy: 0.7829\n",
      "Epoch 30/200\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 0.4915 - accuracy: 0.7791 - val_loss: 0.4807 - val_accuracy: 0.7907\n",
      "Epoch 31/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.4901 - accuracy: 0.7791 - val_loss: 0.4783 - val_accuracy: 0.7907\n",
      "Epoch 32/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.4898 - accuracy: 0.7791 - val_loss: 0.4763 - val_accuracy: 0.7907\n",
      "Epoch 33/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.4884 - accuracy: 0.7791 - val_loss: 0.4737 - val_accuracy: 0.7907\n",
      "Epoch 34/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.4883 - accuracy: 0.7810 - val_loss: 0.4728 - val_accuracy: 0.7984\n",
      "Epoch 35/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.4849 - accuracy: 0.7868 - val_loss: 0.4731 - val_accuracy: 0.8062\n",
      "Epoch 36/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.4926 - accuracy: 0.7926 - val_loss: 0.4680 - val_accuracy: 0.7907\n",
      "Epoch 37/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 0.4808 - accuracy: 0.7849 - val_loss: 0.4703 - val_accuracy: 0.7984\n",
      "Epoch 38/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.4791 - accuracy: 0.7907 - val_loss: 0.4655 - val_accuracy: 0.7984\n",
      "Epoch 39/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.4806 - accuracy: 0.7888 - val_loss: 0.4616 - val_accuracy: 0.7907\n",
      "Epoch 40/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.4862 - accuracy: 0.8120 - val_loss: 0.4616 - val_accuracy: 0.7984\n",
      "Epoch 41/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.4789 - accuracy: 0.7868 - val_loss: 0.4643 - val_accuracy: 0.8062\n",
      "Epoch 42/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.4731 - accuracy: 0.7984 - val_loss: 0.4618 - val_accuracy: 0.8062\n",
      "Epoch 43/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.4779 - accuracy: 0.7926 - val_loss: 0.4660 - val_accuracy: 0.8062\n",
      "Epoch 44/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.4738 - accuracy: 0.8043 - val_loss: 0.4544 - val_accuracy: 0.8062\n",
      "Epoch 45/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 0.4663 - accuracy: 0.8081 - val_loss: 0.4606 - val_accuracy: 0.8062\n",
      "Epoch 46/200\n",
      "172/172 [==============================] - 0s 951us/sample - loss: 0.4640 - accuracy: 0.8101 - val_loss: 0.4513 - val_accuracy: 0.8062\n",
      "Epoch 47/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.4683 - accuracy: 0.7946 - val_loss: 0.4516 - val_accuracy: 0.8062\n",
      "Epoch 48/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.4636 - accuracy: 0.8004 - val_loss: 0.4519 - val_accuracy: 0.8062\n",
      "Epoch 49/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.4645 - accuracy: 0.8004 - val_loss: 0.4588 - val_accuracy: 0.8062\n",
      "Epoch 50/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.4652 - accuracy: 0.8081 - val_loss: 0.4500 - val_accuracy: 0.8062\n",
      "Epoch 51/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 0.4654 - accuracy: 0.8140 - val_loss: 0.4475 - val_accuracy: 0.7984\n",
      "Epoch 52/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.4689 - accuracy: 0.7907 - val_loss: 0.4544 - val_accuracy: 0.8062\n",
      "Epoch 53/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.4596 - accuracy: 0.8178 - val_loss: 0.4468 - val_accuracy: 0.8062\n",
      "Epoch 54/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 0.4591 - accuracy: 0.8023 - val_loss: 0.4503 - val_accuracy: 0.8062\n",
      "Epoch 55/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 0.4614 - accuracy: 0.8081 - val_loss: 0.4433 - val_accuracy: 0.7984\n",
      "Epoch 56/200\n",
      "172/172 [==============================] - 0s 956us/sample - loss: 0.4670 - accuracy: 0.7965 - val_loss: 0.4622 - val_accuracy: 0.8372\n",
      "Epoch 57/200\n",
      "172/172 [==============================] - 0s 930us/sample - loss: 0.4573 - accuracy: 0.8043 - val_loss: 0.4423 - val_accuracy: 0.7984\n",
      "Epoch 58/200\n",
      "172/172 [==============================] - 0s 953us/sample - loss: 0.4566 - accuracy: 0.7984 - val_loss: 0.4476 - val_accuracy: 0.8062\n",
      "Epoch 59/200\n",
      "172/172 [==============================] - 0s 946us/sample - loss: 0.4565 - accuracy: 0.8120 - val_loss: 0.4432 - val_accuracy: 0.8062\n",
      "Epoch 60/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.4569 - accuracy: 0.8178 - val_loss: 0.4411 - val_accuracy: 0.7984\n",
      "Epoch 61/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.4523 - accuracy: 0.8081 - val_loss: 0.4485 - val_accuracy: 0.8062\n",
      "Epoch 62/200\n",
      "172/172 [==============================] - 0s 941us/sample - loss: 0.4588 - accuracy: 0.8159 - val_loss: 0.4412 - val_accuracy: 0.8062\n",
      "Epoch 63/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.4573 - accuracy: 0.8120 - val_loss: 0.4397 - val_accuracy: 0.8062\n",
      "Epoch 64/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.4525 - accuracy: 0.8101 - val_loss: 0.4454 - val_accuracy: 0.8062\n",
      "Epoch 65/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.4524 - accuracy: 0.8178 - val_loss: 0.4398 - val_accuracy: 0.8062\n",
      "Epoch 66/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.4571 - accuracy: 0.8101 - val_loss: 0.4567 - val_accuracy: 0.8450\n",
      "Epoch 67/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.4530 - accuracy: 0.8198 - val_loss: 0.4372 - val_accuracy: 0.8062\n",
      "Epoch 68/200\n",
      "172/172 [==============================] - 0s 946us/sample - loss: 0.4497 - accuracy: 0.8217 - val_loss: 0.4370 - val_accuracy: 0.8062\n",
      "Epoch 69/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.4512 - accuracy: 0.8062 - val_loss: 0.4484 - val_accuracy: 0.8062\n",
      "Epoch 70/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 0.4541 - accuracy: 0.8159 - val_loss: 0.4436 - val_accuracy: 0.8062\n",
      "Epoch 71/200\n",
      "172/172 [==============================] - 0s 967us/sample - loss: 0.4684 - accuracy: 0.7907 - val_loss: 0.5073 - val_accuracy: 0.8295\n",
      "Epoch 72/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.4552 - accuracy: 0.8236 - val_loss: 0.4363 - val_accuracy: 0.7907\n",
      "Epoch 73/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.4471 - accuracy: 0.8120 - val_loss: 0.4449 - val_accuracy: 0.8062\n",
      "Epoch 74/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 928us/sample - loss: 0.4480 - accuracy: 0.8198 - val_loss: 0.4341 - val_accuracy: 0.7984\n",
      "Epoch 75/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.4539 - accuracy: 0.8178 - val_loss: 0.4337 - val_accuracy: 0.7984\n",
      "Epoch 76/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.4521 - accuracy: 0.8159 - val_loss: 0.4342 - val_accuracy: 0.8062\n",
      "Epoch 77/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.4503 - accuracy: 0.8004 - val_loss: 0.4584 - val_accuracy: 0.8372\n",
      "Epoch 78/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.4538 - accuracy: 0.8159 - val_loss: 0.4322 - val_accuracy: 0.8062\n",
      "Epoch 79/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.4472 - accuracy: 0.8198 - val_loss: 0.4432 - val_accuracy: 0.8295\n",
      "Epoch 80/200\n",
      "172/172 [==============================] - 0s 882us/sample - loss: 0.4487 - accuracy: 0.8081 - val_loss: 0.4397 - val_accuracy: 0.8140\n",
      "Epoch 81/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.4453 - accuracy: 0.8159 - val_loss: 0.4510 - val_accuracy: 0.8372\n",
      "Epoch 82/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.4582 - accuracy: 0.8178 - val_loss: 0.4411 - val_accuracy: 0.7984\n",
      "Epoch 83/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.4758 - accuracy: 0.7984 - val_loss: 0.4436 - val_accuracy: 0.8372\n",
      "Epoch 84/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.4505 - accuracy: 0.8101 - val_loss: 0.4362 - val_accuracy: 0.8062\n",
      "Epoch 85/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.4414 - accuracy: 0.8178 - val_loss: 0.4317 - val_accuracy: 0.8062\n",
      "Epoch 86/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.4406 - accuracy: 0.8236 - val_loss: 0.4387 - val_accuracy: 0.8140\n",
      "Epoch 87/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.4470 - accuracy: 0.8101 - val_loss: 0.4478 - val_accuracy: 0.8372\n",
      "Epoch 88/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.4460 - accuracy: 0.8275 - val_loss: 0.4303 - val_accuracy: 0.7984\n",
      "Epoch 89/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.4444 - accuracy: 0.8178 - val_loss: 0.4404 - val_accuracy: 0.8372\n",
      "Epoch 90/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 0.4461 - accuracy: 0.8101 - val_loss: 0.4407 - val_accuracy: 0.8372\n",
      "Epoch 91/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.4411 - accuracy: 0.8236 - val_loss: 0.4310 - val_accuracy: 0.8062\n",
      "Epoch 92/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 0.4407 - accuracy: 0.8236 - val_loss: 0.4274 - val_accuracy: 0.8062\n",
      "Epoch 93/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.4374 - accuracy: 0.8236 - val_loss: 0.4321 - val_accuracy: 0.8062\n",
      "Epoch 94/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.4426 - accuracy: 0.8198 - val_loss: 0.4318 - val_accuracy: 0.8140\n",
      "Epoch 95/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.4384 - accuracy: 0.8275 - val_loss: 0.4362 - val_accuracy: 0.8372\n",
      "Epoch 96/200\n",
      "172/172 [==============================] - 0s 941us/sample - loss: 0.4456 - accuracy: 0.8140 - val_loss: 0.4286 - val_accuracy: 0.8062\n",
      "Epoch 97/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.4363 - accuracy: 0.8217 - val_loss: 0.4250 - val_accuracy: 0.8062\n",
      "Epoch 98/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.4447 - accuracy: 0.8101 - val_loss: 0.4246 - val_accuracy: 0.8062\n",
      "Epoch 99/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.4416 - accuracy: 0.8178 - val_loss: 0.4244 - val_accuracy: 0.7984\n",
      "Epoch 100/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.4432 - accuracy: 0.8081 - val_loss: 0.4325 - val_accuracy: 0.8295\n",
      "Epoch 101/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 0.4417 - accuracy: 0.8159 - val_loss: 0.4366 - val_accuracy: 0.8372\n",
      "Epoch 102/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.4378 - accuracy: 0.8198 - val_loss: 0.4299 - val_accuracy: 0.8295\n",
      "Epoch 103/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.4359 - accuracy: 0.8236 - val_loss: 0.4249 - val_accuracy: 0.7984\n",
      "Epoch 104/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 0.4402 - accuracy: 0.8140 - val_loss: 0.4377 - val_accuracy: 0.8372\n",
      "Epoch 105/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.4345 - accuracy: 0.8275 - val_loss: 0.4228 - val_accuracy: 0.7984\n",
      "Epoch 106/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.4352 - accuracy: 0.8236 - val_loss: 0.4279 - val_accuracy: 0.8140\n",
      "Epoch 107/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.4364 - accuracy: 0.8178 - val_loss: 0.4395 - val_accuracy: 0.8372\n",
      "Epoch 108/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.4435 - accuracy: 0.8256 - val_loss: 0.4303 - val_accuracy: 0.7984\n",
      "Epoch 109/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.4348 - accuracy: 0.8236 - val_loss: 0.4298 - val_accuracy: 0.8295\n",
      "Epoch 110/200\n",
      "172/172 [==============================] - 0s 944us/sample - loss: 0.4310 - accuracy: 0.8256 - val_loss: 0.4222 - val_accuracy: 0.7984\n",
      "Epoch 111/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.4355 - accuracy: 0.8081 - val_loss: 0.4480 - val_accuracy: 0.8372\n",
      "Epoch 112/200\n",
      "172/172 [==============================] - 0s 944us/sample - loss: 0.4378 - accuracy: 0.8198 - val_loss: 0.4224 - val_accuracy: 0.7907\n",
      "Epoch 113/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.4326 - accuracy: 0.8372 - val_loss: 0.4214 - val_accuracy: 0.8062\n",
      "Epoch 114/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.4367 - accuracy: 0.8023 - val_loss: 0.4482 - val_accuracy: 0.8372\n",
      "Epoch 115/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.4331 - accuracy: 0.8353 - val_loss: 0.4223 - val_accuracy: 0.8062\n",
      "Epoch 116/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.4345 - accuracy: 0.8333 - val_loss: 0.4361 - val_accuracy: 0.8372\n",
      "Epoch 117/200\n",
      "172/172 [==============================] - 0s 969us/sample - loss: 0.4290 - accuracy: 0.8333 - val_loss: 0.4225 - val_accuracy: 0.7907\n",
      "Epoch 118/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4488 - accuracy: 0.8140 - val_loss: 0.4217 - val_accuracy: 0.7907\n",
      "Epoch 119/200\n",
      "172/172 [==============================] - 0s 999us/sample - loss: 0.4267 - accuracy: 0.8256 - val_loss: 0.4404 - val_accuracy: 0.8372\n",
      "Epoch 120/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.4302 - accuracy: 0.8275 - val_loss: 0.4244 - val_accuracy: 0.8295\n",
      "Epoch 121/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.4289 - accuracy: 0.8314 - val_loss: 0.4249 - val_accuracy: 0.8062\n",
      "Epoch 122/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 0.4374 - accuracy: 0.8256 - val_loss: 0.4277 - val_accuracy: 0.8295\n",
      "Epoch 123/200\n",
      "172/172 [==============================] - 0s 982us/sample - loss: 0.4293 - accuracy: 0.8236 - val_loss: 0.4311 - val_accuracy: 0.8372\n",
      "Epoch 124/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 0.4351 - accuracy: 0.8275 - val_loss: 0.4354 - val_accuracy: 0.7907\n",
      "Epoch 125/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.4574 - accuracy: 0.8120 - val_loss: 0.4271 - val_accuracy: 0.8295\n",
      "Epoch 126/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.4270 - accuracy: 0.8295 - val_loss: 0.4236 - val_accuracy: 0.8295\n",
      "Epoch 127/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.4268 - accuracy: 0.8314 - val_loss: 0.4199 - val_accuracy: 0.8062\n",
      "Epoch 128/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.4288 - accuracy: 0.8314 - val_loss: 0.4199 - val_accuracy: 0.7984\n",
      "Epoch 129/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 876us/sample - loss: 0.4330 - accuracy: 0.8236 - val_loss: 0.4203 - val_accuracy: 0.8062\n",
      "Epoch 130/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.4257 - accuracy: 0.8256 - val_loss: 0.4298 - val_accuracy: 0.8372\n",
      "Epoch 131/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.4244 - accuracy: 0.8353 - val_loss: 0.4240 - val_accuracy: 0.8062\n",
      "Epoch 132/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.4376 - accuracy: 0.8120 - val_loss: 0.4278 - val_accuracy: 0.8372\n",
      "Epoch 133/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.4383 - accuracy: 0.8101 - val_loss: 0.4233 - val_accuracy: 0.8295\n",
      "Epoch 134/200\n",
      "172/172 [==============================] - 0s 882us/sample - loss: 0.4252 - accuracy: 0.8217 - val_loss: 0.4407 - val_accuracy: 0.8450\n",
      "Epoch 135/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 0.4304 - accuracy: 0.8256 - val_loss: 0.4203 - val_accuracy: 0.8140\n",
      "Epoch 136/200\n",
      "172/172 [==============================] - 0s 943us/sample - loss: 0.4239 - accuracy: 0.8295 - val_loss: 0.4279 - val_accuracy: 0.8372\n",
      "Epoch 137/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.4217 - accuracy: 0.8353 - val_loss: 0.4210 - val_accuracy: 0.7984\n",
      "Epoch 138/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.4265 - accuracy: 0.8178 - val_loss: 0.4360 - val_accuracy: 0.8450\n",
      "Epoch 139/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.4251 - accuracy: 0.8333 - val_loss: 0.4224 - val_accuracy: 0.8295\n",
      "Epoch 140/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.4259 - accuracy: 0.8314 - val_loss: 0.4192 - val_accuracy: 0.8062\n",
      "Epoch 141/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.4283 - accuracy: 0.8333 - val_loss: 0.4201 - val_accuracy: 0.8217\n",
      "Epoch 142/200\n",
      "172/172 [==============================] - 0s 960us/sample - loss: 0.4230 - accuracy: 0.8372 - val_loss: 0.4186 - val_accuracy: 0.7984\n",
      "Epoch 143/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.4210 - accuracy: 0.8314 - val_loss: 0.4318 - val_accuracy: 0.8372\n",
      "Epoch 144/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 0.4194 - accuracy: 0.8333 - val_loss: 0.4179 - val_accuracy: 0.7984\n",
      "Epoch 145/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.4301 - accuracy: 0.8256 - val_loss: 0.4212 - val_accuracy: 0.8295\n",
      "Epoch 146/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.4286 - accuracy: 0.8178 - val_loss: 0.4811 - val_accuracy: 0.8062\n",
      "Epoch 147/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 0.4448 - accuracy: 0.8140 - val_loss: 0.4205 - val_accuracy: 0.8295\n",
      "Epoch 148/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.4359 - accuracy: 0.8198 - val_loss: 0.4171 - val_accuracy: 0.7984\n",
      "Epoch 149/200\n",
      "172/172 [==============================] - 0s 967us/sample - loss: 0.4263 - accuracy: 0.8295 - val_loss: 0.4165 - val_accuracy: 0.7984\n",
      "Epoch 150/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.4304 - accuracy: 0.8159 - val_loss: 0.4530 - val_accuracy: 0.8295\n",
      "Epoch 151/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.4226 - accuracy: 0.8275 - val_loss: 0.4172 - val_accuracy: 0.7907\n",
      "Epoch 152/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.4249 - accuracy: 0.8236 - val_loss: 0.4158 - val_accuracy: 0.8062\n",
      "Epoch 153/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 0.4212 - accuracy: 0.8333 - val_loss: 0.4201 - val_accuracy: 0.8295\n",
      "Epoch 154/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.4183 - accuracy: 0.8353 - val_loss: 0.4158 - val_accuracy: 0.7984\n",
      "Epoch 155/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.4170 - accuracy: 0.8198 - val_loss: 0.4495 - val_accuracy: 0.8295\n",
      "Epoch 156/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.4232 - accuracy: 0.8314 - val_loss: 0.4166 - val_accuracy: 0.7984\n",
      "Epoch 157/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 0.4210 - accuracy: 0.8372 - val_loss: 0.4194 - val_accuracy: 0.8295\n",
      "Epoch 158/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 0.4195 - accuracy: 0.8372 - val_loss: 0.4236 - val_accuracy: 0.8372\n",
      "Epoch 159/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 0.4227 - accuracy: 0.8314 - val_loss: 0.4241 - val_accuracy: 0.8372\n",
      "Epoch 160/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.4175 - accuracy: 0.8372 - val_loss: 0.4270 - val_accuracy: 0.8372\n",
      "Epoch 161/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 0.4159 - accuracy: 0.8372 - val_loss: 0.4153 - val_accuracy: 0.8217\n",
      "Epoch 162/200\n",
      "172/172 [==============================] - 0s 937us/sample - loss: 0.4168 - accuracy: 0.8333 - val_loss: 0.4187 - val_accuracy: 0.8295\n",
      "Epoch 163/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.4272 - accuracy: 0.8353 - val_loss: 0.4158 - val_accuracy: 0.7907\n",
      "Epoch 164/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.4421 - accuracy: 0.8159 - val_loss: 0.4789 - val_accuracy: 0.8140\n",
      "Epoch 165/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.4422 - accuracy: 0.8217 - val_loss: 0.4155 - val_accuracy: 0.7984\n",
      "Epoch 166/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 0.4154 - accuracy: 0.8314 - val_loss: 0.4329 - val_accuracy: 0.8372\n",
      "Epoch 167/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.4182 - accuracy: 0.8333 - val_loss: 0.4166 - val_accuracy: 0.8295\n",
      "Epoch 168/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.4148 - accuracy: 0.8353 - val_loss: 0.4151 - val_accuracy: 0.7984\n",
      "Epoch 169/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.4138 - accuracy: 0.8391 - val_loss: 0.4202 - val_accuracy: 0.8372\n",
      "Epoch 170/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.4220 - accuracy: 0.8314 - val_loss: 0.4334 - val_accuracy: 0.8372\n",
      "Epoch 171/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.4175 - accuracy: 0.8372 - val_loss: 0.4358 - val_accuracy: 0.8372\n",
      "Epoch 172/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 0.4178 - accuracy: 0.8314 - val_loss: 0.4175 - val_accuracy: 0.8295\n",
      "Epoch 173/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.4153 - accuracy: 0.8372 - val_loss: 0.4152 - val_accuracy: 0.8062\n",
      "Epoch 174/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.4273 - accuracy: 0.8159 - val_loss: 0.4181 - val_accuracy: 0.8217\n",
      "Epoch 175/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 0.4160 - accuracy: 0.8333 - val_loss: 0.4173 - val_accuracy: 0.8217\n",
      "Epoch 176/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.4122 - accuracy: 0.8333 - val_loss: 0.4171 - val_accuracy: 0.8295\n",
      "Epoch 177/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.4161 - accuracy: 0.8391 - val_loss: 0.4145 - val_accuracy: 0.8217\n",
      "Epoch 178/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 0.4398 - accuracy: 0.8217 - val_loss: 0.4761 - val_accuracy: 0.8062\n",
      "Epoch 179/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.4189 - accuracy: 0.8372 - val_loss: 0.4184 - val_accuracy: 0.8295\n",
      "Epoch 180/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.4125 - accuracy: 0.8372 - val_loss: 0.4306 - val_accuracy: 0.8372\n",
      "Epoch 181/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 0.4125 - accuracy: 0.8333 - val_loss: 0.4179 - val_accuracy: 0.7907\n",
      "Epoch 182/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.4229 - accuracy: 0.8314 - val_loss: 0.4152 - val_accuracy: 0.7984\n",
      "Epoch 183/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.4133 - accuracy: 0.8372 - val_loss: 0.4171 - val_accuracy: 0.8217\n",
      "Epoch 184/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 909us/sample - loss: 0.4319 - accuracy: 0.8236 - val_loss: 0.4238 - val_accuracy: 0.8372\n",
      "Epoch 185/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.4150 - accuracy: 0.8295 - val_loss: 0.4153 - val_accuracy: 0.7984\n",
      "Epoch 186/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 0.4126 - accuracy: 0.8314 - val_loss: 0.4277 - val_accuracy: 0.8372\n",
      "Epoch 187/200\n",
      "172/172 [==============================] - 0s 937us/sample - loss: 0.4137 - accuracy: 0.8430 - val_loss: 0.4167 - val_accuracy: 0.7907\n",
      "Epoch 188/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.4099 - accuracy: 0.8275 - val_loss: 0.4311 - val_accuracy: 0.8450\n",
      "Epoch 189/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.4063 - accuracy: 0.8430 - val_loss: 0.4146 - val_accuracy: 0.8140\n",
      "Epoch 190/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.4113 - accuracy: 0.8353 - val_loss: 0.4149 - val_accuracy: 0.8217\n",
      "Epoch 191/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.4186 - accuracy: 0.8295 - val_loss: 0.4328 - val_accuracy: 0.8372\n",
      "Epoch 192/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 0.4171 - accuracy: 0.8391 - val_loss: 0.4314 - val_accuracy: 0.8450\n",
      "Epoch 193/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.4109 - accuracy: 0.8411 - val_loss: 0.4167 - val_accuracy: 0.8217\n",
      "Epoch 194/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.4085 - accuracy: 0.8391 - val_loss: 0.4194 - val_accuracy: 0.8295\n",
      "Epoch 195/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.4141 - accuracy: 0.8353 - val_loss: 0.4275 - val_accuracy: 0.8372\n",
      "Epoch 196/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 0.4200 - accuracy: 0.8430 - val_loss: 0.4511 - val_accuracy: 0.8217\n",
      "Epoch 197/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.4272 - accuracy: 0.8217 - val_loss: 0.4193 - val_accuracy: 0.8295\n",
      "Epoch 198/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.4339 - accuracy: 0.8236 - val_loss: 0.4309 - val_accuracy: 0.7907\n",
      "Epoch 199/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.4369 - accuracy: 0.8159 - val_loss: 0.4694 - val_accuracy: 0.8217\n",
      "Epoch 200/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 0.4106 - accuracy: 0.8314 - val_loss: 0.4183 - val_accuracy: 0.8295\n",
      "Beginning training for dr=0.001, l_lambda=1.0e-03, reg_type=l1, act: relu\n",
      "Train on 172 samples, validate on 43 samples\n",
      "Epoch 1/200\n",
      "172/172 [==============================] - 1s 8ms/sample - loss: 1.3351 - accuracy: 0.6667 - val_loss: 0.9647 - val_accuracy: 0.6667\n",
      "Epoch 2/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 0.8245 - accuracy: 0.6667 - val_loss: 0.7385 - val_accuracy: 0.6667\n",
      "Epoch 3/200\n",
      "172/172 [==============================] - 0s 859us/sample - loss: 0.6884 - accuracy: 0.6667 - val_loss: 0.6371 - val_accuracy: 0.6667\n",
      "Epoch 4/200\n",
      "172/172 [==============================] - 0s 857us/sample - loss: 0.6124 - accuracy: 0.7752 - val_loss: 0.5827 - val_accuracy: 0.7829\n",
      "Epoch 5/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 0.5736 - accuracy: 0.7791 - val_loss: 0.5526 - val_accuracy: 0.7829\n",
      "Epoch 6/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.5512 - accuracy: 0.7791 - val_loss: 0.5368 - val_accuracy: 0.7829\n",
      "Epoch 7/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 0.5376 - accuracy: 0.7791 - val_loss: 0.5253 - val_accuracy: 0.7829\n",
      "Epoch 8/200\n",
      "172/172 [==============================] - 0s 862us/sample - loss: 0.5278 - accuracy: 0.7791 - val_loss: 0.5171 - val_accuracy: 0.7829\n",
      "Epoch 9/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5233 - accuracy: 0.7791 - val_loss: 0.5138 - val_accuracy: 0.7829\n",
      "Epoch 10/200\n",
      "172/172 [==============================] - 0s 853us/sample - loss: 0.5202 - accuracy: 0.7791 - val_loss: 0.5115 - val_accuracy: 0.7829\n",
      "Epoch 11/200\n",
      "172/172 [==============================] - 0s 850us/sample - loss: 0.5182 - accuracy: 0.7791 - val_loss: 0.5113 - val_accuracy: 0.7829\n",
      "Epoch 12/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.5181 - accuracy: 0.7791 - val_loss: 0.5103 - val_accuracy: 0.7829\n",
      "Epoch 13/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.5178 - accuracy: 0.7791 - val_loss: 0.5100 - val_accuracy: 0.7829\n",
      "Epoch 14/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 0.5170 - accuracy: 0.7791 - val_loss: 0.5100 - val_accuracy: 0.7829\n",
      "Epoch 15/200\n",
      "172/172 [==============================] - 0s 862us/sample - loss: 0.5180 - accuracy: 0.7791 - val_loss: 0.5099 - val_accuracy: 0.7829\n",
      "Epoch 16/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.5176 - accuracy: 0.7791 - val_loss: 0.5096 - val_accuracy: 0.7829\n",
      "Epoch 17/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 18/200\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 19/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 20/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 21/200\n",
      "172/172 [==============================] - 0s 864us/sample - loss: 0.5171 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 22/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.5168 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 23/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 24/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 25/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 26/200\n",
      "172/172 [==============================] - 0s 946us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 27/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 28/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.5171 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 29/200\n",
      "172/172 [==============================] - 0s 951us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 30/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 0.5168 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 31/200\n",
      "172/172 [==============================] - 0s 930us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 32/200\n",
      "172/172 [==============================] - 0s 954us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 33/200\n",
      "172/172 [==============================] - 0s 940us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 34/200\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 35/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 0.5173 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 36/200\n",
      "172/172 [==============================] - 0s 962us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 37/200\n",
      "172/172 [==============================] - 0s 945us/sample - loss: 0.5158 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 38/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 980us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 39/200\n",
      "172/172 [==============================] - 0s 977us/sample - loss: 0.5158 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 40/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.5176 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 41/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 42/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 0.5172 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 43/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.5171 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 44/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 45/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 46/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 47/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 48/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 49/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 50/200\n",
      "172/172 [==============================] - 0s 945us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 51/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.5169 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 52/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 53/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 54/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.5168 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 55/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 56/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 57/200\n",
      "172/172 [==============================] - 0s 937us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 58/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 0.5158 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 59/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 0.5172 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 60/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 61/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 62/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5157 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 63/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.5176 - accuracy: 0.7791 - val_loss: 0.5098 - val_accuracy: 0.7829\n",
      "Epoch 64/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 65/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 66/200\n",
      "172/172 [==============================] - 0s 959us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 67/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 68/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 69/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 70/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 71/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.5170 - accuracy: 0.7791 - val_loss: 0.5099 - val_accuracy: 0.7829\n",
      "Epoch 72/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5169 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 73/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 74/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 75/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 76/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5085 - val_accuracy: 0.7829\n",
      "Epoch 77/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 78/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.5171 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 79/200\n",
      "172/172 [==============================] - 0s 942us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 80/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.5170 - accuracy: 0.7791 - val_loss: 0.5098 - val_accuracy: 0.7829\n",
      "Epoch 81/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5100 - val_accuracy: 0.7829\n",
      "Epoch 82/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5100 - val_accuracy: 0.7829\n",
      "Epoch 83/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.5180 - accuracy: 0.7791 - val_loss: 0.5111 - val_accuracy: 0.7829\n",
      "Epoch 84/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.5171 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 85/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 86/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 87/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 88/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 89/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 90/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 91/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5096 - val_accuracy: 0.7829\n",
      "Epoch 92/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 93/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 905us/sample - loss: 0.5174 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 94/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.5158 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 95/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.5171 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 96/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 0.5157 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 97/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 98/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5158 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 99/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 100/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 101/200\n",
      "172/172 [==============================] - 0s 940us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 102/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 103/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.5172 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 104/200\n",
      "172/172 [==============================] - 0s 951us/sample - loss: 0.5158 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 105/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 106/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 107/200\n",
      "172/172 [==============================] - 0s 930us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 108/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 109/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 110/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 111/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 112/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 113/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 114/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 115/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 116/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 117/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 0.5158 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 118/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 0.5158 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 119/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5101 - val_accuracy: 0.7829\n",
      "Epoch 120/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 121/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.5168 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 122/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 123/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 124/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5097 - val_accuracy: 0.7829\n",
      "Epoch 125/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 126/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 127/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5097 - val_accuracy: 0.7829\n",
      "Epoch 128/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 129/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 130/200\n",
      "172/172 [==============================] - 0s 951us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 131/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 132/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 133/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.5173 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 134/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 135/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 136/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 137/200\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 138/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 139/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 140/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 141/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 142/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 143/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 144/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 145/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 146/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 147/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.5173 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 148/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 891us/sample - loss: 0.5158 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 149/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 150/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 151/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 0.5171 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 152/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 153/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 154/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 155/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 156/200\n",
      "172/172 [==============================] - 0s 945us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 157/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 158/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 159/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.5170 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 160/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 161/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.5158 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 162/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 163/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.5158 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 164/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 165/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5085 - val_accuracy: 0.7829\n",
      "Epoch 166/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5085 - val_accuracy: 0.7829\n",
      "Epoch 167/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 0.5174 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 168/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 169/200\n",
      "172/172 [==============================] - 0s 960us/sample - loss: 0.5175 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 170/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.5157 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 171/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 172/200\n",
      "172/172 [==============================] - 0s 966us/sample - loss: 0.5158 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 173/200\n",
      "172/172 [==============================] - 0s 999us/sample - loss: 0.5173 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 174/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 175/200\n",
      "172/172 [==============================] - 0s 975us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 176/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 177/200\n",
      "172/172 [==============================] - 0s 965us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 178/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 179/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 180/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 181/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 182/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 183/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 184/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 185/200\n",
      "172/172 [==============================] - 0s 2ms/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 186/200\n",
      "172/172 [==============================] - 0s 2ms/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 187/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 188/200\n",
      "172/172 [==============================] - 0s 2ms/sample - loss: 0.5158 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 189/200\n",
      "172/172 [==============================] - 0s 2ms/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 190/200\n",
      "172/172 [==============================] - 0s 2ms/sample - loss: 0.5189 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 191/200\n",
      "172/172 [==============================] - 0s 2ms/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5097 - val_accuracy: 0.7829\n",
      "Epoch 192/200\n",
      "172/172 [==============================] - 0s 2ms/sample - loss: 0.5174 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 193/200\n",
      "172/172 [==============================] - 0s 2ms/sample - loss: 0.5158 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 194/200\n",
      "172/172 [==============================] - 0s 2ms/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 195/200\n",
      "172/172 [==============================] - 0s 2ms/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 196/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 197/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 198/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 199/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5155 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 200/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Beginning training for dr=0.001, l_lambda=1.0e-03, reg_type=l1, act: tanh\n",
      "Train on 172 samples, validate on 43 samples\n",
      "Epoch 1/200\n",
      "172/172 [==============================] - 2s 12ms/sample - loss: 1.3110 - accuracy: 0.6667 - val_loss: 0.9207 - val_accuracy: 0.6667\n",
      "Epoch 2/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.7686 - accuracy: 0.7326 - val_loss: 0.6740 - val_accuracy: 0.7829\n",
      "Epoch 3/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.6371 - accuracy: 0.7791 - val_loss: 0.5992 - val_accuracy: 0.7829\n",
      "Epoch 4/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5927 - accuracy: 0.7791 - val_loss: 0.5700 - val_accuracy: 0.7829\n",
      "Epoch 5/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5703 - accuracy: 0.7791 - val_loss: 0.5510 - val_accuracy: 0.7829\n",
      "Epoch 6/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5506 - accuracy: 0.7791 - val_loss: 0.5360 - val_accuracy: 0.7829\n",
      "Epoch 7/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5385 - accuracy: 0.7791 - val_loss: 0.5256 - val_accuracy: 0.7829\n",
      "Epoch 8/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5297 - accuracy: 0.7791 - val_loss: 0.5181 - val_accuracy: 0.7829\n",
      "Epoch 9/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5231 - accuracy: 0.7791 - val_loss: 0.5129 - val_accuracy: 0.7829\n",
      "Epoch 10/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5192 - accuracy: 0.7791 - val_loss: 0.5103 - val_accuracy: 0.7829\n",
      "Epoch 11/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5175 - accuracy: 0.7791 - val_loss: 0.5096 - val_accuracy: 0.7829\n",
      "Epoch 12/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5169 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 13/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 14/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 15/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5173 - accuracy: 0.7791 - val_loss: 0.5102 - val_accuracy: 0.7829\n",
      "Epoch 16/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5170 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 17/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 18/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 19/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 20/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5175 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 21/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 22/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5176 - accuracy: 0.7791 - val_loss: 0.5099 - val_accuracy: 0.7829\n",
      "Epoch 23/200\n",
      "172/172 [==============================] - 0s 985us/sample - loss: 0.5168 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 24/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 25/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5168 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 26/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5097 - val_accuracy: 0.7829\n",
      "Epoch 27/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5174 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 28/200\n",
      "172/172 [==============================] - 0s 971us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 29/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5176 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 30/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5171 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 31/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5184 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 32/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5170 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 33/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 34/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5172 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 35/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5173 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 36/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 37/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5181 - accuracy: 0.7791 - val_loss: 0.5097 - val_accuracy: 0.7829\n",
      "Epoch 38/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5169 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 39/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 40/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5171 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 41/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5171 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 42/200\n",
      "172/172 [==============================] - 0s 974us/sample - loss: 0.5169 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 43/200\n",
      "172/172 [==============================] - 0s 970us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5096 - val_accuracy: 0.7829\n",
      "Epoch 44/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5174 - accuracy: 0.7791 - val_loss: 0.5121 - val_accuracy: 0.7829\n",
      "Epoch 45/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5174 - accuracy: 0.7791 - val_loss: 0.5099 - val_accuracy: 0.7829\n",
      "Epoch 46/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 47/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5213 - accuracy: 0.7791 - val_loss: 0.5097 - val_accuracy: 0.7829\n",
      "Epoch 48/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5153 - accuracy: 0.7791 - val_loss: 0.5105 - val_accuracy: 0.7829\n",
      "Epoch 49/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5175 - accuracy: 0.7791 - val_loss: 0.5103 - val_accuracy: 0.7829\n",
      "Epoch 50/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5186 - accuracy: 0.7791 - val_loss: 0.5112 - val_accuracy: 0.7829\n",
      "Epoch 51/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5177 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 52/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5170 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 53/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 54/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5156 - accuracy: 0.7791 - val_loss: 0.5099 - val_accuracy: 0.7829\n",
      "Epoch 55/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5168 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 56/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 57/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 58/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 59/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 60/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5192 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 61/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5186 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 62/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 63/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5178 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 64/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5175 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 65/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5181 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 66/200\n",
      "172/172 [==============================] - 0s 976us/sample - loss: 0.5168 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 67/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 68/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5188 - accuracy: 0.7791 - val_loss: 0.5110 - val_accuracy: 0.7829\n",
      "Epoch 69/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5172 - accuracy: 0.7791 - val_loss: 0.5098 - val_accuracy: 0.7829\n",
      "Epoch 70/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5100 - val_accuracy: 0.7829\n",
      "Epoch 71/200\n",
      "172/172 [==============================] - 0s 973us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5096 - val_accuracy: 0.7829\n",
      "Epoch 72/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5170 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 73/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5194 - accuracy: 0.7791 - val_loss: 0.5097 - val_accuracy: 0.7829\n",
      "Epoch 74/200\n",
      "172/172 [==============================] - 0s 981us/sample - loss: 0.5188 - accuracy: 0.7791 - val_loss: 0.5105 - val_accuracy: 0.7829\n",
      "Epoch 75/200\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 76/200\n",
      "172/172 [==============================] - 0s 949us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5100 - val_accuracy: 0.7829\n",
      "Epoch 77/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 0.5170 - accuracy: 0.7791 - val_loss: 0.5103 - val_accuracy: 0.7829\n",
      "Epoch 78/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 79/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 0.5169 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 80/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5181 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 81/200\n",
      "172/172 [==============================] - 0s 957us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 82/200\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 83/200\n",
      "172/172 [==============================] - 0s 941us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 84/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5097 - val_accuracy: 0.7829\n",
      "Epoch 85/200\n",
      "172/172 [==============================] - 0s 930us/sample - loss: 0.5183 - accuracy: 0.7791 - val_loss: 0.5114 - val_accuracy: 0.7829\n",
      "Epoch 86/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5175 - accuracy: 0.7791 - val_loss: 0.5110 - val_accuracy: 0.7829\n",
      "Epoch 87/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.5174 - accuracy: 0.7791 - val_loss: 0.5103 - val_accuracy: 0.7829\n",
      "Epoch 88/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 89/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 0.5188 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 90/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.5188 - accuracy: 0.7791 - val_loss: 0.5102 - val_accuracy: 0.7829\n",
      "Epoch 91/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.5156 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 92/200\n",
      "172/172 [==============================] - 0s 946us/sample - loss: 0.5179 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 93/200\n",
      "172/172 [==============================] - 0s 941us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 94/200\n",
      "172/172 [==============================] - 0s 975us/sample - loss: 0.5181 - accuracy: 0.7791 - val_loss: 0.5101 - val_accuracy: 0.7829\n",
      "Epoch 95/200\n",
      "172/172 [==============================] - 0s 973us/sample - loss: 0.5173 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 96/200\n",
      "172/172 [==============================] - 0s 956us/sample - loss: 0.5172 - accuracy: 0.7791 - val_loss: 0.5104 - val_accuracy: 0.7829\n",
      "Epoch 97/200\n",
      "172/172 [==============================] - 0s 948us/sample - loss: 0.5178 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 98/200\n",
      "172/172 [==============================] - 0s 990us/sample - loss: 0.5177 - accuracy: 0.7791 - val_loss: 0.5102 - val_accuracy: 0.7829\n",
      "Epoch 99/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5169 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 100/200\n",
      "172/172 [==============================] - 0s 974us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 101/200\n",
      "172/172 [==============================] - 0s 998us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 102/200\n",
      "172/172 [==============================] - 0s 964us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 103/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5172 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 104/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5176 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 105/200\n",
      "172/172 [==============================] - 0s 984us/sample - loss: 0.5156 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 106/200\n",
      "172/172 [==============================] - 0s 994us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 107/200\n",
      "172/172 [==============================] - 0s 942us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 108/200\n",
      "172/172 [==============================] - 0s 948us/sample - loss: 0.5170 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 109/200\n",
      "172/172 [==============================] - 0s 947us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 110/200\n",
      "172/172 [==============================] - 0s 967us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 111/200\n",
      "172/172 [==============================] - 0s 984us/sample - loss: 0.5169 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 112/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 113/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5179 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 114/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5156 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 115/200\n",
      "172/172 [==============================] - 0s 928us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 116/200\n",
      "172/172 [==============================] - 0s 987us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 117/200\n",
      "172/172 [==============================] - 0s 994us/sample - loss: 0.5177 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 118/200\n",
      "172/172 [==============================] - 0s 964us/sample - loss: 0.5169 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 119/200\n",
      "172/172 [==============================] - 0s 954us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 120/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 121/200\n",
      "172/172 [==============================] - 0s 937us/sample - loss: 0.5172 - accuracy: 0.7791 - val_loss: 0.5113 - val_accuracy: 0.7829\n",
      "Epoch 122/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 0.5170 - accuracy: 0.7791 - val_loss: 0.5105 - val_accuracy: 0.7829\n",
      "Epoch 123/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 124/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.5178 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 125/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.5179 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 126/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 127/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.5169 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 128/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.5183 - accuracy: 0.7791 - val_loss: 0.5100 - val_accuracy: 0.7829\n",
      "Epoch 129/200\n",
      "172/172 [==============================] - 0s 959us/sample - loss: 0.5168 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 130/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 0.5178 - accuracy: 0.7791 - val_loss: 0.5096 - val_accuracy: 0.7829\n",
      "Epoch 131/200\n",
      "172/172 [==============================] - 0s 948us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 132/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.5169 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 133/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 134/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 0.5168 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 135/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 136/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5156 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 137/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 138/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 139/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.5168 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 140/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 0.5171 - accuracy: 0.7791 - val_loss: 0.5098 - val_accuracy: 0.7829\n",
      "Epoch 141/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.5178 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 142/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 143/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5098 - val_accuracy: 0.7829\n",
      "Epoch 144/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.5172 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 145/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 0.5174 - accuracy: 0.7791 - val_loss: 0.5102 - val_accuracy: 0.7829\n",
      "Epoch 146/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.5177 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 147/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 148/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.5174 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 149/200\n",
      "172/172 [==============================] - 0s 940us/sample - loss: 0.5175 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 150/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 151/200\n",
      "172/172 [==============================] - 0s 941us/sample - loss: 0.5171 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 152/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.5169 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 153/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5169 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 154/200\n",
      "172/172 [==============================] - 0s 947us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5096 - val_accuracy: 0.7829\n",
      "Epoch 155/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5097 - val_accuracy: 0.7829\n",
      "Epoch 156/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.5181 - accuracy: 0.7791 - val_loss: 0.5097 - val_accuracy: 0.7829\n",
      "Epoch 157/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.5177 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 158/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 159/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.5202 - accuracy: 0.7791 - val_loss: 0.5100 - val_accuracy: 0.7829\n",
      "Epoch 160/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.5172 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 161/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 162/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.5170 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 163/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 164/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 165/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 166/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 167/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 168/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 928us/sample - loss: 0.5174 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 169/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 0.5187 - accuracy: 0.7791 - val_loss: 0.5102 - val_accuracy: 0.7829\n",
      "Epoch 170/200\n",
      "172/172 [==============================] - 0s 941us/sample - loss: 0.5177 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 171/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5097 - val_accuracy: 0.7829\n",
      "Epoch 172/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 0.5168 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 173/200\n",
      "172/172 [==============================] - 0s 945us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 174/200\n",
      "172/172 [==============================] - 0s 957us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 175/200\n",
      "172/172 [==============================] - 0s 962us/sample - loss: 0.5169 - accuracy: 0.7791 - val_loss: 0.5085 - val_accuracy: 0.7829\n",
      "Epoch 176/200\n",
      "172/172 [==============================] - 0s 959us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 177/200\n",
      "172/172 [==============================] - 0s 964us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 178/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.5170 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 179/200\n",
      "172/172 [==============================] - 0s 978us/sample - loss: 0.5181 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 180/200\n",
      "172/172 [==============================] - 0s 964us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 181/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 0.5191 - accuracy: 0.7791 - val_loss: 0.5102 - val_accuracy: 0.7829\n",
      "Epoch 182/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 0.5171 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 183/200\n",
      "172/172 [==============================] - 0s 928us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5096 - val_accuracy: 0.7829\n",
      "Epoch 184/200\n",
      "172/172 [==============================] - 0s 941us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 185/200\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 0.5175 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 186/200\n",
      "172/172 [==============================] - 0s 949us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 187/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5098 - val_accuracy: 0.7829\n",
      "Epoch 188/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 189/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.5169 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 190/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 191/200\n",
      "172/172 [==============================] - 0s 990us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5100 - val_accuracy: 0.7829\n",
      "Epoch 192/200\n",
      "172/172 [==============================] - 0s 999us/sample - loss: 0.5176 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 193/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 194/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 195/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 196/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 197/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 198/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 199/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.5187 - accuracy: 0.7791 - val_loss: 0.5105 - val_accuracy: 0.7829\n",
      "Epoch 200/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.5185 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Beginning training for dr=0.001, l_lambda=1.0e-02, reg_type=l2, act: relu\n",
      "Train on 172 samples, validate on 43 samples\n",
      "Epoch 1/200\n",
      "172/172 [==============================] - 1s 8ms/sample - loss: 0.8866 - accuracy: 0.6667 - val_loss: 0.7654 - val_accuracy: 0.6667\n",
      "Epoch 2/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 0.7158 - accuracy: 0.6667 - val_loss: 0.6626 - val_accuracy: 0.6667\n",
      "Epoch 3/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 0.6335 - accuracy: 0.6938 - val_loss: 0.5972 - val_accuracy: 0.7829\n",
      "Epoch 4/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 0.5817 - accuracy: 0.7791 - val_loss: 0.5558 - val_accuracy: 0.7829\n",
      "Epoch 5/200\n",
      "172/172 [==============================] - 0s 869us/sample - loss: 0.5529 - accuracy: 0.7791 - val_loss: 0.5378 - val_accuracy: 0.7829\n",
      "Epoch 6/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 0.5384 - accuracy: 0.7791 - val_loss: 0.5258 - val_accuracy: 0.7829\n",
      "Epoch 7/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5280 - accuracy: 0.7791 - val_loss: 0.5176 - val_accuracy: 0.7829\n",
      "Epoch 8/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5218 - accuracy: 0.7791 - val_loss: 0.5120 - val_accuracy: 0.7829\n",
      "Epoch 9/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5174 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 10/200\n",
      "172/172 [==============================] - 0s 941us/sample - loss: 0.5146 - accuracy: 0.7791 - val_loss: 0.5060 - val_accuracy: 0.7829\n",
      "Epoch 11/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5127 - accuracy: 0.7791 - val_loss: 0.5052 - val_accuracy: 0.7829\n",
      "Epoch 12/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.5115 - accuracy: 0.7791 - val_loss: 0.5049 - val_accuracy: 0.7829\n",
      "Epoch 13/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 0.5104 - accuracy: 0.7791 - val_loss: 0.5035 - val_accuracy: 0.7829\n",
      "Epoch 14/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.5112 - accuracy: 0.7791 - val_loss: 0.5028 - val_accuracy: 0.7829\n",
      "Epoch 15/200\n",
      "172/172 [==============================] - 0s 945us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 16/200\n",
      "172/172 [==============================] - 0s 983us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 17/200\n",
      "172/172 [==============================] - 0s 953us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 18/200\n",
      "172/172 [==============================] - 0s 940us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 19/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5104 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 20/200\n",
      "172/172 [==============================] - 0s 989us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 21/200\n",
      "172/172 [==============================] - 0s 944us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 22/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 933us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 23/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 24/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 25/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 26/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 27/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 28/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 29/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 30/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 31/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 32/200\n",
      "172/172 [==============================] - 0s 966us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 33/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5028 - val_accuracy: 0.7829\n",
      "Epoch 34/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 35/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 36/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 37/200\n",
      "172/172 [==============================] - 0s 942us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 38/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 39/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 40/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 41/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 42/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 43/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 0.5107 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 44/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 45/200\n",
      "172/172 [==============================] - 0s 937us/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 46/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 47/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 48/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 49/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 50/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 51/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 52/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 53/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 54/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 55/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 56/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 57/200\n",
      "172/172 [==============================] - 0s 946us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 58/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 59/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 60/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 61/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 62/200\n",
      "172/172 [==============================] - 0s 978us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 63/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5108 - accuracy: 0.7791 - val_loss: 0.5028 - val_accuracy: 0.7829\n",
      "Epoch 64/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 65/200\n",
      "172/172 [==============================] - 0s 981us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 66/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 67/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 68/200\n",
      "172/172 [==============================] - 0s 987us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 69/200\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 70/200\n",
      "172/172 [==============================] - 0s 930us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 71/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 72/200\n",
      "172/172 [==============================] - 0s 928us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 73/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.5102 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 74/200\n",
      "172/172 [==============================] - 0s 990us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 75/200\n",
      "172/172 [==============================] - 0s 967us/sample - loss: 0.5107 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 76/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5083 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 77/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 78/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5109 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 79/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 80/200\n",
      "172/172 [==============================] - 0s 2ms/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 81/200\n",
      "172/172 [==============================] - 1s 6ms/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 82/200\n",
      "172/172 [==============================] - 1s 6ms/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 83/200\n",
      "172/172 [==============================] - 1s 6ms/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5033 - val_accuracy: 0.7829\n",
      "Epoch 84/200\n",
      "172/172 [==============================] - 2s 10ms/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5028 - val_accuracy: 0.7829\n",
      "Epoch 85/200\n",
      "172/172 [==============================] - 2s 9ms/sample - loss: 0.5086 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 86/200\n",
      "172/172 [==============================] - 1s 8ms/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 87/200\n",
      "172/172 [==============================] - 2s 10ms/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 88/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 89/200\n",
      "172/172 [==============================] - 1s 8ms/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 90/200\n",
      "172/172 [==============================] - 2s 10ms/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 91/200\n",
      "172/172 [==============================] - 1s 7ms/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 92/200\n",
      "172/172 [==============================] - 1s 7ms/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 93/200\n",
      "172/172 [==============================] - 2s 10ms/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 94/200\n",
      "172/172 [==============================] - 1s 8ms/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 95/200\n",
      "172/172 [==============================] - 1s 9ms/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 96/200\n",
      "172/172 [==============================] - 1s 7ms/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 97/200\n",
      "172/172 [==============================] - 1s 7ms/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 98/200\n",
      "172/172 [==============================] - 2s 10ms/sample - loss: 0.5102 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 99/200\n",
      "172/172 [==============================] - 2s 13ms/sample - loss: 0.5118 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 100/200\n",
      "172/172 [==============================] - 1s 5ms/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 101/200\n",
      "172/172 [==============================] - 2s 11ms/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 102/200\n",
      "172/172 [==============================] - 1s 7ms/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 103/200\n",
      "172/172 [==============================] - 2s 9ms/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 104/200\n",
      "172/172 [==============================] - 2s 9ms/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 105/200\n",
      "172/172 [==============================] - 1s 7ms/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 106/200\n",
      "172/172 [==============================] - 1s 7ms/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 107/200\n",
      "172/172 [==============================] - 1s 5ms/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 108/200\n",
      "172/172 [==============================] - 1s 8ms/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 109/200\n",
      "172/172 [==============================] - 1s 9ms/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 110/200\n",
      "172/172 [==============================] - 1s 6ms/sample - loss: 0.5085 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 111/200\n",
      "172/172 [==============================] - 1s 7ms/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829oss: 0.5158 - accuracy: 0.\n",
      "Epoch 112/200\n",
      "172/172 [==============================] - 1s 7ms/sample - loss: 0.5110 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 113/200\n",
      "172/172 [==============================] - 2s 9ms/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 114/200\n",
      "172/172 [==============================] - 2s 9ms/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 115/200\n",
      "172/172 [==============================] - 1s 8ms/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 116/200\n",
      "172/172 [==============================] - 2s 11ms/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 117/200\n",
      "172/172 [==============================] - 1s 8ms/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 118/200\n",
      "172/172 [==============================] - 1s 7ms/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 119/200\n",
      "172/172 [==============================] - 2s 9ms/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 120/200\n",
      "172/172 [==============================] - 1s 8ms/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 121/200\n",
      "172/172 [==============================] - 1s 7ms/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5026 - val_accuracy: 0.7829\n",
      "Epoch 122/200\n",
      "172/172 [==============================] - 1s 8ms/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 123/200\n",
      "172/172 [==============================] - 1s 7ms/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 124/200\n",
      "172/172 [==============================] - 1s 7ms/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 125/200\n",
      "172/172 [==============================] - 1s 8ms/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 126/200\n",
      "172/172 [==============================] - 1s 8ms/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 127/200\n",
      "172/172 [==============================] - 1s 7ms/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 128/200\n",
      "172/172 [==============================] - 2s 11ms/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 129/200\n",
      "172/172 [==============================] - 2s 9ms/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 130/200\n",
      "172/172 [==============================] - 1s 8ms/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 131/200\n",
      "172/172 [==============================] - 1s 8ms/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 132/200\n",
      "172/172 [==============================] - 1s 9ms/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133/200\n",
      "172/172 [==============================] - 1s 5ms/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 134/200\n",
      "172/172 [==============================] - 1s 7ms/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 135/200\n",
      "172/172 [==============================] - 1s 7ms/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 136/200\n",
      "172/172 [==============================] - 1s 8ms/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 137/200\n",
      "172/172 [==============================] - 1s 7ms/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 138/200\n",
      "172/172 [==============================] - 1s 8ms/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 139/200\n",
      "172/172 [==============================] - 1s 6ms/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 140/200\n",
      "172/172 [==============================] - 1s 7ms/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 141/200\n",
      "172/172 [==============================] - 1s 8ms/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 142/200\n",
      "172/172 [==============================] - 1s 9ms/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 143/200\n",
      "172/172 [==============================] - 1s 9ms/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 144/200\n",
      "172/172 [==============================] - 1s 7ms/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 145/200\n",
      "172/172 [==============================] - 1s 7ms/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 146/200\n",
      "172/172 [==============================] - 2s 9ms/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 147/200\n",
      "172/172 [==============================] - 1s 7ms/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 148/200\n",
      "172/172 [==============================] - 1s 9ms/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 149/200\n",
      "172/172 [==============================] - 1s 8ms/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 150/200\n",
      "172/172 [==============================] - 1s 8ms/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 151/200\n",
      "172/172 [==============================] - 1s 8ms/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 152/200\n",
      "172/172 [==============================] - 2s 9ms/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 153/200\n",
      "172/172 [==============================] - 1s 6ms/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 154/200\n",
      "172/172 [==============================] - 2s 12ms/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 155/200\n",
      "172/172 [==============================] - 1s 7ms/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 156/200\n",
      "172/172 [==============================] - 2s 11ms/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 157/200\n",
      "172/172 [==============================] - 2s 10ms/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 158/200\n",
      "172/172 [==============================] - 1s 5ms/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 159/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 160/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 161/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 162/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.5102 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 163/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 164/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.5104 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 165/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 166/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.5086 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 167/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 168/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 169/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 170/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 171/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 172/200\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 173/200\n",
      "172/172 [==============================] - 0s 940us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 174/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 175/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 0.5086 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 176/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 177/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 178/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 179/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 180/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 181/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 182/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 183/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 184/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 185/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 186/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 187/200\n",
      "172/172 [==============================] - 0s 930us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 188/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 937us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 189/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 190/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 191/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 192/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 193/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 194/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 195/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5028 - val_accuracy: 0.7829\n",
      "Epoch 196/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 197/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 198/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 199/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.5109 - accuracy: 0.7791 - val_loss: 0.5031 - val_accuracy: 0.7829\n",
      "Epoch 200/200\n",
      "172/172 [==============================] - 0s 978us/sample - loss: 0.5105 - accuracy: 0.7791 - val_loss: 0.5030 - val_accuracy: 0.7829\n",
      "Beginning training for dr=0.001, l_lambda=1.0e-02, reg_type=l2, act: tanh\n",
      "Train on 172 samples, validate on 43 samples\n",
      "Epoch 1/200\n",
      "172/172 [==============================] - 1s 9ms/sample - loss: 0.8858 - accuracy: 0.6667 - val_loss: 0.7392 - val_accuracy: 0.6667\n",
      "Epoch 2/200\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 0.6871 - accuracy: 0.6977 - val_loss: 0.6280 - val_accuracy: 0.7829\n",
      "Epoch 3/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 0.6056 - accuracy: 0.7791 - val_loss: 0.5768 - val_accuracy: 0.7829\n",
      "Epoch 4/200\n",
      "172/172 [==============================] - 0s 928us/sample - loss: 0.5756 - accuracy: 0.7791 - val_loss: 0.5525 - val_accuracy: 0.7829\n",
      "Epoch 5/200\n",
      "172/172 [==============================] - 0s 943us/sample - loss: 0.5537 - accuracy: 0.7791 - val_loss: 0.5381 - val_accuracy: 0.7829\n",
      "Epoch 6/200\n",
      "172/172 [==============================] - 0s 946us/sample - loss: 0.5407 - accuracy: 0.7791 - val_loss: 0.5252 - val_accuracy: 0.7829\n",
      "Epoch 7/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.5295 - accuracy: 0.7791 - val_loss: 0.5175 - val_accuracy: 0.7829\n",
      "Epoch 8/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.5224 - accuracy: 0.7791 - val_loss: 0.5120 - val_accuracy: 0.7829\n",
      "Epoch 9/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.5187 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 10/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 0.5153 - accuracy: 0.7791 - val_loss: 0.5059 - val_accuracy: 0.7829\n",
      "Epoch 11/200\n",
      "172/172 [==============================] - 0s 996us/sample - loss: 0.5136 - accuracy: 0.7791 - val_loss: 0.5044 - val_accuracy: 0.7829\n",
      "Epoch 12/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5121 - accuracy: 0.7791 - val_loss: 0.5033 - val_accuracy: 0.7829\n",
      "Epoch 13/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.5113 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 14/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.5123 - accuracy: 0.7791 - val_loss: 0.5042 - val_accuracy: 0.7829\n",
      "Epoch 15/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 16/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.5107 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 17/200\n",
      "172/172 [==============================] - 0s 861us/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 18/200\n",
      "172/172 [==============================] - 0s 928us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 19/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 20/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 21/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 22/200\n",
      "172/172 [==============================] - 0s 978us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5014 - val_accuracy: 0.7829\n",
      "Epoch 23/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 0.5122 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 24/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5111 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 25/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5014 - val_accuracy: 0.7829\n",
      "Epoch 26/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 27/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 28/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 29/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.5109 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 30/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 31/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.5122 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 32/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 33/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 34/200\n",
      "172/172 [==============================] - 0s 860us/sample - loss: 0.5120 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 35/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.5112 - accuracy: 0.7791 - val_loss: 0.5026 - val_accuracy: 0.7829\n",
      "Epoch 36/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.5102 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 37/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5026 - val_accuracy: 0.7829\n",
      "Epoch 38/200\n",
      "172/172 [==============================] - 0s 865us/sample - loss: 0.5120 - accuracy: 0.7791 - val_loss: 0.5032 - val_accuracy: 0.7829\n",
      "Epoch 39/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 40/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 0.5106 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 41/200\n",
      "172/172 [==============================] - 0s 955us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5026 - val_accuracy: 0.7829\n",
      "Epoch 42/200\n",
      "172/172 [==============================] - 0s 943us/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5028 - val_accuracy: 0.7829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 44/200\n",
      "172/172 [==============================] - 0s 956us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 45/200\n",
      "172/172 [==============================] - 0s 942us/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 46/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 47/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.5110 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 48/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 49/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 50/200\n",
      "172/172 [==============================] - 0s 940us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 51/200\n",
      "172/172 [==============================] - 0s 951us/sample - loss: 0.5114 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 52/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 53/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 0.5085 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 54/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.5115 - accuracy: 0.7791 - val_loss: 0.5035 - val_accuracy: 0.7829\n",
      "Epoch 55/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.5125 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 56/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.5130 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 57/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 58/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 59/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5014 - val_accuracy: 0.7829\n",
      "Epoch 60/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 61/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 62/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 63/200\n",
      "172/172 [==============================] - 0s 974us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 64/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 65/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 66/200\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 67/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.5113 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 68/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.5083 - accuracy: 0.7791 - val_loss: 0.5026 - val_accuracy: 0.7829\n",
      "Epoch 69/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5029 - val_accuracy: 0.7829\n",
      "Epoch 70/200\n",
      "172/172 [==============================] - 0s 928us/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 71/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 72/200\n",
      "172/172 [==============================] - 0s 930us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 73/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 74/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 75/200\n",
      "172/172 [==============================] - 0s 964us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 76/200\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 77/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.5102 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 78/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 79/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.5127 - accuracy: 0.7791 - val_loss: 0.5043 - val_accuracy: 0.7829\n",
      "Epoch 80/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.5105 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 81/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 82/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 83/200\n",
      "172/172 [==============================] - 0s 944us/sample - loss: 0.5110 - accuracy: 0.7791 - val_loss: 0.5030 - val_accuracy: 0.7829\n",
      "Epoch 84/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.5118 - accuracy: 0.7791 - val_loss: 0.5026 - val_accuracy: 0.7829\n",
      "Epoch 85/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 86/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 87/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 88/200\n",
      "172/172 [==============================] - 0s 966us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 89/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 90/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 91/200\n",
      "172/172 [==============================] - 0s 948us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 92/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5102 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 93/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 94/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 95/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5026 - val_accuracy: 0.7829\n",
      "Epoch 96/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 97/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 98/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 926us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 99/200\n",
      "172/172 [==============================] - 0s 928us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 100/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.5117 - accuracy: 0.7791 - val_loss: 0.5028 - val_accuracy: 0.7829\n",
      "Epoch 101/200\n",
      "172/172 [==============================] - 0s 965us/sample - loss: 0.5104 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 102/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 103/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 104/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 105/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 106/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 107/200\n",
      "172/172 [==============================] - 0s 980us/sample - loss: 0.5110 - accuracy: 0.7791 - val_loss: 0.5014 - val_accuracy: 0.7829\n",
      "Epoch 108/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.5102 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 109/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 110/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 111/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 112/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5039 - val_accuracy: 0.7829\n",
      "Epoch 113/200\n",
      "172/172 [==============================] - 0s 984us/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 114/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.5084 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 115/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.5104 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 116/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.5102 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 117/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 118/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5036 - val_accuracy: 0.7829\n",
      "Epoch 119/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5120 - accuracy: 0.7791 - val_loss: 0.5039 - val_accuracy: 0.7829\n",
      "Epoch 120/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.5083 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 121/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 122/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 123/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 124/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 0.5081 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 125/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 0.5104 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 126/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.5123 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 127/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 0.5084 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 128/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 129/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 130/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 131/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 132/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 133/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 134/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5034 - val_accuracy: 0.7829\n",
      "Epoch 135/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 136/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 137/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 138/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 139/200\n",
      "172/172 [==============================] - 0s 945us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 140/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 141/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 142/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 143/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 144/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 145/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 0.5102 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 146/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 147/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 0.5102 - accuracy: 0.7791 - val_loss: 0.5028 - val_accuracy: 0.7829\n",
      "Epoch 148/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 149/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 150/200\n",
      "172/172 [==============================] - 0s 882us/sample - loss: 0.5102 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 151/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 152/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 153/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 906us/sample - loss: 0.5102 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 154/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 155/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 156/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 157/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 0.5102 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 158/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 159/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 160/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 161/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.5106 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 162/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 163/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 164/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 165/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 166/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 167/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 168/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5033 - val_accuracy: 0.7829\n",
      "Epoch 169/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 170/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5029 - val_accuracy: 0.7829\n",
      "Epoch 171/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 172/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 173/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 174/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5026 - val_accuracy: 0.7829\n",
      "Epoch 175/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 0.5102 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 176/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 177/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 178/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.5111 - accuracy: 0.7791 - val_loss: 0.5026 - val_accuracy: 0.7829\n",
      "Epoch 179/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 180/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 181/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 182/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 183/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 184/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 185/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 186/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 187/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 188/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 189/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 190/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.5109 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 191/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.5104 - accuracy: 0.7791 - val_loss: 0.5036 - val_accuracy: 0.7829\n",
      "Epoch 192/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 193/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 194/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 195/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.5117 - accuracy: 0.7791 - val_loss: 0.5034 - val_accuracy: 0.7829\n",
      "Epoch 196/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 197/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 198/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 199/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.5104 - accuracy: 0.7791 - val_loss: 0.5026 - val_accuracy: 0.7829\n",
      "Epoch 200/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Beginning training for dr=0.001, l_lambda=1.0e-02, reg_type=l1, act: relu\n",
      "Train on 172 samples, validate on 43 samples\n",
      "Epoch 1/200\n",
      "172/172 [==============================] - 1s 8ms/sample - loss: 7.6934 - accuracy: 0.6667 - val_loss: 4.1399 - val_accuracy: 0.6667\n",
      "Epoch 2/200\n",
      "172/172 [==============================] - 0s 951us/sample - loss: 2.8727 - accuracy: 0.6667 - val_loss: 2.1865 - val_accuracy: 0.6667\n",
      "Epoch 3/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 1.8177 - accuracy: 0.7132 - val_loss: 1.4968 - val_accuracy: 0.7829\n",
      "Epoch 4/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 1.3426 - accuracy: 0.7791 - val_loss: 1.1801 - val_accuracy: 0.7829\n",
      "Epoch 5/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 1.0825 - accuracy: 0.7791 - val_loss: 0.9673 - val_accuracy: 0.7829\n",
      "Epoch 6/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.8983 - accuracy: 0.7791 - val_loss: 0.8077 - val_accuracy: 0.7829\n",
      "Epoch 7/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 914us/sample - loss: 0.7586 - accuracy: 0.7791 - val_loss: 0.6957 - val_accuracy: 0.7829\n",
      "Epoch 8/200\n",
      "172/172 [==============================] - 0s 963us/sample - loss: 0.6632 - accuracy: 0.7791 - val_loss: 0.6199 - val_accuracy: 0.7829\n",
      "Epoch 9/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.6062 - accuracy: 0.7791 - val_loss: 0.5853 - val_accuracy: 0.7829\n",
      "Epoch 10/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 0.5874 - accuracy: 0.7791 - val_loss: 0.5779 - val_accuracy: 0.7829\n",
      "Epoch 11/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5836 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 12/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.5837 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 13/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.5835 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 14/200\n",
      "172/172 [==============================] - 0s 952us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 15/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.5832 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 16/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 0.5837 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 17/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5817 - accuracy: 0.7791 - val_loss: 0.5752 - val_accuracy: 0.7829\n",
      "Epoch 18/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5769 - val_accuracy: 0.7829\n",
      "Epoch 19/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5769 - val_accuracy: 0.7829\n",
      "Epoch 20/200\n",
      "172/172 [==============================] - 0s 957us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5747 - val_accuracy: 0.7829\n",
      "Epoch 21/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 0.5837 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 22/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5752 - val_accuracy: 0.7829\n",
      "Epoch 23/200\n",
      "172/172 [==============================] - 0s 949us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5767 - val_accuracy: 0.7829\n",
      "Epoch 24/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 0.5838 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 25/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5837 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 26/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5752 - val_accuracy: 0.7829\n",
      "Epoch 27/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5818 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 28/200\n",
      "172/172 [==============================] - 0s 956us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5752 - val_accuracy: 0.7829\n",
      "Epoch 29/200\n",
      "172/172 [==============================] - 0s 956us/sample - loss: 0.5818 - accuracy: 0.7791 - val_loss: 0.5769 - val_accuracy: 0.7829\n",
      "Epoch 30/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5767 - val_accuracy: 0.7829\n",
      "Epoch 31/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 32/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 33/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5767 - val_accuracy: 0.7829\n",
      "Epoch 34/200\n",
      "172/172 [==============================] - 0s 941us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 35/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5818 - accuracy: 0.7791 - val_loss: 0.5771 - val_accuracy: 0.7829\n",
      "Epoch 36/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 37/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 38/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5834 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 39/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5820 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 40/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 41/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 42/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5820 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 43/200\n",
      "172/172 [==============================] - 0s 981us/sample - loss: 0.5839 - accuracy: 0.7791 - val_loss: 0.5767 - val_accuracy: 0.7829\n",
      "Epoch 44/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5819 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 45/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 46/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5817 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 47/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 48/200\n",
      "172/172 [==============================] - 0s 2ms/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5751 - val_accuracy: 0.7829\n",
      "Epoch 49/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5768 - val_accuracy: 0.7829\n",
      "Epoch 50/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 51/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5768 - val_accuracy: 0.7829\n",
      "Epoch 52/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5752 - val_accuracy: 0.7829\n",
      "Epoch 53/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5817 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 54/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 55/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5814 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 56/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 57/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 58/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5816 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 59/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5832 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 60/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5752 - val_accuracy: 0.7829\n",
      "Epoch 61/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 62/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5746 - val_accuracy: 0.7829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/200\n",
      "172/172 [==============================] - 0s 983us/sample - loss: 0.5818 - accuracy: 0.7791 - val_loss: 0.5769 - val_accuracy: 0.7829\n",
      "Epoch 64/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 65/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5816 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 66/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5833 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 67/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5832 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 68/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5748 - val_accuracy: 0.7829\n",
      "Epoch 69/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 70/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5818 - accuracy: 0.7791 - val_loss: 0.5750 - val_accuracy: 0.7829\n",
      "Epoch 71/200\n",
      "172/172 [==============================] - 0s 999us/sample - loss: 0.5849 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 72/200\n",
      "172/172 [==============================] - 0s 978us/sample - loss: 0.5850 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 73/200\n",
      "172/172 [==============================] - 0s 979us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 74/200\n",
      "172/172 [==============================] - 0s 972us/sample - loss: 0.5820 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 75/200\n",
      "172/172 [==============================] - 0s 971us/sample - loss: 0.5816 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 76/200\n",
      "172/172 [==============================] - 0s 974us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5747 - val_accuracy: 0.7829\n",
      "Epoch 77/200\n",
      "172/172 [==============================] - 0s 997us/sample - loss: 0.5816 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 78/200\n",
      "172/172 [==============================] - 0s 977us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 79/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5819 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 80/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5751 - val_accuracy: 0.7829\n",
      "Epoch 81/200\n",
      "172/172 [==============================] - 0s 956us/sample - loss: 0.5820 - accuracy: 0.7791 - val_loss: 0.5751 - val_accuracy: 0.7829\n",
      "Epoch 82/200\n",
      "172/172 [==============================] - 0s 982us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5750 - val_accuracy: 0.7829\n",
      "Epoch 83/200\n",
      "172/172 [==============================] - 0s 947us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 84/200\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5752 - val_accuracy: 0.7829\n",
      "Epoch 85/200\n",
      "172/172 [==============================] - 0s 969us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 86/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 87/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 88/200\n",
      "172/172 [==============================] - 0s 981us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 89/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5750 - val_accuracy: 0.7829\n",
      "Epoch 90/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5746 - val_accuracy: 0.7829\n",
      "Epoch 91/200\n",
      "172/172 [==============================] - 0s 954us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5767 - val_accuracy: 0.7829\n",
      "Epoch 92/200\n",
      "172/172 [==============================] - 0s 981us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5749 - val_accuracy: 0.7829\n",
      "Epoch 93/200\n",
      "172/172 [==============================] - 0s 953us/sample - loss: 0.5818 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 94/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 95/200\n",
      "172/172 [==============================] - 0s 946us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 96/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5748 - val_accuracy: 0.7829\n",
      "Epoch 97/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.5814 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 98/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 99/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 100/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.5818 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 101/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5747 - val_accuracy: 0.7829\n",
      "Epoch 102/200\n",
      "172/172 [==============================] - 0s 967us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 103/200\n",
      "172/172 [==============================] - 0s 989us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 104/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5747 - val_accuracy: 0.7829\n",
      "Epoch 105/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5819 - accuracy: 0.7791 - val_loss: 0.5768 - val_accuracy: 0.7829\n",
      "Epoch 106/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5752 - val_accuracy: 0.7829\n",
      "Epoch 107/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 108/200\n",
      "172/172 [==============================] - 0s 979us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 109/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5818 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 110/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5751 - val_accuracy: 0.7829\n",
      "Epoch 111/200\n",
      "172/172 [==============================] - 0s 963us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 112/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 113/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5771 - val_accuracy: 0.7829\n",
      "Epoch 114/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5767 - val_accuracy: 0.7829\n",
      "Epoch 115/200\n",
      "172/172 [==============================] - 0s 854us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 116/200\n",
      "172/172 [==============================] - 0s 865us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 117/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 118/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5848 - accuracy: 0.7791 - val_loss: 0.5771 - val_accuracy: 0.7829\n",
      "Epoch 119/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5819 - accuracy: 0.7791 - val_loss: 0.5771 - val_accuracy: 0.7829\n",
      "Epoch 120/200\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 0.5840 - accuracy: 0.7791 - val_loss: 0.5750 - val_accuracy: 0.7829\n",
      "Epoch 121/200\n",
      "172/172 [==============================] - 0s 858us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 122/200\n",
      "172/172 [==============================] - 0s 850us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 123/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5818 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 124/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5834 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 125/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.5817 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 126/200\n",
      "172/172 [==============================] - 0s 832us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5751 - val_accuracy: 0.7829\n",
      "Epoch 127/200\n",
      "172/172 [==============================] - 0s 834us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 128/200\n",
      "172/172 [==============================] - 0s 833us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 129/200\n",
      "172/172 [==============================] - 0s 854us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5752 - val_accuracy: 0.7829\n",
      "Epoch 130/200\n",
      "172/172 [==============================] - 0s 930us/sample - loss: 0.5819 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 131/200\n",
      "172/172 [==============================] - 0s 928us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 132/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5747 - val_accuracy: 0.7829\n",
      "Epoch 133/200\n",
      "172/172 [==============================] - 0s 943us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5769 - val_accuracy: 0.7829\n",
      "Epoch 134/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 135/200\n",
      "172/172 [==============================] - 0s 953us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5770 - val_accuracy: 0.7829\n",
      "Epoch 136/200\n",
      "172/172 [==============================] - 0s 860us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5748 - val_accuracy: 0.7829\n",
      "Epoch 137/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5818 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 138/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5752 - val_accuracy: 0.7829\n",
      "Epoch 139/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.5820 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 140/200\n",
      "172/172 [==============================] - 0s 958us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5750 - val_accuracy: 0.7829\n",
      "Epoch 141/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 142/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5814 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 143/200\n",
      "172/172 [==============================] - 0s 952us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 144/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 145/200\n",
      "172/172 [==============================] - 0s 839us/sample - loss: 0.5818 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 146/200\n",
      "172/172 [==============================] - 0s 840us/sample - loss: 0.5834 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 147/200\n",
      "172/172 [==============================] - 0s 842us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5771 - val_accuracy: 0.7829\n",
      "Epoch 148/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.5845 - accuracy: 0.7791 - val_loss: 0.5751 - val_accuracy: 0.7829\n",
      "Epoch 149/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 150/200\n",
      "172/172 [==============================] - 0s 999us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5751 - val_accuracy: 0.7829\n",
      "Epoch 151/200\n",
      "172/172 [==============================] - 0s 842us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 152/200\n",
      "172/172 [==============================] - 0s 834us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5752 - val_accuracy: 0.7829\n",
      "Epoch 153/200\n",
      "172/172 [==============================] - 0s 827us/sample - loss: 0.5814 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 154/200\n",
      "172/172 [==============================] - 0s 827us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 155/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 156/200\n",
      "172/172 [==============================] - 0s 944us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 157/200\n",
      "172/172 [==============================] - 0s 965us/sample - loss: 0.5844 - accuracy: 0.7791 - val_loss: 0.5748 - val_accuracy: 0.7829\n",
      "Epoch 158/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5819 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 159/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.5834 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 160/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 0.5833 - accuracy: 0.7791 - val_loss: 0.5747 - val_accuracy: 0.7829\n",
      "Epoch 161/200\n",
      "172/172 [==============================] - 0s 842us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5774 - val_accuracy: 0.7829\n",
      "Epoch 162/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.5820 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 163/200\n",
      "172/172 [==============================] - 0s 845us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 164/200\n",
      "172/172 [==============================] - 0s 861us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 165/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.5814 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 166/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 167/200\n",
      "172/172 [==============================] - 0s 973us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 168/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 169/200\n",
      "172/172 [==============================] - 0s 949us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 170/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5820 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 171/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5751 - val_accuracy: 0.7829\n",
      "Epoch 172/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5819 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 906us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 174/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 175/200\n",
      "172/172 [==============================] - 0s 854us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5777 - val_accuracy: 0.7829\n",
      "Epoch 176/200\n",
      "172/172 [==============================] - 0s 864us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 177/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 178/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 179/200\n",
      "172/172 [==============================] - 0s 983us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 180/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5744 - val_accuracy: 0.7829\n",
      "Epoch 181/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5816 - accuracy: 0.7791 - val_loss: 0.5752 - val_accuracy: 0.7829\n",
      "Epoch 182/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 183/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 184/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 185/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5819 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 186/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5819 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 187/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 188/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5750 - val_accuracy: 0.7829\n",
      "Epoch 189/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 190/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.5818 - accuracy: 0.7791 - val_loss: 0.5752 - val_accuracy: 0.7829\n",
      "Epoch 191/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 192/200\n",
      "172/172 [==============================] - 0s 960us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5750 - val_accuracy: 0.7829\n",
      "Epoch 193/200\n",
      "172/172 [==============================] - 0s 953us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5768 - val_accuracy: 0.7829\n",
      "Epoch 194/200\n",
      "172/172 [==============================] - 0s 945us/sample - loss: 0.5819 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 195/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 0.5819 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 196/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5749 - val_accuracy: 0.7829\n",
      "Epoch 197/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.5819 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 198/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.5818 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 199/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 200/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.5817 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Beginning training for dr=0.001, l_lambda=1.0e-02, reg_type=l1, act: tanh\n",
      "Train on 172 samples, validate on 43 samples\n",
      "Epoch 1/200\n",
      "172/172 [==============================] - 1s 8ms/sample - loss: 7.6313 - accuracy: 0.6667 - val_loss: 4.0644 - val_accuracy: 0.6667\n",
      "Epoch 2/200\n",
      "172/172 [==============================] - 0s 785us/sample - loss: 2.7940 - accuracy: 0.7364 - val_loss: 2.1056 - val_accuracy: 0.7829\n",
      "Epoch 3/200\n",
      "172/172 [==============================] - 0s 803us/sample - loss: 1.7512 - accuracy: 0.7791 - val_loss: 1.4451 - val_accuracy: 0.7829\n",
      "Epoch 4/200\n",
      "172/172 [==============================] - 0s 811us/sample - loss: 1.3001 - accuracy: 0.7791 - val_loss: 1.1433 - val_accuracy: 0.7829\n",
      "Epoch 5/200\n",
      "172/172 [==============================] - 0s 828us/sample - loss: 1.0563 - accuracy: 0.7791 - val_loss: 0.9490 - val_accuracy: 0.7829\n",
      "Epoch 6/200\n",
      "172/172 [==============================] - 0s 967us/sample - loss: 0.8853 - accuracy: 0.7791 - val_loss: 0.8012 - val_accuracy: 0.7829\n",
      "Epoch 7/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.7562 - accuracy: 0.7791 - val_loss: 0.6945 - val_accuracy: 0.7829\n",
      "Epoch 8/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.6628 - accuracy: 0.7791 - val_loss: 0.6188 - val_accuracy: 0.7829\n",
      "Epoch 9/200\n",
      "172/172 [==============================] - 0s 844us/sample - loss: 0.6061 - accuracy: 0.7791 - val_loss: 0.5846 - val_accuracy: 0.7829\n",
      "Epoch 10/200\n",
      "172/172 [==============================] - 0s 793us/sample - loss: 0.5875 - accuracy: 0.7791 - val_loss: 0.5780 - val_accuracy: 0.7829\n",
      "Epoch 11/200\n",
      "172/172 [==============================] - 0s 861us/sample - loss: 0.5843 - accuracy: 0.7791 - val_loss: 0.5768 - val_accuracy: 0.7829\n",
      "Epoch 12/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 0.5847 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 13/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5767 - val_accuracy: 0.7829\n",
      "Epoch 14/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.5833 - accuracy: 0.7791 - val_loss: 0.5770 - val_accuracy: 0.7829\n",
      "Epoch 15/200\n",
      "172/172 [==============================] - 0s 822us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5779 - val_accuracy: 0.7829\n",
      "Epoch 16/200\n",
      "172/172 [==============================] - 0s 788us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5771 - val_accuracy: 0.7829\n",
      "Epoch 17/200\n",
      "172/172 [==============================] - 0s 783us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 18/200\n",
      "172/172 [==============================] - 0s 774us/sample - loss: 0.5832 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 19/200\n",
      "172/172 [==============================] - 0s 788us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 20/200\n",
      "172/172 [==============================] - 0s 832us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 21/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5769 - val_accuracy: 0.7829\n",
      "Epoch 22/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 23/200\n",
      "172/172 [==============================] - 0s 826us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5767 - val_accuracy: 0.7829\n",
      "Epoch 24/200\n",
      "172/172 [==============================] - 0s 785us/sample - loss: 0.5838 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 25/200\n",
      "172/172 [==============================] - 0s 812us/sample - loss: 0.5840 - accuracy: 0.7791 - val_loss: 0.5770 - val_accuracy: 0.7829\n",
      "Epoch 26/200\n",
      "172/172 [==============================] - 0s 805us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 27/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 847us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5769 - val_accuracy: 0.7829\n",
      "Epoch 28/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 29/200\n",
      "172/172 [==============================] - 0s 978us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 30/200\n",
      "172/172 [==============================] - 0s 842us/sample - loss: 0.5844 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 31/200\n",
      "172/172 [==============================] - 0s 809us/sample - loss: 0.5838 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 32/200\n",
      "172/172 [==============================] - 0s 802us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 33/200\n",
      "172/172 [==============================] - 0s 801us/sample - loss: 0.5833 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 34/200\n",
      "172/172 [==============================] - 0s 946us/sample - loss: 0.5837 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 35/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5847 - accuracy: 0.7791 - val_loss: 0.5778 - val_accuracy: 0.7829\n",
      "Epoch 36/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 0.5833 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 37/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 38/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 39/200\n",
      "172/172 [==============================] - 0s 845us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5773 - val_accuracy: 0.7829\n",
      "Epoch 40/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 41/200\n",
      "172/172 [==============================] - 0s 796us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 42/200\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 0.5817 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 43/200\n",
      "172/172 [==============================] - 0s 812us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5769 - val_accuracy: 0.7829\n",
      "Epoch 44/200\n",
      "172/172 [==============================] - 0s 826us/sample - loss: 0.5844 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 45/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 46/200\n",
      "172/172 [==============================] - 0s 833us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 47/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5836 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 48/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.5819 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 49/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5784 - val_accuracy: 0.7829\n",
      "Epoch 50/200\n",
      "172/172 [==============================] - 0s 854us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 51/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.5836 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 52/200\n",
      "172/172 [==============================] - 0s 998us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5748 - val_accuracy: 0.7829\n",
      "Epoch 53/200\n",
      "172/172 [==============================] - 0s 984us/sample - loss: 0.5820 - accuracy: 0.7791 - val_loss: 0.5770 - val_accuracy: 0.7829\n",
      "Epoch 54/200\n",
      "172/172 [==============================] - 0s 861us/sample - loss: 0.5836 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 55/200\n",
      "172/172 [==============================] - 0s 853us/sample - loss: 0.5851 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 56/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.5820 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 57/200\n",
      "172/172 [==============================] - 0s 971us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5776 - val_accuracy: 0.7829\n",
      "Epoch 58/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 59/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.5834 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 60/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 61/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5852 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 62/200\n",
      "172/172 [==============================] - 0s 944us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5752 - val_accuracy: 0.7829\n",
      "Epoch 63/200\n",
      "172/172 [==============================] - 0s 955us/sample - loss: 0.5844 - accuracy: 0.7791 - val_loss: 0.5796 - val_accuracy: 0.7829\n",
      "Epoch 64/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 65/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 0.5837 - accuracy: 0.7791 - val_loss: 0.5768 - val_accuracy: 0.7829\n",
      "Epoch 66/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5752 - val_accuracy: 0.7829\n",
      "Epoch 67/200\n",
      "172/172 [==============================] - 0s 949us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 68/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5748 - val_accuracy: 0.7829\n",
      "Epoch 69/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 70/200\n",
      "172/172 [==============================] - 0s 987us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 71/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 72/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 73/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 74/200\n",
      "172/172 [==============================] - 0s 948us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 75/200\n",
      "172/172 [==============================] - 0s 952us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 76/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5751 - val_accuracy: 0.7829\n",
      "Epoch 77/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5778 - val_accuracy: 0.7829\n",
      "Epoch 78/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5849 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 79/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.5832 - accuracy: 0.7791 - val_loss: 0.5767 - val_accuracy: 0.7829\n",
      "Epoch 80/200\n",
      "172/172 [==============================] - 0s 843us/sample - loss: 0.5845 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 81/200\n",
      "172/172 [==============================] - 0s 850us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 82/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 890us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 83/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 84/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 85/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5768 - val_accuracy: 0.7829\n",
      "Epoch 86/200\n",
      "172/172 [==============================] - 0s 858us/sample - loss: 0.5833 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 87/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5751 - val_accuracy: 0.7829\n",
      "Epoch 88/200\n",
      "172/172 [==============================] - 0s 856us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 89/200\n",
      "172/172 [==============================] - 0s 848us/sample - loss: 0.5849 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 90/200\n",
      "172/172 [==============================] - 0s 827us/sample - loss: 0.5841 - accuracy: 0.7791 - val_loss: 0.5767 - val_accuracy: 0.7829\n",
      "Epoch 91/200\n",
      "172/172 [==============================] - 0s 837us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5779 - val_accuracy: 0.7829\n",
      "Epoch 92/200\n",
      "172/172 [==============================] - 0s 821us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 93/200\n",
      "172/172 [==============================] - 0s 833us/sample - loss: 0.5820 - accuracy: 0.7791 - val_loss: 0.5772 - val_accuracy: 0.7829\n",
      "Epoch 94/200\n",
      "172/172 [==============================] - 0s 825us/sample - loss: 0.5842 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 95/200\n",
      "172/172 [==============================] - 0s 820us/sample - loss: 0.5840 - accuracy: 0.7791 - val_loss: 0.5769 - val_accuracy: 0.7829\n",
      "Epoch 96/200\n",
      "172/172 [==============================] - 0s 828us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 97/200\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 0.5866 - accuracy: 0.7791 - val_loss: 0.5793 - val_accuracy: 0.7829\n",
      "Epoch 98/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5771 - val_accuracy: 0.7829\n",
      "Epoch 99/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5767 - val_accuracy: 0.7829\n",
      "Epoch 100/200\n",
      "172/172 [==============================] - 0s 826us/sample - loss: 0.5832 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 101/200\n",
      "172/172 [==============================] - 0s 832us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 102/200\n",
      "172/172 [==============================] - 0s 827us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 103/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 0.5837 - accuracy: 0.7791 - val_loss: 0.5785 - val_accuracy: 0.7829\n",
      "Epoch 104/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 105/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5784 - val_accuracy: 0.7829\n",
      "Epoch 106/200\n",
      "172/172 [==============================] - 0s 980us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 107/200\n",
      "172/172 [==============================] - 0s 848us/sample - loss: 0.5843 - accuracy: 0.7791 - val_loss: 0.5778 - val_accuracy: 0.7829\n",
      "Epoch 108/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 109/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 0.5835 - accuracy: 0.7791 - val_loss: 0.5772 - val_accuracy: 0.7829\n",
      "Epoch 110/200\n",
      "172/172 [==============================] - 0s 948us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 111/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 112/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 113/200\n",
      "172/172 [==============================] - 0s 856us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5767 - val_accuracy: 0.7829\n",
      "Epoch 114/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 115/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 116/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 117/200\n",
      "172/172 [==============================] - 0s 977us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 118/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 119/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5767 - val_accuracy: 0.7829\n",
      "Epoch 120/200\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5751 - val_accuracy: 0.7829\n",
      "Epoch 121/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 122/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 123/200\n",
      "172/172 [==============================] - 0s 957us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 124/200\n",
      "172/172 [==============================] - 0s 966us/sample - loss: 0.5833 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 125/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5819 - accuracy: 0.7791 - val_loss: 0.5769 - val_accuracy: 0.7829\n",
      "Epoch 126/200\n",
      "172/172 [==============================] - 0s 969us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 127/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.5846 - accuracy: 0.7791 - val_loss: 0.5770 - val_accuracy: 0.7829\n",
      "Epoch 128/200\n",
      "172/172 [==============================] - 0s 979us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 129/200\n",
      "172/172 [==============================] - 0s 968us/sample - loss: 0.5839 - accuracy: 0.7791 - val_loss: 0.5771 - val_accuracy: 0.7829\n",
      "Epoch 130/200\n",
      "172/172 [==============================] - 0s 859us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 131/200\n",
      "172/172 [==============================] - 0s 850us/sample - loss: 0.5839 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 132/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5748 - val_accuracy: 0.7829\n",
      "Epoch 133/200\n",
      "172/172 [==============================] - 0s 849us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5775 - val_accuracy: 0.7829\n",
      "Epoch 134/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 0.5845 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 135/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5769 - val_accuracy: 0.7829\n",
      "Epoch 136/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5854 - accuracy: 0.7791 - val_loss: 0.5752 - val_accuracy: 0.7829\n",
      "Epoch 137/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5872 - accuracy: 0.7791 - val_loss: 0.5790 - val_accuracy: 0.7829\n",
      "Epoch 138/200\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 139/200\n",
      "172/172 [==============================] - 0s 968us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 140/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.5855 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 141/200\n",
      "172/172 [==============================] - 0s 961us/sample - loss: 0.5850 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 142/200\n",
      "172/172 [==============================] - 0s 961us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 143/200\n",
      "172/172 [==============================] - 0s 963us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 144/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 145/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 146/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 147/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5836 - accuracy: 0.7791 - val_loss: 0.5777 - val_accuracy: 0.7829\n",
      "Epoch 148/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 149/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.5843 - accuracy: 0.7791 - val_loss: 0.5778 - val_accuracy: 0.7829\n",
      "Epoch 150/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 151/200\n",
      "172/172 [==============================] - 0s 849us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 152/200\n",
      "172/172 [==============================] - 0s 842us/sample - loss: 0.5839 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 153/200\n",
      "172/172 [==============================] - 0s 845us/sample - loss: 0.5836 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 154/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.5844 - accuracy: 0.7791 - val_loss: 0.5769 - val_accuracy: 0.7829\n",
      "Epoch 155/200\n",
      "172/172 [==============================] - 0s 858us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5781 - val_accuracy: 0.7829\n",
      "Epoch 156/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.5833 - accuracy: 0.7791 - val_loss: 0.5775 - val_accuracy: 0.7829\n",
      "Epoch 157/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 158/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.5820 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 159/200\n",
      "172/172 [==============================] - 0s 845us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 160/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.5832 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 161/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5774 - val_accuracy: 0.7829\n",
      "Epoch 162/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 163/200\n",
      "172/172 [==============================] - 0s 835us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5770 - val_accuracy: 0.7829\n",
      "Epoch 164/200\n",
      "172/172 [==============================] - 0s 826us/sample - loss: 0.5876 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 165/200\n",
      "172/172 [==============================] - 0s 825us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 166/200\n",
      "172/172 [==============================] - 0s 821us/sample - loss: 0.5832 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 167/200\n",
      "172/172 [==============================] - 0s 823us/sample - loss: 0.5838 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 168/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 169/200\n",
      "172/172 [==============================] - 0s 829us/sample - loss: 0.5851 - accuracy: 0.7791 - val_loss: 0.5768 - val_accuracy: 0.7829\n",
      "Epoch 170/200\n",
      "172/172 [==============================] - 0s 820us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 171/200\n",
      "172/172 [==============================] - 0s 828us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 172/200\n",
      "172/172 [==============================] - 0s 820us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 173/200\n",
      "172/172 [==============================] - 0s 816us/sample - loss: 0.5842 - accuracy: 0.7791 - val_loss: 0.5771 - val_accuracy: 0.7829\n",
      "Epoch 174/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.5850 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 175/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 0.5832 - accuracy: 0.7791 - val_loss: 0.5791 - val_accuracy: 0.7829\n",
      "Epoch 176/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.5840 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 177/200\n",
      "172/172 [==============================] - 0s 844us/sample - loss: 0.5834 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 178/200\n",
      "172/172 [==============================] - 0s 845us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 179/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 180/200\n",
      "172/172 [==============================] - 0s 856us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 181/200\n",
      "172/172 [==============================] - 0s 850us/sample - loss: 0.5849 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 182/200\n",
      "172/172 [==============================] - 0s 840us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 183/200\n",
      "172/172 [==============================] - 0s 849us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5771 - val_accuracy: 0.7829\n",
      "Epoch 184/200\n",
      "172/172 [==============================] - 0s 856us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 185/200\n",
      "172/172 [==============================] - 0s 858us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 186/200\n",
      "172/172 [==============================] - 0s 856us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 187/200\n",
      "172/172 [==============================] - 0s 943us/sample - loss: 0.5835 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 188/200\n",
      "172/172 [==============================] - 0s 940us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5752 - val_accuracy: 0.7829\n",
      "Epoch 189/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5768 - val_accuracy: 0.7829\n",
      "Epoch 190/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5752 - val_accuracy: 0.7829\n",
      "Epoch 191/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.5836 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 192/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 852us/sample - loss: 0.5849 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 193/200\n",
      "172/172 [==============================] - 0s 974us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5767 - val_accuracy: 0.7829\n",
      "Epoch 194/200\n",
      "172/172 [==============================] - 0s 976us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 195/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.5833 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 196/200\n",
      "172/172 [==============================] - 0s 983us/sample - loss: 0.5840 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 197/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5833 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 198/200\n",
      "172/172 [==============================] - 0s 978us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 199/200\n",
      "172/172 [==============================] - 0s 854us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 200/200\n",
      "172/172 [==============================] - 0s 987us/sample - loss: 0.5819 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Beginning training for dr=0.001, l_lambda=1.0e-01, reg_type=l2, act: relu\n",
      "Train on 172 samples, validate on 43 samples\n",
      "Epoch 1/200\n",
      "172/172 [==============================] - 1s 8ms/sample - loss: 3.2584 - accuracy: 0.6667 - val_loss: 2.2153 - val_accuracy: 0.6667\n",
      "Epoch 2/200\n",
      "172/172 [==============================] - 0s 844us/sample - loss: 1.8614 - accuracy: 0.6667 - val_loss: 1.5616 - val_accuracy: 0.6667\n",
      "Epoch 3/200\n",
      "172/172 [==============================] - 0s 842us/sample - loss: 1.4047 - accuracy: 0.6667 - val_loss: 1.2281 - val_accuracy: 0.6667\n",
      "Epoch 4/200\n",
      "172/172 [==============================] - 0s 975us/sample - loss: 1.1140 - accuracy: 0.7209 - val_loss: 0.9834 - val_accuracy: 0.7829\n",
      "Epoch 5/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.9074 - accuracy: 0.7791 - val_loss: 0.8210 - val_accuracy: 0.7829\n",
      "Epoch 6/200\n",
      "172/172 [==============================] - 0s 864us/sample - loss: 0.7712 - accuracy: 0.7791 - val_loss: 0.7109 - val_accuracy: 0.7829\n",
      "Epoch 7/200\n",
      "172/172 [==============================] - 0s 819us/sample - loss: 0.6845 - accuracy: 0.7791 - val_loss: 0.6380 - val_accuracy: 0.7829\n",
      "Epoch 8/200\n",
      "172/172 [==============================] - 0s 804us/sample - loss: 0.6213 - accuracy: 0.7791 - val_loss: 0.5898 - val_accuracy: 0.7829\n",
      "Epoch 9/200\n",
      "172/172 [==============================] - 0s 806us/sample - loss: 0.5809 - accuracy: 0.7791 - val_loss: 0.5573 - val_accuracy: 0.7829\n",
      "Epoch 10/200\n",
      "172/172 [==============================] - 0s 827us/sample - loss: 0.5543 - accuracy: 0.7791 - val_loss: 0.5366 - val_accuracy: 0.7829\n",
      "Epoch 11/200\n",
      "172/172 [==============================] - 0s 810us/sample - loss: 0.5369 - accuracy: 0.7791 - val_loss: 0.5228 - val_accuracy: 0.7829\n",
      "Epoch 12/200\n",
      "172/172 [==============================] - 0s 814us/sample - loss: 0.5251 - accuracy: 0.7791 - val_loss: 0.5144 - val_accuracy: 0.7829\n",
      "Epoch 13/200\n",
      "172/172 [==============================] - 0s 813us/sample - loss: 0.5186 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 14/200\n",
      "172/172 [==============================] - 0s 801us/sample - loss: 0.5151 - accuracy: 0.7791 - val_loss: 0.5062 - val_accuracy: 0.7829\n",
      "Epoch 15/200\n",
      "172/172 [==============================] - 0s 836us/sample - loss: 0.5124 - accuracy: 0.7791 - val_loss: 0.5051 - val_accuracy: 0.7829\n",
      "Epoch 16/200\n",
      "172/172 [==============================] - 0s 807us/sample - loss: 0.5110 - accuracy: 0.7791 - val_loss: 0.5034 - val_accuracy: 0.7829\n",
      "Epoch 17/200\n",
      "172/172 [==============================] - 0s 956us/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 18/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5107 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 19/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 20/200\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 21/200\n",
      "172/172 [==============================] - 0s 856us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 22/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 23/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 24/200\n",
      "172/172 [==============================] - 0s 840us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 25/200\n",
      "172/172 [==============================] - 0s 837us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 26/200\n",
      "172/172 [==============================] - 0s 826us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 27/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 28/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 29/200\n",
      "172/172 [==============================] - 0s 960us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 30/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 31/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 32/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 33/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 34/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 35/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 36/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 37/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 38/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 39/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 40/200\n",
      "172/172 [==============================] - 0s 944us/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 41/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 42/200\n",
      "172/172 [==============================] - 0s 954us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 43/200\n",
      "172/172 [==============================] - 0s 965us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 44/200\n",
      "172/172 [==============================] - 0s 965us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 45/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 46/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 48/200\n",
      "172/172 [==============================] - 0s 856us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 49/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 50/200\n",
      "172/172 [==============================] - 0s 856us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 51/200\n",
      "172/172 [==============================] - 0s 859us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 52/200\n",
      "172/172 [==============================] - 0s 864us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 53/200\n",
      "172/172 [==============================] - 0s 859us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 54/200\n",
      "172/172 [==============================] - 0s 857us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 55/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 56/200\n",
      "172/172 [==============================] - 0s 940us/sample - loss: 0.5105 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 57/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 58/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 59/200\n",
      "172/172 [==============================] - 0s 845us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 60/200\n",
      "172/172 [==============================] - 0s 831us/sample - loss: 0.5085 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 61/200\n",
      "172/172 [==============================] - 0s 829us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 62/200\n",
      "172/172 [==============================] - 0s 830us/sample - loss: 0.5117 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 63/200\n",
      "172/172 [==============================] - 0s 830us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 64/200\n",
      "172/172 [==============================] - 0s 829us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 65/200\n",
      "172/172 [==============================] - 0s 836us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 66/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 67/200\n",
      "172/172 [==============================] - 0s 940us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 68/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 69/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 70/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 71/200\n",
      "172/172 [==============================] - 0s 860us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 72/200\n",
      "172/172 [==============================] - 0s 850us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 73/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 74/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 75/200\n",
      "172/172 [==============================] - 0s 860us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 76/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 77/200\n",
      "172/172 [==============================] - 0s 957us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 78/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 79/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 0.5106 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 80/200\n",
      "172/172 [==============================] - 0s 953us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 81/200\n",
      "172/172 [==============================] - 0s 996us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 82/200\n",
      "172/172 [==============================] - 0s 989us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 83/200\n",
      "172/172 [==============================] - 0s 965us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 84/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.5112 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 85/200\n",
      "172/172 [==============================] - 0s 955us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 86/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 87/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 88/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 89/200\n",
      "172/172 [==============================] - 0s 980us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 90/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 91/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 92/200\n",
      "172/172 [==============================] - 0s 995us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 93/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 94/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 95/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 96/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 97/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 98/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 99/200\n",
      "172/172 [==============================] - 0s 854us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 100/200\n",
      "172/172 [==============================] - 0s 856us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 101/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 102/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 864us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 103/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 104/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 105/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 106/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 107/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 108/200\n",
      "172/172 [==============================] - 0s 842us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 109/200\n",
      "172/172 [==============================] - 0s 825us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 110/200\n",
      "172/172 [==============================] - 0s 822us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 111/200\n",
      "172/172 [==============================] - 0s 818us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 112/200\n",
      "172/172 [==============================] - 0s 821us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 113/200\n",
      "172/172 [==============================] - 0s 818us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 114/200\n",
      "172/172 [==============================] - 0s 822us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 115/200\n",
      "172/172 [==============================] - 0s 839us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 116/200\n",
      "172/172 [==============================] - 0s 843us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 117/200\n",
      "172/172 [==============================] - 0s 853us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 118/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 119/200\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 120/200\n",
      "172/172 [==============================] - 0s 963us/sample - loss: 0.5106 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 121/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 122/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 123/200\n",
      "172/172 [==============================] - 0s 857us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 124/200\n",
      "172/172 [==============================] - 0s 858us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 125/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 126/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 127/200\n",
      "172/172 [==============================] - 0s 859us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 128/200\n",
      "172/172 [==============================] - 0s 858us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 129/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 130/200\n",
      "172/172 [==============================] - 0s 942us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 131/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 132/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 133/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 134/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 135/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 136/200\n",
      "172/172 [==============================] - 0s 860us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 137/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 138/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 139/200\n",
      "172/172 [==============================] - 0s 850us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 140/200\n",
      "172/172 [==============================] - 0s 850us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 141/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 142/200\n",
      "172/172 [==============================] - 0s 845us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 143/200\n",
      "172/172 [==============================] - 0s 848us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 144/200\n",
      "172/172 [==============================] - 0s 943us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 145/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 146/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 147/200\n",
      "172/172 [==============================] - 0s 848us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 148/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 149/200\n",
      "172/172 [==============================] - 0s 849us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 150/200\n",
      "172/172 [==============================] - 0s 850us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 151/200\n",
      "172/172 [==============================] - 0s 853us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 152/200\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 153/200\n",
      "172/172 [==============================] - 0s 849us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 154/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 155/200\n",
      "172/172 [==============================] - 0s 850us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 156/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 157/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 962us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 158/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 159/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 160/200\n",
      "172/172 [==============================] - 0s 861us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 161/200\n",
      "172/172 [==============================] - 0s 853us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 162/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 163/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 164/200\n",
      "172/172 [==============================] - 0s 848us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 165/200\n",
      "172/172 [==============================] - 0s 845us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 166/200\n",
      "172/172 [==============================] - 0s 848us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 167/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 168/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 169/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 170/200\n",
      "172/172 [==============================] - 0s 854us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 171/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 172/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 173/200\n",
      "172/172 [==============================] - 0s 848us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 174/200\n",
      "172/172 [==============================] - 0s 824us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 175/200\n",
      "172/172 [==============================] - 0s 817us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 176/200\n",
      "172/172 [==============================] - 0s 821us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 177/200\n",
      "172/172 [==============================] - 0s 815us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 178/200\n",
      "172/172 [==============================] - 0s 822us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 179/200\n",
      "172/172 [==============================] - 0s 818us/sample - loss: 0.5105 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 180/200\n",
      "172/172 [==============================] - 0s 821us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 181/200\n",
      "172/172 [==============================] - 0s 821us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 182/200\n",
      "172/172 [==============================] - 0s 827us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 183/200\n",
      "172/172 [==============================] - 0s 827us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 184/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 185/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 186/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 187/200\n",
      "172/172 [==============================] - 0s 865us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 188/200\n",
      "172/172 [==============================] - 0s 842us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 189/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 190/200\n",
      "172/172 [==============================] - 0s 842us/sample - loss: 0.5109 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 191/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 192/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 193/200\n",
      "172/172 [==============================] - 0s 849us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 194/200\n",
      "172/172 [==============================] - 0s 849us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 195/200\n",
      "172/172 [==============================] - 0s 842us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 196/200\n",
      "172/172 [==============================] - 0s 843us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 197/200\n",
      "172/172 [==============================] - 0s 848us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 198/200\n",
      "172/172 [==============================] - 0s 942us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 199/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 200/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Beginning training for dr=0.001, l_lambda=1.0e-01, reg_type=l2, act: tanh\n",
      "Train on 172 samples, validate on 43 samples\n",
      "Epoch 1/200\n",
      "172/172 [==============================] - 1s 7ms/sample - loss: 3.2214 - accuracy: 0.6667 - val_loss: 2.1570 - val_accuracy: 0.6667\n",
      "Epoch 2/200\n",
      "172/172 [==============================] - 0s 825us/sample - loss: 1.7944 - accuracy: 0.7016 - val_loss: 1.4795 - val_accuracy: 0.7829\n",
      "Epoch 3/200\n",
      "172/172 [==============================] - 0s 979us/sample - loss: 1.3312 - accuracy: 0.7791 - val_loss: 1.1641 - val_accuracy: 0.7829\n",
      "Epoch 4/200\n",
      "172/172 [==============================] - 0s 951us/sample - loss: 1.0666 - accuracy: 0.7791 - val_loss: 0.9488 - val_accuracy: 0.7829\n",
      "Epoch 5/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.8850 - accuracy: 0.7791 - val_loss: 0.8012 - val_accuracy: 0.7829\n",
      "Epoch 6/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 0.7592 - accuracy: 0.7791 - val_loss: 0.6995 - val_accuracy: 0.7829\n",
      "Epoch 7/200\n",
      "172/172 [==============================] - 0s 835us/sample - loss: 0.6742 - accuracy: 0.7791 - val_loss: 0.6302 - val_accuracy: 0.7829\n",
      "Epoch 8/200\n",
      "172/172 [==============================] - 0s 833us/sample - loss: 0.6159 - accuracy: 0.7791 - val_loss: 0.5839 - val_accuracy: 0.7829\n",
      "Epoch 9/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.5763 - accuracy: 0.7791 - val_loss: 0.5530 - val_accuracy: 0.7829\n",
      "Epoch 10/200\n",
      "172/172 [==============================] - 0s 834us/sample - loss: 0.5508 - accuracy: 0.7791 - val_loss: 0.5333 - val_accuracy: 0.7829\n",
      "Epoch 11/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 854us/sample - loss: 0.5371 - accuracy: 0.7791 - val_loss: 0.5205 - val_accuracy: 0.7829\n",
      "Epoch 12/200\n",
      "172/172 [==============================] - 0s 844us/sample - loss: 0.5239 - accuracy: 0.7791 - val_loss: 0.5132 - val_accuracy: 0.7829\n",
      "Epoch 13/200\n",
      "172/172 [==============================] - 0s 843us/sample - loss: 0.5191 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 14/200\n",
      "172/172 [==============================] - 0s 835us/sample - loss: 0.5155 - accuracy: 0.7791 - val_loss: 0.5056 - val_accuracy: 0.7829\n",
      "Epoch 15/200\n",
      "172/172 [==============================] - 0s 955us/sample - loss: 0.5115 - accuracy: 0.7791 - val_loss: 0.5039 - val_accuracy: 0.7829\n",
      "Epoch 16/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5108 - accuracy: 0.7791 - val_loss: 0.5028 - val_accuracy: 0.7829\n",
      "Epoch 17/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.5104 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 18/200\n",
      "172/172 [==============================] - 0s 862us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 19/200\n",
      "172/172 [==============================] - 0s 804us/sample - loss: 0.5117 - accuracy: 0.7791 - val_loss: 0.5035 - val_accuracy: 0.7829\n",
      "Epoch 20/200\n",
      "172/172 [==============================] - 0s 819us/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 21/200\n",
      "172/172 [==============================] - 0s 821us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5030 - val_accuracy: 0.7829\n",
      "Epoch 22/200\n",
      "172/172 [==============================] - 0s 819us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 23/200\n",
      "172/172 [==============================] - 0s 821us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 24/200\n",
      "172/172 [==============================] - 0s 804us/sample - loss: 0.5107 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 25/200\n",
      "172/172 [==============================] - 0s 842us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 26/200\n",
      "172/172 [==============================] - 0s 805us/sample - loss: 0.5117 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 27/200\n",
      "172/172 [==============================] - 0s 830us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 28/200\n",
      "172/172 [==============================] - 0s 817us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 29/200\n",
      "172/172 [==============================] - 0s 816us/sample - loss: 0.5104 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 30/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 31/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.5135 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 32/200\n",
      "172/172 [==============================] - 0s 841us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 33/200\n",
      "172/172 [==============================] - 0s 814us/sample - loss: 0.5122 - accuracy: 0.7791 - val_loss: 0.5026 - val_accuracy: 0.7829\n",
      "Epoch 34/200\n",
      "172/172 [==============================] - 0s 811us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 35/200\n",
      "172/172 [==============================] - 0s 823us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 36/200\n",
      "172/172 [==============================] - 0s 819us/sample - loss: 0.5105 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 37/200\n",
      "172/172 [==============================] - 0s 823us/sample - loss: 0.5108 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 38/200\n",
      "172/172 [==============================] - 0s 828us/sample - loss: 0.5086 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 39/200\n",
      "172/172 [==============================] - 0s 831us/sample - loss: 0.5109 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 40/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 41/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 42/200\n",
      "172/172 [==============================] - 0s 849us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 43/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 44/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.5115 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 45/200\n",
      "172/172 [==============================] - 0s 941us/sample - loss: 0.5106 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 46/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 47/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.5106 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 48/200\n",
      "172/172 [==============================] - 0s 882us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 49/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 50/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 51/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 52/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 53/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 54/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 55/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 56/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5106 - accuracy: 0.7791 - val_loss: 0.5026 - val_accuracy: 0.7829\n",
      "Epoch 57/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 58/200\n",
      "172/172 [==============================] - 0s 986us/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5035 - val_accuracy: 0.7829\n",
      "Epoch 59/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5106 - accuracy: 0.7791 - val_loss: 0.5026 - val_accuracy: 0.7829\n",
      "Epoch 60/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5122 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 61/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5085 - accuracy: 0.7791 - val_loss: 0.5034 - val_accuracy: 0.7829\n",
      "Epoch 62/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5104 - accuracy: 0.7791 - val_loss: 0.5030 - val_accuracy: 0.7829\n",
      "Epoch 63/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 64/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5107 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 65/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 66/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 67/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 68/200\n",
      "172/172 [==============================] - 0s 958us/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 69/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 70/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 71/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 72/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 73/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5124 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 74/200\n",
      "172/172 [==============================] - 0s 987us/sample - loss: 0.5085 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 75/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 76/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5032 - val_accuracy: 0.7829\n",
      "Epoch 77/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5029 - val_accuracy: 0.7829\n",
      "Epoch 78/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 79/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5106 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 80/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 81/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 82/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 83/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 84/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 85/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5014 - val_accuracy: 0.7829\n",
      "Epoch 86/200\n",
      "172/172 [==============================] - 0s 972us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5014 - val_accuracy: 0.7829\n",
      "Epoch 87/200\n",
      "172/172 [==============================] - 0s 988us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 88/200\n",
      "172/172 [==============================] - 0s 977us/sample - loss: 0.5113 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 89/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 90/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 91/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 92/200\n",
      "172/172 [==============================] - 0s 962us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5014 - val_accuracy: 0.7829\n",
      "Epoch 93/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 94/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 95/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 96/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 97/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 98/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 99/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.5109 - accuracy: 0.7791 - val_loss: 0.5028 - val_accuracy: 0.7829\n",
      "Epoch 100/200\n",
      "172/172 [==============================] - 0s 854us/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 101/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 102/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 103/200\n",
      "172/172 [==============================] - 0s 850us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 104/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 105/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 106/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 107/200\n",
      "172/172 [==============================] - 0s 862us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 108/200\n",
      "172/172 [==============================] - 0s 869us/sample - loss: 0.5104 - accuracy: 0.7791 - val_loss: 0.5013 - val_accuracy: 0.7829\n",
      "Epoch 109/200\n",
      "172/172 [==============================] - 0s 999us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 110/200\n",
      "172/172 [==============================] - 0s 944us/sample - loss: 0.5108 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 111/200\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 112/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 113/200\n",
      "172/172 [==============================] - 0s 860us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 114/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 115/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 116/200\n",
      "172/172 [==============================] - 0s 864us/sample - loss: 0.5114 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 117/200\n",
      "172/172 [==============================] - 0s 858us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 118/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 0.5114 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 119/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 120/200\n",
      "172/172 [==============================] - 0s 864us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 121/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 859us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 122/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 123/200\n",
      "172/172 [==============================] - 0s 941us/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 124/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 125/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 126/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 127/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 128/200\n",
      "172/172 [==============================] - 0s 928us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5035 - val_accuracy: 0.7829\n",
      "Epoch 129/200\n",
      "172/172 [==============================] - 0s 869us/sample - loss: 0.5110 - accuracy: 0.7791 - val_loss: 0.5037 - val_accuracy: 0.7829\n",
      "Epoch 130/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 131/200\n",
      "172/172 [==============================] - 0s 856us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 132/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 133/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5014 - val_accuracy: 0.7829\n",
      "Epoch 134/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5014 - val_accuracy: 0.7829\n",
      "Epoch 135/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 136/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5014 - val_accuracy: 0.7829\n",
      "Epoch 137/200\n",
      "172/172 [==============================] - 0s 980us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 138/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 139/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 140/200\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 141/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 142/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 143/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 144/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 145/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 146/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 147/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 148/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 149/200\n",
      "172/172 [==============================] - 0s 967us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5026 - val_accuracy: 0.7829\n",
      "Epoch 150/200\n",
      "172/172 [==============================] - 0s 1000us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 151/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 152/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 153/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5030 - val_accuracy: 0.7829\n",
      "Epoch 154/200\n",
      "172/172 [==============================] - 0s 999us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 155/200\n",
      "172/172 [==============================] - 0s 882us/sample - loss: 0.5109 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 156/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5026 - val_accuracy: 0.7829\n",
      "Epoch 157/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 158/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 159/200\n",
      "172/172 [==============================] - 0s 860us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 160/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 161/200\n",
      "172/172 [==============================] - 0s 969us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 162/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 0.5106 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 163/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 164/200\n",
      "172/172 [==============================] - 0s 853us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 165/200\n",
      "172/172 [==============================] - 0s 857us/sample - loss: 0.5111 - accuracy: 0.7791 - val_loss: 0.5031 - val_accuracy: 0.7829\n",
      "Epoch 166/200\n",
      "172/172 [==============================] - 0s 937us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 167/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 168/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 169/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.5102 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 170/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 171/200\n",
      "172/172 [==============================] - 0s 865us/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5033 - val_accuracy: 0.7829\n",
      "Epoch 172/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 173/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 174/200\n",
      "172/172 [==============================] - 0s 947us/sample - loss: 0.5105 - accuracy: 0.7791 - val_loss: 0.5033 - val_accuracy: 0.7829\n",
      "Epoch 175/200\n",
      "172/172 [==============================] - 0s 967us/sample - loss: 0.5105 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 176/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 870us/sample - loss: 0.5111 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 177/200\n",
      "172/172 [==============================] - 0s 844us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 178/200\n",
      "172/172 [==============================] - 0s 850us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 179/200\n",
      "172/172 [==============================] - 0s 834us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 180/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.5140 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 181/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 0.5084 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 182/200\n",
      "172/172 [==============================] - 0s 831us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 183/200\n",
      "172/172 [==============================] - 0s 823us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 184/200\n",
      "172/172 [==============================] - 0s 859us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 185/200\n",
      "172/172 [==============================] - 0s 835us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 186/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 187/200\n",
      "172/172 [==============================] - 0s 946us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 188/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 189/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 190/200\n",
      "172/172 [==============================] - 0s 853us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 191/200\n",
      "172/172 [==============================] - 0s 859us/sample - loss: 0.5106 - accuracy: 0.7791 - val_loss: 0.5042 - val_accuracy: 0.7829\n",
      "Epoch 192/200\n",
      "172/172 [==============================] - 0s 854us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 193/200\n",
      "172/172 [==============================] - 0s 843us/sample - loss: 0.5129 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 194/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5029 - val_accuracy: 0.7829\n",
      "Epoch 195/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 196/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 197/200\n",
      "172/172 [==============================] - 0s 853us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 198/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 199/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 200/200\n",
      "172/172 [==============================] - 0s 957us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Beginning training for dr=0.001, l_lambda=1.0e-01, reg_type=l1, act: relu\n",
      "Train on 172 samples, validate on 43 samples\n",
      "Epoch 1/200\n",
      "172/172 [==============================] - 2s 9ms/sample - loss: 71.1676 - accuracy: 0.6667 - val_loss: 35.8128 - val_accuracy: 0.6667\n",
      "Epoch 2/200\n",
      "172/172 [==============================] - 0s 945us/sample - loss: 23.2824 - accuracy: 0.6667 - val_loss: 16.5978 - val_accuracy: 0.6667\n",
      "Epoch 3/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 13.0440 - accuracy: 0.6938 - val_loss: 10.0319 - val_accuracy: 0.7829\n",
      "Epoch 4/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 8.5034 - accuracy: 0.7791 - val_loss: 6.9535 - val_accuracy: 0.7829\n",
      "Epoch 5/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 5.9993 - accuracy: 0.7791 - val_loss: 4.9454 - val_accuracy: 0.7829\n",
      "Epoch 6/200\n",
      "172/172 [==============================] - 0s 845us/sample - loss: 4.2166 - accuracy: 0.7791 - val_loss: 3.4039 - val_accuracy: 0.7829\n",
      "Epoch 7/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 2.8771 - accuracy: 0.7791 - val_loss: 2.3245 - val_accuracy: 0.7829\n",
      "Epoch 8/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 1.9679 - accuracy: 0.7791 - val_loss: 1.6152 - val_accuracy: 0.7829\n",
      "Epoch 9/200\n",
      "172/172 [==============================] - 0s 823us/sample - loss: 1.4512 - accuracy: 0.7791 - val_loss: 1.3187 - val_accuracy: 0.7829\n",
      "Epoch 10/200\n",
      "172/172 [==============================] - 0s 822us/sample - loss: 1.2890 - accuracy: 0.7791 - val_loss: 1.2591 - val_accuracy: 0.7829\n",
      "Epoch 11/200\n",
      "172/172 [==============================] - 0s 825us/sample - loss: 1.2584 - accuracy: 0.7791 - val_loss: 1.2480 - val_accuracy: 0.7829\n",
      "Epoch 12/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 1.2522 - accuracy: 0.7791 - val_loss: 1.2424 - val_accuracy: 0.7829\n",
      "Epoch 13/200\n",
      "172/172 [==============================] - 0s 845us/sample - loss: 1.2421 - accuracy: 0.7791 - val_loss: 1.2500 - val_accuracy: 0.7829\n",
      "Epoch 14/200\n",
      "172/172 [==============================] - 0s 825us/sample - loss: 1.2470 - accuracy: 0.7791 - val_loss: 1.2479 - val_accuracy: 0.7829\n",
      "Epoch 15/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 1.2472 - accuracy: 0.7791 - val_loss: 1.2553 - val_accuracy: 0.7829\n",
      "Epoch 16/200\n",
      "172/172 [==============================] - 0s 970us/sample - loss: 1.2472 - accuracy: 0.7791 - val_loss: 1.2429 - val_accuracy: 0.7829\n",
      "Epoch 17/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2492 - accuracy: 0.7791 - val_loss: 1.2429 - val_accuracy: 0.7829\n",
      "Epoch 18/200\n",
      "172/172 [==============================] - 0s 837us/sample - loss: 1.2436 - accuracy: 0.7791 - val_loss: 1.2481 - val_accuracy: 0.7829\n",
      "Epoch 19/200\n",
      "172/172 [==============================] - 0s 814us/sample - loss: 1.2484 - accuracy: 0.7791 - val_loss: 1.2428 - val_accuracy: 0.7829\n",
      "Epoch 20/200\n",
      "172/172 [==============================] - 0s 844us/sample - loss: 1.2465 - accuracy: 0.7791 - val_loss: 1.2379 - val_accuracy: 0.7829\n",
      "Epoch 21/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 1.2470 - accuracy: 0.7791 - val_loss: 1.2528 - val_accuracy: 0.7829\n",
      "Epoch 22/200\n",
      "172/172 [==============================] - 0s 854us/sample - loss: 1.2467 - accuracy: 0.7791 - val_loss: 1.2420 - val_accuracy: 0.7829\n",
      "Epoch 23/200\n",
      "172/172 [==============================] - 0s 835us/sample - loss: 1.2459 - accuracy: 0.7791 - val_loss: 1.2539 - val_accuracy: 0.7829\n",
      "Epoch 24/200\n",
      "172/172 [==============================] - 0s 842us/sample - loss: 1.2482 - accuracy: 0.7791 - val_loss: 1.2425 - val_accuracy: 0.7829\n",
      "Epoch 25/200\n",
      "172/172 [==============================] - 0s 828us/sample - loss: 1.2421 - accuracy: 0.7791 - val_loss: 1.2502 - val_accuracy: 0.7829\n",
      "Epoch 26/200\n",
      "172/172 [==============================] - 0s 835us/sample - loss: 1.2504 - accuracy: 0.7791 - val_loss: 1.2393 - val_accuracy: 0.7829\n",
      "Epoch 27/200\n",
      "172/172 [==============================] - 0s 860us/sample - loss: 1.2430 - accuracy: 0.7791 - val_loss: 1.2502 - val_accuracy: 0.7829\n",
      "Epoch 28/200\n",
      "172/172 [==============================] - 0s 840us/sample - loss: 1.2484 - accuracy: 0.7791 - val_loss: 1.2427 - val_accuracy: 0.7829\n",
      "Epoch 29/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 1.2460 - accuracy: 0.7791 - val_loss: 1.2499 - val_accuracy: 0.7829\n",
      "Epoch 30/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 922us/sample - loss: 1.2429 - accuracy: 0.7791 - val_loss: 1.2466 - val_accuracy: 0.7829\n",
      "Epoch 31/200\n",
      "172/172 [==============================] - 0s 860us/sample - loss: 1.2515 - accuracy: 0.7791 - val_loss: 1.2402 - val_accuracy: 0.7829\n",
      "Epoch 32/200\n",
      "172/172 [==============================] - 0s 811us/sample - loss: 1.2463 - accuracy: 0.7791 - val_loss: 1.2412 - val_accuracy: 0.7829\n",
      "Epoch 33/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 1.2432 - accuracy: 0.7791 - val_loss: 1.2468 - val_accuracy: 0.7829\n",
      "Epoch 34/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 1.2495 - accuracy: 0.7791 - val_loss: 1.2440 - val_accuracy: 0.7829\n",
      "Epoch 35/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 1.2428 - accuracy: 0.7791 - val_loss: 1.2622 - val_accuracy: 0.7829\n",
      "Epoch 36/200\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 1.2495 - accuracy: 0.7791 - val_loss: 1.2402 - val_accuracy: 0.7829\n",
      "Epoch 37/200\n",
      "172/172 [==============================] - 0s 856us/sample - loss: 1.2450 - accuracy: 0.7791 - val_loss: 1.2536 - val_accuracy: 0.7829\n",
      "Epoch 38/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 1.2470 - accuracy: 0.7791 - val_loss: 1.2386 - val_accuracy: 0.7829\n",
      "Epoch 39/200\n",
      "172/172 [==============================] - 0s 946us/sample - loss: 1.2457 - accuracy: 0.7791 - val_loss: 1.2483 - val_accuracy: 0.7829\n",
      "Epoch 40/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 1.2490 - accuracy: 0.7791 - val_loss: 1.2405 - val_accuracy: 0.7829\n",
      "Epoch 41/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 1.2452 - accuracy: 0.7791 - val_loss: 1.2430 - val_accuracy: 0.7829\n",
      "Epoch 42/200\n",
      "172/172 [==============================] - 0s 990us/sample - loss: 1.2482 - accuracy: 0.7791 - val_loss: 1.2435 - val_accuracy: 0.7829\n",
      "Epoch 43/200\n",
      "172/172 [==============================] - 0s 960us/sample - loss: 1.2451 - accuracy: 0.7791 - val_loss: 1.2544 - val_accuracy: 0.7829\n",
      "Epoch 44/200\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 1.2473 - accuracy: 0.7791 - val_loss: 1.2495 - val_accuracy: 0.7829\n",
      "Epoch 45/200\n",
      "172/172 [==============================] - 0s 972us/sample - loss: 1.2466 - accuracy: 0.7791 - val_loss: 1.2437 - val_accuracy: 0.7829\n",
      "Epoch 46/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 1.2458 - accuracy: 0.7791 - val_loss: 1.2441 - val_accuracy: 0.7829\n",
      "Epoch 47/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 1.2504 - accuracy: 0.7791 - val_loss: 1.2469 - val_accuracy: 0.7829\n",
      "Epoch 48/200\n",
      "172/172 [==============================] - 0s 882us/sample - loss: 1.2465 - accuracy: 0.7791 - val_loss: 1.2391 - val_accuracy: 0.7829\n",
      "Epoch 49/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 1.2454 - accuracy: 0.7791 - val_loss: 1.2552 - val_accuracy: 0.7829\n",
      "Epoch 50/200\n",
      "172/172 [==============================] - 0s 976us/sample - loss: 1.2443 - accuracy: 0.7791 - val_loss: 1.2433 - val_accuracy: 0.7829\n",
      "Epoch 51/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 1.2481 - accuracy: 0.7791 - val_loss: 1.2509 - val_accuracy: 0.7829\n",
      "Epoch 52/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 1.2474 - accuracy: 0.7791 - val_loss: 1.2403 - val_accuracy: 0.7829\n",
      "Epoch 53/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 1.2422 - accuracy: 0.7791 - val_loss: 1.2484 - val_accuracy: 0.7829\n",
      "Epoch 54/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2504 - accuracy: 0.7791 - val_loss: 1.2389 - val_accuracy: 0.7829\n",
      "Epoch 55/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2401 - accuracy: 0.7791 - val_loss: 1.2489 - val_accuracy: 0.7829\n",
      "Epoch 56/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2506 - accuracy: 0.7791 - val_loss: 1.2431 - val_accuracy: 0.7829\n",
      "Epoch 57/200\n",
      "172/172 [==============================] - 0s 940us/sample - loss: 1.2464 - accuracy: 0.7791 - val_loss: 1.2515 - val_accuracy: 0.7829\n",
      "Epoch 58/200\n",
      "172/172 [==============================] - 0s 965us/sample - loss: 1.2428 - accuracy: 0.7791 - val_loss: 1.2473 - val_accuracy: 0.7829\n",
      "Epoch 59/200\n",
      "172/172 [==============================] - 0s 941us/sample - loss: 1.2508 - accuracy: 0.7791 - val_loss: 1.2431 - val_accuracy: 0.7829\n",
      "Epoch 60/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 1.2446 - accuracy: 0.7791 - val_loss: 1.2429 - val_accuracy: 0.7829\n",
      "Epoch 61/200\n",
      "172/172 [==============================] - 0s 986us/sample - loss: 1.2474 - accuracy: 0.7791 - val_loss: 1.2408 - val_accuracy: 0.7829\n",
      "Epoch 62/200\n",
      "172/172 [==============================] - 0s 958us/sample - loss: 1.2458 - accuracy: 0.7791 - val_loss: 1.2402 - val_accuracy: 0.7829\n",
      "Epoch 63/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 1.2446 - accuracy: 0.7791 - val_loss: 1.2637 - val_accuracy: 0.7829\n",
      "Epoch 64/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2487 - accuracy: 0.7791 - val_loss: 1.2428 - val_accuracy: 0.7829\n",
      "Epoch 65/200\n",
      "172/172 [==============================] - 0s 952us/sample - loss: 1.2427 - accuracy: 0.7791 - val_loss: 1.2556 - val_accuracy: 0.7829\n",
      "Epoch 66/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2512 - accuracy: 0.7791 - val_loss: 1.2369 - val_accuracy: 0.7829\n",
      "Epoch 67/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2426 - accuracy: 0.7791 - val_loss: 1.2492 - val_accuracy: 0.7829\n",
      "Epoch 68/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2500 - accuracy: 0.7791 - val_loss: 1.2375 - val_accuracy: 0.7829\n",
      "Epoch 69/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 1.2432 - accuracy: 0.7791 - val_loss: 1.2463 - val_accuracy: 0.7829\n",
      "Epoch 70/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 1.2454 - accuracy: 0.7791 - val_loss: 1.2477 - val_accuracy: 0.7829\n",
      "Epoch 71/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2500 - accuracy: 0.7791 - val_loss: 1.2468 - val_accuracy: 0.7829\n",
      "Epoch 72/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 1.2455 - accuracy: 0.7791 - val_loss: 1.2444 - val_accuracy: 0.7829\n",
      "Epoch 73/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 1.2465 - accuracy: 0.7791 - val_loss: 1.2466 - val_accuracy: 0.7829\n",
      "Epoch 74/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 1.2453 - accuracy: 0.7791 - val_loss: 1.2459 - val_accuracy: 0.7829\n",
      "Epoch 75/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 1.2436 - accuracy: 0.7791 - val_loss: 1.2464 - val_accuracy: 0.7829\n",
      "Epoch 76/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 1.2511 - accuracy: 0.7791 - val_loss: 1.2357 - val_accuracy: 0.7829\n",
      "Epoch 77/200\n",
      "172/172 [==============================] - 0s 869us/sample - loss: 1.2430 - accuracy: 0.7791 - val_loss: 1.2579 - val_accuracy: 0.7829\n",
      "Epoch 78/200\n",
      "172/172 [==============================] - 0s 974us/sample - loss: 1.2472 - accuracy: 0.7791 - val_loss: 1.2433 - val_accuracy: 0.7829\n",
      "Epoch 79/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2466 - accuracy: 0.7791 - val_loss: 1.2509 - val_accuracy: 0.7829\n",
      "Epoch 80/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2504 - accuracy: 0.7791 - val_loss: 1.2401 - val_accuracy: 0.7829\n",
      "Epoch 81/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2456 - accuracy: 0.7791 - val_loss: 1.2402 - val_accuracy: 0.7829\n",
      "Epoch 82/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2474 - accuracy: 0.7791 - val_loss: 1.2414 - val_accuracy: 0.7829\n",
      "Epoch 83/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2452 - accuracy: 0.7791 - val_loss: 1.2534 - val_accuracy: 0.7829\n",
      "Epoch 84/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2476 - accuracy: 0.7791 - val_loss: 1.2453 - val_accuracy: 0.7829\n",
      "Epoch 85/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2435 - accuracy: 0.7791 - val_loss: 1.2544 - val_accuracy: 0.7829\n",
      "Epoch 86/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2483 - accuracy: 0.7791 - val_loss: 1.2467 - val_accuracy: 0.7829\n",
      "Epoch 87/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2473 - accuracy: 0.7791 - val_loss: 1.2432 - val_accuracy: 0.7829\n",
      "Epoch 88/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2449 - accuracy: 0.7791 - val_loss: 1.2470 - val_accuracy: 0.7829\n",
      "Epoch 89/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2489 - accuracy: 0.7791 - val_loss: 1.2414 - val_accuracy: 0.7829\n",
      "Epoch 90/200\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 1.2434 - accuracy: 0.7791 - val_loss: 1.2415 - val_accuracy: 0.7829\n",
      "Epoch 91/200\n",
      "172/172 [==============================] - 0s 864us/sample - loss: 1.2481 - accuracy: 0.7791 - val_loss: 1.2562 - val_accuracy: 0.7829\n",
      "Epoch 92/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 1.2473 - accuracy: 0.7791 - val_loss: 1.2428 - val_accuracy: 0.7829\n",
      "Epoch 93/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 1.2438 - accuracy: 0.7791 - val_loss: 1.2507 - val_accuracy: 0.7829\n",
      "Epoch 94/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 1.2494 - accuracy: 0.7791 - val_loss: 1.2395 - val_accuracy: 0.7829\n",
      "Epoch 95/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 1.2432 - accuracy: 0.7791 - val_loss: 1.2538 - val_accuracy: 0.7829\n",
      "Epoch 96/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 1.2533 - accuracy: 0.7791 - val_loss: 1.2356 - val_accuracy: 0.7829\n",
      "Epoch 97/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 1.2399 - accuracy: 0.7791 - val_loss: 1.2479 - val_accuracy: 0.7829\n",
      "Epoch 98/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 1.2482 - accuracy: 0.7791 - val_loss: 1.2445 - val_accuracy: 0.7829\n",
      "Epoch 99/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 1.2470 - accuracy: 0.7791 - val_loss: 1.2464 - val_accuracy: 0.7829\n",
      "Epoch 100/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2434 - accuracy: 0.7791 - val_loss: 1.2487 - val_accuracy: 0.7829\n",
      "Epoch 101/200\n",
      "172/172 [==============================] - 0s 2ms/sample - loss: 1.2508 - accuracy: 0.7791 - val_loss: 1.2388 - val_accuracy: 0.7829\n",
      "Epoch 102/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2434 - accuracy: 0.7791 - val_loss: 1.2458 - val_accuracy: 0.7829\n",
      "Epoch 103/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2485 - accuracy: 0.7791 - val_loss: 1.2494 - val_accuracy: 0.7829\n",
      "Epoch 104/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2474 - accuracy: 0.7791 - val_loss: 1.2392 - val_accuracy: 0.7829\n",
      "Epoch 105/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2439 - accuracy: 0.7791 - val_loss: 1.2636 - val_accuracy: 0.7829\n",
      "Epoch 106/200\n",
      "172/172 [==============================] - 0s 962us/sample - loss: 1.2492 - accuracy: 0.7791 - val_loss: 1.2377 - val_accuracy: 0.7829\n",
      "Epoch 107/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 1.2437 - accuracy: 0.7791 - val_loss: 1.2553 - val_accuracy: 0.7829\n",
      "Epoch 108/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 1.2493 - accuracy: 0.7791 - val_loss: 1.2379 - val_accuracy: 0.7829\n",
      "Epoch 109/200\n",
      "172/172 [==============================] - 0s 961us/sample - loss: 1.2443 - accuracy: 0.7791 - val_loss: 1.2471 - val_accuracy: 0.7829\n",
      "Epoch 110/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2480 - accuracy: 0.7791 - val_loss: 1.2378 - val_accuracy: 0.7829\n",
      "Epoch 111/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2446 - accuracy: 0.7791 - val_loss: 1.2453 - val_accuracy: 0.7829\n",
      "Epoch 112/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2483 - accuracy: 0.7791 - val_loss: 1.2436 - val_accuracy: 0.7829\n",
      "Epoch 113/200\n",
      "172/172 [==============================] - 0s 964us/sample - loss: 1.2445 - accuracy: 0.7791 - val_loss: 1.2493 - val_accuracy: 0.7829\n",
      "Epoch 114/200\n",
      "172/172 [==============================] - 0s 858us/sample - loss: 1.2436 - accuracy: 0.7791 - val_loss: 1.2501 - val_accuracy: 0.7829\n",
      "Epoch 115/200\n",
      "172/172 [==============================] - 0s 865us/sample - loss: 1.2486 - accuracy: 0.7791 - val_loss: 1.2466 - val_accuracy: 0.7829\n",
      "Epoch 116/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 1.2496 - accuracy: 0.7791 - val_loss: 1.2412 - val_accuracy: 0.7829\n",
      "Epoch 117/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 1.2441 - accuracy: 0.7791 - val_loss: 1.2470 - val_accuracy: 0.7829\n",
      "Epoch 118/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 1.2470 - accuracy: 0.7791 - val_loss: 1.2407 - val_accuracy: 0.7829\n",
      "Epoch 119/200\n",
      "172/172 [==============================] - 0s 861us/sample - loss: 1.2442 - accuracy: 0.7791 - val_loss: 1.2550 - val_accuracy: 0.7829\n",
      "Epoch 120/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2472 - accuracy: 0.7791 - val_loss: 1.2421 - val_accuracy: 0.7829\n",
      "Epoch 121/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2466 - accuracy: 0.7791 - val_loss: 1.2484 - val_accuracy: 0.7829\n",
      "Epoch 122/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 1.2463 - accuracy: 0.7791 - val_loss: 1.2425 - val_accuracy: 0.7829\n",
      "Epoch 123/200\n",
      "172/172 [==============================] - 0s 940us/sample - loss: 1.2441 - accuracy: 0.7791 - val_loss: 1.2467 - val_accuracy: 0.7829\n",
      "Epoch 124/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2503 - accuracy: 0.7791 - val_loss: 1.2425 - val_accuracy: 0.7829\n",
      "Epoch 125/200\n",
      "172/172 [==============================] - 0s 844us/sample - loss: 1.2414 - accuracy: 0.7791 - val_loss: 1.2495 - val_accuracy: 0.7829\n",
      "Epoch 126/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 1.2485 - accuracy: 0.7791 - val_loss: 1.2410 - val_accuracy: 0.7829\n",
      "Epoch 127/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 1.2463 - accuracy: 0.7791 - val_loss: 1.2536 - val_accuracy: 0.7829\n",
      "Epoch 128/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 1.2455 - accuracy: 0.7791 - val_loss: 1.2474 - val_accuracy: 0.7829\n",
      "Epoch 129/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 1.2482 - accuracy: 0.7791 - val_loss: 1.2401 - val_accuracy: 0.7829\n",
      "Epoch 130/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 1.2431 - accuracy: 0.7791 - val_loss: 1.2446 - val_accuracy: 0.7829\n",
      "Epoch 131/200\n",
      "172/172 [==============================] - 0s 849us/sample - loss: 1.2496 - accuracy: 0.7791 - val_loss: 1.2405 - val_accuracy: 0.7829\n",
      "Epoch 132/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 1.2473 - accuracy: 0.7791 - val_loss: 1.2366 - val_accuracy: 0.7829\n",
      "Epoch 133/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 1.2423 - accuracy: 0.7791 - val_loss: 1.2586 - val_accuracy: 0.7829\n",
      "Epoch 134/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 1.2468 - accuracy: 0.7791 - val_loss: 1.2433 - val_accuracy: 0.7829\n",
      "Epoch 135/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2461 - accuracy: 0.7791 - val_loss: 1.2584 - val_accuracy: 0.7829\n",
      "Epoch 136/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2496 - accuracy: 0.7791 - val_loss: 1.2347 - val_accuracy: 0.7829\n",
      "Epoch 137/200\n",
      "172/172 [==============================] - 0s 969us/sample - loss: 1.2452 - accuracy: 0.7791 - val_loss: 1.2496 - val_accuracy: 0.7829\n",
      "Epoch 138/200\n",
      "172/172 [==============================] - 0s 949us/sample - loss: 1.2493 - accuracy: 0.7791 - val_loss: 1.2395 - val_accuracy: 0.7829\n",
      "Epoch 139/200\n",
      "172/172 [==============================] - 0s 949us/sample - loss: 1.2430 - accuracy: 0.7791 - val_loss: 1.2512 - val_accuracy: 0.7829\n",
      "Epoch 140/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 973us/sample - loss: 1.2485 - accuracy: 0.7791 - val_loss: 1.2464 - val_accuracy: 0.7829\n",
      "Epoch 141/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 1.2478 - accuracy: 0.7791 - val_loss: 1.2439 - val_accuracy: 0.7829\n",
      "Epoch 142/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 1.2426 - accuracy: 0.7791 - val_loss: 1.2471 - val_accuracy: 0.7829\n",
      "Epoch 143/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2482 - accuracy: 0.7791 - val_loss: 1.2476 - val_accuracy: 0.7829\n",
      "Epoch 144/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 1.2476 - accuracy: 0.7791 - val_loss: 1.2456 - val_accuracy: 0.7829\n",
      "Epoch 145/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 1.2427 - accuracy: 0.7791 - val_loss: 1.2461 - val_accuracy: 0.7829\n",
      "Epoch 146/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 1.2479 - accuracy: 0.7791 - val_loss: 1.2357 - val_accuracy: 0.7829\n",
      "Epoch 147/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2451 - accuracy: 0.7791 - val_loss: 1.2603 - val_accuracy: 0.7829\n",
      "Epoch 148/200\n",
      "172/172 [==============================] - 0s 966us/sample - loss: 1.2457 - accuracy: 0.7791 - val_loss: 1.2412 - val_accuracy: 0.7829\n",
      "Epoch 149/200\n",
      "172/172 [==============================] - 0s 990us/sample - loss: 1.2461 - accuracy: 0.7791 - val_loss: 1.2513 - val_accuracy: 0.7829\n",
      "Epoch 150/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 1.2461 - accuracy: 0.7791 - val_loss: 1.2400 - val_accuracy: 0.7829\n",
      "Epoch 151/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 1.2468 - accuracy: 0.7791 - val_loss: 1.2437 - val_accuracy: 0.7829\n",
      "Epoch 152/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2499 - accuracy: 0.7791 - val_loss: 1.2382 - val_accuracy: 0.7829\n",
      "Epoch 153/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 1.2404 - accuracy: 0.7791 - val_loss: 1.2485 - val_accuracy: 0.7829\n",
      "Epoch 154/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 1.2490 - accuracy: 0.7791 - val_loss: 1.2483 - val_accuracy: 0.7829\n",
      "Epoch 155/200\n",
      "172/172 [==============================] - 0s 983us/sample - loss: 1.2443 - accuracy: 0.7791 - val_loss: 1.2537 - val_accuracy: 0.7829\n",
      "Epoch 156/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 1.2466 - accuracy: 0.7791 - val_loss: 1.2453 - val_accuracy: 0.7829\n",
      "Epoch 157/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 1.2473 - accuracy: 0.7791 - val_loss: 1.2425 - val_accuracy: 0.7829\n",
      "Epoch 158/200\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 1.2436 - accuracy: 0.7791 - val_loss: 1.2474 - val_accuracy: 0.7829\n",
      "Epoch 159/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2488 - accuracy: 0.7791 - val_loss: 1.2407 - val_accuracy: 0.7829\n",
      "Epoch 160/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2460 - accuracy: 0.7791 - val_loss: 1.2389 - val_accuracy: 0.7829\n",
      "Epoch 161/200\n",
      "172/172 [==============================] - 0s 998us/sample - loss: 1.2462 - accuracy: 0.7791 - val_loss: 1.2589 - val_accuracy: 0.7829\n",
      "Epoch 162/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2474 - accuracy: 0.7791 - val_loss: 1.2422 - val_accuracy: 0.7829\n",
      "Epoch 163/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 1.2445 - accuracy: 0.7791 - val_loss: 1.2543 - val_accuracy: 0.7829\n",
      "Epoch 164/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 1.2506 - accuracy: 0.7791 - val_loss: 1.2401 - val_accuracy: 0.7829\n",
      "Epoch 165/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 1.2406 - accuracy: 0.7791 - val_loss: 1.2470 - val_accuracy: 0.7829\n",
      "Epoch 166/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 1.2518 - accuracy: 0.7791 - val_loss: 1.2422 - val_accuracy: 0.7829\n",
      "Epoch 167/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2435 - accuracy: 0.7791 - val_loss: 1.2482 - val_accuracy: 0.7829\n",
      "Epoch 168/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2450 - accuracy: 0.7791 - val_loss: 1.2417 - val_accuracy: 0.7829\n",
      "Epoch 169/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2491 - accuracy: 0.7791 - val_loss: 1.2499 - val_accuracy: 0.7829\n",
      "Epoch 170/200\n",
      "172/172 [==============================] - 0s 2ms/sample - loss: 1.2439 - accuracy: 0.7791 - val_loss: 1.2429 - val_accuracy: 0.7829\n",
      "Epoch 171/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2523 - accuracy: 0.7791 - val_loss: 1.2413 - val_accuracy: 0.7829\n",
      "Epoch 172/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2454 - accuracy: 0.7791 - val_loss: 1.2466 - val_accuracy: 0.7829\n",
      "Epoch 173/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 1.2463 - accuracy: 0.7791 - val_loss: 1.2443 - val_accuracy: 0.7829\n",
      "Epoch 174/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 1.2452 - accuracy: 0.7791 - val_loss: 1.2396 - val_accuracy: 0.7829\n",
      "Epoch 175/200\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 1.2426 - accuracy: 0.7791 - val_loss: 1.2646 - val_accuracy: 0.7829\n",
      "Epoch 176/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 1.2527 - accuracy: 0.7791 - val_loss: 1.2376 - val_accuracy: 0.7829\n",
      "Epoch 177/200\n",
      "172/172 [==============================] - 0s 944us/sample - loss: 1.2424 - accuracy: 0.7791 - val_loss: 1.2534 - val_accuracy: 0.7829\n",
      "Epoch 178/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 1.2464 - accuracy: 0.7791 - val_loss: 1.2416 - val_accuracy: 0.7829\n",
      "Epoch 179/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2465 - accuracy: 0.7791 - val_loss: 1.2467 - val_accuracy: 0.7829\n",
      "Epoch 180/200\n",
      "172/172 [==============================] - 0s 998us/sample - loss: 1.2472 - accuracy: 0.7791 - val_loss: 1.2374 - val_accuracy: 0.7829\n",
      "Epoch 181/200\n",
      "172/172 [==============================] - 0s 979us/sample - loss: 1.2450 - accuracy: 0.7791 - val_loss: 1.2440 - val_accuracy: 0.7829\n",
      "Epoch 182/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2467 - accuracy: 0.7791 - val_loss: 1.2441 - val_accuracy: 0.7829\n",
      "Epoch 183/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2448 - accuracy: 0.7791 - val_loss: 1.2552 - val_accuracy: 0.7829\n",
      "Epoch 184/200\n",
      "172/172 [==============================] - 0s 996us/sample - loss: 1.2454 - accuracy: 0.7791 - val_loss: 1.2473 - val_accuracy: 0.7829\n",
      "Epoch 185/200\n",
      "172/172 [==============================] - 0s 969us/sample - loss: 1.2465 - accuracy: 0.7791 - val_loss: 1.2437 - val_accuracy: 0.7829\n",
      "Epoch 186/200\n",
      "172/172 [==============================] - 0s 859us/sample - loss: 1.2473 - accuracy: 0.7791 - val_loss: 1.2409 - val_accuracy: 0.7829\n",
      "Epoch 187/200\n",
      "172/172 [==============================] - 0s 859us/sample - loss: 1.2464 - accuracy: 0.7791 - val_loss: 1.2451 - val_accuracy: 0.7829\n",
      "Epoch 188/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 1.2474 - accuracy: 0.7791 - val_loss: 1.2398 - val_accuracy: 0.7829\n",
      "Epoch 189/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2449 - accuracy: 0.7791 - val_loss: 1.2572 - val_accuracy: 0.7829\n",
      "Epoch 190/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 1.2448 - accuracy: 0.7791 - val_loss: 1.2412 - val_accuracy: 0.7829\n",
      "Epoch 191/200\n",
      "172/172 [==============================] - 0s 860us/sample - loss: 1.2475 - accuracy: 0.7791 - val_loss: 1.2473 - val_accuracy: 0.7829\n",
      "Epoch 192/200\n",
      "172/172 [==============================] - 0s 864us/sample - loss: 1.2487 - accuracy: 0.7791 - val_loss: 1.2392 - val_accuracy: 0.7829\n",
      "Epoch 193/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 1.2430 - accuracy: 0.7791 - val_loss: 1.2496 - val_accuracy: 0.7829\n",
      "Epoch 194/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2493 - accuracy: 0.7791 - val_loss: 1.2425 - val_accuracy: 0.7829\n",
      "Epoch 195/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 962us/sample - loss: 1.2407 - accuracy: 0.7791 - val_loss: 1.2525 - val_accuracy: 0.7829\n",
      "Epoch 196/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 1.2514 - accuracy: 0.7791 - val_loss: 1.2405 - val_accuracy: 0.7829\n",
      "Epoch 197/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 1.2428 - accuracy: 0.7791 - val_loss: 1.2495 - val_accuracy: 0.7829\n",
      "Epoch 198/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2475 - accuracy: 0.7791 - val_loss: 1.2482 - val_accuracy: 0.7829\n",
      "Epoch 199/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 1.2494 - accuracy: 0.7791 - val_loss: 1.2400 - val_accuracy: 0.7829\n",
      "Epoch 200/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 1.2425 - accuracy: 0.7791 - val_loss: 1.2485 - val_accuracy: 0.7829\n",
      "Beginning training for dr=0.001, l_lambda=1.0e-01, reg_type=l1, act: tanh\n",
      "Train on 172 samples, validate on 43 samples\n",
      "Epoch 1/200\n",
      "172/172 [==============================] - 1s 8ms/sample - loss: 71.3528 - accuracy: 0.6667 - val_loss: 36.0115 - val_accuracy: 0.6667\n",
      "Epoch 2/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 23.3918 - accuracy: 0.7248 - val_loss: 16.7018 - val_accuracy: 0.7829\n",
      "Epoch 3/200\n",
      "172/172 [==============================] - 0s 813us/sample - loss: 13.1170 - accuracy: 0.7791 - val_loss: 10.0858 - val_accuracy: 0.7829\n",
      "Epoch 4/200\n",
      "172/172 [==============================] - 0s 843us/sample - loss: 8.5663 - accuracy: 0.7791 - val_loss: 7.0316 - val_accuracy: 0.7829\n",
      "Epoch 5/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 6.0865 - accuracy: 0.7791 - val_loss: 5.0501 - val_accuracy: 0.7829\n",
      "Epoch 6/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 4.3250 - accuracy: 0.7791 - val_loss: 3.5181 - val_accuracy: 0.7829\n",
      "Epoch 7/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 2.9893 - accuracy: 0.7791 - val_loss: 2.4229 - val_accuracy: 0.7829\n",
      "Epoch 8/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 2.0435 - accuracy: 0.7791 - val_loss: 1.6623 - val_accuracy: 0.7829\n",
      "Epoch 9/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.4754 - accuracy: 0.7791 - val_loss: 1.3263 - val_accuracy: 0.7829\n",
      "Epoch 10/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2944 - accuracy: 0.7791 - val_loss: 1.2595 - val_accuracy: 0.7829\n",
      "Epoch 11/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2579 - accuracy: 0.7791 - val_loss: 1.2512 - val_accuracy: 0.7829\n",
      "Epoch 12/200\n",
      "172/172 [==============================] - 0s 981us/sample - loss: 1.2519 - accuracy: 0.7791 - val_loss: 1.2404 - val_accuracy: 0.7829\n",
      "Epoch 13/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 1.2423 - accuracy: 0.7791 - val_loss: 1.2519 - val_accuracy: 0.7829\n",
      "Epoch 14/200\n",
      "172/172 [==============================] - 0s 842us/sample - loss: 1.2459 - accuracy: 0.7791 - val_loss: 1.2526 - val_accuracy: 0.7829\n",
      "Epoch 15/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2458 - accuracy: 0.7791 - val_loss: 1.2548 - val_accuracy: 0.7829\n",
      "Epoch 16/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 1.2483 - accuracy: 0.7791 - val_loss: 1.2479 - val_accuracy: 0.7829\n",
      "Epoch 17/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 1.2476 - accuracy: 0.7791 - val_loss: 1.2403 - val_accuracy: 0.7829\n",
      "Epoch 18/200\n",
      "172/172 [==============================] - 0s 957us/sample - loss: 1.2445 - accuracy: 0.7791 - val_loss: 1.2540 - val_accuracy: 0.7829\n",
      "Epoch 19/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 1.2485 - accuracy: 0.7791 - val_loss: 1.2423 - val_accuracy: 0.7829\n",
      "Epoch 20/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 1.2454 - accuracy: 0.7791 - val_loss: 1.2353 - val_accuracy: 0.7829\n",
      "Epoch 21/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 1.2460 - accuracy: 0.7791 - val_loss: 1.2489 - val_accuracy: 0.7829\n",
      "Epoch 22/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2493 - accuracy: 0.7791 - val_loss: 1.2445 - val_accuracy: 0.7829\n",
      "Epoch 23/200\n",
      "172/172 [==============================] - 0s 965us/sample - loss: 1.2468 - accuracy: 0.7791 - val_loss: 1.2576 - val_accuracy: 0.7829\n",
      "Epoch 24/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 1.2463 - accuracy: 0.7791 - val_loss: 1.2432 - val_accuracy: 0.7829\n",
      "Epoch 25/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 1.2429 - accuracy: 0.7791 - val_loss: 1.2515 - val_accuracy: 0.7829\n",
      "Epoch 26/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 1.2500 - accuracy: 0.7791 - val_loss: 1.2428 - val_accuracy: 0.7829\n",
      "Epoch 27/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 1.2424 - accuracy: 0.7791 - val_loss: 1.2467 - val_accuracy: 0.7829\n",
      "Epoch 28/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2478 - accuracy: 0.7791 - val_loss: 1.2453 - val_accuracy: 0.7829\n",
      "Epoch 29/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2441 - accuracy: 0.7791 - val_loss: 1.2515 - val_accuracy: 0.7829\n",
      "Epoch 30/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2429 - accuracy: 0.7791 - val_loss: 1.2471 - val_accuracy: 0.7829\n",
      "Epoch 31/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2521 - accuracy: 0.7791 - val_loss: 1.2419 - val_accuracy: 0.7829\n",
      "Epoch 32/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2448 - accuracy: 0.7791 - val_loss: 1.2404 - val_accuracy: 0.7829\n",
      "Epoch 33/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2431 - accuracy: 0.7791 - val_loss: 1.2459 - val_accuracy: 0.7829\n",
      "Epoch 34/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2451 - accuracy: 0.7791 - val_loss: 1.2453 - val_accuracy: 0.7829\n",
      "Epoch 35/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2425 - accuracy: 0.7791 - val_loss: 1.2569 - val_accuracy: 0.7829\n",
      "Epoch 36/200\n",
      "172/172 [==============================] - 0s 947us/sample - loss: 1.2468 - accuracy: 0.7791 - val_loss: 1.2449 - val_accuracy: 0.7829\n",
      "Epoch 37/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2433 - accuracy: 0.7791 - val_loss: 1.2496 - val_accuracy: 0.7829\n",
      "Epoch 38/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2459 - accuracy: 0.7791 - val_loss: 1.2433 - val_accuracy: 0.7829\n",
      "Epoch 39/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2446 - accuracy: 0.7791 - val_loss: 1.2491 - val_accuracy: 0.7829\n",
      "Epoch 40/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2480 - accuracy: 0.7791 - val_loss: 1.2352 - val_accuracy: 0.7829\n",
      "Epoch 41/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2443 - accuracy: 0.7791 - val_loss: 1.2422 - val_accuracy: 0.7829\n",
      "Epoch 42/200\n",
      "172/172 [==============================] - 0s 985us/sample - loss: 1.2456 - accuracy: 0.7791 - val_loss: 1.2422 - val_accuracy: 0.7829\n",
      "Epoch 43/200\n",
      "172/172 [==============================] - 0s 989us/sample - loss: 1.2445 - accuracy: 0.7791 - val_loss: 1.2536 - val_accuracy: 0.7829\n",
      "Epoch 44/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2463 - accuracy: 0.7791 - val_loss: 1.2493 - val_accuracy: 0.7829\n",
      "Epoch 45/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2449 - accuracy: 0.7791 - val_loss: 1.2406 - val_accuracy: 0.7829\n",
      "Epoch 46/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2424 - accuracy: 0.7791 - val_loss: 1.2505 - val_accuracy: 0.7829\n",
      "Epoch 47/200\n",
      "172/172 [==============================] - 0s 941us/sample - loss: 1.2487 - accuracy: 0.7791 - val_loss: 1.2445 - val_accuracy: 0.7829\n",
      "Epoch 48/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2452 - accuracy: 0.7791 - val_loss: 1.2414 - val_accuracy: 0.7829\n",
      "Epoch 49/200\n",
      "172/172 [==============================] - 0s 963us/sample - loss: 1.2457 - accuracy: 0.7791 - val_loss: 1.2551 - val_accuracy: 0.7829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 1.2458 - accuracy: 0.7791 - val_loss: 1.2466 - val_accuracy: 0.7829\n",
      "Epoch 51/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 1.2495 - accuracy: 0.7791 - val_loss: 1.2518 - val_accuracy: 0.7829\n",
      "Epoch 52/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 1.2474 - accuracy: 0.7791 - val_loss: 1.2383 - val_accuracy: 0.7829\n",
      "Epoch 53/200\n",
      "172/172 [==============================] - 0s 848us/sample - loss: 1.2420 - accuracy: 0.7791 - val_loss: 1.2500 - val_accuracy: 0.7829\n",
      "Epoch 54/200\n",
      "172/172 [==============================] - 0s 978us/sample - loss: 1.2487 - accuracy: 0.7791 - val_loss: 1.2420 - val_accuracy: 0.7829\n",
      "Epoch 55/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2396 - accuracy: 0.7791 - val_loss: 1.2463 - val_accuracy: 0.7829\n",
      "Epoch 56/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2488 - accuracy: 0.7791 - val_loss: 1.2451 - val_accuracy: 0.7829\n",
      "Epoch 57/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2465 - accuracy: 0.7791 - val_loss: 1.2505 - val_accuracy: 0.7829\n",
      "Epoch 58/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 1.2411 - accuracy: 0.7791 - val_loss: 1.2523 - val_accuracy: 0.7829\n",
      "Epoch 59/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 1.2492 - accuracy: 0.7791 - val_loss: 1.2426 - val_accuracy: 0.7829\n",
      "Epoch 60/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 1.2430 - accuracy: 0.7791 - val_loss: 1.2387 - val_accuracy: 0.7829\n",
      "Epoch 61/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 1.2473 - accuracy: 0.7791 - val_loss: 1.2408 - val_accuracy: 0.7829\n",
      "Epoch 62/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 1.2451 - accuracy: 0.7791 - val_loss: 1.2386 - val_accuracy: 0.7829\n",
      "Epoch 63/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 1.2448 - accuracy: 0.7791 - val_loss: 1.2604 - val_accuracy: 0.7829\n",
      "Epoch 64/200\n",
      "172/172 [==============================] - 0s 869us/sample - loss: 1.2468 - accuracy: 0.7791 - val_loss: 1.2433 - val_accuracy: 0.7829\n",
      "Epoch 65/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 1.2417 - accuracy: 0.7791 - val_loss: 1.2510 - val_accuracy: 0.7829\n",
      "Epoch 66/200\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 1.2483 - accuracy: 0.7791 - val_loss: 1.2409 - val_accuracy: 0.7829\n",
      "Epoch 67/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 1.2416 - accuracy: 0.7791 - val_loss: 1.2491 - val_accuracy: 0.7829\n",
      "Epoch 68/200\n",
      "172/172 [==============================] - 0s 978us/sample - loss: 1.2490 - accuracy: 0.7791 - val_loss: 1.2395 - val_accuracy: 0.7829\n",
      "Epoch 69/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 1.2439 - accuracy: 0.7791 - val_loss: 1.2464 - val_accuracy: 0.7829\n",
      "Epoch 70/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 1.2440 - accuracy: 0.7791 - val_loss: 1.2475 - val_accuracy: 0.7829\n",
      "Epoch 71/200\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 1.2498 - accuracy: 0.7791 - val_loss: 1.2477 - val_accuracy: 0.7829\n",
      "Epoch 72/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 1.2434 - accuracy: 0.7791 - val_loss: 1.2435 - val_accuracy: 0.7829\n",
      "Epoch 73/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 1.2462 - accuracy: 0.7791 - val_loss: 1.2462 - val_accuracy: 0.7829\n",
      "Epoch 74/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 1.2467 - accuracy: 0.7791 - val_loss: 1.2495 - val_accuracy: 0.7829\n",
      "Epoch 75/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 1.2432 - accuracy: 0.7791 - val_loss: 1.2438 - val_accuracy: 0.7829\n",
      "Epoch 76/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 1.2480 - accuracy: 0.7791 - val_loss: 1.2362 - val_accuracy: 0.7829\n",
      "Epoch 77/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 1.2423 - accuracy: 0.7791 - val_loss: 1.2526 - val_accuracy: 0.7829\n",
      "Epoch 78/200\n",
      "172/172 [==============================] - 0s 861us/sample - loss: 1.2448 - accuracy: 0.7791 - val_loss: 1.2493 - val_accuracy: 0.7829\n",
      "Epoch 79/200\n",
      "172/172 [==============================] - 0s 859us/sample - loss: 1.2450 - accuracy: 0.7791 - val_loss: 1.2515 - val_accuracy: 0.7829\n",
      "Epoch 80/200\n",
      "172/172 [==============================] - 0s 857us/sample - loss: 1.2468 - accuracy: 0.7791 - val_loss: 1.2367 - val_accuracy: 0.7829\n",
      "Epoch 81/200\n",
      "172/172 [==============================] - 0s 947us/sample - loss: 1.2445 - accuracy: 0.7791 - val_loss: 1.2423 - val_accuracy: 0.7829\n",
      "Epoch 82/200\n",
      "172/172 [==============================] - 0s 928us/sample - loss: 1.2456 - accuracy: 0.7791 - val_loss: 1.2389 - val_accuracy: 0.7829\n",
      "Epoch 83/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 1.2445 - accuracy: 0.7791 - val_loss: 1.2523 - val_accuracy: 0.7829\n",
      "Epoch 84/200\n",
      "172/172 [==============================] - 0s 862us/sample - loss: 1.2450 - accuracy: 0.7791 - val_loss: 1.2483 - val_accuracy: 0.7829\n",
      "Epoch 85/200\n",
      "172/172 [==============================] - 0s 853us/sample - loss: 1.2438 - accuracy: 0.7791 - val_loss: 1.2516 - val_accuracy: 0.7829\n",
      "Epoch 86/200\n",
      "172/172 [==============================] - 0s 857us/sample - loss: 1.2461 - accuracy: 0.7791 - val_loss: 1.2488 - val_accuracy: 0.7829\n",
      "Epoch 87/200\n",
      "172/172 [==============================] - 0s 860us/sample - loss: 1.2460 - accuracy: 0.7791 - val_loss: 1.2397 - val_accuracy: 0.7829\n",
      "Epoch 88/200\n",
      "172/172 [==============================] - 0s 857us/sample - loss: 1.2443 - accuracy: 0.7791 - val_loss: 1.2498 - val_accuracy: 0.7829\n",
      "Epoch 89/200\n",
      "172/172 [==============================] - 0s 858us/sample - loss: 1.2474 - accuracy: 0.7791 - val_loss: 1.2400 - val_accuracy: 0.7829\n",
      "Epoch 90/200\n",
      "172/172 [==============================] - 0s 864us/sample - loss: 1.2412 - accuracy: 0.7791 - val_loss: 1.2375 - val_accuracy: 0.7829\n",
      "Epoch 91/200\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 1.2477 - accuracy: 0.7791 - val_loss: 1.2550 - val_accuracy: 0.7829\n",
      "Epoch 92/200\n",
      "172/172 [==============================] - 0s 862us/sample - loss: 1.2455 - accuracy: 0.7791 - val_loss: 1.2429 - val_accuracy: 0.7829\n",
      "Epoch 93/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 1.2436 - accuracy: 0.7791 - val_loss: 1.2552 - val_accuracy: 0.7829\n",
      "Epoch 94/200\n",
      "172/172 [==============================] - 0s 957us/sample - loss: 1.2461 - accuracy: 0.7791 - val_loss: 1.2428 - val_accuracy: 0.7829\n",
      "Epoch 95/200\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 1.2417 - accuracy: 0.7791 - val_loss: 1.2520 - val_accuracy: 0.7829\n",
      "Epoch 96/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 1.2517 - accuracy: 0.7791 - val_loss: 1.2356 - val_accuracy: 0.7829\n",
      "Epoch 97/200\n",
      "172/172 [==============================] - 0s 861us/sample - loss: 1.2391 - accuracy: 0.7791 - val_loss: 1.2436 - val_accuracy: 0.7829\n",
      "Epoch 98/200\n",
      "172/172 [==============================] - 0s 858us/sample - loss: 1.2485 - accuracy: 0.7791 - val_loss: 1.2512 - val_accuracy: 0.7829\n",
      "Epoch 99/200\n",
      "172/172 [==============================] - 0s 857us/sample - loss: 1.2465 - accuracy: 0.7791 - val_loss: 1.2471 - val_accuracy: 0.7829\n",
      "Epoch 100/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 1.2428 - accuracy: 0.7791 - val_loss: 1.2465 - val_accuracy: 0.7829\n",
      "Epoch 101/200\n",
      "172/172 [==============================] - 0s 862us/sample - loss: 1.2495 - accuracy: 0.7791 - val_loss: 1.2410 - val_accuracy: 0.7829\n",
      "Epoch 102/200\n",
      "172/172 [==============================] - 0s 856us/sample - loss: 1.2424 - accuracy: 0.7791 - val_loss: 1.2465 - val_accuracy: 0.7829\n",
      "Epoch 103/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 1.2463 - accuracy: 0.7791 - val_loss: 1.2494 - val_accuracy: 0.7829\n",
      "Epoch 104/200\n",
      "172/172 [==============================] - 0s 860us/sample - loss: 1.2448 - accuracy: 0.7791 - val_loss: 1.2381 - val_accuracy: 0.7829\n",
      "Epoch 105/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 862us/sample - loss: 1.2421 - accuracy: 0.7791 - val_loss: 1.2574 - val_accuracy: 0.7829\n",
      "Epoch 106/200\n",
      "172/172 [==============================] - 0s 859us/sample - loss: 1.2472 - accuracy: 0.7791 - val_loss: 1.2447 - val_accuracy: 0.7829\n",
      "Epoch 107/200\n",
      "172/172 [==============================] - 0s 945us/sample - loss: 1.2442 - accuracy: 0.7791 - val_loss: 1.2534 - val_accuracy: 0.7829\n",
      "Epoch 108/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 1.2501 - accuracy: 0.7791 - val_loss: 1.2378 - val_accuracy: 0.7829\n",
      "Epoch 109/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 1.2426 - accuracy: 0.7791 - val_loss: 1.2473 - val_accuracy: 0.7829\n",
      "Epoch 110/200\n",
      "172/172 [==============================] - 0s 853us/sample - loss: 1.2466 - accuracy: 0.7791 - val_loss: 1.2369 - val_accuracy: 0.7829\n",
      "Epoch 111/200\n",
      "172/172 [==============================] - 0s 845us/sample - loss: 1.2436 - accuracy: 0.7791 - val_loss: 1.2464 - val_accuracy: 0.7829\n",
      "Epoch 112/200\n",
      "172/172 [==============================] - 0s 850us/sample - loss: 1.2458 - accuracy: 0.7791 - val_loss: 1.2420 - val_accuracy: 0.7829\n",
      "Epoch 113/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 1.2438 - accuracy: 0.7791 - val_loss: 1.2519 - val_accuracy: 0.7829\n",
      "Epoch 114/200\n",
      "172/172 [==============================] - 0s 853us/sample - loss: 1.2422 - accuracy: 0.7791 - val_loss: 1.2546 - val_accuracy: 0.7829\n",
      "Epoch 115/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 1.2465 - accuracy: 0.7791 - val_loss: 1.2446 - val_accuracy: 0.7829\n",
      "Epoch 116/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 1.2445 - accuracy: 0.7791 - val_loss: 1.2459 - val_accuracy: 0.7829\n",
      "Epoch 117/200\n",
      "172/172 [==============================] - 0s 853us/sample - loss: 1.2433 - accuracy: 0.7791 - val_loss: 1.2429 - val_accuracy: 0.7829\n",
      "Epoch 118/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 1.2450 - accuracy: 0.7791 - val_loss: 1.2437 - val_accuracy: 0.7829\n",
      "Epoch 119/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 1.2451 - accuracy: 0.7791 - val_loss: 1.2517 - val_accuracy: 0.7829\n",
      "Epoch 120/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 1.2467 - accuracy: 0.7791 - val_loss: 1.2403 - val_accuracy: 0.7829\n",
      "Epoch 121/200\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 1.2462 - accuracy: 0.7791 - val_loss: 1.2469 - val_accuracy: 0.7829\n",
      "Epoch 122/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 1.2445 - accuracy: 0.7791 - val_loss: 1.2413 - val_accuracy: 0.7829\n",
      "Epoch 123/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 1.2427 - accuracy: 0.7791 - val_loss: 1.2484 - val_accuracy: 0.7829\n",
      "Epoch 124/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 1.2489 - accuracy: 0.7791 - val_loss: 1.2428 - val_accuracy: 0.7829\n",
      "Epoch 125/200\n",
      "172/172 [==============================] - 0s 848us/sample - loss: 1.2422 - accuracy: 0.7791 - val_loss: 1.2488 - val_accuracy: 0.7829\n",
      "Epoch 126/200\n",
      "172/172 [==============================] - 0s 856us/sample - loss: 1.2463 - accuracy: 0.7791 - val_loss: 1.2456 - val_accuracy: 0.7829\n",
      "Epoch 127/200\n",
      "172/172 [==============================] - 0s 849us/sample - loss: 1.2441 - accuracy: 0.7791 - val_loss: 1.2525 - val_accuracy: 0.7829\n",
      "Epoch 128/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 1.2449 - accuracy: 0.7791 - val_loss: 1.2490 - val_accuracy: 0.7829\n",
      "Epoch 129/200\n",
      "172/172 [==============================] - 0s 869us/sample - loss: 1.2458 - accuracy: 0.7791 - val_loss: 1.2393 - val_accuracy: 0.7829\n",
      "Epoch 130/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 1.2404 - accuracy: 0.7791 - val_loss: 1.2445 - val_accuracy: 0.7829\n",
      "Epoch 131/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 1.2511 - accuracy: 0.7791 - val_loss: 1.2416 - val_accuracy: 0.7829\n",
      "Epoch 132/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 1.2457 - accuracy: 0.7791 - val_loss: 1.2368 - val_accuracy: 0.7829\n",
      "Epoch 133/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 1.2420 - accuracy: 0.7791 - val_loss: 1.2560 - val_accuracy: 0.7829\n",
      "Epoch 134/200\n",
      "172/172 [==============================] - 0s 976us/sample - loss: 1.2453 - accuracy: 0.7791 - val_loss: 1.2487 - val_accuracy: 0.7829\n",
      "Epoch 135/200\n",
      "172/172 [==============================] - 0s 948us/sample - loss: 1.2437 - accuracy: 0.7791 - val_loss: 1.2586 - val_accuracy: 0.7829\n",
      "Epoch 136/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 1.2483 - accuracy: 0.7791 - val_loss: 1.2349 - val_accuracy: 0.7829\n",
      "Epoch 137/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 1.2417 - accuracy: 0.7791 - val_loss: 1.2476 - val_accuracy: 0.7829\n",
      "Epoch 138/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 1.2465 - accuracy: 0.7791 - val_loss: 1.2422 - val_accuracy: 0.7829\n",
      "Epoch 139/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 1.2406 - accuracy: 0.7791 - val_loss: 1.2491 - val_accuracy: 0.7829\n",
      "Epoch 140/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 1.2460 - accuracy: 0.7791 - val_loss: 1.2420 - val_accuracy: 0.7829\n",
      "Epoch 141/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 1.2495 - accuracy: 0.7791 - val_loss: 1.2439 - val_accuracy: 0.7829\n",
      "Epoch 142/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 1.2437 - accuracy: 0.7791 - val_loss: 1.2488 - val_accuracy: 0.7829\n",
      "Epoch 143/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 1.2481 - accuracy: 0.7791 - val_loss: 1.2491 - val_accuracy: 0.7829\n",
      "Epoch 144/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 1.2445 - accuracy: 0.7791 - val_loss: 1.2455 - val_accuracy: 0.7829\n",
      "Epoch 145/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 1.2430 - accuracy: 0.7791 - val_loss: 1.2440 - val_accuracy: 0.7829\n",
      "Epoch 146/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 1.2456 - accuracy: 0.7791 - val_loss: 1.2406 - val_accuracy: 0.7829\n",
      "Epoch 147/200\n",
      "172/172 [==============================] - 0s 946us/sample - loss: 1.2446 - accuracy: 0.7791 - val_loss: 1.2521 - val_accuracy: 0.7829\n",
      "Epoch 148/200\n",
      "172/172 [==============================] - 0s 953us/sample - loss: 1.2444 - accuracy: 0.7791 - val_loss: 1.2464 - val_accuracy: 0.7829\n",
      "Epoch 149/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 1.2443 - accuracy: 0.7791 - val_loss: 1.2516 - val_accuracy: 0.7829\n",
      "Epoch 150/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 1.2450 - accuracy: 0.7791 - val_loss: 1.2390 - val_accuracy: 0.7829\n",
      "Epoch 151/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 1.2442 - accuracy: 0.7791 - val_loss: 1.2419 - val_accuracy: 0.7829\n",
      "Epoch 152/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 1.2484 - accuracy: 0.7791 - val_loss: 1.2337 - val_accuracy: 0.7829\n",
      "Epoch 153/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 1.2412 - accuracy: 0.7791 - val_loss: 1.2481 - val_accuracy: 0.7829\n",
      "Epoch 154/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 1.2461 - accuracy: 0.7791 - val_loss: 1.2512 - val_accuracy: 0.7829\n",
      "Epoch 155/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 1.2439 - accuracy: 0.7791 - val_loss: 1.2523 - val_accuracy: 0.7829\n",
      "Epoch 156/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 1.2445 - accuracy: 0.7791 - val_loss: 1.2478 - val_accuracy: 0.7829\n",
      "Epoch 157/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 1.2468 - accuracy: 0.7791 - val_loss: 1.2402 - val_accuracy: 0.7829\n",
      "Epoch 158/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 1.2424 - accuracy: 0.7791 - val_loss: 1.2509 - val_accuracy: 0.7829\n",
      "Epoch 159/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 1.2473 - accuracy: 0.7791 - val_loss: 1.2399 - val_accuracy: 0.7829\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 968us/sample - loss: 1.2450 - accuracy: 0.7791 - val_loss: 1.2347 - val_accuracy: 0.7829\n",
      "Epoch 161/200\n",
      "172/172 [==============================] - 0s 949us/sample - loss: 1.2449 - accuracy: 0.7791 - val_loss: 1.2524 - val_accuracy: 0.7829\n",
      "Epoch 162/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 1.2445 - accuracy: 0.7791 - val_loss: 1.2436 - val_accuracy: 0.7829\n",
      "Epoch 163/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 1.2489 - accuracy: 0.7791 - val_loss: 1.2573 - val_accuracy: 0.7829\n",
      "Epoch 164/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 1.2489 - accuracy: 0.7791 - val_loss: 1.2393 - val_accuracy: 0.7829\n",
      "Epoch 165/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 1.2404 - accuracy: 0.7791 - val_loss: 1.2470 - val_accuracy: 0.7829\n",
      "Epoch 166/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 1.2498 - accuracy: 0.7791 - val_loss: 1.2464 - val_accuracy: 0.7829\n",
      "Epoch 167/200\n",
      "172/172 [==============================] - 0s 869us/sample - loss: 1.2409 - accuracy: 0.7791 - val_loss: 1.2473 - val_accuracy: 0.7829\n",
      "Epoch 168/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 1.2443 - accuracy: 0.7791 - val_loss: 1.2460 - val_accuracy: 0.7829\n",
      "Epoch 169/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 1.2458 - accuracy: 0.7791 - val_loss: 1.2507 - val_accuracy: 0.7829\n",
      "Epoch 170/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 1.2414 - accuracy: 0.7791 - val_loss: 1.2433 - val_accuracy: 0.7829\n",
      "Epoch 171/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 1.2493 - accuracy: 0.7791 - val_loss: 1.2425 - val_accuracy: 0.7829\n",
      "Epoch 172/200\n",
      "172/172 [==============================] - 0s 940us/sample - loss: 1.2418 - accuracy: 0.7791 - val_loss: 1.2438 - val_accuracy: 0.7829\n",
      "Epoch 173/200\n",
      "172/172 [==============================] - 0s 972us/sample - loss: 1.2465 - accuracy: 0.7791 - val_loss: 1.2430 - val_accuracy: 0.7829\n",
      "Epoch 174/200\n",
      "172/172 [==============================] - 0s 949us/sample - loss: 1.2435 - accuracy: 0.7791 - val_loss: 1.2404 - val_accuracy: 0.7829\n",
      "Epoch 175/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 1.2416 - accuracy: 0.7791 - val_loss: 1.2555 - val_accuracy: 0.7829\n",
      "Epoch 176/200\n",
      "172/172 [==============================] - 0s 854us/sample - loss: 1.2485 - accuracy: 0.7791 - val_loss: 1.2422 - val_accuracy: 0.7829\n",
      "Epoch 177/200\n",
      "172/172 [==============================] - 0s 849us/sample - loss: 1.2414 - accuracy: 0.7791 - val_loss: 1.2500 - val_accuracy: 0.7829\n",
      "Epoch 178/200\n",
      "172/172 [==============================] - 0s 856us/sample - loss: 1.2453 - accuracy: 0.7791 - val_loss: 1.2441 - val_accuracy: 0.7829\n",
      "Epoch 179/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 1.2447 - accuracy: 0.7791 - val_loss: 1.2483 - val_accuracy: 0.7829\n",
      "Epoch 180/200\n",
      "172/172 [==============================] - 0s 848us/sample - loss: 1.2462 - accuracy: 0.7791 - val_loss: 1.2339 - val_accuracy: 0.7829\n",
      "Epoch 181/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 1.2435 - accuracy: 0.7791 - val_loss: 1.2434 - val_accuracy: 0.7829\n",
      "Epoch 182/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 1.2443 - accuracy: 0.7791 - val_loss: 1.2455 - val_accuracy: 0.7829\n",
      "Epoch 183/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 1.2450 - accuracy: 0.7791 - val_loss: 1.2566 - val_accuracy: 0.7829\n",
      "Epoch 184/200\n",
      "172/172 [==============================] - 0s 856us/sample - loss: 1.2448 - accuracy: 0.7791 - val_loss: 1.2478 - val_accuracy: 0.7829\n",
      "Epoch 185/200\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 1.2449 - accuracy: 0.7791 - val_loss: 1.2409 - val_accuracy: 0.7829\n",
      "Epoch 186/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 1.2443 - accuracy: 0.7791 - val_loss: 1.2474 - val_accuracy: 0.7829\n",
      "Epoch 187/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 1.2438 - accuracy: 0.7791 - val_loss: 1.2415 - val_accuracy: 0.7829\n",
      "Epoch 188/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 1.2447 - accuracy: 0.7791 - val_loss: 1.2408 - val_accuracy: 0.7829\n",
      "Epoch 189/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 1.2435 - accuracy: 0.7791 - val_loss: 1.2545 - val_accuracy: 0.7829\n",
      "Epoch 190/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 1.2433 - accuracy: 0.7791 - val_loss: 1.2425 - val_accuracy: 0.7829\n",
      "Epoch 191/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 1.2472 - accuracy: 0.7791 - val_loss: 1.2491 - val_accuracy: 0.7829\n",
      "Epoch 192/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 1.2471 - accuracy: 0.7791 - val_loss: 1.2360 - val_accuracy: 0.7829\n",
      "Epoch 193/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 1.2417 - accuracy: 0.7791 - val_loss: 1.2521 - val_accuracy: 0.7829\n",
      "Epoch 194/200\n",
      "172/172 [==============================] - 0s 856us/sample - loss: 1.2464 - accuracy: 0.7791 - val_loss: 1.2462 - val_accuracy: 0.7829\n",
      "Epoch 195/200\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 1.2409 - accuracy: 0.7791 - val_loss: 1.2509 - val_accuracy: 0.7829\n",
      "Epoch 196/200\n",
      "172/172 [==============================] - 0s 853us/sample - loss: 1.2482 - accuracy: 0.7791 - val_loss: 1.2420 - val_accuracy: 0.7829\n",
      "Epoch 197/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 1.2433 - accuracy: 0.7791 - val_loss: 1.2439 - val_accuracy: 0.7829\n",
      "Epoch 198/200\n",
      "172/172 [==============================] - 0s 849us/sample - loss: 1.2433 - accuracy: 0.7791 - val_loss: 1.2508 - val_accuracy: 0.7829\n",
      "Epoch 199/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 1.2480 - accuracy: 0.7791 - val_loss: 1.2411 - val_accuracy: 0.7829\n",
      "Epoch 200/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 1.2413 - accuracy: 0.7791 - val_loss: 1.2460 - val_accuracy: 0.7829\n",
      "Beginning training for dr=0.010, l_lambda=1.0e-03, reg_type=l2, act: relu\n",
      "Train on 172 samples, validate on 43 samples\n",
      "Epoch 1/200\n",
      "172/172 [==============================] - 1s 7ms/sample - loss: 0.6494 - accuracy: 0.6667 - val_loss: 0.6216 - val_accuracy: 0.6667\n",
      "Epoch 2/200\n",
      "172/172 [==============================] - 0s 809us/sample - loss: 0.5990 - accuracy: 0.6667 - val_loss: 0.5706 - val_accuracy: 0.6667\n",
      "Epoch 3/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 0.5549 - accuracy: 0.7190 - val_loss: 0.5324 - val_accuracy: 0.7829\n",
      "Epoch 4/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 0.5248 - accuracy: 0.7791 - val_loss: 0.5121 - val_accuracy: 0.7829\n",
      "Epoch 5/200\n",
      "172/172 [==============================] - 0s 928us/sample - loss: 0.5157 - accuracy: 0.7791 - val_loss: 0.5085 - val_accuracy: 0.7829\n",
      "Epoch 6/200\n",
      "172/172 [==============================] - 0s 848us/sample - loss: 0.5156 - accuracy: 0.7791 - val_loss: 0.5068 - val_accuracy: 0.7829\n",
      "Epoch 7/200\n",
      "172/172 [==============================] - 0s 832us/sample - loss: 0.5130 - accuracy: 0.7791 - val_loss: 0.5058 - val_accuracy: 0.7829\n",
      "Epoch 8/200\n",
      "172/172 [==============================] - 0s 830us/sample - loss: 0.5136 - accuracy: 0.7791 - val_loss: 0.5049 - val_accuracy: 0.7829\n",
      "Epoch 9/200\n",
      "172/172 [==============================] - 0s 819us/sample - loss: 0.5113 - accuracy: 0.7791 - val_loss: 0.5042 - val_accuracy: 0.7829\n",
      "Epoch 10/200\n",
      "172/172 [==============================] - 0s 831us/sample - loss: 0.5106 - accuracy: 0.7791 - val_loss: 0.5037 - val_accuracy: 0.7829\n",
      "Epoch 11/200\n",
      "172/172 [==============================] - 0s 826us/sample - loss: 0.5102 - accuracy: 0.7791 - val_loss: 0.5035 - val_accuracy: 0.7829\n",
      "Epoch 12/200\n",
      "172/172 [==============================] - 0s 836us/sample - loss: 0.5113 - accuracy: 0.7791 - val_loss: 0.5026 - val_accuracy: 0.7829\n",
      "Epoch 13/200\n",
      "172/172 [==============================] - 0s 865us/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 14/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 860us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 15/200\n",
      "172/172 [==============================] - 0s 811us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 16/200\n",
      "172/172 [==============================] - 0s 832us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 17/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 18/200\n",
      "172/172 [==============================] - 0s 928us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5013 - val_accuracy: 0.7829\n",
      "Epoch 19/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 20/200\n",
      "172/172 [==============================] - 0s 833us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5010 - val_accuracy: 0.7829\n",
      "Epoch 21/200\n",
      "172/172 [==============================] - 0s 825us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5028 - val_accuracy: 0.7829\n",
      "Epoch 22/200\n",
      "172/172 [==============================] - 0s 825us/sample - loss: 0.5082 - accuracy: 0.7791 - val_loss: 0.5012 - val_accuracy: 0.7829\n",
      "Epoch 23/200\n",
      "172/172 [==============================] - 0s 840us/sample - loss: 0.5080 - accuracy: 0.7791 - val_loss: 0.5007 - val_accuracy: 0.7829\n",
      "Epoch 24/200\n",
      "172/172 [==============================] - 0s 819us/sample - loss: 0.5081 - accuracy: 0.7791 - val_loss: 0.5004 - val_accuracy: 0.7829\n",
      "Epoch 25/200\n",
      "172/172 [==============================] - 0s 826us/sample - loss: 0.5082 - accuracy: 0.7791 - val_loss: 0.5004 - val_accuracy: 0.7829\n",
      "Epoch 26/200\n",
      "172/172 [==============================] - 0s 817us/sample - loss: 0.5085 - accuracy: 0.7791 - val_loss: 0.5003 - val_accuracy: 0.7829\n",
      "Epoch 27/200\n",
      "172/172 [==============================] - 0s 833us/sample - loss: 0.5082 - accuracy: 0.7791 - val_loss: 0.4999 - val_accuracy: 0.7829\n",
      "Epoch 28/200\n",
      "172/172 [==============================] - 0s 825us/sample - loss: 0.5079 - accuracy: 0.7791 - val_loss: 0.5000 - val_accuracy: 0.7829\n",
      "Epoch 29/200\n",
      "172/172 [==============================] - 0s 832us/sample - loss: 0.5072 - accuracy: 0.7791 - val_loss: 0.5000 - val_accuracy: 0.7829\n",
      "Epoch 30/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.5073 - accuracy: 0.7791 - val_loss: 0.4998 - val_accuracy: 0.7829\n",
      "Epoch 31/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.5073 - accuracy: 0.7791 - val_loss: 0.4994 - val_accuracy: 0.7829\n",
      "Epoch 32/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 0.5072 - accuracy: 0.7791 - val_loss: 0.4996 - val_accuracy: 0.7829\n",
      "Epoch 33/200\n",
      "172/172 [==============================] - 0s 838us/sample - loss: 0.5073 - accuracy: 0.7791 - val_loss: 0.4994 - val_accuracy: 0.7829\n",
      "Epoch 34/200\n",
      "172/172 [==============================] - 0s 832us/sample - loss: 0.5063 - accuracy: 0.7791 - val_loss: 0.4987 - val_accuracy: 0.7829\n",
      "Epoch 35/200\n",
      "172/172 [==============================] - 0s 834us/sample - loss: 0.5061 - accuracy: 0.7791 - val_loss: 0.4986 - val_accuracy: 0.7829\n",
      "Epoch 36/200\n",
      "172/172 [==============================] - 0s 834us/sample - loss: 0.5080 - accuracy: 0.7791 - val_loss: 0.4983 - val_accuracy: 0.7829\n",
      "Epoch 37/200\n",
      "172/172 [==============================] - 0s 830us/sample - loss: 0.5056 - accuracy: 0.7791 - val_loss: 0.4983 - val_accuracy: 0.7829\n",
      "Epoch 38/200\n",
      "172/172 [==============================] - 0s 831us/sample - loss: 0.5045 - accuracy: 0.7791 - val_loss: 0.4983 - val_accuracy: 0.7829\n",
      "Epoch 39/200\n",
      "172/172 [==============================] - 0s 837us/sample - loss: 0.5056 - accuracy: 0.7791 - val_loss: 0.4982 - val_accuracy: 0.7829\n",
      "Epoch 40/200\n",
      "172/172 [==============================] - 0s 869us/sample - loss: 0.5066 - accuracy: 0.7791 - val_loss: 0.4977 - val_accuracy: 0.7829\n",
      "Epoch 41/200\n",
      "172/172 [==============================] - 0s 845us/sample - loss: 0.5072 - accuracy: 0.7791 - val_loss: 0.4972 - val_accuracy: 0.7829\n",
      "Epoch 42/200\n",
      "172/172 [==============================] - 0s 848us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.4984 - val_accuracy: 0.7829\n",
      "Epoch 43/200\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 0.5056 - accuracy: 0.7791 - val_loss: 0.4967 - val_accuracy: 0.7829\n",
      "Epoch 44/200\n",
      "172/172 [==============================] - 0s 995us/sample - loss: 0.5069 - accuracy: 0.7791 - val_loss: 0.4965 - val_accuracy: 0.7829\n",
      "Epoch 45/200\n",
      "172/172 [==============================] - 0s 957us/sample - loss: 0.5059 - accuracy: 0.7791 - val_loss: 0.4971 - val_accuracy: 0.7829\n",
      "Epoch 46/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.5059 - accuracy: 0.7791 - val_loss: 0.4966 - val_accuracy: 0.7829\n",
      "Epoch 47/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.5051 - accuracy: 0.7791 - val_loss: 0.4959 - val_accuracy: 0.7829\n",
      "Epoch 48/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.5055 - accuracy: 0.7791 - val_loss: 0.4956 - val_accuracy: 0.7829\n",
      "Epoch 49/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.5049 - accuracy: 0.7791 - val_loss: 0.4967 - val_accuracy: 0.7829\n",
      "Epoch 50/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.5056 - accuracy: 0.7791 - val_loss: 0.4949 - val_accuracy: 0.7829\n",
      "Epoch 51/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.5046 - accuracy: 0.7791 - val_loss: 0.4946 - val_accuracy: 0.7829\n",
      "Epoch 52/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.5033 - accuracy: 0.7791 - val_loss: 0.4943 - val_accuracy: 0.7829\n",
      "Epoch 53/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 0.5042 - accuracy: 0.7791 - val_loss: 0.4938 - val_accuracy: 0.7829\n",
      "Epoch 54/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.5055 - accuracy: 0.7791 - val_loss: 0.4950 - val_accuracy: 0.7829\n",
      "Epoch 55/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.5064 - accuracy: 0.7791 - val_loss: 0.4935 - val_accuracy: 0.7829\n",
      "Epoch 56/200\n",
      "172/172 [==============================] - 0s 930us/sample - loss: 0.5069 - accuracy: 0.7791 - val_loss: 0.4956 - val_accuracy: 0.7829\n",
      "Epoch 57/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5033 - accuracy: 0.7791 - val_loss: 0.4928 - val_accuracy: 0.7829\n",
      "Epoch 58/200\n",
      "172/172 [==============================] - 0s 987us/sample - loss: 0.5019 - accuracy: 0.7791 - val_loss: 0.4924 - val_accuracy: 0.7829\n",
      "Epoch 59/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 0.5027 - accuracy: 0.7791 - val_loss: 0.4912 - val_accuracy: 0.7829\n",
      "Epoch 60/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.5012 - accuracy: 0.7791 - val_loss: 0.4910 - val_accuracy: 0.7829\n",
      "Epoch 61/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.5002 - accuracy: 0.7791 - val_loss: 0.4899 - val_accuracy: 0.7829\n",
      "Epoch 62/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.4996 - accuracy: 0.7791 - val_loss: 0.4895 - val_accuracy: 0.7829\n",
      "Epoch 63/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.5003 - accuracy: 0.7791 - val_loss: 0.4892 - val_accuracy: 0.7829\n",
      "Epoch 64/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.4992 - accuracy: 0.7791 - val_loss: 0.4887 - val_accuracy: 0.7829\n",
      "Epoch 65/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.4995 - accuracy: 0.7791 - val_loss: 0.4876 - val_accuracy: 0.7829\n",
      "Epoch 66/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.4973 - accuracy: 0.7791 - val_loss: 0.4865 - val_accuracy: 0.7829\n",
      "Epoch 67/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.4979 - accuracy: 0.7791 - val_loss: 0.4862 - val_accuracy: 0.7829\n",
      "Epoch 68/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.4996 - accuracy: 0.7791 - val_loss: 0.4851 - val_accuracy: 0.7829\n",
      "Epoch 69/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 974us/sample - loss: 0.4980 - accuracy: 0.7791 - val_loss: 0.4852 - val_accuracy: 0.7829\n",
      "Epoch 70/200\n",
      "172/172 [==============================] - 0s 955us/sample - loss: 0.4942 - accuracy: 0.7791 - val_loss: 0.4834 - val_accuracy: 0.7829\n",
      "Epoch 71/200\n",
      "172/172 [==============================] - 0s 961us/sample - loss: 0.4934 - accuracy: 0.7791 - val_loss: 0.4825 - val_accuracy: 0.7829\n",
      "Epoch 72/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.4917 - accuracy: 0.7791 - val_loss: 0.4799 - val_accuracy: 0.7829\n",
      "Epoch 73/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.4935 - accuracy: 0.7791 - val_loss: 0.4823 - val_accuracy: 0.7829\n",
      "Epoch 74/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 0.4894 - accuracy: 0.7791 - val_loss: 0.4777 - val_accuracy: 0.7829\n",
      "Epoch 75/200\n",
      "172/172 [==============================] - 0s 849us/sample - loss: 0.4879 - accuracy: 0.7791 - val_loss: 0.4771 - val_accuracy: 0.7829\n",
      "Epoch 76/200\n",
      "172/172 [==============================] - 0s 850us/sample - loss: 0.4891 - accuracy: 0.7791 - val_loss: 0.4758 - val_accuracy: 0.7829\n",
      "Epoch 77/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 0.4861 - accuracy: 0.7791 - val_loss: 0.4755 - val_accuracy: 0.7829\n",
      "Epoch 78/200\n",
      "172/172 [==============================] - 0s 856us/sample - loss: 0.4849 - accuracy: 0.7849 - val_loss: 0.4744 - val_accuracy: 0.7984\n",
      "Epoch 79/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 0.4842 - accuracy: 0.7907 - val_loss: 0.4729 - val_accuracy: 0.7984\n",
      "Epoch 80/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 0.4827 - accuracy: 0.7868 - val_loss: 0.4707 - val_accuracy: 0.7984\n",
      "Epoch 81/200\n",
      "172/172 [==============================] - 0s 850us/sample - loss: 0.4926 - accuracy: 0.7771 - val_loss: 0.4743 - val_accuracy: 0.7984\n",
      "Epoch 82/200\n",
      "172/172 [==============================] - 0s 959us/sample - loss: 0.4808 - accuracy: 0.7888 - val_loss: 0.4704 - val_accuracy: 0.7984\n",
      "Epoch 83/200\n",
      "172/172 [==============================] - 0s 930us/sample - loss: 0.4785 - accuracy: 0.7868 - val_loss: 0.4682 - val_accuracy: 0.7984\n",
      "Epoch 84/200\n",
      "172/172 [==============================] - 0s 944us/sample - loss: 0.4784 - accuracy: 0.7810 - val_loss: 0.4683 - val_accuracy: 0.7907\n",
      "Epoch 85/200\n",
      "172/172 [==============================] - 0s 848us/sample - loss: 0.4798 - accuracy: 0.7810 - val_loss: 0.4686 - val_accuracy: 0.7984\n",
      "Epoch 86/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 0.4757 - accuracy: 0.7888 - val_loss: 0.4677 - val_accuracy: 0.7984\n",
      "Epoch 87/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 0.4830 - accuracy: 0.7868 - val_loss: 0.4648 - val_accuracy: 0.7984\n",
      "Epoch 88/200\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 0.4763 - accuracy: 0.8062 - val_loss: 0.4672 - val_accuracy: 0.7984\n",
      "Epoch 89/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.4725 - accuracy: 0.7888 - val_loss: 0.4620 - val_accuracy: 0.7984\n",
      "Epoch 90/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.4700 - accuracy: 0.7926 - val_loss: 0.4616 - val_accuracy: 0.7984\n",
      "Epoch 91/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.4701 - accuracy: 0.7868 - val_loss: 0.4605 - val_accuracy: 0.7984\n",
      "Epoch 92/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.4717 - accuracy: 0.8101 - val_loss: 0.4629 - val_accuracy: 0.7984\n",
      "Epoch 93/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.4682 - accuracy: 0.7984 - val_loss: 0.4584 - val_accuracy: 0.7907\n",
      "Epoch 94/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 0.4671 - accuracy: 0.7907 - val_loss: 0.4641 - val_accuracy: 0.8062\n",
      "Epoch 95/200\n",
      "172/172 [==============================] - 0s 981us/sample - loss: 0.4753 - accuracy: 0.8159 - val_loss: 0.4574 - val_accuracy: 0.7907\n",
      "Epoch 96/200\n",
      "172/172 [==============================] - 0s 959us/sample - loss: 0.4673 - accuracy: 0.7907 - val_loss: 0.4558 - val_accuracy: 0.7907\n",
      "Epoch 97/200\n",
      "172/172 [==============================] - 0s 954us/sample - loss: 0.4681 - accuracy: 0.8081 - val_loss: 0.4592 - val_accuracy: 0.8062\n",
      "Epoch 98/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.4766 - accuracy: 0.7849 - val_loss: 0.4570 - val_accuracy: 0.8062\n",
      "Epoch 99/200\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 0.4725 - accuracy: 0.8178 - val_loss: 0.4558 - val_accuracy: 0.7984\n",
      "Epoch 100/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.4661 - accuracy: 0.7868 - val_loss: 0.4530 - val_accuracy: 0.7984\n",
      "Epoch 101/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 0.4628 - accuracy: 0.8043 - val_loss: 0.4557 - val_accuracy: 0.8062\n",
      "Epoch 102/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 0.4608 - accuracy: 0.7984 - val_loss: 0.4548 - val_accuracy: 0.8062\n",
      "Epoch 103/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.4611 - accuracy: 0.7984 - val_loss: 0.4563 - val_accuracy: 0.8062\n",
      "Epoch 104/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.4610 - accuracy: 0.8023 - val_loss: 0.4541 - val_accuracy: 0.8062\n",
      "Epoch 105/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.4587 - accuracy: 0.8101 - val_loss: 0.4545 - val_accuracy: 0.8062\n",
      "Epoch 106/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.4712 - accuracy: 0.7888 - val_loss: 0.4571 - val_accuracy: 0.8062\n",
      "Epoch 107/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.4567 - accuracy: 0.8120 - val_loss: 0.4545 - val_accuracy: 0.8062\n",
      "Epoch 108/200\n",
      "172/172 [==============================] - 0s 988us/sample - loss: 0.4580 - accuracy: 0.8101 - val_loss: 0.4508 - val_accuracy: 0.8062\n",
      "Epoch 109/200\n",
      "172/172 [==============================] - 0s 955us/sample - loss: 0.4584 - accuracy: 0.8159 - val_loss: 0.4532 - val_accuracy: 0.8062\n",
      "Epoch 110/200\n",
      "172/172 [==============================] - 0s 973us/sample - loss: 0.4593 - accuracy: 0.8101 - val_loss: 0.4496 - val_accuracy: 0.8062\n",
      "Epoch 111/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.4571 - accuracy: 0.8178 - val_loss: 0.4493 - val_accuracy: 0.8062\n",
      "Epoch 112/200\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 0.4577 - accuracy: 0.8004 - val_loss: 0.4498 - val_accuracy: 0.8062\n",
      "Epoch 113/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.4582 - accuracy: 0.8159 - val_loss: 0.4518 - val_accuracy: 0.8062\n",
      "Epoch 114/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.4573 - accuracy: 0.8178 - val_loss: 0.4471 - val_accuracy: 0.8062\n",
      "Epoch 115/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 0.4563 - accuracy: 0.8023 - val_loss: 0.4512 - val_accuracy: 0.8062\n",
      "Epoch 116/200\n",
      "172/172 [==============================] - 0s 848us/sample - loss: 0.4571 - accuracy: 0.8120 - val_loss: 0.4450 - val_accuracy: 0.8062\n",
      "Epoch 117/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 0.4527 - accuracy: 0.8217 - val_loss: 0.4480 - val_accuracy: 0.8062\n",
      "Epoch 118/200\n",
      "172/172 [==============================] - 0s 850us/sample - loss: 0.4565 - accuracy: 0.8023 - val_loss: 0.4512 - val_accuracy: 0.8062\n",
      "Epoch 119/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.4519 - accuracy: 0.8198 - val_loss: 0.4449 - val_accuracy: 0.8062\n",
      "Epoch 120/200\n",
      "172/172 [==============================] - 0s 849us/sample - loss: 0.4567 - accuracy: 0.8004 - val_loss: 0.4483 - val_accuracy: 0.8062\n",
      "Epoch 121/200\n",
      "172/172 [==============================] - 0s 967us/sample - loss: 0.4517 - accuracy: 0.8159 - val_loss: 0.4504 - val_accuracy: 0.8062\n",
      "Epoch 122/200\n",
      "172/172 [==============================] - 0s 948us/sample - loss: 0.4534 - accuracy: 0.8159 - val_loss: 0.4449 - val_accuracy: 0.8062\n",
      "Epoch 123/200\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 0.4568 - accuracy: 0.7965 - val_loss: 0.4482 - val_accuracy: 0.8062\n",
      "Epoch 124/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 857us/sample - loss: 0.4499 - accuracy: 0.8236 - val_loss: 0.4413 - val_accuracy: 0.8062\n",
      "Epoch 125/200\n",
      "172/172 [==============================] - 0s 845us/sample - loss: 0.4516 - accuracy: 0.8081 - val_loss: 0.4466 - val_accuracy: 0.8062\n",
      "Epoch 126/200\n",
      "172/172 [==============================] - 0s 843us/sample - loss: 0.4511 - accuracy: 0.8198 - val_loss: 0.4479 - val_accuracy: 0.8062\n",
      "Epoch 127/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 0.4461 - accuracy: 0.8178 - val_loss: 0.4430 - val_accuracy: 0.8062\n",
      "Epoch 128/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 0.4516 - accuracy: 0.8140 - val_loss: 0.4452 - val_accuracy: 0.8062\n",
      "Epoch 129/200\n",
      "172/172 [==============================] - 0s 844us/sample - loss: 0.4478 - accuracy: 0.8178 - val_loss: 0.4443 - val_accuracy: 0.8062\n",
      "Epoch 130/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 0.4477 - accuracy: 0.8140 - val_loss: 0.4435 - val_accuracy: 0.8062\n",
      "Epoch 131/200\n",
      "172/172 [==============================] - 0s 844us/sample - loss: 0.4458 - accuracy: 0.8198 - val_loss: 0.4419 - val_accuracy: 0.8062\n",
      "Epoch 132/200\n",
      "172/172 [==============================] - 0s 845us/sample - loss: 0.4497 - accuracy: 0.8236 - val_loss: 0.4414 - val_accuracy: 0.8062\n",
      "Epoch 133/200\n",
      "172/172 [==============================] - 0s 864us/sample - loss: 0.4488 - accuracy: 0.8120 - val_loss: 0.4394 - val_accuracy: 0.8062\n",
      "Epoch 134/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 0.4463 - accuracy: 0.8081 - val_loss: 0.4457 - val_accuracy: 0.8140\n",
      "Epoch 135/200\n",
      "172/172 [==============================] - 0s 974us/sample - loss: 0.4444 - accuracy: 0.8236 - val_loss: 0.4402 - val_accuracy: 0.8062\n",
      "Epoch 136/200\n",
      "172/172 [==============================] - 0s 965us/sample - loss: 0.4490 - accuracy: 0.8062 - val_loss: 0.4433 - val_accuracy: 0.8140\n",
      "Epoch 137/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.4448 - accuracy: 0.8217 - val_loss: 0.4412 - val_accuracy: 0.8062\n",
      "Epoch 138/200\n",
      "172/172 [==============================] - 0s 864us/sample - loss: 0.4442 - accuracy: 0.8198 - val_loss: 0.4396 - val_accuracy: 0.8062\n",
      "Epoch 139/200\n",
      "172/172 [==============================] - 0s 865us/sample - loss: 0.4553 - accuracy: 0.8004 - val_loss: 0.4487 - val_accuracy: 0.8372\n",
      "Epoch 140/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.4560 - accuracy: 0.8236 - val_loss: 0.4367 - val_accuracy: 0.7984\n",
      "Epoch 141/200\n",
      "172/172 [==============================] - 0s 869us/sample - loss: 0.4449 - accuracy: 0.8217 - val_loss: 0.4374 - val_accuracy: 0.8062\n",
      "Epoch 142/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 0.4451 - accuracy: 0.8159 - val_loss: 0.4392 - val_accuracy: 0.8062\n",
      "Epoch 143/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.4400 - accuracy: 0.8217 - val_loss: 0.4401 - val_accuracy: 0.8140\n",
      "Epoch 144/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 0.4398 - accuracy: 0.8256 - val_loss: 0.4379 - val_accuracy: 0.8062\n",
      "Epoch 145/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.4452 - accuracy: 0.8236 - val_loss: 0.4359 - val_accuracy: 0.8062\n",
      "Epoch 146/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.4472 - accuracy: 0.8101 - val_loss: 0.4388 - val_accuracy: 0.8140\n",
      "Epoch 147/200\n",
      "172/172 [==============================] - 0s 987us/sample - loss: 0.4405 - accuracy: 0.8178 - val_loss: 0.4401 - val_accuracy: 0.8140\n",
      "Epoch 148/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4426 - accuracy: 0.8275 - val_loss: 0.4347 - val_accuracy: 0.7984\n",
      "Epoch 149/200\n",
      "172/172 [==============================] - 0s 976us/sample - loss: 0.4479 - accuracy: 0.8101 - val_loss: 0.4393 - val_accuracy: 0.8217\n",
      "Epoch 150/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.4431 - accuracy: 0.8217 - val_loss: 0.4336 - val_accuracy: 0.7907\n",
      "Epoch 151/200\n",
      "172/172 [==============================] - 0s 882us/sample - loss: 0.4421 - accuracy: 0.8159 - val_loss: 0.4470 - val_accuracy: 0.8372\n",
      "Epoch 152/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.4434 - accuracy: 0.8159 - val_loss: 0.4343 - val_accuracy: 0.8062\n",
      "Epoch 153/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.4472 - accuracy: 0.8140 - val_loss: 0.4476 - val_accuracy: 0.8372\n",
      "Epoch 154/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 0.4390 - accuracy: 0.8295 - val_loss: 0.4347 - val_accuracy: 0.8062\n",
      "Epoch 155/200\n",
      "172/172 [==============================] - 0s 869us/sample - loss: 0.4421 - accuracy: 0.8275 - val_loss: 0.4376 - val_accuracy: 0.8140\n",
      "Epoch 156/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.4376 - accuracy: 0.8217 - val_loss: 0.4326 - val_accuracy: 0.8062\n",
      "Epoch 157/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.4376 - accuracy: 0.8198 - val_loss: 0.4366 - val_accuracy: 0.8217\n",
      "Epoch 158/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 0.4368 - accuracy: 0.8314 - val_loss: 0.4317 - val_accuracy: 0.8062\n",
      "Epoch 159/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 0.4349 - accuracy: 0.8217 - val_loss: 0.4367 - val_accuracy: 0.8295\n",
      "Epoch 160/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 0.4344 - accuracy: 0.8236 - val_loss: 0.4332 - val_accuracy: 0.8140\n",
      "Epoch 161/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.4380 - accuracy: 0.8236 - val_loss: 0.4349 - val_accuracy: 0.8140\n",
      "Epoch 162/200\n",
      "172/172 [==============================] - 0s 940us/sample - loss: 0.4365 - accuracy: 0.8217 - val_loss: 0.4320 - val_accuracy: 0.8062\n",
      "Epoch 163/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 0.4408 - accuracy: 0.8198 - val_loss: 0.4411 - val_accuracy: 0.8372\n",
      "Epoch 164/200\n",
      "172/172 [==============================] - 0s 848us/sample - loss: 0.4384 - accuracy: 0.8178 - val_loss: 0.4313 - val_accuracy: 0.8062\n",
      "Epoch 165/200\n",
      "172/172 [==============================] - 0s 844us/sample - loss: 0.4344 - accuracy: 0.8275 - val_loss: 0.4352 - val_accuracy: 0.8372\n",
      "Epoch 166/200\n",
      "172/172 [==============================] - 0s 848us/sample - loss: 0.4381 - accuracy: 0.8256 - val_loss: 0.4312 - val_accuracy: 0.7984\n",
      "Epoch 167/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 0.4564 - accuracy: 0.8062 - val_loss: 0.4371 - val_accuracy: 0.8372\n",
      "Epoch 168/200\n",
      "172/172 [==============================] - 0s 845us/sample - loss: 0.4323 - accuracy: 0.8256 - val_loss: 0.4326 - val_accuracy: 0.8140\n",
      "Epoch 169/200\n",
      "172/172 [==============================] - 0s 843us/sample - loss: 0.4453 - accuracy: 0.8140 - val_loss: 0.4459 - val_accuracy: 0.8372\n",
      "Epoch 170/200\n",
      "172/172 [==============================] - 0s 841us/sample - loss: 0.4418 - accuracy: 0.8236 - val_loss: 0.4298 - val_accuracy: 0.8062\n",
      "Epoch 171/200\n",
      "172/172 [==============================] - 0s 849us/sample - loss: 0.4344 - accuracy: 0.8236 - val_loss: 0.4343 - val_accuracy: 0.8372\n",
      "Epoch 172/200\n",
      "172/172 [==============================] - 0s 848us/sample - loss: 0.4323 - accuracy: 0.8178 - val_loss: 0.4331 - val_accuracy: 0.8217\n",
      "Epoch 173/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.4330 - accuracy: 0.8217 - val_loss: 0.4345 - val_accuracy: 0.8372\n",
      "Epoch 174/200\n",
      "172/172 [==============================] - 0s 975us/sample - loss: 0.4367 - accuracy: 0.8295 - val_loss: 0.4294 - val_accuracy: 0.8140\n",
      "Epoch 175/200\n",
      "172/172 [==============================] - 0s 960us/sample - loss: 0.4333 - accuracy: 0.8217 - val_loss: 0.4295 - val_accuracy: 0.8140\n",
      "Epoch 176/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.4327 - accuracy: 0.8236 - val_loss: 0.4340 - val_accuracy: 0.8372\n",
      "Epoch 177/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.4368 - accuracy: 0.8217 - val_loss: 0.4273 - val_accuracy: 0.8062\n",
      "Epoch 178/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.4352 - accuracy: 0.8198 - val_loss: 0.4288 - val_accuracy: 0.8140\n",
      "Epoch 179/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 880us/sample - loss: 0.4305 - accuracy: 0.8295 - val_loss: 0.4291 - val_accuracy: 0.8140\n",
      "Epoch 180/200\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 0.4322 - accuracy: 0.8217 - val_loss: 0.4349 - val_accuracy: 0.8372\n",
      "Epoch 181/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 0.4418 - accuracy: 0.8217 - val_loss: 0.4269 - val_accuracy: 0.7984\n",
      "Epoch 182/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.4322 - accuracy: 0.8198 - val_loss: 0.4334 - val_accuracy: 0.8372\n",
      "Epoch 183/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.4323 - accuracy: 0.8295 - val_loss: 0.4256 - val_accuracy: 0.8062\n",
      "Epoch 184/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 0.4387 - accuracy: 0.8140 - val_loss: 0.4347 - val_accuracy: 0.8372\n",
      "Epoch 185/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.4349 - accuracy: 0.8256 - val_loss: 0.4280 - val_accuracy: 0.8295\n",
      "Epoch 186/200\n",
      "172/172 [==============================] - 0s 946us/sample - loss: 0.4372 - accuracy: 0.8275 - val_loss: 0.4253 - val_accuracy: 0.7907\n",
      "Epoch 187/200\n",
      "172/172 [==============================] - 0s 981us/sample - loss: 0.4332 - accuracy: 0.8256 - val_loss: 0.4299 - val_accuracy: 0.8372\n",
      "Epoch 188/200\n",
      "172/172 [==============================] - 0s 954us/sample - loss: 0.4282 - accuracy: 0.8275 - val_loss: 0.4288 - val_accuracy: 0.8372\n",
      "Epoch 189/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.4302 - accuracy: 0.8314 - val_loss: 0.4311 - val_accuracy: 0.8372\n",
      "Epoch 190/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.4256 - accuracy: 0.8295 - val_loss: 0.4249 - val_accuracy: 0.7984\n",
      "Epoch 191/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.4378 - accuracy: 0.8062 - val_loss: 0.4319 - val_accuracy: 0.8372\n",
      "Epoch 192/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.4341 - accuracy: 0.8198 - val_loss: 0.4268 - val_accuracy: 0.8217\n",
      "Epoch 193/200\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 0.4331 - accuracy: 0.8295 - val_loss: 0.4244 - val_accuracy: 0.8062\n",
      "Epoch 194/200\n",
      "172/172 [==============================] - 0s 864us/sample - loss: 0.4317 - accuracy: 0.8198 - val_loss: 0.4263 - val_accuracy: 0.8140\n",
      "Epoch 195/200\n",
      "172/172 [==============================] - 0s 859us/sample - loss: 0.4274 - accuracy: 0.8178 - val_loss: 0.4320 - val_accuracy: 0.8372\n",
      "Epoch 196/200\n",
      "172/172 [==============================] - 0s 841us/sample - loss: 0.4412 - accuracy: 0.8256 - val_loss: 0.4245 - val_accuracy: 0.8140\n",
      "Epoch 197/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 0.4276 - accuracy: 0.8314 - val_loss: 0.4267 - val_accuracy: 0.8372\n",
      "Epoch 198/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 0.4306 - accuracy: 0.8159 - val_loss: 0.4314 - val_accuracy: 0.8372\n",
      "Epoch 199/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.4255 - accuracy: 0.8256 - val_loss: 0.4259 - val_accuracy: 0.8372\n",
      "Epoch 200/200\n",
      "172/172 [==============================] - 0s 948us/sample - loss: 0.4290 - accuracy: 0.8256 - val_loss: 0.4259 - val_accuracy: 0.8372\n",
      "Beginning training for dr=0.010, l_lambda=1.0e-03, reg_type=l2, act: tanh\n",
      "Train on 172 samples, validate on 43 samples\n",
      "Epoch 1/200\n",
      "172/172 [==============================] - 1s 7ms/sample - loss: 0.6308 - accuracy: 0.6667 - val_loss: 0.5833 - val_accuracy: 0.6667\n",
      "Epoch 2/200\n",
      "172/172 [==============================] - 0s 963us/sample - loss: 0.5534 - accuracy: 0.7287 - val_loss: 0.5220 - val_accuracy: 0.7829\n",
      "Epoch 3/200\n",
      "172/172 [==============================] - 0s 820us/sample - loss: 0.5241 - accuracy: 0.7791 - val_loss: 0.5136 - val_accuracy: 0.7829\n",
      "Epoch 4/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.5211 - accuracy: 0.7791 - val_loss: 0.5112 - val_accuracy: 0.7829\n",
      "Epoch 5/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 0.5175 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 6/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5081 - val_accuracy: 0.7829\n",
      "Epoch 7/200\n",
      "172/172 [==============================] - 0s 828us/sample - loss: 0.5151 - accuracy: 0.7791 - val_loss: 0.5073 - val_accuracy: 0.7829\n",
      "Epoch 8/200\n",
      "172/172 [==============================] - 0s 822us/sample - loss: 0.5153 - accuracy: 0.7791 - val_loss: 0.5076 - val_accuracy: 0.7829\n",
      "Epoch 9/200\n",
      "172/172 [==============================] - 0s 824us/sample - loss: 0.5133 - accuracy: 0.7791 - val_loss: 0.5053 - val_accuracy: 0.7829\n",
      "Epoch 10/200\n",
      "172/172 [==============================] - 0s 814us/sample - loss: 0.5125 - accuracy: 0.7791 - val_loss: 0.5043 - val_accuracy: 0.7829\n",
      "Epoch 11/200\n",
      "172/172 [==============================] - 0s 815us/sample - loss: 0.5120 - accuracy: 0.7791 - val_loss: 0.5037 - val_accuracy: 0.7829\n",
      "Epoch 12/200\n",
      "172/172 [==============================] - 0s 816us/sample - loss: 0.5114 - accuracy: 0.7791 - val_loss: 0.5028 - val_accuracy: 0.7829\n",
      "Epoch 13/200\n",
      "172/172 [==============================] - 0s 820us/sample - loss: 0.5127 - accuracy: 0.7791 - val_loss: 0.5043 - val_accuracy: 0.7829\n",
      "Epoch 14/200\n",
      "172/172 [==============================] - 0s 827us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 15/200\n",
      "172/172 [==============================] - 0s 817us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 16/200\n",
      "172/172 [==============================] - 0s 821us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5005 - val_accuracy: 0.7829\n",
      "Epoch 17/200\n",
      "172/172 [==============================] - 0s 829us/sample - loss: 0.5110 - accuracy: 0.7791 - val_loss: 0.5000 - val_accuracy: 0.7829\n",
      "Epoch 18/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.4986 - val_accuracy: 0.7829\n",
      "Epoch 19/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.4990 - val_accuracy: 0.7829\n",
      "Epoch 20/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 0.5060 - accuracy: 0.7791 - val_loss: 0.4975 - val_accuracy: 0.7829\n",
      "Epoch 21/200\n",
      "172/172 [==============================] - 0s 824us/sample - loss: 0.5060 - accuracy: 0.7791 - val_loss: 0.4975 - val_accuracy: 0.7829\n",
      "Epoch 22/200\n",
      "172/172 [==============================] - 0s 831us/sample - loss: 0.5065 - accuracy: 0.7791 - val_loss: 0.4964 - val_accuracy: 0.7829\n",
      "Epoch 23/200\n",
      "172/172 [==============================] - 0s 826us/sample - loss: 0.5062 - accuracy: 0.7791 - val_loss: 0.4950 - val_accuracy: 0.7829\n",
      "Epoch 24/200\n",
      "172/172 [==============================] - 0s 833us/sample - loss: 0.5043 - accuracy: 0.7810 - val_loss: 0.4966 - val_accuracy: 0.7829\n",
      "Epoch 25/200\n",
      "172/172 [==============================] - 0s 832us/sample - loss: 0.5025 - accuracy: 0.7810 - val_loss: 0.4934 - val_accuracy: 0.7829\n",
      "Epoch 26/200\n",
      "172/172 [==============================] - 0s 840us/sample - loss: 0.5032 - accuracy: 0.7810 - val_loss: 0.4927 - val_accuracy: 0.7829\n",
      "Epoch 27/200\n",
      "172/172 [==============================] - 0s 845us/sample - loss: 0.5037 - accuracy: 0.7791 - val_loss: 0.4914 - val_accuracy: 0.7829\n",
      "Epoch 28/200\n",
      "172/172 [==============================] - 0s 841us/sample - loss: 0.5009 - accuracy: 0.7810 - val_loss: 0.4899 - val_accuracy: 0.7829\n",
      "Epoch 29/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 0.4978 - accuracy: 0.7810 - val_loss: 0.4895 - val_accuracy: 0.7829\n",
      "Epoch 30/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 0.4981 - accuracy: 0.7791 - val_loss: 0.4867 - val_accuracy: 0.7829\n",
      "Epoch 31/200\n",
      "172/172 [==============================] - 0s 946us/sample - loss: 0.4960 - accuracy: 0.7810 - val_loss: 0.4845 - val_accuracy: 0.7829\n",
      "Epoch 32/200\n",
      "172/172 [==============================] - 0s 955us/sample - loss: 0.4951 - accuracy: 0.7791 - val_loss: 0.4823 - val_accuracy: 0.7829\n",
      "Epoch 33/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 955us/sample - loss: 0.4940 - accuracy: 0.7810 - val_loss: 0.4827 - val_accuracy: 0.7907\n",
      "Epoch 34/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.4958 - accuracy: 0.7829 - val_loss: 0.4786 - val_accuracy: 0.7907\n",
      "Epoch 35/200\n",
      "172/172 [==============================] - 0s 864us/sample - loss: 0.4927 - accuracy: 0.7791 - val_loss: 0.4760 - val_accuracy: 0.7907\n",
      "Epoch 36/200\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 0.4876 - accuracy: 0.7791 - val_loss: 0.4754 - val_accuracy: 0.7984\n",
      "Epoch 37/200\n",
      "172/172 [==============================] - 0s 864us/sample - loss: 0.4884 - accuracy: 0.7829 - val_loss: 0.4716 - val_accuracy: 0.7907\n",
      "Epoch 38/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.4871 - accuracy: 0.7907 - val_loss: 0.4698 - val_accuracy: 0.7984\n",
      "Epoch 39/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.4835 - accuracy: 0.7829 - val_loss: 0.4688 - val_accuracy: 0.7984\n",
      "Epoch 40/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 0.4840 - accuracy: 0.7965 - val_loss: 0.4650 - val_accuracy: 0.7984\n",
      "Epoch 41/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.4890 - accuracy: 0.7888 - val_loss: 0.4716 - val_accuracy: 0.8062\n",
      "Epoch 42/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.4773 - accuracy: 0.7907 - val_loss: 0.4618 - val_accuracy: 0.7984\n",
      "Epoch 43/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.4781 - accuracy: 0.7907 - val_loss: 0.4649 - val_accuracy: 0.8062\n",
      "Epoch 44/200\n",
      "172/172 [==============================] - 0s 994us/sample - loss: 0.4764 - accuracy: 0.7926 - val_loss: 0.4607 - val_accuracy: 0.7984\n",
      "Epoch 45/200\n",
      "172/172 [==============================] - 0s 987us/sample - loss: 0.4742 - accuracy: 0.7926 - val_loss: 0.4580 - val_accuracy: 0.7984\n",
      "Epoch 46/200\n",
      "172/172 [==============================] - 0s 985us/sample - loss: 0.4741 - accuracy: 0.8004 - val_loss: 0.4564 - val_accuracy: 0.7984\n",
      "Epoch 47/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.4751 - accuracy: 0.7907 - val_loss: 0.4593 - val_accuracy: 0.8062\n",
      "Epoch 48/200\n",
      "172/172 [==============================] - 0s 865us/sample - loss: 0.4715 - accuracy: 0.8081 - val_loss: 0.4530 - val_accuracy: 0.7984\n",
      "Epoch 49/200\n",
      "172/172 [==============================] - 0s 864us/sample - loss: 0.4756 - accuracy: 0.8062 - val_loss: 0.4602 - val_accuracy: 0.8062\n",
      "Epoch 50/200\n",
      "172/172 [==============================] - 0s 865us/sample - loss: 0.4681 - accuracy: 0.7984 - val_loss: 0.4514 - val_accuracy: 0.8062\n",
      "Epoch 51/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 0.4664 - accuracy: 0.7984 - val_loss: 0.4525 - val_accuracy: 0.8062\n",
      "Epoch 52/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.4691 - accuracy: 0.7965 - val_loss: 0.4485 - val_accuracy: 0.7984\n",
      "Epoch 53/200\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 0.4672 - accuracy: 0.8043 - val_loss: 0.4516 - val_accuracy: 0.8062\n",
      "Epoch 54/200\n",
      "172/172 [==============================] - 0s 861us/sample - loss: 0.4640 - accuracy: 0.8120 - val_loss: 0.4479 - val_accuracy: 0.7984\n",
      "Epoch 55/200\n",
      "172/172 [==============================] - 0s 865us/sample - loss: 0.4739 - accuracy: 0.8023 - val_loss: 0.4458 - val_accuracy: 0.7984\n",
      "Epoch 56/200\n",
      "172/172 [==============================] - 0s 859us/sample - loss: 0.4655 - accuracy: 0.8081 - val_loss: 0.4446 - val_accuracy: 0.7984\n",
      "Epoch 57/200\n",
      "172/172 [==============================] - 0s 951us/sample - loss: 0.4712 - accuracy: 0.7868 - val_loss: 0.4481 - val_accuracy: 0.8062\n",
      "Epoch 58/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.4615 - accuracy: 0.8081 - val_loss: 0.4486 - val_accuracy: 0.8062\n",
      "Epoch 59/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.4621 - accuracy: 0.8043 - val_loss: 0.4484 - val_accuracy: 0.8062\n",
      "Epoch 60/200\n",
      "172/172 [==============================] - 0s 842us/sample - loss: 0.4676 - accuracy: 0.8101 - val_loss: 0.4442 - val_accuracy: 0.8062\n",
      "Epoch 61/200\n",
      "172/172 [==============================] - 0s 837us/sample - loss: 0.4620 - accuracy: 0.8178 - val_loss: 0.4419 - val_accuracy: 0.7984\n",
      "Epoch 62/200\n",
      "172/172 [==============================] - 0s 841us/sample - loss: 0.4626 - accuracy: 0.7946 - val_loss: 0.4630 - val_accuracy: 0.8295\n",
      "Epoch 63/200\n",
      "172/172 [==============================] - 0s 840us/sample - loss: 0.4914 - accuracy: 0.7946 - val_loss: 0.4419 - val_accuracy: 0.8062\n",
      "Epoch 64/200\n",
      "172/172 [==============================] - 0s 840us/sample - loss: 0.4592 - accuracy: 0.8120 - val_loss: 0.4469 - val_accuracy: 0.8062\n",
      "Epoch 65/200\n",
      "172/172 [==============================] - 0s 839us/sample - loss: 0.4572 - accuracy: 0.8140 - val_loss: 0.4467 - val_accuracy: 0.8062\n",
      "Epoch 66/200\n",
      "172/172 [==============================] - 0s 841us/sample - loss: 0.4566 - accuracy: 0.8101 - val_loss: 0.4402 - val_accuracy: 0.8062\n",
      "Epoch 67/200\n",
      "172/172 [==============================] - 0s 849us/sample - loss: 0.4548 - accuracy: 0.8159 - val_loss: 0.4424 - val_accuracy: 0.8062\n",
      "Epoch 68/200\n",
      "172/172 [==============================] - 0s 849us/sample - loss: 0.4544 - accuracy: 0.8159 - val_loss: 0.4387 - val_accuracy: 0.8062\n",
      "Epoch 69/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.4592 - accuracy: 0.8004 - val_loss: 0.4548 - val_accuracy: 0.8372\n",
      "Epoch 70/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.4523 - accuracy: 0.8217 - val_loss: 0.4373 - val_accuracy: 0.8062\n",
      "Epoch 71/200\n",
      "172/172 [==============================] - 0s 971us/sample - loss: 0.4546 - accuracy: 0.8043 - val_loss: 0.4436 - val_accuracy: 0.8062\n",
      "Epoch 72/200\n",
      "172/172 [==============================] - 0s 958us/sample - loss: 0.4685 - accuracy: 0.8140 - val_loss: 0.4404 - val_accuracy: 0.7984\n",
      "Epoch 73/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 0.4714 - accuracy: 0.7926 - val_loss: 0.4595 - val_accuracy: 0.8295\n",
      "Epoch 74/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 0.4530 - accuracy: 0.8198 - val_loss: 0.4372 - val_accuracy: 0.8062\n",
      "Epoch 75/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.4486 - accuracy: 0.8081 - val_loss: 0.4359 - val_accuracy: 0.7984\n",
      "Epoch 76/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.4513 - accuracy: 0.8062 - val_loss: 0.4371 - val_accuracy: 0.8062\n",
      "Epoch 77/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 0.4493 - accuracy: 0.8140 - val_loss: 0.4343 - val_accuracy: 0.7984\n",
      "Epoch 78/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.4486 - accuracy: 0.8101 - val_loss: 0.4402 - val_accuracy: 0.8062\n",
      "Epoch 79/200\n",
      "172/172 [==============================] - 0s 864us/sample - loss: 0.4458 - accuracy: 0.8217 - val_loss: 0.4379 - val_accuracy: 0.8062\n",
      "Epoch 80/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.4499 - accuracy: 0.8159 - val_loss: 0.4392 - val_accuracy: 0.8062\n",
      "Epoch 81/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 0.4480 - accuracy: 0.8062 - val_loss: 0.4387 - val_accuracy: 0.8062\n",
      "Epoch 82/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.4537 - accuracy: 0.8217 - val_loss: 0.4329 - val_accuracy: 0.7984\n",
      "Epoch 83/200\n",
      "172/172 [==============================] - 0s 942us/sample - loss: 0.4460 - accuracy: 0.8217 - val_loss: 0.4363 - val_accuracy: 0.8062\n",
      "Epoch 84/200\n",
      "172/172 [==============================] - 0s 963us/sample - loss: 0.4491 - accuracy: 0.8256 - val_loss: 0.4348 - val_accuracy: 0.8062\n",
      "Epoch 85/200\n",
      "172/172 [==============================] - 0s 949us/sample - loss: 0.4579 - accuracy: 0.8140 - val_loss: 0.4482 - val_accuracy: 0.8372\n",
      "Epoch 86/200\n",
      "172/172 [==============================] - 0s 882us/sample - loss: 0.4442 - accuracy: 0.8120 - val_loss: 0.4315 - val_accuracy: 0.8062\n",
      "Epoch 87/200\n",
      "172/172 [==============================] - 0s 869us/sample - loss: 0.4450 - accuracy: 0.8236 - val_loss: 0.4309 - val_accuracy: 0.8062\n",
      "Epoch 88/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 875us/sample - loss: 0.4441 - accuracy: 0.8159 - val_loss: 0.4295 - val_accuracy: 0.7984\n",
      "Epoch 89/200\n",
      "172/172 [==============================] - 0s 862us/sample - loss: 0.4574 - accuracy: 0.8023 - val_loss: 0.4293 - val_accuracy: 0.8062\n",
      "Epoch 90/200\n",
      "172/172 [==============================] - 0s 861us/sample - loss: 0.4560 - accuracy: 0.8062 - val_loss: 0.4401 - val_accuracy: 0.8217\n",
      "Epoch 91/200\n",
      "172/172 [==============================] - 0s 862us/sample - loss: 0.4432 - accuracy: 0.8120 - val_loss: 0.4323 - val_accuracy: 0.8062\n",
      "Epoch 92/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 0.4451 - accuracy: 0.8198 - val_loss: 0.4521 - val_accuracy: 0.8372\n",
      "Epoch 93/200\n",
      "172/172 [==============================] - 0s 858us/sample - loss: 0.4591 - accuracy: 0.8217 - val_loss: 0.4398 - val_accuracy: 0.8062\n",
      "Epoch 94/200\n",
      "172/172 [==============================] - 0s 869us/sample - loss: 0.4565 - accuracy: 0.8081 - val_loss: 0.4586 - val_accuracy: 0.8372\n",
      "Epoch 95/200\n",
      "172/172 [==============================] - 0s 862us/sample - loss: 0.4502 - accuracy: 0.8236 - val_loss: 0.4306 - val_accuracy: 0.8062\n",
      "Epoch 96/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.4458 - accuracy: 0.8062 - val_loss: 0.4354 - val_accuracy: 0.8062\n",
      "Epoch 97/200\n",
      "172/172 [==============================] - 0s 962us/sample - loss: 0.4496 - accuracy: 0.8198 - val_loss: 0.4306 - val_accuracy: 0.7984\n",
      "Epoch 98/200\n",
      "172/172 [==============================] - 0s 951us/sample - loss: 0.4488 - accuracy: 0.8140 - val_loss: 0.4281 - val_accuracy: 0.8062\n",
      "Epoch 99/200\n",
      "172/172 [==============================] - 0s 859us/sample - loss: 0.4481 - accuracy: 0.8159 - val_loss: 0.4529 - val_accuracy: 0.8295\n",
      "Epoch 100/200\n",
      "172/172 [==============================] - 0s 840us/sample - loss: 0.4416 - accuracy: 0.8198 - val_loss: 0.4313 - val_accuracy: 0.8062\n",
      "Epoch 101/200\n",
      "172/172 [==============================] - 0s 841us/sample - loss: 0.4403 - accuracy: 0.8236 - val_loss: 0.4305 - val_accuracy: 0.8062\n",
      "Epoch 102/200\n",
      "172/172 [==============================] - 0s 843us/sample - loss: 0.4367 - accuracy: 0.8236 - val_loss: 0.4286 - val_accuracy: 0.8062\n",
      "Epoch 103/200\n",
      "172/172 [==============================] - 0s 837us/sample - loss: 0.4418 - accuracy: 0.8140 - val_loss: 0.4298 - val_accuracy: 0.8062\n",
      "Epoch 104/200\n",
      "172/172 [==============================] - 0s 840us/sample - loss: 0.4424 - accuracy: 0.8159 - val_loss: 0.4382 - val_accuracy: 0.8372\n",
      "Epoch 105/200\n",
      "172/172 [==============================] - 0s 842us/sample - loss: 0.4340 - accuracy: 0.8295 - val_loss: 0.4265 - val_accuracy: 0.8062\n",
      "Epoch 106/200\n",
      "172/172 [==============================] - 0s 840us/sample - loss: 0.4428 - accuracy: 0.8081 - val_loss: 0.4328 - val_accuracy: 0.8140\n",
      "Epoch 107/200\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 0.4441 - accuracy: 0.8256 - val_loss: 0.4324 - val_accuracy: 0.7984\n",
      "Epoch 108/200\n",
      "172/172 [==============================] - 0s 841us/sample - loss: 0.4392 - accuracy: 0.8159 - val_loss: 0.4413 - val_accuracy: 0.8372\n",
      "Epoch 109/200\n",
      "172/172 [==============================] - 0s 840us/sample - loss: 0.4422 - accuracy: 0.8198 - val_loss: 0.4260 - val_accuracy: 0.7907\n",
      "Epoch 110/200\n",
      "172/172 [==============================] - 0s 989us/sample - loss: 0.4400 - accuracy: 0.8081 - val_loss: 0.4360 - val_accuracy: 0.8372\n",
      "Epoch 111/200\n",
      "172/172 [==============================] - 0s 949us/sample - loss: 0.4518 - accuracy: 0.8159 - val_loss: 0.4575 - val_accuracy: 0.8372\n",
      "Epoch 112/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.4380 - accuracy: 0.8314 - val_loss: 0.4243 - val_accuracy: 0.7984\n",
      "Epoch 113/200\n",
      "172/172 [==============================] - 0s 849us/sample - loss: 0.4338 - accuracy: 0.8236 - val_loss: 0.4375 - val_accuracy: 0.8372\n",
      "Epoch 114/200\n",
      "172/172 [==============================] - 0s 840us/sample - loss: 0.4420 - accuracy: 0.8120 - val_loss: 0.4445 - val_accuracy: 0.8295\n",
      "Epoch 115/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 0.4352 - accuracy: 0.8236 - val_loss: 0.4274 - val_accuracy: 0.7984\n",
      "Epoch 116/200\n",
      "172/172 [==============================] - 0s 865us/sample - loss: 0.4353 - accuracy: 0.8236 - val_loss: 0.4329 - val_accuracy: 0.8372\n",
      "Epoch 117/200\n",
      "172/172 [==============================] - 0s 864us/sample - loss: 0.4349 - accuracy: 0.8198 - val_loss: 0.4362 - val_accuracy: 0.8372\n",
      "Epoch 118/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 0.4497 - accuracy: 0.8062 - val_loss: 0.4247 - val_accuracy: 0.8062\n",
      "Epoch 119/200\n",
      "172/172 [==============================] - 0s 862us/sample - loss: 0.4355 - accuracy: 0.8256 - val_loss: 0.4231 - val_accuracy: 0.8062\n",
      "Epoch 120/200\n",
      "172/172 [==============================] - 0s 865us/sample - loss: 0.4443 - accuracy: 0.8217 - val_loss: 0.4373 - val_accuracy: 0.8372\n",
      "Epoch 121/200\n",
      "172/172 [==============================] - 0s 865us/sample - loss: 0.4352 - accuracy: 0.8333 - val_loss: 0.4292 - val_accuracy: 0.8295\n",
      "Epoch 122/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 0.4308 - accuracy: 0.8275 - val_loss: 0.4228 - val_accuracy: 0.7984\n",
      "Epoch 123/200\n",
      "172/172 [==============================] - 0s 994us/sample - loss: 0.4386 - accuracy: 0.8178 - val_loss: 0.4350 - val_accuracy: 0.8372\n",
      "Epoch 124/200\n",
      "172/172 [==============================] - 0s 955us/sample - loss: 0.4325 - accuracy: 0.8236 - val_loss: 0.4297 - val_accuracy: 0.8295\n",
      "Epoch 125/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.4292 - accuracy: 0.8295 - val_loss: 0.4283 - val_accuracy: 0.8295\n",
      "Epoch 126/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 0.4310 - accuracy: 0.8275 - val_loss: 0.4232 - val_accuracy: 0.8062\n",
      "Epoch 127/200\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 0.4500 - accuracy: 0.8159 - val_loss: 0.4647 - val_accuracy: 0.8295\n",
      "Epoch 128/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 0.4399 - accuracy: 0.8140 - val_loss: 0.4320 - val_accuracy: 0.8372\n",
      "Epoch 129/200\n",
      "172/172 [==============================] - 0s 862us/sample - loss: 0.4306 - accuracy: 0.8217 - val_loss: 0.4230 - val_accuracy: 0.8140\n",
      "Epoch 130/200\n",
      "172/172 [==============================] - 0s 869us/sample - loss: 0.4298 - accuracy: 0.8333 - val_loss: 0.4211 - val_accuracy: 0.7984\n",
      "Epoch 131/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.4452 - accuracy: 0.8256 - val_loss: 0.4212 - val_accuracy: 0.7984\n",
      "Epoch 132/200\n",
      "172/172 [==============================] - 0s 869us/sample - loss: 0.4340 - accuracy: 0.8198 - val_loss: 0.4412 - val_accuracy: 0.8372\n",
      "Epoch 133/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.4240 - accuracy: 0.8372 - val_loss: 0.4188 - val_accuracy: 0.7984\n",
      "Epoch 134/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.4324 - accuracy: 0.8217 - val_loss: 0.4206 - val_accuracy: 0.8140\n",
      "Epoch 135/200\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 0.4244 - accuracy: 0.8333 - val_loss: 0.4188 - val_accuracy: 0.8062\n",
      "Epoch 136/200\n",
      "172/172 [==============================] - 0s 984us/sample - loss: 0.4301 - accuracy: 0.8198 - val_loss: 0.4521 - val_accuracy: 0.8450\n",
      "Epoch 137/200\n",
      "172/172 [==============================] - 0s 968us/sample - loss: 0.4311 - accuracy: 0.8198 - val_loss: 0.4210 - val_accuracy: 0.8295\n",
      "Epoch 138/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.4262 - accuracy: 0.8333 - val_loss: 0.4277 - val_accuracy: 0.8372\n",
      "Epoch 139/200\n",
      "172/172 [==============================] - 0s 845us/sample - loss: 0.4265 - accuracy: 0.8256 - val_loss: 0.4194 - val_accuracy: 0.8295\n",
      "Epoch 140/200\n",
      "172/172 [==============================] - 0s 841us/sample - loss: 0.4278 - accuracy: 0.8275 - val_loss: 0.4178 - val_accuracy: 0.7984\n",
      "Epoch 141/200\n",
      "172/172 [==============================] - 0s 845us/sample - loss: 0.4347 - accuracy: 0.8062 - val_loss: 0.4522 - val_accuracy: 0.8450\n",
      "Epoch 142/200\n",
      "172/172 [==============================] - 0s 843us/sample - loss: 0.4263 - accuracy: 0.8256 - val_loss: 0.4218 - val_accuracy: 0.7984\n",
      "Epoch 143/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 845us/sample - loss: 0.4192 - accuracy: 0.8411 - val_loss: 0.4318 - val_accuracy: 0.8372\n",
      "Epoch 144/200\n",
      "172/172 [==============================] - 0s 838us/sample - loss: 0.4262 - accuracy: 0.8314 - val_loss: 0.4261 - val_accuracy: 0.8372\n",
      "Epoch 145/200\n",
      "172/172 [==============================] - 0s 841us/sample - loss: 0.4234 - accuracy: 0.8372 - val_loss: 0.4177 - val_accuracy: 0.7984\n",
      "Epoch 146/200\n",
      "172/172 [==============================] - 0s 837us/sample - loss: 0.4238 - accuracy: 0.8236 - val_loss: 0.4204 - val_accuracy: 0.8295\n",
      "Epoch 147/200\n",
      "172/172 [==============================] - 0s 844us/sample - loss: 0.4281 - accuracy: 0.8256 - val_loss: 0.4372 - val_accuracy: 0.8372\n",
      "Epoch 148/200\n",
      "172/172 [==============================] - 0s 837us/sample - loss: 0.4314 - accuracy: 0.8314 - val_loss: 0.4401 - val_accuracy: 0.8450\n",
      "Epoch 149/200\n",
      "172/172 [==============================] - 0s 947us/sample - loss: 0.4456 - accuracy: 0.8198 - val_loss: 0.4233 - val_accuracy: 0.7984\n",
      "Epoch 150/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 0.4212 - accuracy: 0.8120 - val_loss: 0.4263 - val_accuracy: 0.8372\n",
      "Epoch 151/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.4273 - accuracy: 0.8314 - val_loss: 0.4175 - val_accuracy: 0.8062\n",
      "Epoch 152/200\n",
      "172/172 [==============================] - 0s 836us/sample - loss: 0.4234 - accuracy: 0.8236 - val_loss: 0.4252 - val_accuracy: 0.8372\n",
      "Epoch 153/200\n",
      "172/172 [==============================] - 0s 839us/sample - loss: 0.4208 - accuracy: 0.8333 - val_loss: 0.4208 - val_accuracy: 0.8295\n",
      "Epoch 154/200\n",
      "172/172 [==============================] - 0s 836us/sample - loss: 0.4354 - accuracy: 0.8236 - val_loss: 0.4175 - val_accuracy: 0.7984\n",
      "Epoch 155/200\n",
      "172/172 [==============================] - 0s 838us/sample - loss: 0.4175 - accuracy: 0.8353 - val_loss: 0.4283 - val_accuracy: 0.8372\n",
      "Epoch 156/200\n",
      "172/172 [==============================] - 0s 858us/sample - loss: 0.4195 - accuracy: 0.8411 - val_loss: 0.4169 - val_accuracy: 0.8140\n",
      "Epoch 157/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 0.4291 - accuracy: 0.8120 - val_loss: 0.4571 - val_accuracy: 0.8295\n",
      "Epoch 158/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 0.4329 - accuracy: 0.8217 - val_loss: 0.4269 - val_accuracy: 0.8372\n",
      "Epoch 159/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 0.4170 - accuracy: 0.8391 - val_loss: 0.4219 - val_accuracy: 0.7984\n",
      "Epoch 160/200\n",
      "172/172 [==============================] - 0s 865us/sample - loss: 0.4331 - accuracy: 0.8159 - val_loss: 0.4756 - val_accuracy: 0.8140\n",
      "Epoch 161/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 0.4355 - accuracy: 0.8198 - val_loss: 0.4166 - val_accuracy: 0.7829\n",
      "Epoch 162/200\n",
      "172/172 [==============================] - 0s 940us/sample - loss: 0.4238 - accuracy: 0.8217 - val_loss: 0.4240 - val_accuracy: 0.8295\n",
      "Epoch 163/200\n",
      "172/172 [==============================] - 0s 971us/sample - loss: 0.4194 - accuracy: 0.8372 - val_loss: 0.4224 - val_accuracy: 0.8295\n",
      "Epoch 164/200\n",
      "172/172 [==============================] - 0s 954us/sample - loss: 0.4188 - accuracy: 0.8411 - val_loss: 0.4164 - val_accuracy: 0.7984\n",
      "Epoch 165/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.4209 - accuracy: 0.8372 - val_loss: 0.4173 - val_accuracy: 0.7907\n",
      "Epoch 166/200\n",
      "172/172 [==============================] - 0s 861us/sample - loss: 0.4167 - accuracy: 0.8314 - val_loss: 0.4320 - val_accuracy: 0.8372\n",
      "Epoch 167/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 0.4214 - accuracy: 0.8333 - val_loss: 0.4259 - val_accuracy: 0.7984\n",
      "Epoch 168/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 0.4321 - accuracy: 0.8198 - val_loss: 0.4170 - val_accuracy: 0.8295\n",
      "Epoch 169/200\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 0.4185 - accuracy: 0.8391 - val_loss: 0.4173 - val_accuracy: 0.8295\n",
      "Epoch 170/200\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 0.4155 - accuracy: 0.8314 - val_loss: 0.4291 - val_accuracy: 0.8450\n",
      "Epoch 171/200\n",
      "172/172 [==============================] - 0s 864us/sample - loss: 0.4145 - accuracy: 0.8372 - val_loss: 0.4166 - val_accuracy: 0.7907\n",
      "Epoch 172/200\n",
      "172/172 [==============================] - 0s 865us/sample - loss: 0.4148 - accuracy: 0.8391 - val_loss: 0.4254 - val_accuracy: 0.8372\n",
      "Epoch 173/200\n",
      "172/172 [==============================] - 0s 865us/sample - loss: 0.4156 - accuracy: 0.8430 - val_loss: 0.4181 - val_accuracy: 0.8295\n",
      "Epoch 174/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 0.4251 - accuracy: 0.8314 - val_loss: 0.4158 - val_accuracy: 0.7907\n",
      "Epoch 175/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.4167 - accuracy: 0.8391 - val_loss: 0.4175 - val_accuracy: 0.8295\n",
      "Epoch 176/200\n",
      "172/172 [==============================] - 0s 987us/sample - loss: 0.4179 - accuracy: 0.8353 - val_loss: 0.4157 - val_accuracy: 0.7984\n",
      "Epoch 177/200\n",
      "172/172 [==============================] - 0s 955us/sample - loss: 0.4223 - accuracy: 0.8236 - val_loss: 0.4228 - val_accuracy: 0.8372\n",
      "Epoch 178/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 0.4146 - accuracy: 0.8391 - val_loss: 0.4420 - val_accuracy: 0.8527\n",
      "Epoch 179/200\n",
      "172/172 [==============================] - 0s 842us/sample - loss: 0.4250 - accuracy: 0.8256 - val_loss: 0.4151 - val_accuracy: 0.7984\n",
      "Epoch 180/200\n",
      "172/172 [==============================] - 0s 849us/sample - loss: 0.4160 - accuracy: 0.8372 - val_loss: 0.4155 - val_accuracy: 0.7907\n",
      "Epoch 181/200\n",
      "172/172 [==============================] - 0s 947us/sample - loss: 0.4230 - accuracy: 0.8275 - val_loss: 0.4163 - val_accuracy: 0.7907\n",
      "Epoch 182/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.4427 - accuracy: 0.8081 - val_loss: 0.4155 - val_accuracy: 0.8062\n",
      "Epoch 183/200\n",
      "172/172 [==============================] - 0s 937us/sample - loss: 0.4190 - accuracy: 0.8314 - val_loss: 0.4152 - val_accuracy: 0.8140\n",
      "Epoch 184/200\n",
      "172/172 [==============================] - 0s 843us/sample - loss: 0.4137 - accuracy: 0.8314 - val_loss: 0.4170 - val_accuracy: 0.8217\n",
      "Epoch 185/200\n",
      "172/172 [==============================] - 0s 842us/sample - loss: 0.4123 - accuracy: 0.8314 - val_loss: 0.4220 - val_accuracy: 0.8372\n",
      "Epoch 186/200\n",
      "172/172 [==============================] - 0s 833us/sample - loss: 0.4186 - accuracy: 0.8411 - val_loss: 0.4453 - val_accuracy: 0.8450\n",
      "Epoch 187/200\n",
      "172/172 [==============================] - 0s 840us/sample - loss: 0.4251 - accuracy: 0.8391 - val_loss: 0.4148 - val_accuracy: 0.8217\n",
      "Epoch 188/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 0.4135 - accuracy: 0.8391 - val_loss: 0.4144 - val_accuracy: 0.8140\n",
      "Epoch 189/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4109 - accuracy: 0.8391 - val_loss: 0.4419 - val_accuracy: 0.8450\n",
      "Epoch 190/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.4240 - accuracy: 0.8120 - val_loss: 0.4216 - val_accuracy: 0.8295\n",
      "Epoch 191/200\n",
      "172/172 [==============================] - 0s 849us/sample - loss: 0.4124 - accuracy: 0.8353 - val_loss: 0.4151 - val_accuracy: 0.8217\n",
      "Epoch 192/200\n",
      "172/172 [==============================] - 0s 845us/sample - loss: 0.4163 - accuracy: 0.8353 - val_loss: 0.4140 - val_accuracy: 0.8140\n",
      "Epoch 193/200\n",
      "172/172 [==============================] - 0s 940us/sample - loss: 0.4094 - accuracy: 0.8411 - val_loss: 0.4188 - val_accuracy: 0.8217\n",
      "Epoch 194/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.4116 - accuracy: 0.8372 - val_loss: 0.4385 - val_accuracy: 0.7907\n",
      "Epoch 195/200\n",
      "172/172 [==============================] - 0s 976us/sample - loss: 0.4354 - accuracy: 0.8140 - val_loss: 0.4169 - val_accuracy: 0.8217\n",
      "Epoch 196/200\n",
      "172/172 [==============================] - 0s 955us/sample - loss: 0.4067 - accuracy: 0.8430 - val_loss: 0.4158 - val_accuracy: 0.8140\n",
      "Epoch 197/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.4077 - accuracy: 0.8353 - val_loss: 0.4326 - val_accuracy: 0.8372\n",
      "Epoch 198/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 916us/sample - loss: 0.4156 - accuracy: 0.8411 - val_loss: 0.4186 - val_accuracy: 0.8295\n",
      "Epoch 199/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 0.4242 - accuracy: 0.8295 - val_loss: 0.4501 - val_accuracy: 0.8217\n",
      "Epoch 200/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 0.4463 - accuracy: 0.8101 - val_loss: 0.4232 - val_accuracy: 0.7984\n",
      "Beginning training for dr=0.010, l_lambda=1.0e-03, reg_type=l1, act: relu\n",
      "Train on 172 samples, validate on 43 samples\n",
      "Epoch 1/200\n",
      "172/172 [==============================] - 1s 7ms/sample - loss: 1.3288 - accuracy: 0.6667 - val_loss: 0.9556 - val_accuracy: 0.6667\n",
      "Epoch 2/200\n",
      "172/172 [==============================] - 0s 819us/sample - loss: 0.8140 - accuracy: 0.6667 - val_loss: 0.7240 - val_accuracy: 0.6667\n",
      "Epoch 3/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.6723 - accuracy: 0.7054 - val_loss: 0.6224 - val_accuracy: 0.7829\n",
      "Epoch 4/200\n",
      "172/172 [==============================] - 0s 981us/sample - loss: 0.6010 - accuracy: 0.7791 - val_loss: 0.5727 - val_accuracy: 0.7829\n",
      "Epoch 5/200\n",
      "172/172 [==============================] - 0s 942us/sample - loss: 0.5657 - accuracy: 0.7791 - val_loss: 0.5495 - val_accuracy: 0.7829\n",
      "Epoch 6/200\n",
      "172/172 [==============================] - 0s 849us/sample - loss: 0.5480 - accuracy: 0.7791 - val_loss: 0.5339 - val_accuracy: 0.7829\n",
      "Epoch 7/200\n",
      "172/172 [==============================] - 0s 821us/sample - loss: 0.5354 - accuracy: 0.7791 - val_loss: 0.5233 - val_accuracy: 0.7829\n",
      "Epoch 8/200\n",
      "172/172 [==============================] - 0s 829us/sample - loss: 0.5265 - accuracy: 0.7791 - val_loss: 0.5157 - val_accuracy: 0.7829\n",
      "Epoch 9/200\n",
      "172/172 [==============================] - 0s 832us/sample - loss: 0.5211 - accuracy: 0.7791 - val_loss: 0.5127 - val_accuracy: 0.7829\n",
      "Epoch 10/200\n",
      "172/172 [==============================] - 0s 840us/sample - loss: 0.5185 - accuracy: 0.7791 - val_loss: 0.5112 - val_accuracy: 0.7829\n",
      "Epoch 11/200\n",
      "172/172 [==============================] - 0s 882us/sample - loss: 0.5173 - accuracy: 0.7791 - val_loss: 0.5109 - val_accuracy: 0.7829\n",
      "Epoch 12/200\n",
      "172/172 [==============================] - 0s 996us/sample - loss: 0.5171 - accuracy: 0.7791 - val_loss: 0.5105 - val_accuracy: 0.7829\n",
      "Epoch 13/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5168 - accuracy: 0.7791 - val_loss: 0.5099 - val_accuracy: 0.7829\n",
      "Epoch 14/200\n",
      "172/172 [==============================] - 0s 945us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5097 - val_accuracy: 0.7829\n",
      "Epoch 15/200\n",
      "172/172 [==============================] - 0s 957us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 16/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5173 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 17/200\n",
      "172/172 [==============================] - 0s 994us/sample - loss: 0.5175 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 18/200\n",
      "172/172 [==============================] - 0s 1000us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 19/200\n",
      "172/172 [==============================] - 0s 949us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 20/200\n",
      "172/172 [==============================] - 0s 940us/sample - loss: 0.5168 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 21/200\n",
      "172/172 [==============================] - 0s 831us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 22/200\n",
      "172/172 [==============================] - 0s 849us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 23/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 24/200\n",
      "172/172 [==============================] - 0s 869us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 25/200\n",
      "172/172 [==============================] - 0s 984us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 26/200\n",
      "172/172 [==============================] - 0s 954us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 27/200\n",
      "172/172 [==============================] - 0s 963us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 28/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 29/200\n",
      "172/172 [==============================] - 0s 977us/sample - loss: 0.5174 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 30/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 31/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 32/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 33/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.5168 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 34/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.5168 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 35/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 0.5181 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 36/200\n",
      "172/172 [==============================] - 0s 930us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 37/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 38/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5168 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 39/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 40/200\n",
      "172/172 [==============================] - 0s 975us/sample - loss: 0.5171 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 41/200\n",
      "172/172 [==============================] - 0s 977us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 42/200\n",
      "172/172 [==============================] - 0s 986us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 43/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 44/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 45/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 46/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 47/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 48/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 49/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 0.5156 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 50/200\n",
      "172/172 [==============================] - 0s 968us/sample - loss: 0.5173 - accuracy: 0.7791 - val_loss: 0.5098 - val_accuracy: 0.7829\n",
      "Epoch 51/200\n",
      "172/172 [==============================] - 0s 988us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 52/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/200\n",
      "172/172 [==============================] - 0s 978us/sample - loss: 0.5184 - accuracy: 0.7791 - val_loss: 0.5106 - val_accuracy: 0.7829\n",
      "Epoch 54/200\n",
      "172/172 [==============================] - 0s 947us/sample - loss: 0.5168 - accuracy: 0.7791 - val_loss: 0.5096 - val_accuracy: 0.7829\n",
      "Epoch 55/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5097 - val_accuracy: 0.7829\n",
      "Epoch 56/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5098 - val_accuracy: 0.7829\n",
      "Epoch 57/200\n",
      "172/172 [==============================] - 0s 869us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 58/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 59/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 60/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 61/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 62/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 63/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5096 - val_accuracy: 0.7829\n",
      "Epoch 64/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.5180 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 65/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 66/200\n",
      "172/172 [==============================] - 0s 955us/sample - loss: 0.5169 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 67/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 0.5157 - accuracy: 0.7791 - val_loss: 0.5096 - val_accuracy: 0.7829\n",
      "Epoch 68/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5101 - val_accuracy: 0.7829\n",
      "Epoch 69/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.5169 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 70/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 71/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 72/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.5172 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 73/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 74/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.5158 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 75/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.5186 - accuracy: 0.7791 - val_loss: 0.5107 - val_accuracy: 0.7829\n",
      "Epoch 76/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.5169 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 77/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 78/200\n",
      "172/172 [==============================] - 0s 930us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 79/200\n",
      "172/172 [==============================] - 0s 953us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 80/200\n",
      "172/172 [==============================] - 0s 951us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 81/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 82/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 83/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5101 - val_accuracy: 0.7829\n",
      "Epoch 84/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.5172 - accuracy: 0.7791 - val_loss: 0.5101 - val_accuracy: 0.7829\n",
      "Epoch 85/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 86/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 87/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 88/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 89/200\n",
      "172/172 [==============================] - 0s 862us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 90/200\n",
      "172/172 [==============================] - 0s 858us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 91/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 92/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 93/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5168 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 94/200\n",
      "172/172 [==============================] - 0s 869us/sample - loss: 0.5169 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 95/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 96/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 97/200\n",
      "172/172 [==============================] - 0s 946us/sample - loss: 0.5170 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 98/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 99/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 100/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 101/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 102/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 103/200\n",
      "172/172 [==============================] - 0s 972us/sample - loss: 0.5171 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 104/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 105/200\n",
      "172/172 [==============================] - 0s 945us/sample - loss: 0.5158 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 106/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 107/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 108/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 926us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 109/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 110/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.5170 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 111/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 112/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5174 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 113/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5098 - val_accuracy: 0.7829\n",
      "Epoch 114/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5099 - val_accuracy: 0.7829\n",
      "Epoch 115/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 116/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 117/200\n",
      "172/172 [==============================] - 0s 973us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 118/200\n",
      "172/172 [==============================] - 0s 957us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 119/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5178 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 120/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.5173 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 121/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.5169 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 122/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 123/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 124/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 125/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.5170 - accuracy: 0.7791 - val_loss: 0.5107 - val_accuracy: 0.7829\n",
      "Epoch 126/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.5170 - accuracy: 0.7791 - val_loss: 0.5104 - val_accuracy: 0.7829\n",
      "Epoch 127/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.5174 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 128/200\n",
      "172/172 [==============================] - 0s 953us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 129/200\n",
      "172/172 [==============================] - 0s 963us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 130/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 131/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 132/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5098 - val_accuracy: 0.7829\n",
      "Epoch 133/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 0.5183 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 134/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 135/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 136/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.5168 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 137/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.5158 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 138/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 139/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 140/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.5156 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 141/200\n",
      "172/172 [==============================] - 0s 960us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 142/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5097 - val_accuracy: 0.7829\n",
      "Epoch 143/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 0.5175 - accuracy: 0.7791 - val_loss: 0.5111 - val_accuracy: 0.7829\n",
      "Epoch 144/200\n",
      "172/172 [==============================] - 0s 854us/sample - loss: 0.5171 - accuracy: 0.7791 - val_loss: 0.5099 - val_accuracy: 0.7829\n",
      "Epoch 145/200\n",
      "172/172 [==============================] - 0s 848us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 146/200\n",
      "172/172 [==============================] - 0s 848us/sample - loss: 0.5170 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 147/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 148/200\n",
      "172/172 [==============================] - 0s 853us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 149/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 150/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 151/200\n",
      "172/172 [==============================] - 0s 869us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5098 - val_accuracy: 0.7829\n",
      "Epoch 152/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 153/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 154/200\n",
      "172/172 [==============================] - 0s 948us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 155/200\n",
      "172/172 [==============================] - 0s 969us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 156/200\n",
      "172/172 [==============================] - 0s 945us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 157/200\n",
      "172/172 [==============================] - 0s 882us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 158/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 159/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.5168 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 160/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.5174 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 161/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.5174 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 162/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 163/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 888us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 164/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 165/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 166/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 167/200\n",
      "172/172 [==============================] - 0s 947us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 168/200\n",
      "172/172 [==============================] - 0s 940us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 169/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 170/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.5168 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 171/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 172/200\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 173/200\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 174/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 175/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 176/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5097 - val_accuracy: 0.7829\n",
      "Epoch 177/200\n",
      "172/172 [==============================] - 0s 869us/sample - loss: 0.5173 - accuracy: 0.7791 - val_loss: 0.5102 - val_accuracy: 0.7829\n",
      "Epoch 178/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5096 - val_accuracy: 0.7829\n",
      "Epoch 179/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 180/200\n",
      "172/172 [==============================] - 0s 958us/sample - loss: 0.5170 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 181/200\n",
      "172/172 [==============================] - 0s 945us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 182/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 183/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 184/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 185/200\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 186/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 187/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 188/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5100 - val_accuracy: 0.7829\n",
      "Epoch 189/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5100 - val_accuracy: 0.7829\n",
      "Epoch 190/200\n",
      "172/172 [==============================] - 0s 869us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5097 - val_accuracy: 0.7829\n",
      "Epoch 191/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 192/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 193/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5100 - val_accuracy: 0.7829\n",
      "Epoch 194/200\n",
      "172/172 [==============================] - 0s 952us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 195/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 196/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 197/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 198/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 199/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 200/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Beginning training for dr=0.010, l_lambda=1.0e-03, reg_type=l1, act: tanh\n",
      "Train on 172 samples, validate on 43 samples\n",
      "Epoch 1/200\n",
      "172/172 [==============================] - 1s 7ms/sample - loss: 1.3132 - accuracy: 0.6667 - val_loss: 0.9218 - val_accuracy: 0.6667\n",
      "Epoch 2/200\n",
      "172/172 [==============================] - 0s 795us/sample - loss: 0.7720 - accuracy: 0.7287 - val_loss: 0.6817 - val_accuracy: 0.7829\n",
      "Epoch 3/200\n",
      "172/172 [==============================] - 0s 810us/sample - loss: 0.6396 - accuracy: 0.7791 - val_loss: 0.6003 - val_accuracy: 0.7829\n",
      "Epoch 4/200\n",
      "172/172 [==============================] - 0s 822us/sample - loss: 0.5916 - accuracy: 0.7791 - val_loss: 0.5702 - val_accuracy: 0.7829\n",
      "Epoch 5/200\n",
      "172/172 [==============================] - 0s 813us/sample - loss: 0.5680 - accuracy: 0.7791 - val_loss: 0.5509 - val_accuracy: 0.7829\n",
      "Epoch 6/200\n",
      "172/172 [==============================] - 0s 814us/sample - loss: 0.5529 - accuracy: 0.7791 - val_loss: 0.5365 - val_accuracy: 0.7829\n",
      "Epoch 7/200\n",
      "172/172 [==============================] - 0s 837us/sample - loss: 0.5386 - accuracy: 0.7791 - val_loss: 0.5256 - val_accuracy: 0.7829\n",
      "Epoch 8/200\n",
      "172/172 [==============================] - 0s 822us/sample - loss: 0.5294 - accuracy: 0.7791 - val_loss: 0.5183 - val_accuracy: 0.7829\n",
      "Epoch 9/200\n",
      "172/172 [==============================] - 0s 810us/sample - loss: 0.5244 - accuracy: 0.7791 - val_loss: 0.5129 - val_accuracy: 0.7829\n",
      "Epoch 10/200\n",
      "172/172 [==============================] - 0s 812us/sample - loss: 0.5189 - accuracy: 0.7791 - val_loss: 0.5102 - val_accuracy: 0.7829\n",
      "Epoch 11/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5171 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 12/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.5177 - accuracy: 0.7791 - val_loss: 0.5097 - val_accuracy: 0.7829\n",
      "Epoch 13/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.5176 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 14/200\n",
      "172/172 [==============================] - 0s 835us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5098 - val_accuracy: 0.7829\n",
      "Epoch 15/200\n",
      "172/172 [==============================] - 0s 822us/sample - loss: 0.5170 - accuracy: 0.7791 - val_loss: 0.5099 - val_accuracy: 0.7829\n",
      "Epoch 16/200\n",
      "172/172 [==============================] - 0s 820us/sample - loss: 0.5173 - accuracy: 0.7791 - val_loss: 0.5102 - val_accuracy: 0.7829\n",
      "Epoch 17/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 834us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 18/200\n",
      "172/172 [==============================] - 0s 820us/sample - loss: 0.5169 - accuracy: 0.7791 - val_loss: 0.5099 - val_accuracy: 0.7829\n",
      "Epoch 19/200\n",
      "172/172 [==============================] - 0s 856us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 20/200\n",
      "172/172 [==============================] - 0s 815us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5097 - val_accuracy: 0.7829\n",
      "Epoch 21/200\n",
      "172/172 [==============================] - 0s 849us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5101 - val_accuracy: 0.7829\n",
      "Epoch 22/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.5168 - accuracy: 0.7791 - val_loss: 0.5096 - val_accuracy: 0.7829\n",
      "Epoch 23/200\n",
      "172/172 [==============================] - 0s 843us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 24/200\n",
      "172/172 [==============================] - 0s 840us/sample - loss: 0.5170 - accuracy: 0.7791 - val_loss: 0.5101 - val_accuracy: 0.7829\n",
      "Epoch 25/200\n",
      "172/172 [==============================] - 0s 957us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 26/200\n",
      "172/172 [==============================] - 0s 944us/sample - loss: 0.5184 - accuracy: 0.7791 - val_loss: 0.5103 - val_accuracy: 0.7829\n",
      "Epoch 27/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5168 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 28/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 0.5172 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 29/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 30/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.5172 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 31/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.5180 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 32/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.5190 - accuracy: 0.7791 - val_loss: 0.5105 - val_accuracy: 0.7829\n",
      "Epoch 33/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.5171 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 34/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 35/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 0.5173 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 36/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5085 - val_accuracy: 0.7829\n",
      "Epoch 37/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 38/200\n",
      "172/172 [==============================] - 0s 968us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 39/200\n",
      "172/172 [==============================] - 0s 943us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5100 - val_accuracy: 0.7829\n",
      "Epoch 40/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 0.5179 - accuracy: 0.7791 - val_loss: 0.5106 - val_accuracy: 0.7829\n",
      "Epoch 41/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 42/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 43/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.5175 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 44/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 0.5170 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 45/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5098 - val_accuracy: 0.7829\n",
      "Epoch 46/200\n",
      "172/172 [==============================] - 0s 869us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5096 - val_accuracy: 0.7829\n",
      "Epoch 47/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 48/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 0.5178 - accuracy: 0.7791 - val_loss: 0.5097 - val_accuracy: 0.7829\n",
      "Epoch 49/200\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 0.5169 - accuracy: 0.7791 - val_loss: 0.5096 - val_accuracy: 0.7829\n",
      "Epoch 50/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.5172 - accuracy: 0.7791 - val_loss: 0.5098 - val_accuracy: 0.7829\n",
      "Epoch 51/200\n",
      "172/172 [==============================] - 0s 965us/sample - loss: 0.5172 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 52/200\n",
      "172/172 [==============================] - 0s 944us/sample - loss: 0.5207 - accuracy: 0.7791 - val_loss: 0.5100 - val_accuracy: 0.7829\n",
      "Epoch 53/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.5179 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 54/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 55/200\n",
      "172/172 [==============================] - 0s 840us/sample - loss: 0.5175 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 56/200\n",
      "172/172 [==============================] - 0s 845us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 57/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 58/200\n",
      "172/172 [==============================] - 0s 853us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 59/200\n",
      "172/172 [==============================] - 0s 844us/sample - loss: 0.5168 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 60/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 61/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 0.5170 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 62/200\n",
      "172/172 [==============================] - 0s 849us/sample - loss: 0.5185 - accuracy: 0.7791 - val_loss: 0.5096 - val_accuracy: 0.7829\n",
      "Epoch 63/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 64/200\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 0.5176 - accuracy: 0.7791 - val_loss: 0.5100 - val_accuracy: 0.7829\n",
      "Epoch 65/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.5190 - accuracy: 0.7791 - val_loss: 0.5119 - val_accuracy: 0.7829\n",
      "Epoch 66/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 67/200\n",
      "172/172 [==============================] - 0s 843us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 68/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 69/200\n",
      "172/172 [==============================] - 0s 843us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 70/200\n",
      "172/172 [==============================] - 0s 848us/sample - loss: 0.5182 - accuracy: 0.7791 - val_loss: 0.5110 - val_accuracy: 0.7829\n",
      "Epoch 71/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 72/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 857us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 73/200\n",
      "172/172 [==============================] - 0s 843us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 74/200\n",
      "172/172 [==============================] - 0s 843us/sample - loss: 0.5171 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 75/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 76/200\n",
      "172/172 [==============================] - 0s 848us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 77/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.5185 - accuracy: 0.7791 - val_loss: 0.5096 - val_accuracy: 0.7829\n",
      "Epoch 78/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 0.5172 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 79/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.5173 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 80/200\n",
      "172/172 [==============================] - 0s 857us/sample - loss: 0.5175 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 81/200\n",
      "172/172 [==============================] - 0s 853us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 82/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.5169 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 83/200\n",
      "172/172 [==============================] - 0s 842us/sample - loss: 0.5171 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 84/200\n",
      "172/172 [==============================] - 0s 842us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 85/200\n",
      "172/172 [==============================] - 0s 841us/sample - loss: 0.5189 - accuracy: 0.7791 - val_loss: 0.5096 - val_accuracy: 0.7829\n",
      "Epoch 86/200\n",
      "172/172 [==============================] - 0s 844us/sample - loss: 0.5157 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 87/200\n",
      "172/172 [==============================] - 0s 845us/sample - loss: 0.5168 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 88/200\n",
      "172/172 [==============================] - 0s 845us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 89/200\n",
      "172/172 [==============================] - 0s 845us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 90/200\n",
      "172/172 [==============================] - 0s 842us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 91/200\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 92/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.5173 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 93/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5097 - val_accuracy: 0.7829\n",
      "Epoch 94/200\n",
      "172/172 [==============================] - 0s 843us/sample - loss: 0.5170 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 95/200\n",
      "172/172 [==============================] - 0s 849us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 96/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.5187 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 97/200\n",
      "172/172 [==============================] - 0s 841us/sample - loss: 0.5198 - accuracy: 0.7791 - val_loss: 0.5098 - val_accuracy: 0.7829\n",
      "Epoch 98/200\n",
      "172/172 [==============================] - 0s 844us/sample - loss: 0.5170 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 99/200\n",
      "172/172 [==============================] - 0s 848us/sample - loss: 0.5172 - accuracy: 0.7791 - val_loss: 0.5097 - val_accuracy: 0.7829\n",
      "Epoch 100/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 0.5200 - accuracy: 0.7791 - val_loss: 0.5105 - val_accuracy: 0.7829\n",
      "Epoch 101/200\n",
      "172/172 [==============================] - 0s 843us/sample - loss: 0.5177 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 102/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 0.5169 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 103/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 104/200\n",
      "172/172 [==============================] - 0s 928us/sample - loss: 0.5176 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 105/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 106/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 0.5199 - accuracy: 0.7791 - val_loss: 0.5099 - val_accuracy: 0.7829\n",
      "Epoch 107/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5102 - val_accuracy: 0.7829\n",
      "Epoch 108/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 0.5193 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 109/200\n",
      "172/172 [==============================] - 0s 843us/sample - loss: 0.5176 - accuracy: 0.7791 - val_loss: 0.5099 - val_accuracy: 0.7829\n",
      "Epoch 110/200\n",
      "172/172 [==============================] - 0s 857us/sample - loss: 0.5173 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 111/200\n",
      "172/172 [==============================] - 0s 844us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 112/200\n",
      "172/172 [==============================] - 0s 843us/sample - loss: 0.5171 - accuracy: 0.7791 - val_loss: 0.5096 - val_accuracy: 0.7829\n",
      "Epoch 113/200\n",
      "172/172 [==============================] - 0s 842us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 114/200\n",
      "172/172 [==============================] - 0s 849us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 115/200\n",
      "172/172 [==============================] - 0s 850us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 116/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 0.5168 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 117/200\n",
      "172/172 [==============================] - 0s 860us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 118/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5096 - val_accuracy: 0.7829\n",
      "Epoch 119/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 120/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5096 - val_accuracy: 0.7829\n",
      "Epoch 121/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5100 - val_accuracy: 0.7829\n",
      "Epoch 122/200\n",
      "172/172 [==============================] - 0s 839us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5115 - val_accuracy: 0.7829\n",
      "Epoch 123/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 0.5175 - accuracy: 0.7791 - val_loss: 0.5102 - val_accuracy: 0.7829\n",
      "Epoch 124/200\n",
      "172/172 [==============================] - 0s 844us/sample - loss: 0.5171 - accuracy: 0.7791 - val_loss: 0.5105 - val_accuracy: 0.7829\n",
      "Epoch 125/200\n",
      "172/172 [==============================] - 0s 848us/sample - loss: 0.5182 - accuracy: 0.7791 - val_loss: 0.5114 - val_accuracy: 0.7829\n",
      "Epoch 126/200\n",
      "172/172 [==============================] - 0s 840us/sample - loss: 0.5171 - accuracy: 0.7791 - val_loss: 0.5101 - val_accuracy: 0.7829\n",
      "Epoch 127/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 850us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5098 - val_accuracy: 0.7829\n",
      "Epoch 128/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 129/200\n",
      "172/172 [==============================] - 0s 859us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 130/200\n",
      "172/172 [==============================] - 0s 844us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 131/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 132/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 133/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 134/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.5183 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 135/200\n",
      "172/172 [==============================] - 0s 839us/sample - loss: 0.5169 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 136/200\n",
      "172/172 [==============================] - 0s 842us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 137/200\n",
      "172/172 [==============================] - 0s 844us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 138/200\n",
      "172/172 [==============================] - 0s 838us/sample - loss: 0.5181 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 139/200\n",
      "172/172 [==============================] - 0s 844us/sample - loss: 0.5174 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 140/200\n",
      "172/172 [==============================] - 0s 845us/sample - loss: 0.5183 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 141/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.5176 - accuracy: 0.7791 - val_loss: 0.5107 - val_accuracy: 0.7829\n",
      "Epoch 142/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.5169 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 143/200\n",
      "172/172 [==============================] - 0s 844us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 144/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.5177 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 145/200\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 146/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 147/200\n",
      "172/172 [==============================] - 0s 859us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 148/200\n",
      "172/172 [==============================] - 0s 842us/sample - loss: 0.5169 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 149/200\n",
      "172/172 [==============================] - 0s 844us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 150/200\n",
      "172/172 [==============================] - 0s 845us/sample - loss: 0.5158 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 151/200\n",
      "172/172 [==============================] - 0s 843us/sample - loss: 0.5169 - accuracy: 0.7791 - val_loss: 0.5106 - val_accuracy: 0.7829\n",
      "Epoch 152/200\n",
      "172/172 [==============================] - 0s 845us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 153/200\n",
      "172/172 [==============================] - 0s 845us/sample - loss: 0.5173 - accuracy: 0.7791 - val_loss: 0.5096 - val_accuracy: 0.7829\n",
      "Epoch 154/200\n",
      "172/172 [==============================] - 0s 848us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 155/200\n",
      "172/172 [==============================] - 0s 842us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 156/200\n",
      "172/172 [==============================] - 0s 854us/sample - loss: 0.5178 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 157/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 158/200\n",
      "172/172 [==============================] - 0s 963us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 159/200\n",
      "172/172 [==============================] - 0s 969us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 160/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 161/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 0.5174 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 162/200\n",
      "172/172 [==============================] - 0s 849us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 163/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.5170 - accuracy: 0.7791 - val_loss: 0.5098 - val_accuracy: 0.7829\n",
      "Epoch 164/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 0.5176 - accuracy: 0.7791 - val_loss: 0.5112 - val_accuracy: 0.7829\n",
      "Epoch 165/200\n",
      "172/172 [==============================] - 0s 840us/sample - loss: 0.5172 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 166/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.5155 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 167/200\n",
      "172/172 [==============================] - 0s 850us/sample - loss: 0.5169 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 168/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.5186 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 169/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 170/200\n",
      "172/172 [==============================] - 0s 862us/sample - loss: 0.5158 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 171/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 172/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 0.5168 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 173/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 174/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 175/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 176/200\n",
      "172/172 [==============================] - 0s 845us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 177/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 178/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.5170 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 179/200\n",
      "172/172 [==============================] - 0s 849us/sample - loss: 0.5171 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 180/200\n",
      "172/172 [==============================] - 0s 862us/sample - loss: 0.5180 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 181/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 182/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 857us/sample - loss: 0.5186 - accuracy: 0.7791 - val_loss: 0.5097 - val_accuracy: 0.7829\n",
      "Epoch 183/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 184/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 185/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5085 - val_accuracy: 0.7829\n",
      "Epoch 186/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 187/200\n",
      "172/172 [==============================] - 0s 965us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5084 - val_accuracy: 0.7829\n",
      "Epoch 188/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 189/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 190/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.5176 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 191/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 192/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 0.5171 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 193/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.5172 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 194/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.5170 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 195/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 196/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5187 - accuracy: 0.7791 - val_loss: 0.5110 - val_accuracy: 0.7829\n",
      "Epoch 197/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 198/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 199/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 200/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Beginning training for dr=0.010, l_lambda=1.0e-02, reg_type=l2, act: relu\n",
      "Train on 172 samples, validate on 43 samples\n",
      "Epoch 1/200\n",
      "172/172 [==============================] - 1s 8ms/sample - loss: 0.8834 - accuracy: 0.6667 - val_loss: 0.7623 - val_accuracy: 0.6667\n",
      "Epoch 2/200\n",
      "172/172 [==============================] - 0s 834us/sample - loss: 0.7145 - accuracy: 0.6667 - val_loss: 0.6642 - val_accuracy: 0.6667\n",
      "Epoch 3/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 0.6336 - accuracy: 0.7074 - val_loss: 0.5980 - val_accuracy: 0.7829\n",
      "Epoch 4/200\n",
      "172/172 [==============================] - 0s 836us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5576 - val_accuracy: 0.7829\n",
      "Epoch 5/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 0.5534 - accuracy: 0.7791 - val_loss: 0.5366 - val_accuracy: 0.7829\n",
      "Epoch 6/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.5365 - accuracy: 0.7791 - val_loss: 0.5246 - val_accuracy: 0.7829\n",
      "Epoch 7/200\n",
      "172/172 [==============================] - 0s 806us/sample - loss: 0.5271 - accuracy: 0.7791 - val_loss: 0.5166 - val_accuracy: 0.7829\n",
      "Epoch 8/200\n",
      "172/172 [==============================] - 0s 820us/sample - loss: 0.5209 - accuracy: 0.7791 - val_loss: 0.5115 - val_accuracy: 0.7829\n",
      "Epoch 9/200\n",
      "172/172 [==============================] - 0s 853us/sample - loss: 0.5170 - accuracy: 0.7791 - val_loss: 0.5080 - val_accuracy: 0.7829\n",
      "Epoch 10/200\n",
      "172/172 [==============================] - 0s 860us/sample - loss: 0.5140 - accuracy: 0.7791 - val_loss: 0.5059 - val_accuracy: 0.7829\n",
      "Epoch 11/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.5124 - accuracy: 0.7791 - val_loss: 0.5045 - val_accuracy: 0.7829\n",
      "Epoch 12/200\n",
      "172/172 [==============================] - 0s 952us/sample - loss: 0.5113 - accuracy: 0.7791 - val_loss: 0.5035 - val_accuracy: 0.7829\n",
      "Epoch 13/200\n",
      "172/172 [==============================] - 0s 957us/sample - loss: 0.5122 - accuracy: 0.7791 - val_loss: 0.5039 - val_accuracy: 0.7829\n",
      "Epoch 14/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.5105 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 15/200\n",
      "172/172 [==============================] - 0s 848us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 16/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 17/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 18/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.5116 - accuracy: 0.7791 - val_loss: 0.5029 - val_accuracy: 0.7829\n",
      "Epoch 19/200\n",
      "172/172 [==============================] - 0s 882us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 20/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 21/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 22/200\n",
      "172/172 [==============================] - 0s 928us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 23/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 24/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 25/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 26/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 27/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5029 - val_accuracy: 0.7829\n",
      "Epoch 28/200\n",
      "172/172 [==============================] - 0s 958us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 29/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.5085 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 30/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 31/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 32/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5032 - val_accuracy: 0.7829\n",
      "Epoch 33/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 34/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.5102 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 35/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 36/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/200\n",
      "172/172 [==============================] - 0s 972us/sample - loss: 0.5086 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 38/200\n",
      "172/172 [==============================] - 0s 949us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 39/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5104 - accuracy: 0.7791 - val_loss: 0.5034 - val_accuracy: 0.7829\n",
      "Epoch 40/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5028 - val_accuracy: 0.7829\n",
      "Epoch 41/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 42/200\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 43/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5029 - val_accuracy: 0.7829\n",
      "Epoch 44/200\n",
      "172/172 [==============================] - 0s 977us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 45/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 46/200\n",
      "172/172 [==============================] - 0s 977us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 47/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 48/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 49/200\n",
      "172/172 [==============================] - 0s 976us/sample - loss: 0.5086 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 50/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 51/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 52/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 53/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 54/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 55/200\n",
      "172/172 [==============================] - 0s 858us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 56/200\n",
      "172/172 [==============================] - 0s 860us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 57/200\n",
      "172/172 [==============================] - 0s 968us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 58/200\n",
      "172/172 [==============================] - 0s 993us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 59/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 60/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 61/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 62/200\n",
      "172/172 [==============================] - 0s 943us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 63/200\n",
      "172/172 [==============================] - 0s 940us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 64/200\n",
      "172/172 [==============================] - 0s 969us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 65/200\n",
      "172/172 [==============================] - 0s 955us/sample - loss: 0.5086 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 66/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 67/200\n",
      "172/172 [==============================] - 0s 981us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 68/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 69/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 70/200\n",
      "172/172 [==============================] - 0s 857us/sample - loss: 0.5104 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 71/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 72/200\n",
      "172/172 [==============================] - 0s 962us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 73/200\n",
      "172/172 [==============================] - 0s 856us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 74/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 75/200\n",
      "172/172 [==============================] - 0s 977us/sample - loss: 0.5085 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 76/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 77/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 78/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 79/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 80/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 81/200\n",
      "172/172 [==============================] - 0s 986us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 82/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 83/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 84/200\n",
      "172/172 [==============================] - 0s 940us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 85/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 86/200\n",
      "172/172 [==============================] - 0s 951us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 87/200\n",
      "172/172 [==============================] - 0s 941us/sample - loss: 0.5104 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 88/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 89/200\n",
      "172/172 [==============================] - 0s 858us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5030 - val_accuracy: 0.7829\n",
      "Epoch 90/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5026 - val_accuracy: 0.7829\n",
      "Epoch 91/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 92/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 873us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 93/200\n",
      "172/172 [==============================] - 0s 937us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5029 - val_accuracy: 0.7829\n",
      "Epoch 94/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 95/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 96/200\n",
      "172/172 [==============================] - 0s 882us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 97/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 98/200\n",
      "172/172 [==============================] - 0s 850us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 99/200\n",
      "172/172 [==============================] - 0s 941us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 100/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 101/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 102/200\n",
      "172/172 [==============================] - 0s 865us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 103/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 104/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 105/200\n",
      "172/172 [==============================] - 0s 858us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 106/200\n",
      "172/172 [==============================] - 0s 862us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 107/200\n",
      "172/172 [==============================] - 0s 956us/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 108/200\n",
      "172/172 [==============================] - 0s 984us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 109/200\n",
      "172/172 [==============================] - 0s 974us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 110/200\n",
      "172/172 [==============================] - 0s 940us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 111/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 112/200\n",
      "172/172 [==============================] - 0s 973us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 113/200\n",
      "172/172 [==============================] - 0s 959us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 114/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 115/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 116/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 117/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 118/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 119/200\n",
      "172/172 [==============================] - 0s 865us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 120/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 121/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 122/200\n",
      "172/172 [==============================] - 0s 860us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 123/200\n",
      "172/172 [==============================] - 0s 864us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 124/200\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 125/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 126/200\n",
      "172/172 [==============================] - 0s 937us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 127/200\n",
      "172/172 [==============================] - 0s 839us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 128/200\n",
      "172/172 [==============================] - 0s 836us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 129/200\n",
      "172/172 [==============================] - 0s 831us/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5031 - val_accuracy: 0.7829\n",
      "Epoch 130/200\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 131/200\n",
      "172/172 [==============================] - 0s 837us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 132/200\n",
      "172/172 [==============================] - 0s 835us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 133/200\n",
      "172/172 [==============================] - 0s 862us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 134/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5105 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 135/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 136/200\n",
      "172/172 [==============================] - 0s 836us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5029 - val_accuracy: 0.7829\n",
      "Epoch 137/200\n",
      "172/172 [==============================] - 0s 930us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 138/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 139/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 140/200\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 141/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 142/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 143/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 144/200\n",
      "172/172 [==============================] - 0s 858us/sample - loss: 0.5107 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 145/200\n",
      "172/172 [==============================] - 0s 856us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 146/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.5104 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 147/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 910us/sample - loss: 0.5111 - accuracy: 0.7791 - val_loss: 0.5031 - val_accuracy: 0.7829\n",
      "Epoch 148/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5028 - val_accuracy: 0.7829\n",
      "Epoch 149/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 150/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 151/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 152/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 153/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5026 - val_accuracy: 0.7829\n",
      "Epoch 154/200\n",
      "172/172 [==============================] - 0s 861us/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 155/200\n",
      "172/172 [==============================] - 0s 864us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 156/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.5102 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 157/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 158/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 159/200\n",
      "172/172 [==============================] - 0s 864us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 160/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 161/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 162/200\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 163/200\n",
      "172/172 [==============================] - 0s 928us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 164/200\n",
      "172/172 [==============================] - 0s 942us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 165/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 166/200\n",
      "172/172 [==============================] - 0s 984us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 167/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 168/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 169/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 170/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 171/200\n",
      "172/172 [==============================] - 0s 859us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 172/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 173/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 174/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 175/200\n",
      "172/172 [==============================] - 0s 993us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 176/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 177/200\n",
      "172/172 [==============================] - 0s 982us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 178/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 179/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 180/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 181/200\n",
      "172/172 [==============================] - 0s 882us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 182/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 183/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 184/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 185/200\n",
      "172/172 [==============================] - 0s 861us/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 186/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 187/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 188/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 189/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5128 - accuracy: 0.7791 - val_loss: 0.5033 - val_accuracy: 0.7829\n",
      "Epoch 190/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 191/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 192/200\n",
      "172/172 [==============================] - 0s 862us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 193/200\n",
      "172/172 [==============================] - 0s 861us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5014 - val_accuracy: 0.7829\n",
      "Epoch 194/200\n",
      "172/172 [==============================] - 0s 862us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 195/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 196/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 197/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 198/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 199/200\n",
      "172/172 [==============================] - 0s 862us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 200/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Beginning training for dr=0.010, l_lambda=1.0e-02, reg_type=l2, act: tanh\n",
      "Train on 172 samples, validate on 43 samples\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 2s 10ms/sample - loss: 0.8704 - accuracy: 0.6667 - val_loss: 0.7300 - val_accuracy: 0.6667\n",
      "Epoch 2/200\n",
      "172/172 [==============================] - 0s 957us/sample - loss: 0.6699 - accuracy: 0.7248 - val_loss: 0.6143 - val_accuracy: 0.7829\n",
      "Epoch 3/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 0.5996 - accuracy: 0.7791 - val_loss: 0.5725 - val_accuracy: 0.7829\n",
      "Epoch 4/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 0.5683 - accuracy: 0.7791 - val_loss: 0.5489 - val_accuracy: 0.7829\n",
      "Epoch 5/200\n",
      "172/172 [==============================] - 0s 822us/sample - loss: 0.5494 - accuracy: 0.7791 - val_loss: 0.5343 - val_accuracy: 0.7829\n",
      "Epoch 6/200\n",
      "172/172 [==============================] - 0s 810us/sample - loss: 0.5364 - accuracy: 0.7791 - val_loss: 0.5250 - val_accuracy: 0.7829\n",
      "Epoch 7/200\n",
      "172/172 [==============================] - 0s 853us/sample - loss: 0.5279 - accuracy: 0.7791 - val_loss: 0.5164 - val_accuracy: 0.7829\n",
      "Epoch 8/200\n",
      "172/172 [==============================] - 0s 806us/sample - loss: 0.5216 - accuracy: 0.7791 - val_loss: 0.5115 - val_accuracy: 0.7829\n",
      "Epoch 9/200\n",
      "172/172 [==============================] - 0s 817us/sample - loss: 0.5181 - accuracy: 0.7791 - val_loss: 0.5081 - val_accuracy: 0.7829\n",
      "Epoch 10/200\n",
      "172/172 [==============================] - 0s 813us/sample - loss: 0.5151 - accuracy: 0.7791 - val_loss: 0.5071 - val_accuracy: 0.7829\n",
      "Epoch 11/200\n",
      "172/172 [==============================] - 0s 834us/sample - loss: 0.5127 - accuracy: 0.7791 - val_loss: 0.5045 - val_accuracy: 0.7829\n",
      "Epoch 12/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.5120 - accuracy: 0.7791 - val_loss: 0.5034 - val_accuracy: 0.7829\n",
      "Epoch 13/200\n",
      "172/172 [==============================] - 0s 840us/sample - loss: 0.5102 - accuracy: 0.7791 - val_loss: 0.5036 - val_accuracy: 0.7829\n",
      "Epoch 14/200\n",
      "172/172 [==============================] - 0s 835us/sample - loss: 0.5105 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 15/200\n",
      "172/172 [==============================] - 0s 827us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 16/200\n",
      "172/172 [==============================] - 0s 937us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 17/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 18/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 19/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 20/200\n",
      "172/172 [==============================] - 0s 862us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 21/200\n",
      "172/172 [==============================] - 0s 827us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 22/200\n",
      "172/172 [==============================] - 0s 815us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 23/200\n",
      "172/172 [==============================] - 0s 822us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 24/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 25/200\n",
      "172/172 [==============================] - 0s 815us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 26/200\n",
      "172/172 [==============================] - 0s 827us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 27/200\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 0.5112 - accuracy: 0.7791 - val_loss: 0.5033 - val_accuracy: 0.7829\n",
      "Epoch 28/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 29/200\n",
      "172/172 [==============================] - 0s 969us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 30/200\n",
      "172/172 [==============================] - 0s 974us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 31/200\n",
      "172/172 [==============================] - 0s 976us/sample - loss: 0.5106 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 32/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 33/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 34/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 35/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 36/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 37/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 38/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 39/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 40/200\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 41/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.5104 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 42/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 43/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 44/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 45/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 0.5085 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 46/200\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 0.5110 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 47/200\n",
      "172/172 [==============================] - 0s 947us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 48/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.5115 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 49/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 50/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 51/200\n",
      "172/172 [==============================] - 0s 953us/sample - loss: 0.5122 - accuracy: 0.7791 - val_loss: 0.5038 - val_accuracy: 0.7829\n",
      "Epoch 52/200\n",
      "172/172 [==============================] - 0s 988us/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5030 - val_accuracy: 0.7829\n",
      "Epoch 53/200\n",
      "172/172 [==============================] - 0s 970us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 54/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5029 - val_accuracy: 0.7829\n",
      "Epoch 55/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 56/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 57/200\n",
      "172/172 [==============================] - 0s 973us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 58/200\n",
      "172/172 [==============================] - 0s 981us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 59/200\n",
      "172/172 [==============================] - 0s 959us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 60/200\n",
      "172/172 [==============================] - 0s 941us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5026 - val_accuracy: 0.7829\n",
      "Epoch 61/200\n",
      "172/172 [==============================] - 0s 956us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 62/200\n",
      "172/172 [==============================] - 0s 937us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 63/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 64/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5102 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 65/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 66/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5126 - accuracy: 0.7791 - val_loss: 0.5036 - val_accuracy: 0.7829\n",
      "Epoch 67/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 68/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 69/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 70/200\n",
      "172/172 [==============================] - 0s 945us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5028 - val_accuracy: 0.7829\n",
      "Epoch 71/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.5109 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 72/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 73/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 74/200\n",
      "172/172 [==============================] - 0s 948us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 75/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 76/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 77/200\n",
      "172/172 [==============================] - 0s 997us/sample - loss: 0.5105 - accuracy: 0.7791 - val_loss: 0.5039 - val_accuracy: 0.7829\n",
      "Epoch 78/200\n",
      "172/172 [==============================] - 0s 970us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 79/200\n",
      "172/172 [==============================] - 0s 941us/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 80/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 81/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 82/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5124 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 83/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5108 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 84/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 85/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5106 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 86/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 87/200\n",
      "172/172 [==============================] - 0s 937us/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 88/200\n",
      "172/172 [==============================] - 0s 976us/sample - loss: 0.5105 - accuracy: 0.7791 - val_loss: 0.5029 - val_accuracy: 0.7829\n",
      "Epoch 89/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5086 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 90/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 91/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 92/200\n",
      "172/172 [==============================] - 0s 942us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 93/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.5104 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 94/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 95/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 96/200\n",
      "172/172 [==============================] - 0s 944us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 97/200\n",
      "172/172 [==============================] - 0s 952us/sample - loss: 0.5109 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 98/200\n",
      "172/172 [==============================] - 0s 956us/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 99/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5113 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 100/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 101/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5107 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 102/200\n",
      "172/172 [==============================] - 0s 972us/sample - loss: 0.5109 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 103/200\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5029 - val_accuracy: 0.7829\n",
      "Epoch 104/200\n",
      "172/172 [==============================] - 0s 978us/sample - loss: 0.5107 - accuracy: 0.7791 - val_loss: 0.5041 - val_accuracy: 0.7829\n",
      "Epoch 105/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 0.5106 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 106/200\n",
      "172/172 [==============================] - 0s 970us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 107/200\n",
      "172/172 [==============================] - 0s 942us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 108/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 109/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 110/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.5117 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 111/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 900us/sample - loss: 0.5086 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 112/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5035 - val_accuracy: 0.7829\n",
      "Epoch 113/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5116 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 114/200\n",
      "172/172 [==============================] - 0s 952us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 115/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.5116 - accuracy: 0.7791 - val_loss: 0.5026 - val_accuracy: 0.7829\n",
      "Epoch 116/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 117/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 118/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 119/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 120/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 121/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 122/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 123/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.5129 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 124/200\n",
      "172/172 [==============================] - 0s 1000us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 125/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.5108 - accuracy: 0.7791 - val_loss: 0.5039 - val_accuracy: 0.7829\n",
      "Epoch 126/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 127/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 128/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 129/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 130/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 131/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5033 - val_accuracy: 0.7829\n",
      "Epoch 132/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 0.5108 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 133/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 134/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 135/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 136/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 137/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 138/200\n",
      "172/172 [==============================] - 0s 949us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 139/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.5113 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 140/200\n",
      "172/172 [==============================] - 0s 859us/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 141/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 142/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5106 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 143/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5026 - val_accuracy: 0.7829\n",
      "Epoch 144/200\n",
      "172/172 [==============================] - 0s 960us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5029 - val_accuracy: 0.7829\n",
      "Epoch 145/200\n",
      "172/172 [==============================] - 0s 1000us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 146/200\n",
      "172/172 [==============================] - 0s 994us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 147/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5104 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 148/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 149/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 150/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 151/200\n",
      "172/172 [==============================] - 0s 987us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 152/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 153/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 154/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 155/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 156/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.5104 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 157/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 158/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 159/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 160/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5031 - val_accuracy: 0.7829\n",
      "Epoch 161/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 162/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 163/200\n",
      "172/172 [==============================] - 0s 940us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 164/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5138 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 165/200\n",
      "172/172 [==============================] - 0s 882us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 166/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 924us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 167/200\n",
      "172/172 [==============================] - 0s 996us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 168/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 169/200\n",
      "172/172 [==============================] - 0s 971us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 170/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 171/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5013 - val_accuracy: 0.7829\n",
      "Epoch 172/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 173/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 174/200\n",
      "172/172 [==============================] - 0s 951us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 175/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 176/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 177/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 178/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 179/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5014 - val_accuracy: 0.7829\n",
      "Epoch 180/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 181/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 182/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.5086 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 183/200\n",
      "172/172 [==============================] - 0s 948us/sample - loss: 0.5102 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 184/200\n",
      "172/172 [==============================] - 0s 941us/sample - loss: 0.5113 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 185/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5029 - val_accuracy: 0.7829\n",
      "Epoch 186/200\n",
      "172/172 [==============================] - 0s 961us/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5030 - val_accuracy: 0.7829\n",
      "Epoch 187/200\n",
      "172/172 [==============================] - 0s 946us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 188/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 189/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 190/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.5110 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 191/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 192/200\n",
      "172/172 [==============================] - 0s 869us/sample - loss: 0.5111 - accuracy: 0.7791 - val_loss: 0.5026 - val_accuracy: 0.7829\n",
      "Epoch 193/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 194/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.5111 - accuracy: 0.7791 - val_loss: 0.5047 - val_accuracy: 0.7829\n",
      "Epoch 195/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.5115 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 196/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 197/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 0.5118 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 198/200\n",
      "172/172 [==============================] - 0s 955us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 199/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 200/200\n",
      "172/172 [==============================] - 0s 952us/sample - loss: 0.5084 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Beginning training for dr=0.010, l_lambda=1.0e-02, reg_type=l1, act: relu\n",
      "Train on 172 samples, validate on 43 samples\n",
      "Epoch 1/200\n",
      "172/172 [==============================] - 1s 8ms/sample - loss: 7.7019 - accuracy: 0.6667 - val_loss: 4.1532 - val_accuracy: 0.6667\n",
      "Epoch 2/200\n",
      "172/172 [==============================] - 0s 983us/sample - loss: 2.8821 - accuracy: 0.6667 - val_loss: 2.1904 - val_accuracy: 0.6667\n",
      "Epoch 3/200\n",
      "172/172 [==============================] - 0s 973us/sample - loss: 1.8170 - accuracy: 0.7132 - val_loss: 1.4976 - val_accuracy: 0.7829\n",
      "Epoch 4/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 1.3362 - accuracy: 0.7791 - val_loss: 1.1661 - val_accuracy: 0.7829\n",
      "Epoch 5/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 1.0730 - accuracy: 0.7791 - val_loss: 0.9606 - val_accuracy: 0.7829\n",
      "Epoch 6/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 0.8956 - accuracy: 0.7791 - val_loss: 0.8069 - val_accuracy: 0.7829\n",
      "Epoch 7/200\n",
      "172/172 [==============================] - 0s 837us/sample - loss: 0.7595 - accuracy: 0.7791 - val_loss: 0.6956 - val_accuracy: 0.7829\n",
      "Epoch 8/200\n",
      "172/172 [==============================] - 0s 841us/sample - loss: 0.6616 - accuracy: 0.7791 - val_loss: 0.6175 - val_accuracy: 0.7829\n",
      "Epoch 9/200\n",
      "172/172 [==============================] - 0s 837us/sample - loss: 0.6057 - accuracy: 0.7791 - val_loss: 0.5841 - val_accuracy: 0.7829\n",
      "Epoch 10/200\n",
      "172/172 [==============================] - 0s 831us/sample - loss: 0.5882 - accuracy: 0.7791 - val_loss: 0.5778 - val_accuracy: 0.7829\n",
      "Epoch 11/200\n",
      "172/172 [==============================] - 0s 840us/sample - loss: 0.5835 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 12/200\n",
      "172/172 [==============================] - 0s 839us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 13/200\n",
      "172/172 [==============================] - 0s 831us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 14/200\n",
      "172/172 [==============================] - 0s 839us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 15/200\n",
      "172/172 [==============================] - 0s 977us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5771 - val_accuracy: 0.7829\n",
      "Epoch 16/200\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 17/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.5834 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 18/200\n",
      "172/172 [==============================] - 0s 841us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 19/200\n",
      "172/172 [==============================] - 0s 837us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 20/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 843us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5750 - val_accuracy: 0.7829\n",
      "Epoch 21/200\n",
      "172/172 [==============================] - 0s 834us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 22/200\n",
      "172/172 [==============================] - 0s 834us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 23/200\n",
      "172/172 [==============================] - 0s 834us/sample - loss: 0.5832 - accuracy: 0.7791 - val_loss: 0.5778 - val_accuracy: 0.7829\n",
      "Epoch 24/200\n",
      "172/172 [==============================] - 0s 832us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 25/200\n",
      "172/172 [==============================] - 0s 829us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 26/200\n",
      "172/172 [==============================] - 0s 838us/sample - loss: 0.5834 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 27/200\n",
      "172/172 [==============================] - 0s 836us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5769 - val_accuracy: 0.7829\n",
      "Epoch 28/200\n",
      "172/172 [==============================] - 0s 865us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 29/200\n",
      "172/172 [==============================] - 0s 949us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 30/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 31/200\n",
      "172/172 [==============================] - 0s 835us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 32/200\n",
      "172/172 [==============================] - 0s 810us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 33/200\n",
      "172/172 [==============================] - 0s 835us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 34/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 35/200\n",
      "172/172 [==============================] - 0s 829us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5776 - val_accuracy: 0.7829\n",
      "Epoch 36/200\n",
      "172/172 [==============================] - 0s 810us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5752 - val_accuracy: 0.7829\n",
      "Epoch 37/200\n",
      "172/172 [==============================] - 0s 811us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 38/200\n",
      "172/172 [==============================] - 0s 817us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 39/200\n",
      "172/172 [==============================] - 0s 817us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 40/200\n",
      "172/172 [==============================] - 0s 812us/sample - loss: 0.5833 - accuracy: 0.7791 - val_loss: 0.5747 - val_accuracy: 0.7829\n",
      "Epoch 41/200\n",
      "172/172 [==============================] - 0s 806us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 42/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 43/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 44/200\n",
      "172/172 [==============================] - 0s 882us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 45/200\n",
      "172/172 [==============================] - 0s 814us/sample - loss: 0.5839 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 46/200\n",
      "172/172 [==============================] - 0s 804us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5771 - val_accuracy: 0.7829\n",
      "Epoch 47/200\n",
      "172/172 [==============================] - 0s 814us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 48/200\n",
      "172/172 [==============================] - 0s 808us/sample - loss: 0.5833 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 49/200\n",
      "172/172 [==============================] - 0s 804us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 50/200\n",
      "172/172 [==============================] - 0s 810us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 51/200\n",
      "172/172 [==============================] - 0s 808us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 52/200\n",
      "172/172 [==============================] - 0s 813us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5751 - val_accuracy: 0.7829\n",
      "Epoch 53/200\n",
      "172/172 [==============================] - 0s 808us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 54/200\n",
      "172/172 [==============================] - 0s 833us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 55/200\n",
      "172/172 [==============================] - 0s 827us/sample - loss: 0.5813 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 56/200\n",
      "172/172 [==============================] - 0s 967us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5751 - val_accuracy: 0.7829\n",
      "Epoch 57/200\n",
      "172/172 [==============================] - 0s 928us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 58/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.5832 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 59/200\n",
      "172/172 [==============================] - 0s 882us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 60/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5751 - val_accuracy: 0.7829\n",
      "Epoch 61/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5752 - val_accuracy: 0.7829\n",
      "Epoch 62/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5750 - val_accuracy: 0.7829\n",
      "Epoch 63/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 0.5817 - accuracy: 0.7791 - val_loss: 0.5771 - val_accuracy: 0.7829\n",
      "Epoch 64/200\n",
      "172/172 [==============================] - 0s 882us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 65/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 0.5818 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 66/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5752 - val_accuracy: 0.7829\n",
      "Epoch 67/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.5818 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 68/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.5835 - accuracy: 0.7791 - val_loss: 0.5752 - val_accuracy: 0.7829\n",
      "Epoch 69/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5817 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 70/200\n",
      "172/172 [==============================] - 0s 962us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5751 - val_accuracy: 0.7829\n",
      "Epoch 71/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.5832 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 72/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 73/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 74/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 75/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 887us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 76/200\n",
      "172/172 [==============================] - 0s 882us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5748 - val_accuracy: 0.7829\n",
      "Epoch 77/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5768 - val_accuracy: 0.7829\n",
      "Epoch 78/200\n",
      "172/172 [==============================] - 0s 860us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 79/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 80/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.5836 - accuracy: 0.7791 - val_loss: 0.5750 - val_accuracy: 0.7829\n",
      "Epoch 81/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5752 - val_accuracy: 0.7829\n",
      "Epoch 82/200\n",
      "172/172 [==============================] - 0s 985us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5752 - val_accuracy: 0.7829\n",
      "Epoch 83/200\n",
      "172/172 [==============================] - 0s 928us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 84/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5752 - val_accuracy: 0.7829\n",
      "Epoch 85/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 0.5820 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 86/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 87/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 88/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 89/200\n",
      "172/172 [==============================] - 0s 963us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5751 - val_accuracy: 0.7829\n",
      "Epoch 90/200\n",
      "172/172 [==============================] - 0s 859us/sample - loss: 0.5848 - accuracy: 0.7791 - val_loss: 0.5747 - val_accuracy: 0.7829\n",
      "Epoch 91/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 92/200\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 93/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 94/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 95/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 96/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5747 - val_accuracy: 0.7829\n",
      "Epoch 97/200\n",
      "172/172 [==============================] - 0s 858us/sample - loss: 0.5820 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 98/200\n",
      "172/172 [==============================] - 0s 857us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 99/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 100/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 101/200\n",
      "172/172 [==============================] - 0s 980us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5750 - val_accuracy: 0.7829\n",
      "Epoch 102/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5819 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 103/200\n",
      "172/172 [==============================] - 0s 983us/sample - loss: 0.5836 - accuracy: 0.7791 - val_loss: 0.5769 - val_accuracy: 0.7829\n",
      "Epoch 104/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5752 - val_accuracy: 0.7829\n",
      "Epoch 105/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5771 - val_accuracy: 0.7829\n",
      "Epoch 106/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 107/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5820 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 108/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5838 - accuracy: 0.7791 - val_loss: 0.5751 - val_accuracy: 0.7829\n",
      "Epoch 109/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.5820 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 110/200\n",
      "172/172 [==============================] - 0s 980us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5746 - val_accuracy: 0.7829\n",
      "Epoch 111/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 112/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5751 - val_accuracy: 0.7829\n",
      "Epoch 113/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 114/200\n",
      "172/172 [==============================] - 0s 954us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5767 - val_accuracy: 0.7829\n",
      "Epoch 115/200\n",
      "172/172 [==============================] - 0s 993us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 116/200\n",
      "172/172 [==============================] - 0s 998us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 117/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5835 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 118/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5819 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 119/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5774 - val_accuracy: 0.7829\n",
      "Epoch 120/200\n",
      "172/172 [==============================] - 0s 942us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 121/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 122/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 123/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 0.5847 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 124/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.5833 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 125/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.5817 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 126/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5752 - val_accuracy: 0.7829\n",
      "Epoch 127/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 128/200\n",
      "172/172 [==============================] - 0s 969us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 129/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 130/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 987us/sample - loss: 0.5819 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 131/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 132/200\n",
      "172/172 [==============================] - 0s 951us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5751 - val_accuracy: 0.7829\n",
      "Epoch 133/200\n",
      "172/172 [==============================] - 0s 967us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5776 - val_accuracy: 0.7829\n",
      "Epoch 134/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 135/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 136/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5745 - val_accuracy: 0.7829\n",
      "Epoch 137/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 138/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 139/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 140/200\n",
      "172/172 [==============================] - 0s 930us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 141/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5834 - accuracy: 0.7791 - val_loss: 0.5771 - val_accuracy: 0.7829\n",
      "Epoch 142/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5838 - accuracy: 0.7791 - val_loss: 0.5777 - val_accuracy: 0.7829\n",
      "Epoch 143/200\n",
      "172/172 [==============================] - 0s 990us/sample - loss: 0.5837 - accuracy: 0.7791 - val_loss: 0.5785 - val_accuracy: 0.7829\n",
      "Epoch 144/200\n",
      "172/172 [==============================] - 0s 937us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 145/200\n",
      "172/172 [==============================] - 0s 966us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 146/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.5820 - accuracy: 0.7791 - val_loss: 0.5750 - val_accuracy: 0.7829\n",
      "Epoch 147/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5778 - val_accuracy: 0.7829\n",
      "Epoch 148/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.5833 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 149/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5844 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 150/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 151/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 152/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5833 - accuracy: 0.7791 - val_loss: 0.5750 - val_accuracy: 0.7829\n",
      "Epoch 153/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5819 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 154/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 155/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5832 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 156/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.5820 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 157/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5752 - val_accuracy: 0.7829\n",
      "Epoch 158/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 159/200\n",
      "172/172 [==============================] - 0s 989us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 160/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5746 - val_accuracy: 0.7829\n",
      "Epoch 161/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5767 - val_accuracy: 0.7829\n",
      "Epoch 162/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 163/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5772 - val_accuracy: 0.7829\n",
      "Epoch 164/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 165/200\n",
      "172/172 [==============================] - 0s 951us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 166/200\n",
      "172/172 [==============================] - 0s 974us/sample - loss: 0.5845 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 167/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 168/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5751 - val_accuracy: 0.7829\n",
      "Epoch 169/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 170/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 171/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 0.5833 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 172/200\n",
      "172/172 [==============================] - 0s 864us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 173/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 174/200\n",
      "172/172 [==============================] - 0s 928us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 175/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5782 - val_accuracy: 0.7829\n",
      "Epoch 176/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5832 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 177/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5820 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 178/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 179/200\n",
      "172/172 [==============================] - 0s 940us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 180/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5746 - val_accuracy: 0.7829\n",
      "Epoch 181/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 182/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 183/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5775 - val_accuracy: 0.7829\n",
      "Epoch 184/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 185/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 885us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 186/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 0.5820 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 187/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 188/200\n",
      "172/172 [==============================] - 0s 998us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5747 - val_accuracy: 0.7829\n",
      "Epoch 189/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5767 - val_accuracy: 0.7829\n",
      "Epoch 190/200\n",
      "172/172 [==============================] - 0s 960us/sample - loss: 0.5819 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 191/200\n",
      "172/172 [==============================] - 0s 940us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 192/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5750 - val_accuracy: 0.7829\n",
      "Epoch 193/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 194/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 0.5862 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 195/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.5815 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 196/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5746 - val_accuracy: 0.7829\n",
      "Epoch 197/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.5820 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 198/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 0.5820 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 199/200\n",
      "172/172 [==============================] - 0s 947us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 200/200\n",
      "172/172 [==============================] - 0s 953us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Beginning training for dr=0.010, l_lambda=1.0e-02, reg_type=l1, act: tanh\n",
      "Train on 172 samples, validate on 43 samples\n",
      "Epoch 1/200\n",
      "172/172 [==============================] - 1s 8ms/sample - loss: 7.6754 - accuracy: 0.6667 - val_loss: 4.1107 - val_accuracy: 0.6667\n",
      "Epoch 2/200\n",
      "172/172 [==============================] - 0s 861us/sample - loss: 2.8332 - accuracy: 0.7171 - val_loss: 2.1401 - val_accuracy: 0.7829\n",
      "Epoch 3/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 1.7805 - accuracy: 0.7791 - val_loss: 1.4731 - val_accuracy: 0.7829\n",
      "Epoch 4/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.3274 - accuracy: 0.7791 - val_loss: 1.1678 - val_accuracy: 0.7829\n",
      "Epoch 5/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 1.0773 - accuracy: 0.7791 - val_loss: 0.9675 - val_accuracy: 0.7829\n",
      "Epoch 6/200\n",
      "172/172 [==============================] - 0s 853us/sample - loss: 0.9024 - accuracy: 0.7791 - val_loss: 0.8152 - val_accuracy: 0.7829\n",
      "Epoch 7/200\n",
      "172/172 [==============================] - 0s 845us/sample - loss: 0.7666 - accuracy: 0.7791 - val_loss: 0.7029 - val_accuracy: 0.7829\n",
      "Epoch 8/200\n",
      "172/172 [==============================] - 0s 843us/sample - loss: 0.6679 - accuracy: 0.7791 - val_loss: 0.6216 - val_accuracy: 0.7829\n",
      "Epoch 9/200\n",
      "172/172 [==============================] - 0s 840us/sample - loss: 0.6087 - accuracy: 0.7791 - val_loss: 0.5855 - val_accuracy: 0.7829\n",
      "Epoch 10/200\n",
      "172/172 [==============================] - 0s 829us/sample - loss: 0.5893 - accuracy: 0.7791 - val_loss: 0.5776 - val_accuracy: 0.7829\n",
      "Epoch 11/200\n",
      "172/172 [==============================] - 0s 833us/sample - loss: 0.5839 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 12/200\n",
      "172/172 [==============================] - 0s 828us/sample - loss: 0.5843 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 13/200\n",
      "172/172 [==============================] - 0s 829us/sample - loss: 0.5832 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 14/200\n",
      "172/172 [==============================] - 0s 864us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 15/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.5834 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 16/200\n",
      "172/172 [==============================] - 0s 834us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 17/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.5837 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 18/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 19/200\n",
      "172/172 [==============================] - 0s 941us/sample - loss: 0.5819 - accuracy: 0.7791 - val_loss: 0.5769 - val_accuracy: 0.7829\n",
      "Epoch 20/200\n",
      "172/172 [==============================] - 0s 830us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5750 - val_accuracy: 0.7829\n",
      "Epoch 21/200\n",
      "172/172 [==============================] - 0s 822us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 22/200\n",
      "172/172 [==============================] - 0s 829us/sample - loss: 0.5833 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 23/200\n",
      "172/172 [==============================] - 0s 829us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5778 - val_accuracy: 0.7829\n",
      "Epoch 24/200\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 0.5841 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 25/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 26/200\n",
      "172/172 [==============================] - 0s 944us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 27/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 28/200\n",
      "172/172 [==============================] - 0s 993us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5746 - val_accuracy: 0.7829\n",
      "Epoch 29/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5767 - val_accuracy: 0.7829\n",
      "Epoch 30/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5751 - val_accuracy: 0.7829\n",
      "Epoch 31/200\n",
      "172/172 [==============================] - 0s 961us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 32/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5850 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 33/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5749 - val_accuracy: 0.7829\n",
      "Epoch 34/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 0.5832 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 35/200\n",
      "172/172 [==============================] - 0s 850us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5772 - val_accuracy: 0.7829\n",
      "Epoch 36/200\n",
      "172/172 [==============================] - 0s 944us/sample - loss: 0.5853 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 37/200\n",
      "172/172 [==============================] - 0s 882us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 38/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.5819 - accuracy: 0.7791 - val_loss: 0.5749 - val_accuracy: 0.7829\n",
      "Epoch 39/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 0.5835 - accuracy: 0.7791 - val_loss: 0.5776 - val_accuracy: 0.7829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.5838 - accuracy: 0.7791 - val_loss: 0.5752 - val_accuracy: 0.7829\n",
      "Epoch 41/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.5818 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 42/200\n",
      "172/172 [==============================] - 0s 980us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 43/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 44/200\n",
      "172/172 [==============================] - 0s 949us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5768 - val_accuracy: 0.7829\n",
      "Epoch 45/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 46/200\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 0.5840 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 47/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 48/200\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5744 - val_accuracy: 0.7829\n",
      "Epoch 49/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 0.5820 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 50/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5752 - val_accuracy: 0.7829\n",
      "Epoch 51/200\n",
      "172/172 [==============================] - 0s 849us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 52/200\n",
      "172/172 [==============================] - 0s 840us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 53/200\n",
      "172/172 [==============================] - 0s 826us/sample - loss: 0.5843 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 54/200\n",
      "172/172 [==============================] - 0s 835us/sample - loss: 0.5833 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 55/200\n",
      "172/172 [==============================] - 0s 840us/sample - loss: 0.5820 - accuracy: 0.7791 - val_loss: 0.5769 - val_accuracy: 0.7829\n",
      "Epoch 56/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 57/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 58/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 59/200\n",
      "172/172 [==============================] - 0s 853us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 60/200\n",
      "172/172 [==============================] - 0s 858us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 61/200\n",
      "172/172 [==============================] - 0s 858us/sample - loss: 0.5840 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 62/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5749 - val_accuracy: 0.7829\n",
      "Epoch 63/200\n",
      "172/172 [==============================] - 0s 860us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5772 - val_accuracy: 0.7829\n",
      "Epoch 64/200\n",
      "172/172 [==============================] - 0s 861us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 65/200\n",
      "172/172 [==============================] - 0s 859us/sample - loss: 0.5819 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 66/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5749 - val_accuracy: 0.7829\n",
      "Epoch 67/200\n",
      "172/172 [==============================] - 0s 858us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 68/200\n",
      "172/172 [==============================] - 0s 854us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5748 - val_accuracy: 0.7829\n",
      "Epoch 69/200\n",
      "172/172 [==============================] - 0s 940us/sample - loss: 0.5833 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 70/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 71/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.5833 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 72/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 73/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.5840 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 74/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 75/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 76/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5833 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 77/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5774 - val_accuracy: 0.7829\n",
      "Epoch 78/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.5843 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 79/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 80/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5749 - val_accuracy: 0.7829\n",
      "Epoch 81/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5749 - val_accuracy: 0.7829\n",
      "Epoch 82/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 83/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5836 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 84/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 85/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 0.5816 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 86/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 87/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 88/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.5836 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 89/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 90/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5752 - val_accuracy: 0.7829\n",
      "Epoch 91/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.5833 - accuracy: 0.7791 - val_loss: 0.5772 - val_accuracy: 0.7829\n",
      "Epoch 92/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.5832 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 93/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 94/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.5832 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 95/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 966us/sample - loss: 0.5818 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 96/200\n",
      "172/172 [==============================] - 0s 946us/sample - loss: 0.5837 - accuracy: 0.7791 - val_loss: 0.5751 - val_accuracy: 0.7829\n",
      "Epoch 97/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 98/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 99/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 100/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 101/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 0.5846 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 102/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 103/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 104/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.5836 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 105/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5776 - val_accuracy: 0.7829\n",
      "Epoch 106/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 107/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.5816 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 108/200\n",
      "172/172 [==============================] - 0s 956us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5744 - val_accuracy: 0.7829\n",
      "Epoch 109/200\n",
      "172/172 [==============================] - 0s 940us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 110/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.5818 - accuracy: 0.7791 - val_loss: 0.5746 - val_accuracy: 0.7829\n",
      "Epoch 111/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5767 - val_accuracy: 0.7829\n",
      "Epoch 112/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5751 - val_accuracy: 0.7829\n",
      "Epoch 113/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 114/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 115/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 0.5847 - accuracy: 0.7791 - val_loss: 0.5769 - val_accuracy: 0.7829\n",
      "Epoch 116/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.5818 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 117/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 0.5820 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 118/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5751 - val_accuracy: 0.7829\n",
      "Epoch 119/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5775 - val_accuracy: 0.7829\n",
      "Epoch 120/200\n",
      "172/172 [==============================] - 0s 928us/sample - loss: 0.5843 - accuracy: 0.7791 - val_loss: 0.5749 - val_accuracy: 0.7829\n",
      "Epoch 121/200\n",
      "172/172 [==============================] - 0s 965us/sample - loss: 0.5836 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 122/200\n",
      "172/172 [==============================] - 0s 947us/sample - loss: 0.5842 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 123/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5752 - val_accuracy: 0.7829\n",
      "Epoch 124/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 125/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.5820 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 126/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5751 - val_accuracy: 0.7829\n",
      "Epoch 127/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5783 - val_accuracy: 0.7829\n",
      "Epoch 128/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 129/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.5856 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 130/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.5816 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 131/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5751 - val_accuracy: 0.7829\n",
      "Epoch 132/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 133/200\n",
      "172/172 [==============================] - 0s 937us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 134/200\n",
      "172/172 [==============================] - 0s 948us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 135/200\n",
      "172/172 [==============================] - 0s 972us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 136/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.5835 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 137/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 138/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5746 - val_accuracy: 0.7829\n",
      "Epoch 139/200\n",
      "172/172 [==============================] - 0s 882us/sample - loss: 0.5820 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 140/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5749 - val_accuracy: 0.7829\n",
      "Epoch 141/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5750 - val_accuracy: 0.7829\n",
      "Epoch 142/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 143/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.5848 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 144/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5848 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 145/200\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 146/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 0.5832 - accuracy: 0.7791 - val_loss: 0.5747 - val_accuracy: 0.7829\n",
      "Epoch 147/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 0.5832 - accuracy: 0.7791 - val_loss: 0.5770 - val_accuracy: 0.7829\n",
      "Epoch 148/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.5820 - accuracy: 0.7791 - val_loss: 0.5749 - val_accuracy: 0.7829\n",
      "Epoch 149/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 0.5834 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 150/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 853us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5749 - val_accuracy: 0.7829\n",
      "Epoch 151/200\n",
      "172/172 [==============================] - 0s 843us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 152/200\n",
      "172/172 [==============================] - 0s 844us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5749 - val_accuracy: 0.7829\n",
      "Epoch 153/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 154/200\n",
      "172/172 [==============================] - 0s 856us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 155/200\n",
      "172/172 [==============================] - 0s 854us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5772 - val_accuracy: 0.7829\n",
      "Epoch 156/200\n",
      "172/172 [==============================] - 0s 850us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 157/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 0.5832 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 158/200\n",
      "172/172 [==============================] - 0s 843us/sample - loss: 0.5819 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 159/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 160/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5745 - val_accuracy: 0.7829\n",
      "Epoch 161/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5767 - val_accuracy: 0.7829\n",
      "Epoch 162/200\n",
      "172/172 [==============================] - 0s 853us/sample - loss: 0.5820 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 163/200\n",
      "172/172 [==============================] - 0s 848us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 164/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 165/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 0.5847 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 166/200\n",
      "172/172 [==============================] - 0s 859us/sample - loss: 0.5832 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 167/200\n",
      "172/172 [==============================] - 0s 849us/sample - loss: 0.5817 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 168/200\n",
      "172/172 [==============================] - 0s 854us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 169/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 170/200\n",
      "172/172 [==============================] - 0s 843us/sample - loss: 0.5820 - accuracy: 0.7791 - val_loss: 0.5744 - val_accuracy: 0.7829\n",
      "Epoch 171/200\n",
      "172/172 [==============================] - 0s 849us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5748 - val_accuracy: 0.7829\n",
      "Epoch 172/200\n",
      "172/172 [==============================] - 0s 856us/sample - loss: 0.5819 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 173/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 0.5837 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 174/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5833 - accuracy: 0.7791 - val_loss: 0.5750 - val_accuracy: 0.7829\n",
      "Epoch 175/200\n",
      "172/172 [==============================] - 0s 849us/sample - loss: 0.5833 - accuracy: 0.7791 - val_loss: 0.5770 - val_accuracy: 0.7829\n",
      "Epoch 176/200\n",
      "172/172 [==============================] - 0s 825us/sample - loss: 0.5833 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 177/200\n",
      "172/172 [==============================] - 0s 824us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5767 - val_accuracy: 0.7829\n",
      "Epoch 178/200\n",
      "172/172 [==============================] - 0s 825us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 179/200\n",
      "172/172 [==============================] - 0s 822us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 180/200\n",
      "172/172 [==============================] - 0s 826us/sample - loss: 0.5833 - accuracy: 0.7791 - val_loss: 0.5748 - val_accuracy: 0.7829\n",
      "Epoch 181/200\n",
      "172/172 [==============================] - 0s 828us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 182/200\n",
      "172/172 [==============================] - 0s 824us/sample - loss: 0.5819 - accuracy: 0.7791 - val_loss: 0.5751 - val_accuracy: 0.7829\n",
      "Epoch 183/200\n",
      "172/172 [==============================] - 0s 824us/sample - loss: 0.5838 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 184/200\n",
      "172/172 [==============================] - 0s 829us/sample - loss: 0.5817 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 185/200\n",
      "172/172 [==============================] - 0s 832us/sample - loss: 0.5841 - accuracy: 0.7791 - val_loss: 0.5751 - val_accuracy: 0.7829\n",
      "Epoch 186/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5750 - val_accuracy: 0.7829\n",
      "Epoch 187/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 188/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 0.5817 - accuracy: 0.7791 - val_loss: 0.5748 - val_accuracy: 0.7829\n",
      "Epoch 189/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 190/200\n",
      "172/172 [==============================] - 0s 830us/sample - loss: 0.5818 - accuracy: 0.7791 - val_loss: 0.5743 - val_accuracy: 0.7829\n",
      "Epoch 191/200\n",
      "172/172 [==============================] - 0s 829us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 192/200\n",
      "172/172 [==============================] - 0s 825us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5749 - val_accuracy: 0.7829\n",
      "Epoch 193/200\n",
      "172/172 [==============================] - 0s 825us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 194/200\n",
      "172/172 [==============================] - 0s 825us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 195/200\n",
      "172/172 [==============================] - 0s 824us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 196/200\n",
      "172/172 [==============================] - 0s 822us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5748 - val_accuracy: 0.7829\n",
      "Epoch 197/200\n",
      "172/172 [==============================] - 0s 825us/sample - loss: 0.5820 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 198/200\n",
      "172/172 [==============================] - 0s 822us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 199/200\n",
      "172/172 [==============================] - 0s 831us/sample - loss: 0.5835 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 200/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Beginning training for dr=0.010, l_lambda=1.0e-01, reg_type=l2, act: relu\n",
      "Train on 172 samples, validate on 43 samples\n",
      "Epoch 1/200\n",
      "172/172 [==============================] - 1s 8ms/sample - loss: 3.2561 - accuracy: 0.6667 - val_loss: 2.2113 - val_accuracy: 0.6667\n",
      "Epoch 2/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 1.8556 - accuracy: 0.6667 - val_loss: 1.5542 - val_accuracy: 0.6667\n",
      "Epoch 3/200\n",
      "172/172 [==============================] - 0s 822us/sample - loss: 1.3918 - accuracy: 0.7016 - val_loss: 1.2110 - val_accuracy: 0.7829\n",
      "Epoch 4/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 943us/sample - loss: 1.1013 - accuracy: 0.7791 - val_loss: 0.9739 - val_accuracy: 0.7829\n",
      "Epoch 5/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.9030 - accuracy: 0.7791 - val_loss: 0.8152 - val_accuracy: 0.7829\n",
      "Epoch 6/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.7694 - accuracy: 0.7791 - val_loss: 0.7087 - val_accuracy: 0.7829\n",
      "Epoch 7/200\n",
      "172/172 [==============================] - 0s 803us/sample - loss: 0.6801 - accuracy: 0.7791 - val_loss: 0.6360 - val_accuracy: 0.7829\n",
      "Epoch 8/200\n",
      "172/172 [==============================] - 0s 795us/sample - loss: 0.6194 - accuracy: 0.7791 - val_loss: 0.5878 - val_accuracy: 0.7829\n",
      "Epoch 9/200\n",
      "172/172 [==============================] - 0s 829us/sample - loss: 0.5788 - accuracy: 0.7791 - val_loss: 0.5560 - val_accuracy: 0.7829\n",
      "Epoch 10/200\n",
      "172/172 [==============================] - 0s 835us/sample - loss: 0.5529 - accuracy: 0.7791 - val_loss: 0.5350 - val_accuracy: 0.7829\n",
      "Epoch 11/200\n",
      "172/172 [==============================] - 0s 799us/sample - loss: 0.5367 - accuracy: 0.7791 - val_loss: 0.5220 - val_accuracy: 0.7829\n",
      "Epoch 12/200\n",
      "172/172 [==============================] - 0s 792us/sample - loss: 0.5253 - accuracy: 0.7791 - val_loss: 0.5144 - val_accuracy: 0.7829\n",
      "Epoch 13/200\n",
      "172/172 [==============================] - 0s 790us/sample - loss: 0.5180 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 14/200\n",
      "172/172 [==============================] - 0s 830us/sample - loss: 0.5146 - accuracy: 0.7791 - val_loss: 0.5063 - val_accuracy: 0.7829\n",
      "Epoch 15/200\n",
      "172/172 [==============================] - 0s 798us/sample - loss: 0.5117 - accuracy: 0.7791 - val_loss: 0.5045 - val_accuracy: 0.7829\n",
      "Epoch 16/200\n",
      "172/172 [==============================] - 0s 813us/sample - loss: 0.5106 - accuracy: 0.7791 - val_loss: 0.5033 - val_accuracy: 0.7829\n",
      "Epoch 17/200\n",
      "172/172 [==============================] - 0s 836us/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5026 - val_accuracy: 0.7829\n",
      "Epoch 18/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.5108 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 19/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 20/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 21/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 22/200\n",
      "172/172 [==============================] - 0s 807us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 23/200\n",
      "172/172 [==============================] - 0s 806us/sample - loss: 0.5105 - accuracy: 0.7791 - val_loss: 0.5030 - val_accuracy: 0.7829\n",
      "Epoch 24/200\n",
      "172/172 [==============================] - 0s 809us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 25/200\n",
      "172/172 [==============================] - 0s 812us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 26/200\n",
      "172/172 [==============================] - 0s 999us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 27/200\n",
      "172/172 [==============================] - 0s 840us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 28/200\n",
      "172/172 [==============================] - 0s 814us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 29/200\n",
      "172/172 [==============================] - 0s 841us/sample - loss: 0.5102 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 30/200\n",
      "172/172 [==============================] - 0s 848us/sample - loss: 0.5114 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 31/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 32/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 33/200\n",
      "172/172 [==============================] - 0s 940us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 34/200\n",
      "172/172 [==============================] - 0s 854us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 35/200\n",
      "172/172 [==============================] - 0s 837us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 36/200\n",
      "172/172 [==============================] - 0s 837us/sample - loss: 0.5104 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 37/200\n",
      "172/172 [==============================] - 0s 828us/sample - loss: 0.5086 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 38/200\n",
      "172/172 [==============================] - 0s 853us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 39/200\n",
      "172/172 [==============================] - 0s 853us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 40/200\n",
      "172/172 [==============================] - 0s 860us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 41/200\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 42/200\n",
      "172/172 [==============================] - 0s 861us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 43/200\n",
      "172/172 [==============================] - 0s 859us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 44/200\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 45/200\n",
      "172/172 [==============================] - 0s 955us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 46/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 47/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 48/200\n",
      "172/172 [==============================] - 0s 856us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 49/200\n",
      "172/172 [==============================] - 0s 849us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 50/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 51/200\n",
      "172/172 [==============================] - 0s 945us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 52/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 53/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 54/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 55/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 56/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 0.5084 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 57/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 58/200\n",
      "172/172 [==============================] - 0s 994us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 970us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 60/200\n",
      "172/172 [==============================] - 0s 969us/sample - loss: 0.5102 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 61/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 62/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 63/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 64/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 65/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 66/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 67/200\n",
      "172/172 [==============================] - 0s 962us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 68/200\n",
      "172/172 [==============================] - 0s 986us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 69/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 70/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5106 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 71/200\n",
      "172/172 [==============================] - 0s 964us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 72/200\n",
      "172/172 [==============================] - 0s 976us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 73/200\n",
      "172/172 [==============================] - 0s 967us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 74/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 75/200\n",
      "172/172 [==============================] - 0s 928us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 76/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 77/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 78/200\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5026 - val_accuracy: 0.7829\n",
      "Epoch 79/200\n",
      "172/172 [==============================] - 0s 963us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 80/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 81/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 82/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 83/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 84/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 85/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 86/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 87/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.5112 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 88/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 89/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 90/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 91/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 92/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 93/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 94/200\n",
      "172/172 [==============================] - 0s 969us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 95/200\n",
      "172/172 [==============================] - 0s 947us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 96/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.5083 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 97/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 98/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 99/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 0.5107 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 100/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 0.5102 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 101/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.5083 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 102/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5028 - val_accuracy: 0.7829\n",
      "Epoch 103/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 104/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 105/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 106/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 107/200\n",
      "172/172 [==============================] - 0s 970us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 108/200\n",
      "172/172 [==============================] - 0s 946us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 109/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 110/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 111/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 112/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 113/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 114/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 894us/sample - loss: 0.5107 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 115/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5029 - val_accuracy: 0.7829\n",
      "Epoch 116/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 117/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 118/200\n",
      "172/172 [==============================] - 0s 882us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 119/200\n",
      "172/172 [==============================] - 0s 957us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 120/200\n",
      "172/172 [==============================] - 0s 947us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 121/200\n",
      "172/172 [==============================] - 0s 944us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 122/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5028 - val_accuracy: 0.7829\n",
      "Epoch 123/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 124/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 125/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 126/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 127/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 128/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 129/200\n",
      "172/172 [==============================] - 0s 882us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 130/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 131/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 132/200\n",
      "172/172 [==============================] - 0s 971us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 133/200\n",
      "172/172 [==============================] - 0s 954us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 134/200\n",
      "172/172 [==============================] - 0s 958us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 135/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 136/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 137/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 138/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 139/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 140/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 141/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 142/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 143/200\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 144/200\n",
      "172/172 [==============================] - 0s 857us/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 145/200\n",
      "172/172 [==============================] - 0s 948us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 146/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 147/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 148/200\n",
      "172/172 [==============================] - 0s 859us/sample - loss: 0.5106 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 149/200\n",
      "172/172 [==============================] - 0s 860us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 150/200\n",
      "172/172 [==============================] - 0s 853us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 151/200\n",
      "172/172 [==============================] - 0s 854us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 152/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 153/200\n",
      "172/172 [==============================] - 0s 856us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 154/200\n",
      "172/172 [==============================] - 0s 859us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 155/200\n",
      "172/172 [==============================] - 0s 862us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 156/200\n",
      "172/172 [==============================] - 0s 858us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 157/200\n",
      "172/172 [==============================] - 0s 861us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 158/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 159/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 160/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 161/200\n",
      "172/172 [==============================] - 0s 839us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 162/200\n",
      "172/172 [==============================] - 0s 837us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 163/200\n",
      "172/172 [==============================] - 0s 834us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 164/200\n",
      "172/172 [==============================] - 0s 832us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 165/200\n",
      "172/172 [==============================] - 0s 837us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 166/200\n",
      "172/172 [==============================] - 0s 834us/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 167/200\n",
      "172/172 [==============================] - 0s 836us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 168/200\n",
      "172/172 [==============================] - 0s 836us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 169/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 864us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 170/200\n",
      "172/172 [==============================] - 0s 829us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 171/200\n",
      "172/172 [==============================] - 0s 832us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 172/200\n",
      "172/172 [==============================] - 0s 930us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 173/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 174/200\n",
      "172/172 [==============================] - 0s 864us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 175/200\n",
      "172/172 [==============================] - 0s 833us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 176/200\n",
      "172/172 [==============================] - 0s 829us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 177/200\n",
      "172/172 [==============================] - 0s 849us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 178/200\n",
      "172/172 [==============================] - 0s 831us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 179/200\n",
      "172/172 [==============================] - 0s 830us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 180/200\n",
      "172/172 [==============================] - 0s 831us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 181/200\n",
      "172/172 [==============================] - 0s 833us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 182/200\n",
      "172/172 [==============================] - 0s 835us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 183/200\n",
      "172/172 [==============================] - 0s 836us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 184/200\n",
      "172/172 [==============================] - 0s 827us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 185/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 186/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 187/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 188/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 189/200\n",
      "172/172 [==============================] - 0s 832us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 190/200\n",
      "172/172 [==============================] - 0s 831us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 191/200\n",
      "172/172 [==============================] - 0s 831us/sample - loss: 0.5102 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 192/200\n",
      "172/172 [==============================] - 0s 834us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 193/200\n",
      "172/172 [==============================] - 0s 834us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 194/200\n",
      "172/172 [==============================] - 0s 825us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 195/200\n",
      "172/172 [==============================] - 0s 829us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 196/200\n",
      "172/172 [==============================] - 0s 842us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 197/200\n",
      "172/172 [==============================] - 0s 882us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 198/200\n",
      "172/172 [==============================] - 0s 825us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 199/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 200/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Beginning training for dr=0.010, l_lambda=1.0e-01, reg_type=l2, act: tanh\n",
      "Train on 172 samples, validate on 43 samples\n",
      "Epoch 1/200\n",
      "172/172 [==============================] - 2s 10ms/sample - loss: 3.2625 - accuracy: 0.6667 - val_loss: 2.1883 - val_accuracy: 0.6667\n",
      "Epoch 2/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 1.8230 - accuracy: 0.7326 - val_loss: 1.5100 - val_accuracy: 0.7829\n",
      "Epoch 3/200\n",
      "172/172 [==============================] - 0s 830us/sample - loss: 1.3580 - accuracy: 0.7791 - val_loss: 1.1884 - val_accuracy: 0.7829\n",
      "Epoch 4/200\n",
      "172/172 [==============================] - 0s 779us/sample - loss: 1.0890 - accuracy: 0.7791 - val_loss: 0.9676 - val_accuracy: 0.7829\n",
      "Epoch 5/200\n",
      "172/172 [==============================] - 0s 799us/sample - loss: 0.9017 - accuracy: 0.7791 - val_loss: 0.8153 - val_accuracy: 0.7829\n",
      "Epoch 6/200\n",
      "172/172 [==============================] - 0s 790us/sample - loss: 0.7715 - accuracy: 0.7791 - val_loss: 0.7107 - val_accuracy: 0.7829\n",
      "Epoch 7/200\n",
      "172/172 [==============================] - 0s 791us/sample - loss: 0.6824 - accuracy: 0.7791 - val_loss: 0.6376 - val_accuracy: 0.7829\n",
      "Epoch 8/200\n",
      "172/172 [==============================] - 0s 794us/sample - loss: 0.6209 - accuracy: 0.7791 - val_loss: 0.5886 - val_accuracy: 0.7829\n",
      "Epoch 9/200\n",
      "172/172 [==============================] - 0s 792us/sample - loss: 0.5808 - accuracy: 0.7791 - val_loss: 0.5564 - val_accuracy: 0.7829\n",
      "Epoch 10/200\n",
      "172/172 [==============================] - 0s 790us/sample - loss: 0.5538 - accuracy: 0.7791 - val_loss: 0.5353 - val_accuracy: 0.7829\n",
      "Epoch 11/200\n",
      "172/172 [==============================] - 0s 788us/sample - loss: 0.5364 - accuracy: 0.7791 - val_loss: 0.5223 - val_accuracy: 0.7829\n",
      "Epoch 12/200\n",
      "172/172 [==============================] - 0s 799us/sample - loss: 0.5263 - accuracy: 0.7791 - val_loss: 0.5137 - val_accuracy: 0.7829\n",
      "Epoch 13/200\n",
      "172/172 [==============================] - 0s 790us/sample - loss: 0.5190 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 14/200\n",
      "172/172 [==============================] - 0s 800us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5062 - val_accuracy: 0.7829\n",
      "Epoch 15/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.5127 - accuracy: 0.7791 - val_loss: 0.5038 - val_accuracy: 0.7829\n",
      "Epoch 16/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.5111 - accuracy: 0.7791 - val_loss: 0.5032 - val_accuracy: 0.7829\n",
      "Epoch 17/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.5123 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 18/200\n",
      "172/172 [==============================] - 0s 800us/sample - loss: 0.5102 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 19/200\n",
      "172/172 [==============================] - 0s 797us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 20/200\n",
      "172/172 [==============================] - 0s 798us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 21/200\n",
      "172/172 [==============================] - 0s 787us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 22/200\n",
      "172/172 [==============================] - 0s 801us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 23/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 804us/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 24/200\n",
      "172/172 [==============================] - 0s 797us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 25/200\n",
      "172/172 [==============================] - 0s 791us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 26/200\n",
      "172/172 [==============================] - 0s 790us/sample - loss: 0.5112 - accuracy: 0.7791 - val_loss: 0.5029 - val_accuracy: 0.7829\n",
      "Epoch 27/200\n",
      "172/172 [==============================] - 0s 799us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 28/200\n",
      "172/172 [==============================] - 0s 791us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 29/200\n",
      "172/172 [==============================] - 0s 842us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5013 - val_accuracy: 0.7829\n",
      "Epoch 30/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5014 - val_accuracy: 0.7829\n",
      "Epoch 31/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 32/200\n",
      "172/172 [==============================] - 0s 814us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 33/200\n",
      "172/172 [==============================] - 0s 793us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 34/200\n",
      "172/172 [==============================] - 0s 801us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 35/200\n",
      "172/172 [==============================] - 0s 798us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 36/200\n",
      "172/172 [==============================] - 0s 822us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 37/200\n",
      "172/172 [==============================] - 0s 808us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 38/200\n",
      "172/172 [==============================] - 0s 807us/sample - loss: 0.5102 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 39/200\n",
      "172/172 [==============================] - 0s 801us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 40/200\n",
      "172/172 [==============================] - 0s 804us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 41/200\n",
      "172/172 [==============================] - 0s 800us/sample - loss: 0.5102 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 42/200\n",
      "172/172 [==============================] - 0s 829us/sample - loss: 0.5106 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 43/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 44/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 45/200\n",
      "172/172 [==============================] - 0s 928us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 46/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.5107 - accuracy: 0.7791 - val_loss: 0.5035 - val_accuracy: 0.7829\n",
      "Epoch 47/200\n",
      "172/172 [==============================] - 0s 844us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 48/200\n",
      "172/172 [==============================] - 0s 849us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 49/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 50/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 51/200\n",
      "172/172 [==============================] - 0s 848us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5031 - val_accuracy: 0.7829\n",
      "Epoch 52/200\n",
      "172/172 [==============================] - 0s 869us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 53/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 54/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 55/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 56/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 57/200\n",
      "172/172 [==============================] - 0s 979us/sample - loss: 0.5104 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 58/200\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 59/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 60/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 61/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 62/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 63/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 64/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.5104 - accuracy: 0.7791 - val_loss: 0.5014 - val_accuracy: 0.7829\n",
      "Epoch 65/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 66/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.5113 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 67/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 68/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 69/200\n",
      "172/172 [==============================] - 0s 869us/sample - loss: 0.5107 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 70/200\n",
      "172/172 [==============================] - 0s 984us/sample - loss: 0.5133 - accuracy: 0.7791 - val_loss: 0.5026 - val_accuracy: 0.7829\n",
      "Epoch 71/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 72/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 73/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 74/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 75/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 76/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 77/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 78/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 875us/sample - loss: 0.5111 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 79/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 80/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 81/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 82/200\n",
      "172/172 [==============================] - 0s 882us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 83/200\n",
      "172/172 [==============================] - 0s 958us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 84/200\n",
      "172/172 [==============================] - 0s 943us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 85/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 86/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 87/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 88/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.5084 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 89/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 90/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 91/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 92/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 93/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 94/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 95/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.5109 - accuracy: 0.7791 - val_loss: 0.5026 - val_accuracy: 0.7829\n",
      "Epoch 96/200\n",
      "172/172 [==============================] - 0s 958us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 97/200\n",
      "172/172 [==============================] - 0s 940us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 98/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 99/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 100/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 101/200\n",
      "172/172 [==============================] - 0s 848us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 102/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 103/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 104/200\n",
      "172/172 [==============================] - 0s 849us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 105/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 0.5102 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 106/200\n",
      "172/172 [==============================] - 0s 853us/sample - loss: 0.5107 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 107/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 108/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 0.5108 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 109/200\n",
      "172/172 [==============================] - 0s 964us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 110/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 111/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.5122 - accuracy: 0.7791 - val_loss: 0.5032 - val_accuracy: 0.7829\n",
      "Epoch 112/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 0.5104 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 113/200\n",
      "172/172 [==============================] - 0s 849us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5029 - val_accuracy: 0.7829\n",
      "Epoch 114/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5034 - val_accuracy: 0.7829\n",
      "Epoch 115/200\n",
      "172/172 [==============================] - 0s 850us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 116/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 117/200\n",
      "172/172 [==============================] - 0s 849us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 118/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 119/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 120/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 121/200\n",
      "172/172 [==============================] - 0s 843us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 122/200\n",
      "172/172 [==============================] - 0s 937us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 123/200\n",
      "172/172 [==============================] - 0s 930us/sample - loss: 0.5114 - accuracy: 0.7791 - val_loss: 0.5030 - val_accuracy: 0.7829\n",
      "Epoch 124/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 125/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.5105 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 126/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 127/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 0.5102 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 128/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 129/200\n",
      "172/172 [==============================] - 0s 845us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 130/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5032 - val_accuracy: 0.7829\n",
      "Epoch 131/200\n",
      "172/172 [==============================] - 0s 853us/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 132/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 133/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 853us/sample - loss: 0.5105 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 134/200\n",
      "172/172 [==============================] - 0s 849us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 135/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 136/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 137/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5034 - val_accuracy: 0.7829\n",
      "Epoch 138/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 139/200\n",
      "172/172 [==============================] - 0s 844us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 140/200\n",
      "172/172 [==============================] - 0s 842us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 141/200\n",
      "172/172 [==============================] - 0s 856us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 142/200\n",
      "172/172 [==============================] - 0s 845us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 143/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5028 - val_accuracy: 0.7829\n",
      "Epoch 144/200\n",
      "172/172 [==============================] - 0s 849us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 145/200\n",
      "172/172 [==============================] - 0s 836us/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 146/200\n",
      "172/172 [==============================] - 0s 850us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 147/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 148/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 149/200\n",
      "172/172 [==============================] - 0s 961us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5040 - val_accuracy: 0.7829\n",
      "Epoch 150/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 0.5107 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 151/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 152/200\n",
      "172/172 [==============================] - 0s 840us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 153/200\n",
      "172/172 [==============================] - 0s 829us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 154/200\n",
      "172/172 [==============================] - 0s 823us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 155/200\n",
      "172/172 [==============================] - 0s 826us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 156/200\n",
      "172/172 [==============================] - 0s 821us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 157/200\n",
      "172/172 [==============================] - 0s 835us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5014 - val_accuracy: 0.7829\n",
      "Epoch 158/200\n",
      "172/172 [==============================] - 0s 826us/sample - loss: 0.5111 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 159/200\n",
      "172/172 [==============================] - 0s 831us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 160/200\n",
      "172/172 [==============================] - 0s 825us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 161/200\n",
      "172/172 [==============================] - 0s 830us/sample - loss: 0.5108 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 162/200\n",
      "172/172 [==============================] - 0s 869us/sample - loss: 0.5102 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 163/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 164/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 165/200\n",
      "172/172 [==============================] - 0s 839us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 166/200\n",
      "172/172 [==============================] - 0s 828us/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 167/200\n",
      "172/172 [==============================] - 0s 823us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 168/200\n",
      "172/172 [==============================] - 0s 837us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 169/200\n",
      "172/172 [==============================] - 0s 825us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 170/200\n",
      "172/172 [==============================] - 0s 830us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5013 - val_accuracy: 0.7829\n",
      "Epoch 171/200\n",
      "172/172 [==============================] - 0s 836us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5014 - val_accuracy: 0.7829\n",
      "Epoch 172/200\n",
      "172/172 [==============================] - 0s 825us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 173/200\n",
      "172/172 [==============================] - 0s 828us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 174/200\n",
      "172/172 [==============================] - 0s 826us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 175/200\n",
      "172/172 [==============================] - 0s 837us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 176/200\n",
      "172/172 [==============================] - 0s 965us/sample - loss: 0.5105 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 177/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 178/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.5102 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 179/200\n",
      "172/172 [==============================] - 0s 833us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 180/200\n",
      "172/172 [==============================] - 0s 832us/sample - loss: 0.5117 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 181/200\n",
      "172/172 [==============================] - 0s 835us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 182/200\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 183/200\n",
      "172/172 [==============================] - 0s 834us/sample - loss: 0.5107 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 184/200\n",
      "172/172 [==============================] - 0s 829us/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 185/200\n",
      "172/172 [==============================] - 0s 831us/sample - loss: 0.5114 - accuracy: 0.7791 - val_loss: 0.5038 - val_accuracy: 0.7829\n",
      "Epoch 186/200\n",
      "172/172 [==============================] - 0s 828us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 187/200\n",
      "172/172 [==============================] - 0s 850us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 188/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 872us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 189/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 190/200\n",
      "172/172 [==============================] - 0s 945us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 191/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.5104 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 192/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 193/200\n",
      "172/172 [==============================] - 0s 854us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 194/200\n",
      "172/172 [==============================] - 0s 850us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 195/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 196/200\n",
      "172/172 [==============================] - 0s 850us/sample - loss: 0.5108 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 197/200\n",
      "172/172 [==============================] - 0s 853us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 198/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 199/200\n",
      "172/172 [==============================] - 0s 854us/sample - loss: 0.5102 - accuracy: 0.7791 - val_loss: 0.5029 - val_accuracy: 0.7829\n",
      "Epoch 200/200\n",
      "172/172 [==============================] - 0s 850us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Beginning training for dr=0.010, l_lambda=1.0e-01, reg_type=l1, act: relu\n",
      "Train on 172 samples, validate on 43 samples\n",
      "Epoch 1/200\n",
      "172/172 [==============================] - 1s 8ms/sample - loss: 71.1595 - accuracy: 0.6667 - val_loss: 35.7032 - val_accuracy: 0.6667\n",
      "Epoch 2/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 23.1457 - accuracy: 0.6667 - val_loss: 16.4771 - val_accuracy: 0.6667\n",
      "Epoch 3/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 12.9217 - accuracy: 0.7209 - val_loss: 9.9341 - val_accuracy: 0.7829\n",
      "Epoch 4/200\n",
      "172/172 [==============================] - 0s 865us/sample - loss: 8.4229 - accuracy: 0.7791 - val_loss: 6.9063 - val_accuracy: 0.7829\n",
      "Epoch 5/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 5.9569 - accuracy: 0.7791 - val_loss: 4.9191 - val_accuracy: 0.7829\n",
      "Epoch 6/200\n",
      "172/172 [==============================] - 0s 972us/sample - loss: 4.2072 - accuracy: 0.7791 - val_loss: 3.4263 - val_accuracy: 0.7829\n",
      "Epoch 7/200\n",
      "172/172 [==============================] - 0s 968us/sample - loss: 2.9136 - accuracy: 0.7791 - val_loss: 2.3746 - val_accuracy: 0.7829\n",
      "Epoch 8/200\n",
      "172/172 [==============================] - 0s 983us/sample - loss: 2.0077 - accuracy: 0.7791 - val_loss: 1.6436 - val_accuracy: 0.7829\n",
      "Epoch 9/200\n",
      "172/172 [==============================] - 0s 862us/sample - loss: 1.4617 - accuracy: 0.7791 - val_loss: 1.3212 - val_accuracy: 0.7829\n",
      "Epoch 10/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 1.2927 - accuracy: 0.7791 - val_loss: 1.2587 - val_accuracy: 0.7829\n",
      "Epoch 11/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 1.2586 - accuracy: 0.7791 - val_loss: 1.2488 - val_accuracy: 0.7829\n",
      "Epoch 12/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 1.2503 - accuracy: 0.7791 - val_loss: 1.2427 - val_accuracy: 0.7829\n",
      "Epoch 13/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 1.2429 - accuracy: 0.7791 - val_loss: 1.2523 - val_accuracy: 0.7829\n",
      "Epoch 14/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 1.2442 - accuracy: 0.7791 - val_loss: 1.2503 - val_accuracy: 0.7829\n",
      "Epoch 15/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 1.2451 - accuracy: 0.7791 - val_loss: 1.2545 - val_accuracy: 0.7829\n",
      "Epoch 16/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 1.2452 - accuracy: 0.7791 - val_loss: 1.2433 - val_accuracy: 0.7829\n",
      "Epoch 17/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 1.2454 - accuracy: 0.7791 - val_loss: 1.2422 - val_accuracy: 0.7829\n",
      "Epoch 18/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 1.2421 - accuracy: 0.7791 - val_loss: 1.2479 - val_accuracy: 0.7829\n",
      "Epoch 19/200\n",
      "172/172 [==============================] - 0s 978us/sample - loss: 1.2458 - accuracy: 0.7791 - val_loss: 1.2466 - val_accuracy: 0.7829\n",
      "Epoch 20/200\n",
      "172/172 [==============================] - 0s 971us/sample - loss: 1.2461 - accuracy: 0.7791 - val_loss: 1.2346 - val_accuracy: 0.7829\n",
      "Epoch 21/200\n",
      "172/172 [==============================] - 0s 957us/sample - loss: 1.2443 - accuracy: 0.7791 - val_loss: 1.2501 - val_accuracy: 0.7829\n",
      "Epoch 22/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 1.2454 - accuracy: 0.7791 - val_loss: 1.2411 - val_accuracy: 0.7829\n",
      "Epoch 23/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 1.2436 - accuracy: 0.7791 - val_loss: 1.2571 - val_accuracy: 0.7829\n",
      "Epoch 24/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 1.2470 - accuracy: 0.7791 - val_loss: 1.2425 - val_accuracy: 0.7829\n",
      "Epoch 25/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 1.2411 - accuracy: 0.7791 - val_loss: 1.2494 - val_accuracy: 0.7829\n",
      "Epoch 26/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 1.2473 - accuracy: 0.7791 - val_loss: 1.2425 - val_accuracy: 0.7829\n",
      "Epoch 27/200\n",
      "172/172 [==============================] - 0s 869us/sample - loss: 1.2419 - accuracy: 0.7791 - val_loss: 1.2465 - val_accuracy: 0.7829\n",
      "Epoch 28/200\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 1.2460 - accuracy: 0.7791 - val_loss: 1.2431 - val_accuracy: 0.7829\n",
      "Epoch 29/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 1.2442 - accuracy: 0.7791 - val_loss: 1.2541 - val_accuracy: 0.7829\n",
      "Epoch 30/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 1.2433 - accuracy: 0.7791 - val_loss: 1.2409 - val_accuracy: 0.7829\n",
      "Epoch 31/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 1.2488 - accuracy: 0.7791 - val_loss: 1.2438 - val_accuracy: 0.7829\n",
      "Epoch 32/200\n",
      "172/172 [==============================] - 0s 987us/sample - loss: 1.2453 - accuracy: 0.7791 - val_loss: 1.2388 - val_accuracy: 0.7829\n",
      "Epoch 33/200\n",
      "172/172 [==============================] - 0s 963us/sample - loss: 1.2424 - accuracy: 0.7791 - val_loss: 1.2480 - val_accuracy: 0.7829\n",
      "Epoch 34/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 1.2461 - accuracy: 0.7791 - val_loss: 1.2454 - val_accuracy: 0.7829\n",
      "Epoch 35/200\n",
      "172/172 [==============================] - 0s 869us/sample - loss: 1.2414 - accuracy: 0.7791 - val_loss: 1.2589 - val_accuracy: 0.7829\n",
      "Epoch 36/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 1.2478 - accuracy: 0.7791 - val_loss: 1.2420 - val_accuracy: 0.7829\n",
      "Epoch 37/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 1.2422 - accuracy: 0.7791 - val_loss: 1.2476 - val_accuracy: 0.7829\n",
      "Epoch 38/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 1.2452 - accuracy: 0.7791 - val_loss: 1.2390 - val_accuracy: 0.7829\n",
      "Epoch 39/200\n",
      "172/172 [==============================] - 0s 862us/sample - loss: 1.2434 - accuracy: 0.7791 - val_loss: 1.2509 - val_accuracy: 0.7829\n",
      "Epoch 40/200\n",
      "172/172 [==============================] - 0s 864us/sample - loss: 1.2482 - accuracy: 0.7791 - val_loss: 1.2394 - val_accuracy: 0.7829\n",
      "Epoch 41/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 1.2438 - accuracy: 0.7791 - val_loss: 1.2411 - val_accuracy: 0.7829\n",
      "Epoch 42/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 877us/sample - loss: 1.2446 - accuracy: 0.7791 - val_loss: 1.2426 - val_accuracy: 0.7829\n",
      "Epoch 43/200\n",
      "172/172 [==============================] - 0s 959us/sample - loss: 1.2435 - accuracy: 0.7791 - val_loss: 1.2545 - val_accuracy: 0.7829\n",
      "Epoch 44/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 1.2449 - accuracy: 0.7791 - val_loss: 1.2461 - val_accuracy: 0.7829\n",
      "Epoch 45/200\n",
      "172/172 [==============================] - 0s 996us/sample - loss: 1.2450 - accuracy: 0.7791 - val_loss: 1.2443 - val_accuracy: 0.7829\n",
      "Epoch 46/200\n",
      "172/172 [==============================] - 0s 962us/sample - loss: 1.2422 - accuracy: 0.7791 - val_loss: 1.2464 - val_accuracy: 0.7829\n",
      "Epoch 47/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 1.2460 - accuracy: 0.7791 - val_loss: 1.2460 - val_accuracy: 0.7829\n",
      "Epoch 48/200\n",
      "172/172 [==============================] - 0s 861us/sample - loss: 1.2450 - accuracy: 0.7791 - val_loss: 1.2373 - val_accuracy: 0.7829\n",
      "Epoch 49/200\n",
      "172/172 [==============================] - 0s 864us/sample - loss: 1.2420 - accuracy: 0.7791 - val_loss: 1.2554 - val_accuracy: 0.7829\n",
      "Epoch 50/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 1.2446 - accuracy: 0.7791 - val_loss: 1.2422 - val_accuracy: 0.7829\n",
      "Epoch 51/200\n",
      "172/172 [==============================] - 0s 861us/sample - loss: 1.2463 - accuracy: 0.7791 - val_loss: 1.2483 - val_accuracy: 0.7829\n",
      "Epoch 52/200\n",
      "172/172 [==============================] - 0s 862us/sample - loss: 1.2451 - accuracy: 0.7791 - val_loss: 1.2357 - val_accuracy: 0.7829\n",
      "Epoch 53/200\n",
      "172/172 [==============================] - 0s 858us/sample - loss: 1.2413 - accuracy: 0.7791 - val_loss: 1.2497 - val_accuracy: 0.7829\n",
      "Epoch 54/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 1.2475 - accuracy: 0.7791 - val_loss: 1.2438 - val_accuracy: 0.7829\n",
      "Epoch 55/200\n",
      "172/172 [==============================] - 0s 860us/sample - loss: 1.2403 - accuracy: 0.7791 - val_loss: 1.2474 - val_accuracy: 0.7829\n",
      "Epoch 56/200\n",
      "172/172 [==============================] - 0s 860us/sample - loss: 1.2481 - accuracy: 0.7791 - val_loss: 1.2452 - val_accuracy: 0.7829\n",
      "Epoch 57/200\n",
      "172/172 [==============================] - 0s 860us/sample - loss: 1.2453 - accuracy: 0.7791 - val_loss: 1.2492 - val_accuracy: 0.7829\n",
      "Epoch 58/200\n",
      "172/172 [==============================] - 0s 984us/sample - loss: 1.2410 - accuracy: 0.7791 - val_loss: 1.2469 - val_accuracy: 0.7829\n",
      "Epoch 59/200\n",
      "172/172 [==============================] - 0s 968us/sample - loss: 1.2480 - accuracy: 0.7791 - val_loss: 1.2469 - val_accuracy: 0.7829\n",
      "Epoch 60/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2431 - accuracy: 0.7791 - val_loss: 1.2374 - val_accuracy: 0.7829\n",
      "Epoch 61/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 1.2459 - accuracy: 0.7791 - val_loss: 1.2430 - val_accuracy: 0.7829\n",
      "Epoch 62/200\n",
      "172/172 [==============================] - 0s 840us/sample - loss: 1.2428 - accuracy: 0.7791 - val_loss: 1.2384 - val_accuracy: 0.7829\n",
      "Epoch 63/200\n",
      "172/172 [==============================] - 0s 834us/sample - loss: 1.2422 - accuracy: 0.7791 - val_loss: 1.2630 - val_accuracy: 0.7829\n",
      "Epoch 64/200\n",
      "172/172 [==============================] - 0s 859us/sample - loss: 1.2473 - accuracy: 0.7791 - val_loss: 1.2432 - val_accuracy: 0.7829\n",
      "Epoch 65/200\n",
      "172/172 [==============================] - 0s 860us/sample - loss: 1.2404 - accuracy: 0.7791 - val_loss: 1.2538 - val_accuracy: 0.7829\n",
      "Epoch 66/200\n",
      "172/172 [==============================] - 0s 839us/sample - loss: 1.2486 - accuracy: 0.7791 - val_loss: 1.2385 - val_accuracy: 0.7829\n",
      "Epoch 67/200\n",
      "172/172 [==============================] - 0s 844us/sample - loss: 1.2417 - accuracy: 0.7791 - val_loss: 1.2450 - val_accuracy: 0.7829\n",
      "Epoch 68/200\n",
      "172/172 [==============================] - 0s 857us/sample - loss: 1.2484 - accuracy: 0.7791 - val_loss: 1.2404 - val_accuracy: 0.7829\n",
      "Epoch 69/200\n",
      "172/172 [==============================] - 0s 859us/sample - loss: 1.2418 - accuracy: 0.7791 - val_loss: 1.2458 - val_accuracy: 0.7829\n",
      "Epoch 70/200\n",
      "172/172 [==============================] - 0s 860us/sample - loss: 1.2424 - accuracy: 0.7791 - val_loss: 1.2439 - val_accuracy: 0.7829\n",
      "Epoch 71/200\n",
      "172/172 [==============================] - 0s 970us/sample - loss: 1.2499 - accuracy: 0.7791 - val_loss: 1.2490 - val_accuracy: 0.7829\n",
      "Epoch 72/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 1.2422 - accuracy: 0.7791 - val_loss: 1.2405 - val_accuracy: 0.7829\n",
      "Epoch 73/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 1.2446 - accuracy: 0.7791 - val_loss: 1.2493 - val_accuracy: 0.7829\n",
      "Epoch 74/200\n",
      "172/172 [==============================] - 0s 861us/sample - loss: 1.2428 - accuracy: 0.7791 - val_loss: 1.2476 - val_accuracy: 0.7829\n",
      "Epoch 75/200\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 1.2426 - accuracy: 0.7791 - val_loss: 1.2482 - val_accuracy: 0.7829\n",
      "Epoch 76/200\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 1.2486 - accuracy: 0.7791 - val_loss: 1.2378 - val_accuracy: 0.7829\n",
      "Epoch 77/200\n",
      "172/172 [==============================] - 0s 860us/sample - loss: 1.2401 - accuracy: 0.7791 - val_loss: 1.2537 - val_accuracy: 0.7829\n",
      "Epoch 78/200\n",
      "172/172 [==============================] - 0s 857us/sample - loss: 1.2450 - accuracy: 0.7791 - val_loss: 1.2463 - val_accuracy: 0.7829\n",
      "Epoch 79/200\n",
      "172/172 [==============================] - 0s 862us/sample - loss: 1.2431 - accuracy: 0.7791 - val_loss: 1.2529 - val_accuracy: 0.7829\n",
      "Epoch 80/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 1.2456 - accuracy: 0.7791 - val_loss: 1.2346 - val_accuracy: 0.7829\n",
      "Epoch 81/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 1.2461 - accuracy: 0.7791 - val_loss: 1.2410 - val_accuracy: 0.7829\n",
      "Epoch 82/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 1.2443 - accuracy: 0.7791 - val_loss: 1.2391 - val_accuracy: 0.7829\n",
      "Epoch 83/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 1.2431 - accuracy: 0.7791 - val_loss: 1.2528 - val_accuracy: 0.7829\n",
      "Epoch 84/200\n",
      "172/172 [==============================] - 0s 986us/sample - loss: 1.2441 - accuracy: 0.7791 - val_loss: 1.2470 - val_accuracy: 0.7829\n",
      "Epoch 85/200\n",
      "172/172 [==============================] - 0s 960us/sample - loss: 1.2419 - accuracy: 0.7791 - val_loss: 1.2519 - val_accuracy: 0.7829\n",
      "Epoch 86/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 1.2466 - accuracy: 0.7791 - val_loss: 1.2442 - val_accuracy: 0.7829\n",
      "Epoch 87/200\n",
      "172/172 [==============================] - 0s 946us/sample - loss: 1.2446 - accuracy: 0.7791 - val_loss: 1.2431 - val_accuracy: 0.7829\n",
      "Epoch 88/200\n",
      "172/172 [==============================] - 0s 986us/sample - loss: 1.2436 - accuracy: 0.7791 - val_loss: 1.2460 - val_accuracy: 0.7829\n",
      "Epoch 89/200\n",
      "172/172 [==============================] - 0s 994us/sample - loss: 1.2455 - accuracy: 0.7791 - val_loss: 1.2424 - val_accuracy: 0.7829\n",
      "Epoch 90/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 1.2415 - accuracy: 0.7791 - val_loss: 1.2378 - val_accuracy: 0.7829\n",
      "Epoch 91/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 1.2462 - accuracy: 0.7791 - val_loss: 1.2564 - val_accuracy: 0.7829\n",
      "Epoch 92/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 1.2453 - accuracy: 0.7791 - val_loss: 1.2395 - val_accuracy: 0.7829\n",
      "Epoch 93/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 1.2419 - accuracy: 0.7791 - val_loss: 1.2520 - val_accuracy: 0.7829\n",
      "Epoch 94/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 1.2453 - accuracy: 0.7791 - val_loss: 1.2417 - val_accuracy: 0.7829\n",
      "Epoch 95/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 1.2430 - accuracy: 0.7791 - val_loss: 1.2534 - val_accuracy: 0.7829\n",
      "Epoch 96/200\n",
      "172/172 [==============================] - 0s 958us/sample - loss: 1.2497 - accuracy: 0.7791 - val_loss: 1.2371 - val_accuracy: 0.7829\n",
      "Epoch 97/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 967us/sample - loss: 1.2384 - accuracy: 0.7791 - val_loss: 1.2434 - val_accuracy: 0.7829\n",
      "Epoch 98/200\n",
      "172/172 [==============================] - 0s 970us/sample - loss: 1.2454 - accuracy: 0.7791 - val_loss: 1.2476 - val_accuracy: 0.7829\n",
      "Epoch 99/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 1.2462 - accuracy: 0.7791 - val_loss: 1.2489 - val_accuracy: 0.7829\n",
      "Epoch 100/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 1.2434 - accuracy: 0.7791 - val_loss: 1.2441 - val_accuracy: 0.7829\n",
      "Epoch 101/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 1.2472 - accuracy: 0.7791 - val_loss: 1.2420 - val_accuracy: 0.7829\n",
      "Epoch 102/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 1.2432 - accuracy: 0.7791 - val_loss: 1.2441 - val_accuracy: 0.7829\n",
      "Epoch 103/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 1.2453 - accuracy: 0.7791 - val_loss: 1.2522 - val_accuracy: 0.7829\n",
      "Epoch 104/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 1.2447 - accuracy: 0.7791 - val_loss: 1.2397 - val_accuracy: 0.7829\n",
      "Epoch 105/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 1.2409 - accuracy: 0.7791 - val_loss: 1.2613 - val_accuracy: 0.7829\n",
      "Epoch 106/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 1.2468 - accuracy: 0.7791 - val_loss: 1.2419 - val_accuracy: 0.7829\n",
      "Epoch 107/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 1.2409 - accuracy: 0.7791 - val_loss: 1.2509 - val_accuracy: 0.7829\n",
      "Epoch 108/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 1.2477 - accuracy: 0.7791 - val_loss: 1.2369 - val_accuracy: 0.7829\n",
      "Epoch 109/200\n",
      "172/172 [==============================] - 0s 984us/sample - loss: 1.2421 - accuracy: 0.7791 - val_loss: 1.2479 - val_accuracy: 0.7829\n",
      "Epoch 110/200\n",
      "172/172 [==============================] - 0s 975us/sample - loss: 1.2464 - accuracy: 0.7791 - val_loss: 1.2369 - val_accuracy: 0.7829\n",
      "Epoch 111/200\n",
      "172/172 [==============================] - 0s 969us/sample - loss: 1.2443 - accuracy: 0.7791 - val_loss: 1.2452 - val_accuracy: 0.7829\n",
      "Epoch 112/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 1.2443 - accuracy: 0.7791 - val_loss: 1.2408 - val_accuracy: 0.7829\n",
      "Epoch 113/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 1.2438 - accuracy: 0.7791 - val_loss: 1.2499 - val_accuracy: 0.7829\n",
      "Epoch 114/200\n",
      "172/172 [==============================] - 0s 937us/sample - loss: 1.2431 - accuracy: 0.7791 - val_loss: 1.2495 - val_accuracy: 0.7829\n",
      "Epoch 115/200\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 1.2458 - accuracy: 0.7791 - val_loss: 1.2491 - val_accuracy: 0.7829\n",
      "Epoch 116/200\n",
      "172/172 [==============================] - 0s 987us/sample - loss: 1.2449 - accuracy: 0.7791 - val_loss: 1.2425 - val_accuracy: 0.7829\n",
      "Epoch 117/200\n",
      "172/172 [==============================] - 0s 956us/sample - loss: 1.2417 - accuracy: 0.7791 - val_loss: 1.2453 - val_accuracy: 0.7829\n",
      "Epoch 118/200\n",
      "172/172 [==============================] - 0s 958us/sample - loss: 1.2452 - accuracy: 0.7791 - val_loss: 1.2420 - val_accuracy: 0.7829\n",
      "Epoch 119/200\n",
      "172/172 [==============================] - 0s 941us/sample - loss: 1.2425 - accuracy: 0.7791 - val_loss: 1.2541 - val_accuracy: 0.7829\n",
      "Epoch 120/200\n",
      "172/172 [==============================] - 0s 943us/sample - loss: 1.2464 - accuracy: 0.7791 - val_loss: 1.2375 - val_accuracy: 0.7829\n",
      "Epoch 121/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2443 - accuracy: 0.7791 - val_loss: 1.2448 - val_accuracy: 0.7829\n",
      "Epoch 122/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2456 - accuracy: 0.7791 - val_loss: 1.2398 - val_accuracy: 0.7829\n",
      "Epoch 123/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2434 - accuracy: 0.7791 - val_loss: 1.2458 - val_accuracy: 0.7829\n",
      "Epoch 124/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 1.2460 - accuracy: 0.7791 - val_loss: 1.2437 - val_accuracy: 0.7829\n",
      "Epoch 125/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 1.2405 - accuracy: 0.7791 - val_loss: 1.2477 - val_accuracy: 0.7829\n",
      "Epoch 126/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 1.2452 - accuracy: 0.7791 - val_loss: 1.2421 - val_accuracy: 0.7829\n",
      "Epoch 127/200\n",
      "172/172 [==============================] - 0s 943us/sample - loss: 1.2447 - accuracy: 0.7791 - val_loss: 1.2525 - val_accuracy: 0.7829\n",
      "Epoch 128/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 1.2441 - accuracy: 0.7791 - val_loss: 1.2460 - val_accuracy: 0.7829\n",
      "Epoch 129/200\n",
      "172/172 [==============================] - 0s 942us/sample - loss: 1.2458 - accuracy: 0.7791 - val_loss: 1.2433 - val_accuracy: 0.7829\n",
      "Epoch 130/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 1.2419 - accuracy: 0.7791 - val_loss: 1.2407 - val_accuracy: 0.7829\n",
      "Epoch 131/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 1.2485 - accuracy: 0.7791 - val_loss: 1.2450 - val_accuracy: 0.7829\n",
      "Epoch 132/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 1.2459 - accuracy: 0.7791 - val_loss: 1.2372 - val_accuracy: 0.7829\n",
      "Epoch 133/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2405 - accuracy: 0.7791 - val_loss: 1.2585 - val_accuracy: 0.7829\n",
      "Epoch 134/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2448 - accuracy: 0.7791 - val_loss: 1.2485 - val_accuracy: 0.7829\n",
      "Epoch 135/200\n",
      "172/172 [==============================] - 0s 985us/sample - loss: 1.2423 - accuracy: 0.7791 - val_loss: 1.2557 - val_accuracy: 0.7829\n",
      "Epoch 136/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 1.2473 - accuracy: 0.7791 - val_loss: 1.2339 - val_accuracy: 0.7829\n",
      "Epoch 137/200\n",
      "172/172 [==============================] - 0s 930us/sample - loss: 1.2424 - accuracy: 0.7791 - val_loss: 1.2454 - val_accuracy: 0.7829\n",
      "Epoch 138/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 1.2459 - accuracy: 0.7791 - val_loss: 1.2415 - val_accuracy: 0.7829\n",
      "Epoch 139/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 1.2403 - accuracy: 0.7791 - val_loss: 1.2510 - val_accuracy: 0.7829\n",
      "Epoch 140/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 1.2459 - accuracy: 0.7791 - val_loss: 1.2403 - val_accuracy: 0.7829\n",
      "Epoch 141/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 1.2472 - accuracy: 0.7791 - val_loss: 1.2428 - val_accuracy: 0.7829\n",
      "Epoch 142/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 1.2405 - accuracy: 0.7791 - val_loss: 1.2414 - val_accuracy: 0.7829\n",
      "Epoch 143/200\n",
      "172/172 [==============================] - 0s 930us/sample - loss: 1.2457 - accuracy: 0.7791 - val_loss: 1.2499 - val_accuracy: 0.7829\n",
      "Epoch 144/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 1.2442 - accuracy: 0.7791 - val_loss: 1.2445 - val_accuracy: 0.7829\n",
      "Epoch 145/200\n",
      "172/172 [==============================] - 0s 966us/sample - loss: 1.2419 - accuracy: 0.7791 - val_loss: 1.2466 - val_accuracy: 0.7829\n",
      "Epoch 146/200\n",
      "172/172 [==============================] - 0s 988us/sample - loss: 1.2462 - accuracy: 0.7791 - val_loss: 1.2393 - val_accuracy: 0.7829\n",
      "Epoch 147/200\n",
      "172/172 [==============================] - 0s 983us/sample - loss: 1.2424 - accuracy: 0.7791 - val_loss: 1.2546 - val_accuracy: 0.7829\n",
      "Epoch 148/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 1.2449 - accuracy: 0.7791 - val_loss: 1.2426 - val_accuracy: 0.7829\n",
      "Epoch 149/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 1.2434 - accuracy: 0.7791 - val_loss: 1.2528 - val_accuracy: 0.7829\n",
      "Epoch 150/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 1.2454 - accuracy: 0.7791 - val_loss: 1.2385 - val_accuracy: 0.7829\n",
      "Epoch 151/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 1.2439 - accuracy: 0.7791 - val_loss: 1.2434 - val_accuracy: 0.7829\n",
      "Epoch 152/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 894us/sample - loss: 1.2473 - accuracy: 0.7791 - val_loss: 1.2361 - val_accuracy: 0.7829\n",
      "Epoch 153/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 1.2395 - accuracy: 0.7791 - val_loss: 1.2499 - val_accuracy: 0.7829\n",
      "Epoch 154/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 1.2454 - accuracy: 0.7791 - val_loss: 1.2517 - val_accuracy: 0.7829\n",
      "Epoch 155/200\n",
      "172/172 [==============================] - 0s 862us/sample - loss: 1.2435 - accuracy: 0.7791 - val_loss: 1.2533 - val_accuracy: 0.7829\n",
      "Epoch 156/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 1.2452 - accuracy: 0.7791 - val_loss: 1.2450 - val_accuracy: 0.7829\n",
      "Epoch 157/200\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 1.2459 - accuracy: 0.7791 - val_loss: 1.2419 - val_accuracy: 0.7829\n",
      "Epoch 158/200\n",
      "172/172 [==============================] - 0s 966us/sample - loss: 1.2415 - accuracy: 0.7791 - val_loss: 1.2448 - val_accuracy: 0.7829\n",
      "Epoch 159/200\n",
      "172/172 [==============================] - 0s 956us/sample - loss: 1.2463 - accuracy: 0.7791 - val_loss: 1.2460 - val_accuracy: 0.7829\n",
      "Epoch 160/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 1.2446 - accuracy: 0.7791 - val_loss: 1.2346 - val_accuracy: 0.7829\n",
      "Epoch 161/200\n",
      "172/172 [==============================] - 0s 858us/sample - loss: 1.2463 - accuracy: 0.7791 - val_loss: 1.2564 - val_accuracy: 0.7829\n",
      "Epoch 162/200\n",
      "172/172 [==============================] - 0s 849us/sample - loss: 1.2440 - accuracy: 0.7791 - val_loss: 1.2408 - val_accuracy: 0.7829\n",
      "Epoch 163/200\n",
      "172/172 [==============================] - 0s 860us/sample - loss: 1.2424 - accuracy: 0.7791 - val_loss: 1.2546 - val_accuracy: 0.7829\n",
      "Epoch 164/200\n",
      "172/172 [==============================] - 0s 859us/sample - loss: 1.2482 - accuracy: 0.7791 - val_loss: 1.2403 - val_accuracy: 0.7829\n",
      "Epoch 165/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 1.2392 - accuracy: 0.7791 - val_loss: 1.2450 - val_accuracy: 0.7829\n",
      "Epoch 166/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 1.2471 - accuracy: 0.7791 - val_loss: 1.2460 - val_accuracy: 0.7829\n",
      "Epoch 167/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 1.2424 - accuracy: 0.7791 - val_loss: 1.2459 - val_accuracy: 0.7829\n",
      "Epoch 168/200\n",
      "172/172 [==============================] - 0s 864us/sample - loss: 1.2438 - accuracy: 0.7791 - val_loss: 1.2430 - val_accuracy: 0.7829\n",
      "Epoch 169/200\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 1.2448 - accuracy: 0.7791 - val_loss: 1.2502 - val_accuracy: 0.7829\n",
      "Epoch 170/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 1.2420 - accuracy: 0.7791 - val_loss: 1.2384 - val_accuracy: 0.7829\n",
      "Epoch 171/200\n",
      "172/172 [==============================] - 0s 987us/sample - loss: 1.2497 - accuracy: 0.7791 - val_loss: 1.2441 - val_accuracy: 0.7829\n",
      "Epoch 172/200\n",
      "172/172 [==============================] - 0s 959us/sample - loss: 1.2413 - accuracy: 0.7791 - val_loss: 1.2435 - val_accuracy: 0.7829\n",
      "Epoch 173/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 1.2440 - accuracy: 0.7791 - val_loss: 1.2468 - val_accuracy: 0.7829\n",
      "Epoch 174/200\n",
      "172/172 [==============================] - 0s 864us/sample - loss: 1.2439 - accuracy: 0.7791 - val_loss: 1.2400 - val_accuracy: 0.7829\n",
      "Epoch 175/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 1.2401 - accuracy: 0.7791 - val_loss: 1.2610 - val_accuracy: 0.7829\n",
      "Epoch 176/200\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 1.2497 - accuracy: 0.7791 - val_loss: 1.2412 - val_accuracy: 0.7829\n",
      "Epoch 177/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 1.2403 - accuracy: 0.7791 - val_loss: 1.2465 - val_accuracy: 0.7829\n",
      "Epoch 178/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 1.2451 - accuracy: 0.7791 - val_loss: 1.2414 - val_accuracy: 0.7829\n",
      "Epoch 179/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 1.2445 - accuracy: 0.7791 - val_loss: 1.2497 - val_accuracy: 0.7829\n",
      "Epoch 180/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 1.2452 - accuracy: 0.7791 - val_loss: 1.2354 - val_accuracy: 0.7829\n",
      "Epoch 181/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 1.2433 - accuracy: 0.7791 - val_loss: 1.2429 - val_accuracy: 0.7829\n",
      "Epoch 182/200\n",
      "172/172 [==============================] - 0s 862us/sample - loss: 1.2447 - accuracy: 0.7791 - val_loss: 1.2440 - val_accuracy: 0.7829\n",
      "Epoch 183/200\n",
      "172/172 [==============================] - 0s 841us/sample - loss: 1.2441 - accuracy: 0.7791 - val_loss: 1.2562 - val_accuracy: 0.7829\n",
      "Epoch 184/200\n",
      "172/172 [==============================] - 0s 961us/sample - loss: 1.2449 - accuracy: 0.7791 - val_loss: 1.2452 - val_accuracy: 0.7829\n",
      "Epoch 185/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 1.2435 - accuracy: 0.7791 - val_loss: 1.2465 - val_accuracy: 0.7829\n",
      "Epoch 186/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 1.2445 - accuracy: 0.7791 - val_loss: 1.2428 - val_accuracy: 0.7829\n",
      "Epoch 187/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 1.2434 - accuracy: 0.7791 - val_loss: 1.2411 - val_accuracy: 0.7829\n",
      "Epoch 188/200\n",
      "172/172 [==============================] - 0s 845us/sample - loss: 1.2472 - accuracy: 0.7791 - val_loss: 1.2411 - val_accuracy: 0.7829\n",
      "Epoch 189/200\n",
      "172/172 [==============================] - 0s 845us/sample - loss: 1.2425 - accuracy: 0.7791 - val_loss: 1.2564 - val_accuracy: 0.7829\n",
      "Epoch 190/200\n",
      "172/172 [==============================] - 0s 848us/sample - loss: 1.2436 - accuracy: 0.7791 - val_loss: 1.2398 - val_accuracy: 0.7829\n",
      "Epoch 191/200\n",
      "172/172 [==============================] - 0s 842us/sample - loss: 1.2460 - accuracy: 0.7791 - val_loss: 1.2460 - val_accuracy: 0.7829\n",
      "Epoch 192/200\n",
      "172/172 [==============================] - 0s 848us/sample - loss: 1.2472 - accuracy: 0.7791 - val_loss: 1.2339 - val_accuracy: 0.7829\n",
      "Epoch 193/200\n",
      "172/172 [==============================] - 0s 850us/sample - loss: 1.2404 - accuracy: 0.7791 - val_loss: 1.2526 - val_accuracy: 0.7829\n",
      "Epoch 194/200\n",
      "172/172 [==============================] - 0s 848us/sample - loss: 1.2450 - accuracy: 0.7791 - val_loss: 1.2470 - val_accuracy: 0.7829\n",
      "Epoch 195/200\n",
      "172/172 [==============================] - 0s 850us/sample - loss: 1.2407 - accuracy: 0.7791 - val_loss: 1.2514 - val_accuracy: 0.7829\n",
      "Epoch 196/200\n",
      "172/172 [==============================] - 0s 848us/sample - loss: 1.2482 - accuracy: 0.7791 - val_loss: 1.2419 - val_accuracy: 0.7829\n",
      "Epoch 197/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2415 - accuracy: 0.7791 - val_loss: 1.2458 - val_accuracy: 0.7829\n",
      "Epoch 198/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 1.2431 - accuracy: 0.7791 - val_loss: 1.2459 - val_accuracy: 0.7829\n",
      "Epoch 199/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 1.2468 - accuracy: 0.7791 - val_loss: 1.2446 - val_accuracy: 0.7829\n",
      "Epoch 200/200\n",
      "172/172 [==============================] - 0s 822us/sample - loss: 1.2418 - accuracy: 0.7791 - val_loss: 1.2427 - val_accuracy: 0.7829\n",
      "Beginning training for dr=0.010, l_lambda=1.0e-01, reg_type=l1, act: tanh\n",
      "Train on 172 samples, validate on 43 samples\n",
      "Epoch 1/200\n",
      "172/172 [==============================] - 1s 7ms/sample - loss: 71.0904 - accuracy: 0.6667 - val_loss: 35.8418 - val_accuracy: 0.6667\n",
      "Epoch 2/200\n",
      "172/172 [==============================] - 0s 954us/sample - loss: 23.3033 - accuracy: 0.7229 - val_loss: 16.6313 - val_accuracy: 0.7829\n",
      "Epoch 3/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 13.0752 - accuracy: 0.7791 - val_loss: 10.0712 - val_accuracy: 0.7829\n",
      "Epoch 4/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 8.5539 - accuracy: 0.7791 - val_loss: 7.0083 - val_accuracy: 0.7829\n",
      "Epoch 5/200\n",
      "172/172 [==============================] - 0s 795us/sample - loss: 6.0454 - accuracy: 0.7791 - val_loss: 4.9840 - val_accuracy: 0.7829\n",
      "Epoch 6/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 793us/sample - loss: 4.2610 - accuracy: 0.7791 - val_loss: 3.4584 - val_accuracy: 0.7829\n",
      "Epoch 7/200\n",
      "172/172 [==============================] - 0s 788us/sample - loss: 2.9344 - accuracy: 0.7791 - val_loss: 2.3920 - val_accuracy: 0.7829\n",
      "Epoch 8/200\n",
      "172/172 [==============================] - 0s 785us/sample - loss: 2.0194 - accuracy: 0.7791 - val_loss: 1.6615 - val_accuracy: 0.7829\n",
      "Epoch 9/200\n",
      "172/172 [==============================] - 0s 787us/sample - loss: 1.4748 - accuracy: 0.7791 - val_loss: 1.3256 - val_accuracy: 0.7829\n",
      "Epoch 10/200\n",
      "172/172 [==============================] - 0s 795us/sample - loss: 1.2932 - accuracy: 0.7791 - val_loss: 1.2584 - val_accuracy: 0.7829\n",
      "Epoch 11/200\n",
      "172/172 [==============================] - 0s 785us/sample - loss: 1.2583 - accuracy: 0.7791 - val_loss: 1.2468 - val_accuracy: 0.7829\n",
      "Epoch 12/200\n",
      "172/172 [==============================] - 0s 814us/sample - loss: 1.2507 - accuracy: 0.7791 - val_loss: 1.2429 - val_accuracy: 0.7829\n",
      "Epoch 13/200\n",
      "172/172 [==============================] - 0s 792us/sample - loss: 1.2427 - accuracy: 0.7791 - val_loss: 1.2468 - val_accuracy: 0.7829\n",
      "Epoch 14/200\n",
      "172/172 [==============================] - 0s 789us/sample - loss: 1.2440 - accuracy: 0.7791 - val_loss: 1.2477 - val_accuracy: 0.7829\n",
      "Epoch 15/200\n",
      "172/172 [==============================] - 0s 778us/sample - loss: 1.2462 - accuracy: 0.7791 - val_loss: 1.2505 - val_accuracy: 0.7829\n",
      "Epoch 16/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 1.2450 - accuracy: 0.7791 - val_loss: 1.2462 - val_accuracy: 0.7829\n",
      "Epoch 17/200\n",
      "172/172 [==============================] - 0s 858us/sample - loss: 1.2451 - accuracy: 0.7791 - val_loss: 1.2384 - val_accuracy: 0.7829\n",
      "Epoch 18/200\n",
      "172/172 [==============================] - 0s 861us/sample - loss: 1.2428 - accuracy: 0.7791 - val_loss: 1.2474 - val_accuracy: 0.7829\n",
      "Epoch 19/200\n",
      "172/172 [==============================] - 0s 805us/sample - loss: 1.2472 - accuracy: 0.7791 - val_loss: 1.2436 - val_accuracy: 0.7829\n",
      "Epoch 20/200\n",
      "172/172 [==============================] - 0s 797us/sample - loss: 1.2460 - accuracy: 0.7791 - val_loss: 1.2377 - val_accuracy: 0.7829\n",
      "Epoch 21/200\n",
      "172/172 [==============================] - 0s 786us/sample - loss: 1.2431 - accuracy: 0.7791 - val_loss: 1.2472 - val_accuracy: 0.7829\n",
      "Epoch 22/200\n",
      "172/172 [==============================] - 0s 782us/sample - loss: 1.2448 - accuracy: 0.7791 - val_loss: 1.2421 - val_accuracy: 0.7829\n",
      "Epoch 23/200\n",
      "172/172 [==============================] - 0s 799us/sample - loss: 1.2436 - accuracy: 0.7791 - val_loss: 1.2522 - val_accuracy: 0.7829\n",
      "Epoch 24/200\n",
      "172/172 [==============================] - 0s 805us/sample - loss: 1.2465 - accuracy: 0.7791 - val_loss: 1.2434 - val_accuracy: 0.7829\n",
      "Epoch 25/200\n",
      "172/172 [==============================] - 0s 807us/sample - loss: 1.2443 - accuracy: 0.7791 - val_loss: 1.2446 - val_accuracy: 0.7829\n",
      "Epoch 26/200\n",
      "172/172 [==============================] - 0s 810us/sample - loss: 1.2486 - accuracy: 0.7791 - val_loss: 1.2408 - val_accuracy: 0.7829\n",
      "Epoch 27/200\n",
      "172/172 [==============================] - 0s 807us/sample - loss: 1.2416 - accuracy: 0.7791 - val_loss: 1.2443 - val_accuracy: 0.7829\n",
      "Epoch 28/200\n",
      "172/172 [==============================] - 0s 800us/sample - loss: 1.2479 - accuracy: 0.7791 - val_loss: 1.2416 - val_accuracy: 0.7829\n",
      "Epoch 29/200\n",
      "172/172 [==============================] - 0s 809us/sample - loss: 1.2439 - accuracy: 0.7791 - val_loss: 1.2476 - val_accuracy: 0.7829\n",
      "Epoch 30/200\n",
      "172/172 [==============================] - 0s 958us/sample - loss: 1.2435 - accuracy: 0.7791 - val_loss: 1.2448 - val_accuracy: 0.7829\n",
      "Epoch 31/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2490 - accuracy: 0.7791 - val_loss: 1.2396 - val_accuracy: 0.7829\n",
      "Epoch 32/200\n",
      "172/172 [==============================] - 0s 966us/sample - loss: 1.2439 - accuracy: 0.7791 - val_loss: 1.2392 - val_accuracy: 0.7829\n",
      "Epoch 33/200\n",
      "172/172 [==============================] - 0s 822us/sample - loss: 1.2425 - accuracy: 0.7791 - val_loss: 1.2470 - val_accuracy: 0.7829\n",
      "Epoch 34/200\n",
      "172/172 [==============================] - 0s 828us/sample - loss: 1.2466 - accuracy: 0.7791 - val_loss: 1.2421 - val_accuracy: 0.7829\n",
      "Epoch 35/200\n",
      "172/172 [==============================] - 0s 825us/sample - loss: 1.2412 - accuracy: 0.7791 - val_loss: 1.2572 - val_accuracy: 0.7829\n",
      "Epoch 36/200\n",
      "172/172 [==============================] - 0s 822us/sample - loss: 1.2469 - accuracy: 0.7791 - val_loss: 1.2390 - val_accuracy: 0.7829\n",
      "Epoch 37/200\n",
      "172/172 [==============================] - 0s 831us/sample - loss: 1.2440 - accuracy: 0.7791 - val_loss: 1.2478 - val_accuracy: 0.7829\n",
      "Epoch 38/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 1.2438 - accuracy: 0.7791 - val_loss: 1.2383 - val_accuracy: 0.7829\n",
      "Epoch 39/200\n",
      "172/172 [==============================] - 0s 843us/sample - loss: 1.2439 - accuracy: 0.7791 - val_loss: 1.2455 - val_accuracy: 0.7829\n",
      "Epoch 40/200\n",
      "172/172 [==============================] - 0s 854us/sample - loss: 1.2465 - accuracy: 0.7791 - val_loss: 1.2399 - val_accuracy: 0.7829\n",
      "Epoch 41/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 1.2425 - accuracy: 0.7791 - val_loss: 1.2401 - val_accuracy: 0.7829\n",
      "Epoch 42/200\n",
      "172/172 [==============================] - 0s 849us/sample - loss: 1.2444 - accuracy: 0.7791 - val_loss: 1.2419 - val_accuracy: 0.7829\n",
      "Epoch 43/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 1.2439 - accuracy: 0.7791 - val_loss: 1.2486 - val_accuracy: 0.7829\n",
      "Epoch 44/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 1.2434 - accuracy: 0.7791 - val_loss: 1.2494 - val_accuracy: 0.7829\n",
      "Epoch 45/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 1.2451 - accuracy: 0.7791 - val_loss: 1.2383 - val_accuracy: 0.7829\n",
      "Epoch 46/200\n",
      "172/172 [==============================] - 0s 858us/sample - loss: 1.2423 - accuracy: 0.7791 - val_loss: 1.2453 - val_accuracy: 0.7829\n",
      "Epoch 47/200\n",
      "172/172 [==============================] - 0s 850us/sample - loss: 1.2472 - accuracy: 0.7791 - val_loss: 1.2456 - val_accuracy: 0.7829\n",
      "Epoch 48/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 1.2447 - accuracy: 0.7791 - val_loss: 1.2380 - val_accuracy: 0.7829\n",
      "Epoch 49/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 1.2431 - accuracy: 0.7791 - val_loss: 1.2543 - val_accuracy: 0.7829\n",
      "Epoch 50/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 1.2444 - accuracy: 0.7791 - val_loss: 1.2457 - val_accuracy: 0.7829\n",
      "Epoch 51/200\n",
      "172/172 [==============================] - 0s 971us/sample - loss: 1.2459 - accuracy: 0.7791 - val_loss: 1.2455 - val_accuracy: 0.7829\n",
      "Epoch 52/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2460 - accuracy: 0.7791 - val_loss: 1.2383 - val_accuracy: 0.7829\n",
      "Epoch 53/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2401 - accuracy: 0.7791 - val_loss: 1.2448 - val_accuracy: 0.7829\n",
      "Epoch 54/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2476 - accuracy: 0.7791 - val_loss: 1.2430 - val_accuracy: 0.7829\n",
      "Epoch 55/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 1.2393 - accuracy: 0.7791 - val_loss: 1.2422 - val_accuracy: 0.7829\n",
      "Epoch 56/200\n",
      "172/172 [==============================] - 0s 960us/sample - loss: 1.2475 - accuracy: 0.7791 - val_loss: 1.2414 - val_accuracy: 0.7829\n",
      "Epoch 57/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2465 - accuracy: 0.7791 - val_loss: 1.2456 - val_accuracy: 0.7829\n",
      "Epoch 58/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 1.2416 - accuracy: 0.7791 - val_loss: 1.2466 - val_accuracy: 0.7829\n",
      "Epoch 59/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 1.2488 - accuracy: 0.7791 - val_loss: 1.2408 - val_accuracy: 0.7829\n",
      "Epoch 60/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 1.2420 - accuracy: 0.7791 - val_loss: 1.2373 - val_accuracy: 0.7829\n",
      "Epoch 61/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 884us/sample - loss: 1.2447 - accuracy: 0.7791 - val_loss: 1.2399 - val_accuracy: 0.7829\n",
      "Epoch 62/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 1.2428 - accuracy: 0.7791 - val_loss: 1.2388 - val_accuracy: 0.7829\n",
      "Epoch 63/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 1.2415 - accuracy: 0.7791 - val_loss: 1.2610 - val_accuracy: 0.7829\n",
      "Epoch 64/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 1.2454 - accuracy: 0.7791 - val_loss: 1.2427 - val_accuracy: 0.7829\n",
      "Epoch 65/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 1.2405 - accuracy: 0.7791 - val_loss: 1.2468 - val_accuracy: 0.7829\n",
      "Epoch 66/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 1.2482 - accuracy: 0.7791 - val_loss: 1.2355 - val_accuracy: 0.7829\n",
      "Epoch 67/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 1.2409 - accuracy: 0.7791 - val_loss: 1.2428 - val_accuracy: 0.7829\n",
      "Epoch 68/200\n",
      "172/172 [==============================] - 0s 992us/sample - loss: 1.2472 - accuracy: 0.7791 - val_loss: 1.2409 - val_accuracy: 0.7829\n",
      "Epoch 69/200\n",
      "172/172 [==============================] - 0s 966us/sample - loss: 1.2416 - accuracy: 0.7791 - val_loss: 1.2423 - val_accuracy: 0.7829\n",
      "Epoch 70/200\n",
      "172/172 [==============================] - 0s 976us/sample - loss: 1.2437 - accuracy: 0.7791 - val_loss: 1.2411 - val_accuracy: 0.7829\n",
      "Epoch 71/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 1.2475 - accuracy: 0.7791 - val_loss: 1.2468 - val_accuracy: 0.7829\n",
      "Epoch 72/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 1.2412 - accuracy: 0.7791 - val_loss: 1.2423 - val_accuracy: 0.7829\n",
      "Epoch 73/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 1.2445 - accuracy: 0.7791 - val_loss: 1.2416 - val_accuracy: 0.7829\n",
      "Epoch 74/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 1.2435 - accuracy: 0.7791 - val_loss: 1.2451 - val_accuracy: 0.7829\n",
      "Epoch 75/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 1.2415 - accuracy: 0.7791 - val_loss: 1.2425 - val_accuracy: 0.7829\n",
      "Epoch 76/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 1.2482 - accuracy: 0.7791 - val_loss: 1.2378 - val_accuracy: 0.7829\n",
      "Epoch 77/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 1.2417 - accuracy: 0.7791 - val_loss: 1.2531 - val_accuracy: 0.7829\n",
      "Epoch 78/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 1.2434 - accuracy: 0.7791 - val_loss: 1.2442 - val_accuracy: 0.7829\n",
      "Epoch 79/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 1.2445 - accuracy: 0.7791 - val_loss: 1.2487 - val_accuracy: 0.7829\n",
      "Epoch 80/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 1.2456 - accuracy: 0.7791 - val_loss: 1.2359 - val_accuracy: 0.7829\n",
      "Epoch 81/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2441 - accuracy: 0.7791 - val_loss: 1.2365 - val_accuracy: 0.7829\n",
      "Epoch 82/200\n",
      "172/172 [==============================] - 0s 985us/sample - loss: 1.2456 - accuracy: 0.7791 - val_loss: 1.2408 - val_accuracy: 0.7829\n",
      "Epoch 83/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 1.2422 - accuracy: 0.7791 - val_loss: 1.2483 - val_accuracy: 0.7829\n",
      "Epoch 84/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 1.2455 - accuracy: 0.7791 - val_loss: 1.2426 - val_accuracy: 0.7829\n",
      "Epoch 85/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 1.2438 - accuracy: 0.7791 - val_loss: 1.2501 - val_accuracy: 0.7829\n",
      "Epoch 86/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 1.2444 - accuracy: 0.7791 - val_loss: 1.2471 - val_accuracy: 0.7829\n",
      "Epoch 87/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 1.2459 - accuracy: 0.7791 - val_loss: 1.2361 - val_accuracy: 0.7829\n",
      "Epoch 88/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 1.2429 - accuracy: 0.7791 - val_loss: 1.2436 - val_accuracy: 0.7829\n",
      "Epoch 89/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 1.2457 - accuracy: 0.7791 - val_loss: 1.2366 - val_accuracy: 0.7829\n",
      "Epoch 90/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 1.2421 - accuracy: 0.7791 - val_loss: 1.2379 - val_accuracy: 0.7829\n",
      "Epoch 91/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 1.2469 - accuracy: 0.7791 - val_loss: 1.2543 - val_accuracy: 0.7829\n",
      "Epoch 92/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 1.2449 - accuracy: 0.7791 - val_loss: 1.2398 - val_accuracy: 0.7829\n",
      "Epoch 93/200\n",
      "172/172 [==============================] - 0s 980us/sample - loss: 1.2430 - accuracy: 0.7791 - val_loss: 1.2477 - val_accuracy: 0.7829\n",
      "Epoch 94/200\n",
      "172/172 [==============================] - 0s 983us/sample - loss: 1.2447 - accuracy: 0.7791 - val_loss: 1.2406 - val_accuracy: 0.7829\n",
      "Epoch 95/200\n",
      "172/172 [==============================] - 0s 971us/sample - loss: 1.2407 - accuracy: 0.7791 - val_loss: 1.2480 - val_accuracy: 0.7829\n",
      "Epoch 96/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 1.2494 - accuracy: 0.7791 - val_loss: 1.2370 - val_accuracy: 0.7829\n",
      "Epoch 97/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 1.2387 - accuracy: 0.7791 - val_loss: 1.2409 - val_accuracy: 0.7829\n",
      "Epoch 98/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 1.2462 - accuracy: 0.7791 - val_loss: 1.2451 - val_accuracy: 0.7829\n",
      "Epoch 99/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 1.2446 - accuracy: 0.7791 - val_loss: 1.2458 - val_accuracy: 0.7829\n",
      "Epoch 100/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 1.2401 - accuracy: 0.7791 - val_loss: 1.2436 - val_accuracy: 0.7829\n",
      "Epoch 101/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 1.2471 - accuracy: 0.7791 - val_loss: 1.2367 - val_accuracy: 0.7829\n",
      "Epoch 102/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 1.2405 - accuracy: 0.7791 - val_loss: 1.2428 - val_accuracy: 0.7829\n",
      "Epoch 103/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 1.2448 - accuracy: 0.7791 - val_loss: 1.2492 - val_accuracy: 0.7829\n",
      "Epoch 104/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 1.2443 - accuracy: 0.7791 - val_loss: 1.2381 - val_accuracy: 0.7829\n",
      "Epoch 105/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 1.2401 - accuracy: 0.7791 - val_loss: 1.2590 - val_accuracy: 0.7829\n",
      "Epoch 106/200\n",
      "172/172 [==============================] - 0s 973us/sample - loss: 1.2453 - accuracy: 0.7791 - val_loss: 1.2378 - val_accuracy: 0.7829\n",
      "Epoch 107/200\n",
      "172/172 [==============================] - 0s 949us/sample - loss: 1.2412 - accuracy: 0.7791 - val_loss: 1.2473 - val_accuracy: 0.7829\n",
      "Epoch 108/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 1.2457 - accuracy: 0.7791 - val_loss: 1.2360 - val_accuracy: 0.7829\n",
      "Epoch 109/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 1.2424 - accuracy: 0.7791 - val_loss: 1.2403 - val_accuracy: 0.7829\n",
      "Epoch 110/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 1.2443 - accuracy: 0.7791 - val_loss: 1.2390 - val_accuracy: 0.7829\n",
      "Epoch 111/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 1.2425 - accuracy: 0.7791 - val_loss: 1.2415 - val_accuracy: 0.7829\n",
      "Epoch 112/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 1.2453 - accuracy: 0.7791 - val_loss: 1.2406 - val_accuracy: 0.7829\n",
      "Epoch 113/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 1.2437 - accuracy: 0.7791 - val_loss: 1.2467 - val_accuracy: 0.7829\n",
      "Epoch 114/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 1.2405 - accuracy: 0.7791 - val_loss: 1.2488 - val_accuracy: 0.7829\n",
      "Epoch 115/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 1.2460 - accuracy: 0.7791 - val_loss: 1.2441 - val_accuracy: 0.7829\n",
      "Epoch 116/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 875us/sample - loss: 1.2440 - accuracy: 0.7791 - val_loss: 1.2431 - val_accuracy: 0.7829\n",
      "Epoch 117/200\n",
      "172/172 [==============================] - 0s 860us/sample - loss: 1.2411 - accuracy: 0.7791 - val_loss: 1.2410 - val_accuracy: 0.7829\n",
      "Epoch 118/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 1.2452 - accuracy: 0.7791 - val_loss: 1.2415 - val_accuracy: 0.7829\n",
      "Epoch 119/200\n",
      "172/172 [==============================] - 0s 942us/sample - loss: 1.2439 - accuracy: 0.7791 - val_loss: 1.2540 - val_accuracy: 0.7829\n",
      "Epoch 120/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 1.2453 - accuracy: 0.7791 - val_loss: 1.2380 - val_accuracy: 0.7829\n",
      "Epoch 121/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 1.2429 - accuracy: 0.7791 - val_loss: 1.2403 - val_accuracy: 0.7829\n",
      "Epoch 122/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 1.2439 - accuracy: 0.7791 - val_loss: 1.2404 - val_accuracy: 0.7829\n",
      "Epoch 123/200\n",
      "172/172 [==============================] - 0s 848us/sample - loss: 1.2429 - accuracy: 0.7791 - val_loss: 1.2405 - val_accuracy: 0.7829\n",
      "Epoch 124/200\n",
      "172/172 [==============================] - 0s 848us/sample - loss: 1.2455 - accuracy: 0.7791 - val_loss: 1.2435 - val_accuracy: 0.7829\n",
      "Epoch 125/200\n",
      "172/172 [==============================] - 0s 843us/sample - loss: 1.2396 - accuracy: 0.7791 - val_loss: 1.2440 - val_accuracy: 0.7829\n",
      "Epoch 126/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 1.2447 - accuracy: 0.7791 - val_loss: 1.2401 - val_accuracy: 0.7829\n",
      "Epoch 127/200\n",
      "172/172 [==============================] - 0s 849us/sample - loss: 1.2438 - accuracy: 0.7791 - val_loss: 1.2490 - val_accuracy: 0.7829\n",
      "Epoch 128/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 1.2435 - accuracy: 0.7791 - val_loss: 1.2450 - val_accuracy: 0.7829\n",
      "Epoch 129/200\n",
      "172/172 [==============================] - 0s 854us/sample - loss: 1.2445 - accuracy: 0.7791 - val_loss: 1.2372 - val_accuracy: 0.7829\n",
      "Epoch 130/200\n",
      "172/172 [==============================] - 0s 859us/sample - loss: 1.2427 - accuracy: 0.7791 - val_loss: 1.2415 - val_accuracy: 0.7829\n",
      "Epoch 131/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 1.2466 - accuracy: 0.7791 - val_loss: 1.2387 - val_accuracy: 0.7829\n",
      "Epoch 132/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 1.2449 - accuracy: 0.7791 - val_loss: 1.2358 - val_accuracy: 0.7829\n",
      "Epoch 133/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 1.2403 - accuracy: 0.7791 - val_loss: 1.2553 - val_accuracy: 0.7829\n",
      "Epoch 134/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 1.2433 - accuracy: 0.7791 - val_loss: 1.2450 - val_accuracy: 0.7829\n",
      "Epoch 135/200\n",
      "172/172 [==============================] - 0s 853us/sample - loss: 1.2444 - accuracy: 0.7791 - val_loss: 1.2522 - val_accuracy: 0.7829\n",
      "Epoch 136/200\n",
      "172/172 [==============================] - 0s 850us/sample - loss: 1.2462 - accuracy: 0.7791 - val_loss: 1.2343 - val_accuracy: 0.7829\n",
      "Epoch 137/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 1.2411 - accuracy: 0.7791 - val_loss: 1.2438 - val_accuracy: 0.7829\n",
      "Epoch 138/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 1.2465 - accuracy: 0.7791 - val_loss: 1.2412 - val_accuracy: 0.7829\n",
      "Epoch 139/200\n",
      "172/172 [==============================] - 0s 856us/sample - loss: 1.2398 - accuracy: 0.7791 - val_loss: 1.2469 - val_accuracy: 0.7829\n",
      "Epoch 140/200\n",
      "172/172 [==============================] - 0s 858us/sample - loss: 1.2471 - accuracy: 0.7791 - val_loss: 1.2385 - val_accuracy: 0.7829\n",
      "Epoch 141/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 1.2478 - accuracy: 0.7791 - val_loss: 1.2399 - val_accuracy: 0.7829\n",
      "Epoch 142/200\n",
      "172/172 [==============================] - 0s 858us/sample - loss: 1.2386 - accuracy: 0.7791 - val_loss: 1.2439 - val_accuracy: 0.7829\n",
      "Epoch 143/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 1.2466 - accuracy: 0.7791 - val_loss: 1.2456 - val_accuracy: 0.7829\n",
      "Epoch 144/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 1.2439 - accuracy: 0.7791 - val_loss: 1.2430 - val_accuracy: 0.7829\n",
      "Epoch 145/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 1.2423 - accuracy: 0.7791 - val_loss: 1.2412 - val_accuracy: 0.7829\n",
      "Epoch 146/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 1.2451 - accuracy: 0.7791 - val_loss: 1.2371 - val_accuracy: 0.7829\n",
      "Epoch 147/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 1.2433 - accuracy: 0.7791 - val_loss: 1.2533 - val_accuracy: 0.7829\n",
      "Epoch 148/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 1.2428 - accuracy: 0.7791 - val_loss: 1.2399 - val_accuracy: 0.7829\n",
      "Epoch 149/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 1.2442 - accuracy: 0.7791 - val_loss: 1.2471 - val_accuracy: 0.7829\n",
      "Epoch 150/200\n",
      "172/172 [==============================] - 0s 848us/sample - loss: 1.2437 - accuracy: 0.7791 - val_loss: 1.2375 - val_accuracy: 0.7829\n",
      "Epoch 151/200\n",
      "172/172 [==============================] - 0s 850us/sample - loss: 1.2440 - accuracy: 0.7791 - val_loss: 1.2381 - val_accuracy: 0.7829\n",
      "Epoch 152/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 1.2459 - accuracy: 0.7791 - val_loss: 1.2382 - val_accuracy: 0.7829\n",
      "Epoch 153/200\n",
      "172/172 [==============================] - 0s 862us/sample - loss: 1.2389 - accuracy: 0.7791 - val_loss: 1.2416 - val_accuracy: 0.7829\n",
      "Epoch 154/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 1.2450 - accuracy: 0.7791 - val_loss: 1.2478 - val_accuracy: 0.7829\n",
      "Epoch 155/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 1.2439 - accuracy: 0.7791 - val_loss: 1.2475 - val_accuracy: 0.7829\n",
      "Epoch 156/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 1.2439 - accuracy: 0.7791 - val_loss: 1.2461 - val_accuracy: 0.7829\n",
      "Epoch 157/200\n",
      "172/172 [==============================] - 0s 854us/sample - loss: 1.2469 - accuracy: 0.7791 - val_loss: 1.2367 - val_accuracy: 0.7829\n",
      "Epoch 158/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 1.2424 - accuracy: 0.7791 - val_loss: 1.2441 - val_accuracy: 0.7829\n",
      "Epoch 159/200\n",
      "172/172 [==============================] - 0s 957us/sample - loss: 1.2445 - accuracy: 0.7791 - val_loss: 1.2404 - val_accuracy: 0.7829\n",
      "Epoch 160/200\n",
      "172/172 [==============================] - 0s 990us/sample - loss: 1.2433 - accuracy: 0.7791 - val_loss: 1.2350 - val_accuracy: 0.7829\n",
      "Epoch 161/200\n",
      "172/172 [==============================] - 0s 930us/sample - loss: 1.2430 - accuracy: 0.7791 - val_loss: 1.2518 - val_accuracy: 0.7829\n",
      "Epoch 162/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 1.2450 - accuracy: 0.7791 - val_loss: 1.2391 - val_accuracy: 0.7829\n",
      "Epoch 163/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 1.2406 - accuracy: 0.7791 - val_loss: 1.2515 - val_accuracy: 0.7829\n",
      "Epoch 164/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 1.2493 - accuracy: 0.7791 - val_loss: 1.2403 - val_accuracy: 0.7829\n",
      "Epoch 165/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 1.2386 - accuracy: 0.7791 - val_loss: 1.2395 - val_accuracy: 0.7829\n",
      "Epoch 166/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 1.2484 - accuracy: 0.7791 - val_loss: 1.2436 - val_accuracy: 0.7829\n",
      "Epoch 167/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 1.2425 - accuracy: 0.7791 - val_loss: 1.2441 - val_accuracy: 0.7829\n",
      "Epoch 168/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 1.2430 - accuracy: 0.7791 - val_loss: 1.2395 - val_accuracy: 0.7829\n",
      "Epoch 169/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 1.2446 - accuracy: 0.7791 - val_loss: 1.2464 - val_accuracy: 0.7829\n",
      "Epoch 170/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 1.2399 - accuracy: 0.7791 - val_loss: 1.2408 - val_accuracy: 0.7829\n",
      "Epoch 171/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 993us/sample - loss: 1.2476 - accuracy: 0.7791 - val_loss: 1.2393 - val_accuracy: 0.7829\n",
      "Epoch 172/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2405 - accuracy: 0.7791 - val_loss: 1.2399 - val_accuracy: 0.7829\n",
      "Epoch 173/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2435 - accuracy: 0.7791 - val_loss: 1.2435 - val_accuracy: 0.7829\n",
      "Epoch 174/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2435 - accuracy: 0.7791 - val_loss: 1.2378 - val_accuracy: 0.7829\n",
      "Epoch 175/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 1.2401 - accuracy: 0.7791 - val_loss: 1.2559 - val_accuracy: 0.7829\n",
      "Epoch 176/200\n",
      "172/172 [==============================] - 0s 2ms/sample - loss: 1.2470 - accuracy: 0.7791 - val_loss: 1.2407 - val_accuracy: 0.7829\n",
      "Epoch 177/200\n",
      "172/172 [==============================] - 0s 2ms/sample - loss: 1.2410 - accuracy: 0.7791 - val_loss: 1.2437 - val_accuracy: 0.7829\n",
      "Epoch 178/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2431 - accuracy: 0.7791 - val_loss: 1.2398 - val_accuracy: 0.7829\n",
      "Epoch 179/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2432 - accuracy: 0.7791 - val_loss: 1.2426 - val_accuracy: 0.7829\n",
      "Epoch 180/200\n",
      "172/172 [==============================] - 0s 2ms/sample - loss: 1.2436 - accuracy: 0.7791 - val_loss: 1.2359 - val_accuracy: 0.7829\n",
      "Epoch 181/200\n",
      "172/172 [==============================] - 0s 2ms/sample - loss: 1.2441 - accuracy: 0.7791 - val_loss: 1.2415 - val_accuracy: 0.7829\n",
      "Epoch 182/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2438 - accuracy: 0.7791 - val_loss: 1.2420 - val_accuracy: 0.7829\n",
      "Epoch 183/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2444 - accuracy: 0.7791 - val_loss: 1.2515 - val_accuracy: 0.7829\n",
      "Epoch 184/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2438 - accuracy: 0.7791 - val_loss: 1.2465 - val_accuracy: 0.7829\n",
      "Epoch 185/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2428 - accuracy: 0.7791 - val_loss: 1.2385 - val_accuracy: 0.7829\n",
      "Epoch 186/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2445 - accuracy: 0.7791 - val_loss: 1.2403 - val_accuracy: 0.7829\n",
      "Epoch 187/200\n",
      "172/172 [==============================] - 0s 994us/sample - loss: 1.2420 - accuracy: 0.7791 - val_loss: 1.2413 - val_accuracy: 0.7829\n",
      "Epoch 188/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2455 - accuracy: 0.7791 - val_loss: 1.2395 - val_accuracy: 0.7829\n",
      "Epoch 189/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2431 - accuracy: 0.7791 - val_loss: 1.2539 - val_accuracy: 0.7829\n",
      "Epoch 190/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2411 - accuracy: 0.7791 - val_loss: 1.2399 - val_accuracy: 0.7829\n",
      "Epoch 191/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2461 - accuracy: 0.7791 - val_loss: 1.2442 - val_accuracy: 0.7829\n",
      "Epoch 192/200\n",
      "172/172 [==============================] - 0s 952us/sample - loss: 1.2459 - accuracy: 0.7791 - val_loss: 1.2351 - val_accuracy: 0.7829\n",
      "Epoch 193/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2385 - accuracy: 0.7791 - val_loss: 1.2457 - val_accuracy: 0.7829\n",
      "Epoch 194/200\n",
      "172/172 [==============================] - 0s 962us/sample - loss: 1.2450 - accuracy: 0.7791 - val_loss: 1.2466 - val_accuracy: 0.7829\n",
      "Epoch 195/200\n",
      "172/172 [==============================] - 0s 960us/sample - loss: 1.2390 - accuracy: 0.7791 - val_loss: 1.2474 - val_accuracy: 0.7829\n",
      "Epoch 196/200\n",
      "172/172 [==============================] - 0s 970us/sample - loss: 1.2480 - accuracy: 0.7791 - val_loss: 1.2382 - val_accuracy: 0.7829\n",
      "Epoch 197/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2435 - accuracy: 0.7791 - val_loss: 1.2424 - val_accuracy: 0.7829\n",
      "Epoch 198/200\n",
      "172/172 [==============================] - 0s 969us/sample - loss: 1.2413 - accuracy: 0.7791 - val_loss: 1.2476 - val_accuracy: 0.7829\n",
      "Epoch 199/200\n",
      "172/172 [==============================] - 0s 975us/sample - loss: 1.2462 - accuracy: 0.7791 - val_loss: 1.2376 - val_accuracy: 0.7829\n",
      "Epoch 200/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.2403 - accuracy: 0.7791 - val_loss: 1.2423 - val_accuracy: 0.7829\n",
      "Beginning training for dr=0.100, l_lambda=1.0e-03, reg_type=l2, act: relu\n",
      "Train on 172 samples, validate on 43 samples\n",
      "Epoch 1/200\n",
      "172/172 [==============================] - 2s 9ms/sample - loss: 0.6510 - accuracy: 0.6667 - val_loss: 0.6208 - val_accuracy: 0.6667\n",
      "Epoch 2/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.6000 - accuracy: 0.6667 - val_loss: 0.5705 - val_accuracy: 0.6667\n",
      "Epoch 3/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5499 - accuracy: 0.7384 - val_loss: 0.5267 - val_accuracy: 0.7829\n",
      "Epoch 4/200\n",
      "172/172 [==============================] - 0s 937us/sample - loss: 0.5234 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 5/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.5149 - accuracy: 0.7791 - val_loss: 0.5075 - val_accuracy: 0.7829\n",
      "Epoch 6/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5058 - val_accuracy: 0.7829\n",
      "Epoch 7/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 0.5123 - accuracy: 0.7791 - val_loss: 0.5046 - val_accuracy: 0.7829\n",
      "Epoch 8/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 0.5119 - accuracy: 0.7791 - val_loss: 0.5042 - val_accuracy: 0.7829\n",
      "Epoch 9/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5033 - val_accuracy: 0.7829\n",
      "Epoch 10/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5030 - val_accuracy: 0.7829\n",
      "Epoch 11/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 12/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 13/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.5085 - accuracy: 0.7791 - val_loss: 0.5028 - val_accuracy: 0.7829\n",
      "Epoch 14/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5028 - val_accuracy: 0.7829\n",
      "Epoch 15/200\n",
      "172/172 [==============================] - 0s 996us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 16/200\n",
      "172/172 [==============================] - 0s 960us/sample - loss: 0.5118 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 17/200\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 0.5104 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 18/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 0.5116 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 19/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 0.5104 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 20/200\n",
      "172/172 [==============================] - 0s 858us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5013 - val_accuracy: 0.7829\n",
      "Epoch 21/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 22/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5011 - val_accuracy: 0.7829\n",
      "Epoch 23/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5011 - val_accuracy: 0.7829\n",
      "Epoch 24/200\n",
      "172/172 [==============================] - 0s 976us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5010 - val_accuracy: 0.7829\n",
      "Epoch 25/200\n",
      "172/172 [==============================] - 0s 981us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5080 - accuracy: 0.7791 - val_loss: 0.5007 - val_accuracy: 0.7829\n",
      "Epoch 27/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5081 - accuracy: 0.7791 - val_loss: 0.5005 - val_accuracy: 0.7829\n",
      "Epoch 28/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5105 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 29/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 0.5065 - accuracy: 0.7791 - val_loss: 0.5005 - val_accuracy: 0.7829\n",
      "Epoch 30/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.5069 - accuracy: 0.7791 - val_loss: 0.5006 - val_accuracy: 0.7829\n",
      "Epoch 31/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5005 - val_accuracy: 0.7829\n",
      "Epoch 32/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 0.5075 - accuracy: 0.7791 - val_loss: 0.5005 - val_accuracy: 0.7829\n",
      "Epoch 33/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.5073 - accuracy: 0.7791 - val_loss: 0.5003 - val_accuracy: 0.7829\n",
      "Epoch 34/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.5082 - accuracy: 0.7791 - val_loss: 0.5000 - val_accuracy: 0.7829\n",
      "Epoch 35/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5004 - val_accuracy: 0.7829\n",
      "Epoch 36/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.5081 - accuracy: 0.7791 - val_loss: 0.4999 - val_accuracy: 0.7829\n",
      "Epoch 37/200\n",
      "172/172 [==============================] - 0s 882us/sample - loss: 0.5077 - accuracy: 0.7791 - val_loss: 0.4996 - val_accuracy: 0.7829\n",
      "Epoch 38/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.5083 - accuracy: 0.7791 - val_loss: 0.4995 - val_accuracy: 0.7829\n",
      "Epoch 39/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5076 - accuracy: 0.7791 - val_loss: 0.4995 - val_accuracy: 0.7829\n",
      "Epoch 40/200\n",
      "172/172 [==============================] - 0s 969us/sample - loss: 0.5070 - accuracy: 0.7791 - val_loss: 0.4996 - val_accuracy: 0.7829\n",
      "Epoch 41/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.5075 - accuracy: 0.7791 - val_loss: 0.4992 - val_accuracy: 0.7829\n",
      "Epoch 42/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.4991 - val_accuracy: 0.7829\n",
      "Epoch 43/200\n",
      "172/172 [==============================] - 0s 882us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.4996 - val_accuracy: 0.7829\n",
      "Epoch 44/200\n",
      "172/172 [==============================] - 0s 988us/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5002 - val_accuracy: 0.7829\n",
      "Epoch 45/200\n",
      "172/172 [==============================] - 0s 937us/sample - loss: 0.5080 - accuracy: 0.7791 - val_loss: 0.5000 - val_accuracy: 0.7829\n",
      "Epoch 46/200\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 0.5062 - accuracy: 0.7791 - val_loss: 0.4987 - val_accuracy: 0.7829\n",
      "Epoch 47/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.5075 - accuracy: 0.7791 - val_loss: 0.4987 - val_accuracy: 0.7829\n",
      "Epoch 48/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.5083 - accuracy: 0.7791 - val_loss: 0.4984 - val_accuracy: 0.7829\n",
      "Epoch 49/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.5053 - accuracy: 0.7791 - val_loss: 0.4984 - val_accuracy: 0.7829\n",
      "Epoch 50/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 0.5060 - accuracy: 0.7791 - val_loss: 0.4981 - val_accuracy: 0.7829\n",
      "Epoch 51/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5049 - accuracy: 0.7791 - val_loss: 0.4993 - val_accuracy: 0.7829\n",
      "Epoch 52/200\n",
      "172/172 [==============================] - 0s 981us/sample - loss: 0.5068 - accuracy: 0.7791 - val_loss: 0.4994 - val_accuracy: 0.7829\n",
      "Epoch 53/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5074 - accuracy: 0.7791 - val_loss: 0.4988 - val_accuracy: 0.7829\n",
      "Epoch 54/200\n",
      "172/172 [==============================] - 0s 976us/sample - loss: 0.5070 - accuracy: 0.7791 - val_loss: 0.4978 - val_accuracy: 0.7829\n",
      "Epoch 55/200\n",
      "172/172 [==============================] - 0s 949us/sample - loss: 0.5068 - accuracy: 0.7791 - val_loss: 0.4978 - val_accuracy: 0.7829\n",
      "Epoch 56/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.5078 - accuracy: 0.7791 - val_loss: 0.4982 - val_accuracy: 0.7829\n",
      "Epoch 57/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 0.5049 - accuracy: 0.7791 - val_loss: 0.4971 - val_accuracy: 0.7829\n",
      "Epoch 58/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.5058 - accuracy: 0.7791 - val_loss: 0.4965 - val_accuracy: 0.7829\n",
      "Epoch 59/200\n",
      "172/172 [==============================] - 0s 962us/sample - loss: 0.5051 - accuracy: 0.7791 - val_loss: 0.4966 - val_accuracy: 0.7829\n",
      "Epoch 60/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.5063 - accuracy: 0.7791 - val_loss: 0.4968 - val_accuracy: 0.7829\n",
      "Epoch 61/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5041 - accuracy: 0.7791 - val_loss: 0.4987 - val_accuracy: 0.7829\n",
      "Epoch 62/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5039 - accuracy: 0.7791 - val_loss: 0.4957 - val_accuracy: 0.7829\n",
      "Epoch 63/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5040 - accuracy: 0.7791 - val_loss: 0.4954 - val_accuracy: 0.7829\n",
      "Epoch 64/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5065 - accuracy: 0.7791 - val_loss: 0.4951 - val_accuracy: 0.7829\n",
      "Epoch 65/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5047 - accuracy: 0.7791 - val_loss: 0.4962 - val_accuracy: 0.7829\n",
      "Epoch 66/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5033 - accuracy: 0.7791 - val_loss: 0.4942 - val_accuracy: 0.7829\n",
      "Epoch 67/200\n",
      "172/172 [==============================] - 0s 979us/sample - loss: 0.5019 - accuracy: 0.7791 - val_loss: 0.4942 - val_accuracy: 0.7829\n",
      "Epoch 68/200\n",
      "172/172 [==============================] - 0s 992us/sample - loss: 0.5037 - accuracy: 0.7791 - val_loss: 0.4946 - val_accuracy: 0.7829\n",
      "Epoch 69/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.5035 - accuracy: 0.7791 - val_loss: 0.4941 - val_accuracy: 0.7829\n",
      "Epoch 70/200\n",
      "172/172 [==============================] - 0s 988us/sample - loss: 0.5038 - accuracy: 0.7791 - val_loss: 0.4934 - val_accuracy: 0.7829\n",
      "Epoch 71/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.5041 - accuracy: 0.7791 - val_loss: 0.4921 - val_accuracy: 0.7829\n",
      "Epoch 72/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.5021 - accuracy: 0.7791 - val_loss: 0.4921 - val_accuracy: 0.7829\n",
      "Epoch 73/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 0.5008 - accuracy: 0.7791 - val_loss: 0.4914 - val_accuracy: 0.7829\n",
      "Epoch 74/200\n",
      "172/172 [==============================] - 0s 963us/sample - loss: 0.4998 - accuracy: 0.7791 - val_loss: 0.4909 - val_accuracy: 0.7829\n",
      "Epoch 75/200\n",
      "172/172 [==============================] - 0s 999us/sample - loss: 0.4990 - accuracy: 0.7791 - val_loss: 0.4913 - val_accuracy: 0.7829\n",
      "Epoch 76/200\n",
      "172/172 [==============================] - 0s 963us/sample - loss: 0.4989 - accuracy: 0.7791 - val_loss: 0.4901 - val_accuracy: 0.7829\n",
      "Epoch 77/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.5017 - accuracy: 0.7791 - val_loss: 0.4896 - val_accuracy: 0.7829\n",
      "Epoch 78/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.4993 - accuracy: 0.7791 - val_loss: 0.4889 - val_accuracy: 0.7829\n",
      "Epoch 79/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.4978 - accuracy: 0.7791 - val_loss: 0.4909 - val_accuracy: 0.7829\n",
      "Epoch 80/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.4969 - accuracy: 0.7791 - val_loss: 0.4868 - val_accuracy: 0.7829\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 887us/sample - loss: 0.4988 - accuracy: 0.7791 - val_loss: 0.4881 - val_accuracy: 0.7829\n",
      "Epoch 82/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.4983 - accuracy: 0.7791 - val_loss: 0.4852 - val_accuracy: 0.7829\n",
      "Epoch 83/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.4949 - accuracy: 0.7791 - val_loss: 0.4853 - val_accuracy: 0.7829\n",
      "Epoch 84/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.4945 - accuracy: 0.7791 - val_loss: 0.4842 - val_accuracy: 0.7829\n",
      "Epoch 85/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 0.4938 - accuracy: 0.7791 - val_loss: 0.4836 - val_accuracy: 0.7829\n",
      "Epoch 86/200\n",
      "172/172 [==============================] - 0s 882us/sample - loss: 0.4992 - accuracy: 0.7791 - val_loss: 0.4856 - val_accuracy: 0.7829\n",
      "Epoch 87/200\n",
      "172/172 [==============================] - 0s 967us/sample - loss: 0.4926 - accuracy: 0.7791 - val_loss: 0.4835 - val_accuracy: 0.7829\n",
      "Epoch 88/200\n",
      "172/172 [==============================] - 0s 963us/sample - loss: 0.4936 - accuracy: 0.7791 - val_loss: 0.4828 - val_accuracy: 0.7829\n",
      "Epoch 89/200\n",
      "172/172 [==============================] - 0s 987us/sample - loss: 0.4920 - accuracy: 0.7791 - val_loss: 0.4826 - val_accuracy: 0.7829\n",
      "Epoch 90/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 0.4898 - accuracy: 0.7791 - val_loss: 0.4837 - val_accuracy: 0.7829\n",
      "Epoch 91/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 0.4904 - accuracy: 0.7791 - val_loss: 0.4782 - val_accuracy: 0.7829\n",
      "Epoch 92/200\n",
      "172/172 [==============================] - 0s 965us/sample - loss: 0.4873 - accuracy: 0.7791 - val_loss: 0.4766 - val_accuracy: 0.7829\n",
      "Epoch 93/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.4857 - accuracy: 0.7791 - val_loss: 0.4764 - val_accuracy: 0.7829\n",
      "Epoch 94/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.4867 - accuracy: 0.7791 - val_loss: 0.4777 - val_accuracy: 0.7829\n",
      "Epoch 95/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.4851 - accuracy: 0.7791 - val_loss: 0.4740 - val_accuracy: 0.7829\n",
      "Epoch 96/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.4881 - accuracy: 0.7791 - val_loss: 0.4736 - val_accuracy: 0.7829\n",
      "Epoch 97/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.4897 - accuracy: 0.7791 - val_loss: 0.4725 - val_accuracy: 0.7829\n",
      "Epoch 98/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.4909 - accuracy: 0.7771 - val_loss: 0.4751 - val_accuracy: 0.7829\n",
      "Epoch 99/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4833 - accuracy: 0.7791 - val_loss: 0.4708 - val_accuracy: 0.7829\n",
      "Epoch 100/200\n",
      "172/172 [==============================] - 0s 995us/sample - loss: 0.4812 - accuracy: 0.7791 - val_loss: 0.4713 - val_accuracy: 0.7829\n",
      "Epoch 101/200\n",
      "172/172 [==============================] - 0s 973us/sample - loss: 0.4802 - accuracy: 0.7888 - val_loss: 0.4701 - val_accuracy: 0.7984\n",
      "Epoch 102/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 0.4891 - accuracy: 0.7791 - val_loss: 0.4685 - val_accuracy: 0.7829\n",
      "Epoch 103/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.4792 - accuracy: 0.7907 - val_loss: 0.4716 - val_accuracy: 0.7984\n",
      "Epoch 104/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.4777 - accuracy: 0.7810 - val_loss: 0.4669 - val_accuracy: 0.8062\n",
      "Epoch 105/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.4774 - accuracy: 0.7965 - val_loss: 0.4737 - val_accuracy: 0.7984\n",
      "Epoch 106/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.4761 - accuracy: 0.7888 - val_loss: 0.4649 - val_accuracy: 0.7984\n",
      "Epoch 107/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.4775 - accuracy: 0.7849 - val_loss: 0.4673 - val_accuracy: 0.7984\n",
      "Epoch 108/200\n",
      "172/172 [==============================] - 0s 984us/sample - loss: 0.4770 - accuracy: 0.7965 - val_loss: 0.4653 - val_accuracy: 0.7984\n",
      "Epoch 109/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4813 - accuracy: 0.7868 - val_loss: 0.4642 - val_accuracy: 0.7984\n",
      "Epoch 110/200\n",
      "172/172 [==============================] - 0s 928us/sample - loss: 0.4734 - accuracy: 0.8081 - val_loss: 0.4639 - val_accuracy: 0.7907\n",
      "Epoch 111/200\n",
      "172/172 [==============================] - 0s 942us/sample - loss: 0.4745 - accuracy: 0.7888 - val_loss: 0.4651 - val_accuracy: 0.7984\n",
      "Epoch 112/200\n",
      "172/172 [==============================] - 0s 2ms/sample - loss: 0.4740 - accuracy: 0.7926 - val_loss: 0.4692 - val_accuracy: 0.8062\n",
      "Epoch 113/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4713 - accuracy: 0.8043 - val_loss: 0.4616 - val_accuracy: 0.7907\n",
      "Epoch 114/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.4649 - accuracy: 0.8101 - val_loss: 0.4586 - val_accuracy: 0.7984\n",
      "Epoch 115/200\n",
      "172/172 [==============================] - 0s 991us/sample - loss: 0.4733 - accuracy: 0.7946 - val_loss: 0.4647 - val_accuracy: 0.8062\n",
      "Epoch 116/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.4681 - accuracy: 0.8062 - val_loss: 0.4565 - val_accuracy: 0.7984\n",
      "Epoch 117/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.4710 - accuracy: 0.7868 - val_loss: 0.4631 - val_accuracy: 0.8062\n",
      "Epoch 118/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.4621 - accuracy: 0.8081 - val_loss: 0.4549 - val_accuracy: 0.7984\n",
      "Epoch 119/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.4638 - accuracy: 0.8004 - val_loss: 0.4583 - val_accuracy: 0.8062\n",
      "Epoch 120/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.4629 - accuracy: 0.7984 - val_loss: 0.4533 - val_accuracy: 0.7984\n",
      "Epoch 121/200\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 0.4600 - accuracy: 0.8062 - val_loss: 0.4545 - val_accuracy: 0.7984\n",
      "Epoch 122/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.4686 - accuracy: 0.7965 - val_loss: 0.4573 - val_accuracy: 0.8062\n",
      "Epoch 123/200\n",
      "172/172 [==============================] - 0s 947us/sample - loss: 0.4693 - accuracy: 0.8023 - val_loss: 0.4573 - val_accuracy: 0.8062\n",
      "Epoch 124/200\n",
      "172/172 [==============================] - 0s 974us/sample - loss: 0.4648 - accuracy: 0.8120 - val_loss: 0.4529 - val_accuracy: 0.7984\n",
      "Epoch 125/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4646 - accuracy: 0.7965 - val_loss: 0.4515 - val_accuracy: 0.7907\n",
      "Epoch 126/200\n",
      "172/172 [==============================] - 0s 945us/sample - loss: 0.4559 - accuracy: 0.8081 - val_loss: 0.4549 - val_accuracy: 0.8062\n",
      "Epoch 127/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.4652 - accuracy: 0.8043 - val_loss: 0.4537 - val_accuracy: 0.8062\n",
      "Epoch 128/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.4644 - accuracy: 0.8101 - val_loss: 0.4542 - val_accuracy: 0.8062\n",
      "Epoch 129/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.4602 - accuracy: 0.8198 - val_loss: 0.4529 - val_accuracy: 0.8062\n",
      "Epoch 130/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 0.4617 - accuracy: 0.8101 - val_loss: 0.4486 - val_accuracy: 0.7907\n",
      "Epoch 131/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.4715 - accuracy: 0.7984 - val_loss: 0.4572 - val_accuracy: 0.8062\n",
      "Epoch 132/200\n",
      "172/172 [==============================] - 0s 946us/sample - loss: 0.4637 - accuracy: 0.8043 - val_loss: 0.4512 - val_accuracy: 0.8062\n",
      "Epoch 133/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.4576 - accuracy: 0.8198 - val_loss: 0.4518 - val_accuracy: 0.8062\n",
      "Epoch 134/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.4729 - accuracy: 0.7849 - val_loss: 0.4489 - val_accuracy: 0.8062\n",
      "Epoch 135/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 0.4577 - accuracy: 0.8178 - val_loss: 0.4479 - val_accuracy: 0.8062\n",
      "Epoch 136/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4591 - accuracy: 0.8178 - val_loss: 0.4504 - val_accuracy: 0.8062\n",
      "Epoch 137/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4666 - accuracy: 0.7965 - val_loss: 0.4506 - val_accuracy: 0.8062\n",
      "Epoch 138/200\n",
      "172/172 [==============================] - 0s 943us/sample - loss: 0.4694 - accuracy: 0.8178 - val_loss: 0.4479 - val_accuracy: 0.8062\n",
      "Epoch 139/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.4598 - accuracy: 0.7984 - val_loss: 0.4469 - val_accuracy: 0.8062\n",
      "Epoch 140/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.4590 - accuracy: 0.8120 - val_loss: 0.4497 - val_accuracy: 0.8062\n",
      "Epoch 141/200\n",
      "172/172 [==============================] - 0s 944us/sample - loss: 0.4661 - accuracy: 0.8101 - val_loss: 0.4474 - val_accuracy: 0.8062\n",
      "Epoch 142/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.4475 - accuracy: 0.8140 - val_loss: 0.4501 - val_accuracy: 0.8062\n",
      "Epoch 143/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.4489 - accuracy: 0.8140 - val_loss: 0.4435 - val_accuracy: 0.8062\n",
      "Epoch 144/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.4542 - accuracy: 0.8159 - val_loss: 0.4453 - val_accuracy: 0.8062\n",
      "Epoch 145/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 0.4541 - accuracy: 0.8217 - val_loss: 0.4435 - val_accuracy: 0.8062\n",
      "Epoch 146/200\n",
      "172/172 [==============================] - 0s 861us/sample - loss: 0.4410 - accuracy: 0.8140 - val_loss: 0.4455 - val_accuracy: 0.8062\n",
      "Epoch 147/200\n",
      "172/172 [==============================] - 0s 864us/sample - loss: 0.4492 - accuracy: 0.8236 - val_loss: 0.4437 - val_accuracy: 0.8062\n",
      "Epoch 148/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 0.4606 - accuracy: 0.8140 - val_loss: 0.4489 - val_accuracy: 0.8140\n",
      "Epoch 149/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.4466 - accuracy: 0.8236 - val_loss: 0.4461 - val_accuracy: 0.8062\n",
      "Epoch 150/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.4452 - accuracy: 0.8236 - val_loss: 0.4414 - val_accuracy: 0.8062\n",
      "Epoch 151/200\n",
      "172/172 [==============================] - 0s 856us/sample - loss: 0.4485 - accuracy: 0.8217 - val_loss: 0.4520 - val_accuracy: 0.8372\n",
      "Epoch 152/200\n",
      "172/172 [==============================] - 0s 856us/sample - loss: 0.4599 - accuracy: 0.8198 - val_loss: 0.4402 - val_accuracy: 0.8062\n",
      "Epoch 153/200\n",
      "172/172 [==============================] - 0s 857us/sample - loss: 0.4562 - accuracy: 0.8159 - val_loss: 0.4474 - val_accuracy: 0.8295\n",
      "Epoch 154/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 0.4501 - accuracy: 0.8159 - val_loss: 0.4402 - val_accuracy: 0.8062\n",
      "Epoch 155/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.4550 - accuracy: 0.8178 - val_loss: 0.4395 - val_accuracy: 0.8062\n",
      "Epoch 156/200\n",
      "172/172 [==============================] - 0s 833us/sample - loss: 0.4466 - accuracy: 0.8120 - val_loss: 0.4393 - val_accuracy: 0.8062\n",
      "Epoch 157/200\n",
      "172/172 [==============================] - 0s 839us/sample - loss: 0.4544 - accuracy: 0.8081 - val_loss: 0.4413 - val_accuracy: 0.8140\n",
      "Epoch 158/200\n",
      "172/172 [==============================] - 0s 833us/sample - loss: 0.4504 - accuracy: 0.8159 - val_loss: 0.4388 - val_accuracy: 0.8062\n",
      "Epoch 159/200\n",
      "172/172 [==============================] - 0s 826us/sample - loss: 0.4476 - accuracy: 0.8140 - val_loss: 0.4441 - val_accuracy: 0.8295\n",
      "Epoch 160/200\n",
      "172/172 [==============================] - 0s 831us/sample - loss: 0.4513 - accuracy: 0.8217 - val_loss: 0.4380 - val_accuracy: 0.8062\n",
      "Epoch 161/200\n",
      "172/172 [==============================] - 0s 834us/sample - loss: 0.4467 - accuracy: 0.8236 - val_loss: 0.4361 - val_accuracy: 0.8062\n",
      "Epoch 162/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.4531 - accuracy: 0.8159 - val_loss: 0.4391 - val_accuracy: 0.8062\n",
      "Epoch 163/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.4561 - accuracy: 0.8217 - val_loss: 0.4370 - val_accuracy: 0.8062\n",
      "Epoch 164/200\n",
      "172/172 [==============================] - 0s 854us/sample - loss: 0.4425 - accuracy: 0.8140 - val_loss: 0.4402 - val_accuracy: 0.8140\n",
      "Epoch 165/200\n",
      "172/172 [==============================] - 0s 832us/sample - loss: 0.4454 - accuracy: 0.8256 - val_loss: 0.4367 - val_accuracy: 0.8062\n",
      "Epoch 166/200\n",
      "172/172 [==============================] - 0s 829us/sample - loss: 0.4451 - accuracy: 0.8198 - val_loss: 0.4415 - val_accuracy: 0.8295\n",
      "Epoch 167/200\n",
      "172/172 [==============================] - 0s 832us/sample - loss: 0.4472 - accuracy: 0.8159 - val_loss: 0.4374 - val_accuracy: 0.8140\n",
      "Epoch 168/200\n",
      "172/172 [==============================] - 0s 836us/sample - loss: 0.4563 - accuracy: 0.8178 - val_loss: 0.4350 - val_accuracy: 0.8062\n",
      "Epoch 169/200\n",
      "172/172 [==============================] - 0s 832us/sample - loss: 0.4463 - accuracy: 0.8120 - val_loss: 0.4384 - val_accuracy: 0.8140\n",
      "Epoch 170/200\n",
      "172/172 [==============================] - 0s 835us/sample - loss: 0.4429 - accuracy: 0.8198 - val_loss: 0.4358 - val_accuracy: 0.8062\n",
      "Epoch 171/200\n",
      "172/172 [==============================] - 0s 834us/sample - loss: 0.4543 - accuracy: 0.8256 - val_loss: 0.4345 - val_accuracy: 0.8062\n",
      "Epoch 172/200\n",
      "172/172 [==============================] - 0s 810us/sample - loss: 0.4584 - accuracy: 0.8159 - val_loss: 0.4345 - val_accuracy: 0.8062\n",
      "Epoch 173/200\n",
      "172/172 [==============================] - 0s 819us/sample - loss: 0.4477 - accuracy: 0.8236 - val_loss: 0.4362 - val_accuracy: 0.8140\n",
      "Epoch 174/200\n",
      "172/172 [==============================] - 0s 807us/sample - loss: 0.4419 - accuracy: 0.8178 - val_loss: 0.4341 - val_accuracy: 0.8062\n",
      "Epoch 175/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 0.4538 - accuracy: 0.8178 - val_loss: 0.4342 - val_accuracy: 0.8062\n",
      "Epoch 176/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.4463 - accuracy: 0.8101 - val_loss: 0.4351 - val_accuracy: 0.8140\n",
      "Epoch 177/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.4432 - accuracy: 0.8101 - val_loss: 0.4371 - val_accuracy: 0.8295\n",
      "Epoch 178/200\n",
      "172/172 [==============================] - 0s 821us/sample - loss: 0.4376 - accuracy: 0.8256 - val_loss: 0.4343 - val_accuracy: 0.8062\n",
      "Epoch 179/200\n",
      "172/172 [==============================] - 0s 814us/sample - loss: 0.4392 - accuracy: 0.8256 - val_loss: 0.4389 - val_accuracy: 0.8372\n",
      "Epoch 180/200\n",
      "172/172 [==============================] - 0s 807us/sample - loss: 0.4361 - accuracy: 0.8217 - val_loss: 0.4355 - val_accuracy: 0.8140\n",
      "Epoch 181/200\n",
      "172/172 [==============================] - 0s 814us/sample - loss: 0.4457 - accuracy: 0.8236 - val_loss: 0.4327 - val_accuracy: 0.8140\n",
      "Epoch 182/200\n",
      "172/172 [==============================] - 0s 810us/sample - loss: 0.4397 - accuracy: 0.8120 - val_loss: 0.4338 - val_accuracy: 0.8140\n",
      "Epoch 183/200\n",
      "172/172 [==============================] - 0s 810us/sample - loss: 0.4476 - accuracy: 0.8178 - val_loss: 0.4313 - val_accuracy: 0.8062\n",
      "Epoch 184/200\n",
      "172/172 [==============================] - 0s 809us/sample - loss: 0.4429 - accuracy: 0.8178 - val_loss: 0.4341 - val_accuracy: 0.8295\n",
      "Epoch 185/200\n",
      "172/172 [==============================] - 0s 805us/sample - loss: 0.4456 - accuracy: 0.8217 - val_loss: 0.4330 - val_accuracy: 0.8140\n",
      "Epoch 186/200\n",
      "172/172 [==============================] - 0s 820us/sample - loss: 0.4325 - accuracy: 0.8198 - val_loss: 0.4379 - val_accuracy: 0.8372\n",
      "Epoch 187/200\n",
      "172/172 [==============================] - 0s 819us/sample - loss: 0.4372 - accuracy: 0.8275 - val_loss: 0.4315 - val_accuracy: 0.8140\n",
      "Epoch 188/200\n",
      "172/172 [==============================] - 0s 827us/sample - loss: 0.4480 - accuracy: 0.8236 - val_loss: 0.4305 - val_accuracy: 0.8140\n",
      "Epoch 189/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.4383 - accuracy: 0.8217 - val_loss: 0.4309 - val_accuracy: 0.8140\n",
      "Epoch 190/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 0.4315 - accuracy: 0.8217 - val_loss: 0.4299 - val_accuracy: 0.8140\n",
      "Epoch 191/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 955us/sample - loss: 0.4327 - accuracy: 0.8256 - val_loss: 0.4341 - val_accuracy: 0.8372\n",
      "Epoch 192/200\n",
      "172/172 [==============================] - 0s 844us/sample - loss: 0.4404 - accuracy: 0.8236 - val_loss: 0.4300 - val_accuracy: 0.8140\n",
      "Epoch 193/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 0.4360 - accuracy: 0.8178 - val_loss: 0.4351 - val_accuracy: 0.8372\n",
      "Epoch 194/200\n",
      "172/172 [==============================] - 0s 832us/sample - loss: 0.4347 - accuracy: 0.8275 - val_loss: 0.4284 - val_accuracy: 0.8062\n",
      "Epoch 195/200\n",
      "172/172 [==============================] - 0s 844us/sample - loss: 0.4356 - accuracy: 0.8198 - val_loss: 0.4335 - val_accuracy: 0.8372\n",
      "Epoch 196/200\n",
      "172/172 [==============================] - 0s 843us/sample - loss: 0.4387 - accuracy: 0.8275 - val_loss: 0.4289 - val_accuracy: 0.8140\n",
      "Epoch 197/200\n",
      "172/172 [==============================] - 0s 836us/sample - loss: 0.4473 - accuracy: 0.8198 - val_loss: 0.4324 - val_accuracy: 0.8372\n",
      "Epoch 198/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.4326 - accuracy: 0.8236 - val_loss: 0.4288 - val_accuracy: 0.8140\n",
      "Epoch 199/200\n",
      "172/172 [==============================] - 0s 843us/sample - loss: 0.4352 - accuracy: 0.8217 - val_loss: 0.4321 - val_accuracy: 0.8372\n",
      "Epoch 200/200\n",
      "172/172 [==============================] - 0s 844us/sample - loss: 0.4392 - accuracy: 0.8256 - val_loss: 0.4286 - val_accuracy: 0.8140\n",
      "Beginning training for dr=0.100, l_lambda=1.0e-03, reg_type=l2, act: tanh\n",
      "Train on 172 samples, validate on 43 samples\n",
      "Epoch 1/200\n",
      "172/172 [==============================] - 2s 10ms/sample - loss: 0.6362 - accuracy: 0.6667 - val_loss: 0.5848 - val_accuracy: 0.6667\n",
      "Epoch 2/200\n",
      "172/172 [==============================] - 0s 849us/sample - loss: 0.5619 - accuracy: 0.7248 - val_loss: 0.5229 - val_accuracy: 0.7829\n",
      "Epoch 3/200\n",
      "172/172 [==============================] - 0s 850us/sample - loss: 0.5232 - accuracy: 0.7791 - val_loss: 0.5139 - val_accuracy: 0.7829\n",
      "Epoch 4/200\n",
      "172/172 [==============================] - 0s 971us/sample - loss: 0.5210 - accuracy: 0.7791 - val_loss: 0.5114 - val_accuracy: 0.7829\n",
      "Epoch 5/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 0.5181 - accuracy: 0.7791 - val_loss: 0.5098 - val_accuracy: 0.7829\n",
      "Epoch 6/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 0.5190 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 7/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 0.5168 - accuracy: 0.7791 - val_loss: 0.5084 - val_accuracy: 0.7829\n",
      "Epoch 8/200\n",
      "172/172 [==============================] - 0s 844us/sample - loss: 0.5156 - accuracy: 0.7791 - val_loss: 0.5065 - val_accuracy: 0.7829\n",
      "Epoch 9/200\n",
      "172/172 [==============================] - 0s 853us/sample - loss: 0.5144 - accuracy: 0.7791 - val_loss: 0.5062 - val_accuracy: 0.7829\n",
      "Epoch 10/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 0.5130 - accuracy: 0.7791 - val_loss: 0.5052 - val_accuracy: 0.7829\n",
      "Epoch 11/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 0.5112 - accuracy: 0.7791 - val_loss: 0.5052 - val_accuracy: 0.7829\n",
      "Epoch 12/200\n",
      "172/172 [==============================] - 0s 848us/sample - loss: 0.5115 - accuracy: 0.7791 - val_loss: 0.5030 - val_accuracy: 0.7829\n",
      "Epoch 13/200\n",
      "172/172 [==============================] - 0s 845us/sample - loss: 0.5115 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 14/200\n",
      "172/172 [==============================] - 0s 857us/sample - loss: 0.5104 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 15/200\n",
      "172/172 [==============================] - 0s 849us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 16/200\n",
      "172/172 [==============================] - 0s 848us/sample - loss: 0.5080 - accuracy: 0.7791 - val_loss: 0.5010 - val_accuracy: 0.7829\n",
      "Epoch 17/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5007 - val_accuracy: 0.7829\n",
      "Epoch 18/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.5196 - accuracy: 0.7791 - val_loss: 0.4994 - val_accuracy: 0.7829\n",
      "Epoch 19/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.5082 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 20/200\n",
      "172/172 [==============================] - 0s 828us/sample - loss: 0.5143 - accuracy: 0.7791 - val_loss: 0.4988 - val_accuracy: 0.7829\n",
      "Epoch 21/200\n",
      "172/172 [==============================] - 0s 818us/sample - loss: 0.5081 - accuracy: 0.7791 - val_loss: 0.4984 - val_accuracy: 0.7829\n",
      "Epoch 22/200\n",
      "172/172 [==============================] - 0s 817us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.4974 - val_accuracy: 0.7829\n",
      "Epoch 23/200\n",
      "172/172 [==============================] - 0s 827us/sample - loss: 0.5064 - accuracy: 0.7791 - val_loss: 0.4966 - val_accuracy: 0.7829\n",
      "Epoch 24/200\n",
      "172/172 [==============================] - 0s 815us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.4961 - val_accuracy: 0.7829\n",
      "Epoch 25/200\n",
      "172/172 [==============================] - 0s 840us/sample - loss: 0.5069 - accuracy: 0.7810 - val_loss: 0.4977 - val_accuracy: 0.7829\n",
      "Epoch 26/200\n",
      "172/172 [==============================] - 0s 825us/sample - loss: 0.5037 - accuracy: 0.7810 - val_loss: 0.4948 - val_accuracy: 0.7829\n",
      "Epoch 27/200\n",
      "172/172 [==============================] - 0s 818us/sample - loss: 0.5040 - accuracy: 0.7810 - val_loss: 0.4938 - val_accuracy: 0.7829\n",
      "Epoch 28/200\n",
      "172/172 [==============================] - 0s 824us/sample - loss: 0.5028 - accuracy: 0.7810 - val_loss: 0.4931 - val_accuracy: 0.7829\n",
      "Epoch 29/200\n",
      "172/172 [==============================] - 0s 817us/sample - loss: 0.5064 - accuracy: 0.7810 - val_loss: 0.4922 - val_accuracy: 0.7829\n",
      "Epoch 30/200\n",
      "172/172 [==============================] - 0s 823us/sample - loss: 0.5051 - accuracy: 0.7791 - val_loss: 0.4930 - val_accuracy: 0.7829\n",
      "Epoch 31/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.4974 - accuracy: 0.7810 - val_loss: 0.4893 - val_accuracy: 0.7829\n",
      "Epoch 32/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.4989 - accuracy: 0.7810 - val_loss: 0.4896 - val_accuracy: 0.7829\n",
      "Epoch 33/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.4955 - accuracy: 0.7810 - val_loss: 0.4855 - val_accuracy: 0.7829\n",
      "Epoch 34/200\n",
      "172/172 [==============================] - 0s 825us/sample - loss: 0.4971 - accuracy: 0.7791 - val_loss: 0.4837 - val_accuracy: 0.7829\n",
      "Epoch 35/200\n",
      "172/172 [==============================] - 0s 818us/sample - loss: 0.4928 - accuracy: 0.7791 - val_loss: 0.4822 - val_accuracy: 0.7829\n",
      "Epoch 36/200\n",
      "172/172 [==============================] - 0s 834us/sample - loss: 0.4939 - accuracy: 0.7791 - val_loss: 0.4801 - val_accuracy: 0.7907\n",
      "Epoch 37/200\n",
      "172/172 [==============================] - 0s 843us/sample - loss: 0.4910 - accuracy: 0.7868 - val_loss: 0.4770 - val_accuracy: 0.7907\n",
      "Epoch 38/200\n",
      "172/172 [==============================] - 0s 844us/sample - loss: 0.4915 - accuracy: 0.7791 - val_loss: 0.4759 - val_accuracy: 0.7907\n",
      "Epoch 39/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 0.4853 - accuracy: 0.7810 - val_loss: 0.4736 - val_accuracy: 0.7907\n",
      "Epoch 40/200\n",
      "172/172 [==============================] - 0s 842us/sample - loss: 0.4910 - accuracy: 0.7868 - val_loss: 0.4737 - val_accuracy: 0.7984\n",
      "Epoch 41/200\n",
      "172/172 [==============================] - 0s 828us/sample - loss: 0.4852 - accuracy: 0.7810 - val_loss: 0.4700 - val_accuracy: 0.7907\n",
      "Epoch 42/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.4797 - accuracy: 0.7849 - val_loss: 0.4730 - val_accuracy: 0.7907\n",
      "Epoch 43/200\n",
      "172/172 [==============================] - 0s 864us/sample - loss: 0.4911 - accuracy: 0.8178 - val_loss: 0.4665 - val_accuracy: 0.7907\n",
      "Epoch 44/200\n",
      "172/172 [==============================] - 0s 831us/sample - loss: 0.4968 - accuracy: 0.7791 - val_loss: 0.4699 - val_accuracy: 0.7984\n",
      "Epoch 45/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 935us/sample - loss: 0.4810 - accuracy: 0.7946 - val_loss: 0.4638 - val_accuracy: 0.7984\n",
      "Epoch 46/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.4788 - accuracy: 0.7888 - val_loss: 0.4646 - val_accuracy: 0.7984\n",
      "Epoch 47/200\n",
      "172/172 [==============================] - 0s 882us/sample - loss: 0.4789 - accuracy: 0.7965 - val_loss: 0.4615 - val_accuracy: 0.7984\n",
      "Epoch 48/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 0.4797 - accuracy: 0.7965 - val_loss: 0.4627 - val_accuracy: 0.8062\n",
      "Epoch 49/200\n",
      "172/172 [==============================] - 0s 854us/sample - loss: 0.4750 - accuracy: 0.7926 - val_loss: 0.4569 - val_accuracy: 0.7984\n",
      "Epoch 50/200\n",
      "172/172 [==============================] - 0s 849us/sample - loss: 0.4781 - accuracy: 0.7965 - val_loss: 0.4557 - val_accuracy: 0.7984\n",
      "Epoch 51/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.4765 - accuracy: 0.8023 - val_loss: 0.4541 - val_accuracy: 0.7907\n",
      "Epoch 52/200\n",
      "172/172 [==============================] - 0s 854us/sample - loss: 0.4687 - accuracy: 0.7907 - val_loss: 0.4561 - val_accuracy: 0.8062\n",
      "Epoch 53/200\n",
      "172/172 [==============================] - 0s 857us/sample - loss: 0.4697 - accuracy: 0.7868 - val_loss: 0.4512 - val_accuracy: 0.7907\n",
      "Epoch 54/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 0.4714 - accuracy: 0.7946 - val_loss: 0.4582 - val_accuracy: 0.8062\n",
      "Epoch 55/200\n",
      "172/172 [==============================] - 0s 850us/sample - loss: 0.4644 - accuracy: 0.8081 - val_loss: 0.4484 - val_accuracy: 0.7984\n",
      "Epoch 56/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 0.4673 - accuracy: 0.7965 - val_loss: 0.4485 - val_accuracy: 0.8062\n",
      "Epoch 57/200\n",
      "172/172 [==============================] - 0s 869us/sample - loss: 0.4622 - accuracy: 0.7984 - val_loss: 0.4631 - val_accuracy: 0.8140\n",
      "Epoch 58/200\n",
      "172/172 [==============================] - 0s 945us/sample - loss: 0.4842 - accuracy: 0.8004 - val_loss: 0.4465 - val_accuracy: 0.7984\n",
      "Epoch 59/200\n",
      "172/172 [==============================] - 0s 951us/sample - loss: 0.4603 - accuracy: 0.8062 - val_loss: 0.4513 - val_accuracy: 0.8062\n",
      "Epoch 60/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.4616 - accuracy: 0.8081 - val_loss: 0.4463 - val_accuracy: 0.7984\n",
      "Epoch 61/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.4634 - accuracy: 0.7984 - val_loss: 0.4449 - val_accuracy: 0.7984\n",
      "Epoch 62/200\n",
      "172/172 [==============================] - 0s 882us/sample - loss: 0.4612 - accuracy: 0.8140 - val_loss: 0.4454 - val_accuracy: 0.8062\n",
      "Epoch 63/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.4625 - accuracy: 0.7907 - val_loss: 0.4528 - val_accuracy: 0.8062\n",
      "Epoch 64/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.4666 - accuracy: 0.8120 - val_loss: 0.4423 - val_accuracy: 0.7984\n",
      "Epoch 65/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.4679 - accuracy: 0.8023 - val_loss: 0.4415 - val_accuracy: 0.7984\n",
      "Epoch 66/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.4716 - accuracy: 0.8043 - val_loss: 0.4648 - val_accuracy: 0.8372\n",
      "Epoch 67/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 0.4539 - accuracy: 0.8256 - val_loss: 0.4433 - val_accuracy: 0.7907\n",
      "Epoch 68/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.4667 - accuracy: 0.7946 - val_loss: 0.4550 - val_accuracy: 0.8062\n",
      "Epoch 69/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.4632 - accuracy: 0.8198 - val_loss: 0.4444 - val_accuracy: 0.8062\n",
      "Epoch 70/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.4568 - accuracy: 0.8081 - val_loss: 0.4399 - val_accuracy: 0.8062\n",
      "Epoch 71/200\n",
      "172/172 [==============================] - 0s 975us/sample - loss: 0.4633 - accuracy: 0.8217 - val_loss: 0.4385 - val_accuracy: 0.7907\n",
      "Epoch 72/200\n",
      "172/172 [==============================] - 0s 946us/sample - loss: 0.4672 - accuracy: 0.7965 - val_loss: 0.4481 - val_accuracy: 0.8062\n",
      "Epoch 73/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.4507 - accuracy: 0.8159 - val_loss: 0.4378 - val_accuracy: 0.7907\n",
      "Epoch 74/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.4534 - accuracy: 0.7984 - val_loss: 0.4460 - val_accuracy: 0.8062\n",
      "Epoch 75/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.4618 - accuracy: 0.8062 - val_loss: 0.4380 - val_accuracy: 0.7984\n",
      "Epoch 76/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.4541 - accuracy: 0.8081 - val_loss: 0.4450 - val_accuracy: 0.8062\n",
      "Epoch 77/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.4548 - accuracy: 0.8081 - val_loss: 0.4423 - val_accuracy: 0.8062\n",
      "Epoch 78/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 0.4529 - accuracy: 0.8120 - val_loss: 0.4414 - val_accuracy: 0.8062\n",
      "Epoch 79/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.4546 - accuracy: 0.8062 - val_loss: 0.4430 - val_accuracy: 0.8062\n",
      "Epoch 80/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.4671 - accuracy: 0.8081 - val_loss: 0.4348 - val_accuracy: 0.7984\n",
      "Epoch 81/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 0.4558 - accuracy: 0.8140 - val_loss: 0.4559 - val_accuracy: 0.8372\n",
      "Epoch 82/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.4576 - accuracy: 0.8101 - val_loss: 0.4346 - val_accuracy: 0.8062\n",
      "Epoch 83/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.4675 - accuracy: 0.8081 - val_loss: 0.4342 - val_accuracy: 0.7907\n",
      "Epoch 84/200\n",
      "172/172 [==============================] - 0s 976us/sample - loss: 0.4480 - accuracy: 0.8062 - val_loss: 0.4383 - val_accuracy: 0.8062\n",
      "Epoch 85/200\n",
      "172/172 [==============================] - 0s 962us/sample - loss: 0.4525 - accuracy: 0.8159 - val_loss: 0.4339 - val_accuracy: 0.8062\n",
      "Epoch 86/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.4467 - accuracy: 0.7984 - val_loss: 0.4347 - val_accuracy: 0.8062\n",
      "Epoch 87/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.4506 - accuracy: 0.8217 - val_loss: 0.4316 - val_accuracy: 0.7984\n",
      "Epoch 88/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.4469 - accuracy: 0.8178 - val_loss: 0.4322 - val_accuracy: 0.8062\n",
      "Epoch 89/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.4462 - accuracy: 0.8217 - val_loss: 0.4488 - val_accuracy: 0.8450\n",
      "Epoch 90/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.4477 - accuracy: 0.8217 - val_loss: 0.4314 - val_accuracy: 0.7907\n",
      "Epoch 91/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.4478 - accuracy: 0.8004 - val_loss: 0.4574 - val_accuracy: 0.8450\n",
      "Epoch 92/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.4530 - accuracy: 0.8159 - val_loss: 0.4329 - val_accuracy: 0.8062\n",
      "Epoch 93/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.4483 - accuracy: 0.8140 - val_loss: 0.4297 - val_accuracy: 0.7984\n",
      "Epoch 94/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.4451 - accuracy: 0.8101 - val_loss: 0.4510 - val_accuracy: 0.8372\n",
      "Epoch 95/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.4535 - accuracy: 0.8140 - val_loss: 0.4343 - val_accuracy: 0.8062\n",
      "Epoch 96/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 0.4738 - accuracy: 0.8023 - val_loss: 0.4343 - val_accuracy: 0.7984\n",
      "Epoch 97/200\n",
      "172/172 [==============================] - 0s 979us/sample - loss: 0.4460 - accuracy: 0.8120 - val_loss: 0.4399 - val_accuracy: 0.8140\n",
      "Epoch 98/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 0.4482 - accuracy: 0.8217 - val_loss: 0.4298 - val_accuracy: 0.8062\n",
      "Epoch 99/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.4791 - accuracy: 0.7946 - val_loss: 0.4545 - val_accuracy: 0.8295\n",
      "Epoch 100/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 881us/sample - loss: 0.4500 - accuracy: 0.8198 - val_loss: 0.4323 - val_accuracy: 0.7984\n",
      "Epoch 101/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.4474 - accuracy: 0.8140 - val_loss: 0.4353 - val_accuracy: 0.8062\n",
      "Epoch 102/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.4429 - accuracy: 0.8140 - val_loss: 0.4351 - val_accuracy: 0.8062\n",
      "Epoch 103/200\n",
      "172/172 [==============================] - 0s 869us/sample - loss: 0.4460 - accuracy: 0.8217 - val_loss: 0.4325 - val_accuracy: 0.8062\n",
      "Epoch 104/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.4424 - accuracy: 0.8236 - val_loss: 0.4373 - val_accuracy: 0.8140\n",
      "Epoch 105/200\n",
      "172/172 [==============================] - 0s 882us/sample - loss: 0.4419 - accuracy: 0.8140 - val_loss: 0.4294 - val_accuracy: 0.8062\n",
      "Epoch 106/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.4409 - accuracy: 0.8275 - val_loss: 0.4288 - val_accuracy: 0.8062\n",
      "Epoch 107/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.4458 - accuracy: 0.8101 - val_loss: 0.4462 - val_accuracy: 0.8372\n",
      "Epoch 108/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.4417 - accuracy: 0.8256 - val_loss: 0.4274 - val_accuracy: 0.7907\n",
      "Epoch 109/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 0.4378 - accuracy: 0.8256 - val_loss: 0.4432 - val_accuracy: 0.8372\n",
      "Epoch 110/200\n",
      "172/172 [==============================] - 0s 969us/sample - loss: 0.4422 - accuracy: 0.8236 - val_loss: 0.4264 - val_accuracy: 0.8062\n",
      "Epoch 111/200\n",
      "172/172 [==============================] - 0s 945us/sample - loss: 0.4381 - accuracy: 0.8178 - val_loss: 0.4538 - val_accuracy: 0.8372\n",
      "Epoch 112/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 0.4455 - accuracy: 0.8178 - val_loss: 0.4252 - val_accuracy: 0.7984\n",
      "Epoch 113/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 0.4427 - accuracy: 0.8159 - val_loss: 0.4250 - val_accuracy: 0.8062\n",
      "Epoch 114/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 0.4449 - accuracy: 0.8159 - val_loss: 0.4479 - val_accuracy: 0.8450\n",
      "Epoch 115/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.4370 - accuracy: 0.8198 - val_loss: 0.4251 - val_accuracy: 0.8062\n",
      "Epoch 116/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.4434 - accuracy: 0.8062 - val_loss: 0.4471 - val_accuracy: 0.8372\n",
      "Epoch 117/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.4321 - accuracy: 0.8275 - val_loss: 0.4240 - val_accuracy: 0.7984\n",
      "Epoch 118/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.4342 - accuracy: 0.8081 - val_loss: 0.4422 - val_accuracy: 0.8450\n",
      "Epoch 119/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.4411 - accuracy: 0.8217 - val_loss: 0.4258 - val_accuracy: 0.7984\n",
      "Epoch 120/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 0.4425 - accuracy: 0.8236 - val_loss: 0.4268 - val_accuracy: 0.8062\n",
      "Epoch 121/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.4369 - accuracy: 0.8198 - val_loss: 0.4332 - val_accuracy: 0.8295\n",
      "Epoch 122/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.4323 - accuracy: 0.8236 - val_loss: 0.4259 - val_accuracy: 0.8062\n",
      "Epoch 123/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 0.4354 - accuracy: 0.8275 - val_loss: 0.4250 - val_accuracy: 0.8062\n",
      "Epoch 124/200\n",
      "172/172 [==============================] - 0s 957us/sample - loss: 0.4352 - accuracy: 0.8295 - val_loss: 0.4356 - val_accuracy: 0.8372\n",
      "Epoch 125/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.4400 - accuracy: 0.8256 - val_loss: 0.4373 - val_accuracy: 0.8450\n",
      "Epoch 126/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.4347 - accuracy: 0.8120 - val_loss: 0.4232 - val_accuracy: 0.8062\n",
      "Epoch 127/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.4277 - accuracy: 0.8236 - val_loss: 0.4385 - val_accuracy: 0.8450\n",
      "Epoch 128/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 0.4402 - accuracy: 0.8256 - val_loss: 0.4302 - val_accuracy: 0.8295\n",
      "Epoch 129/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.4309 - accuracy: 0.8217 - val_loss: 0.4243 - val_accuracy: 0.8140\n",
      "Epoch 130/200\n",
      "172/172 [==============================] - 0s 976us/sample - loss: 0.4426 - accuracy: 0.8198 - val_loss: 0.4219 - val_accuracy: 0.8062\n",
      "Epoch 131/200\n",
      "172/172 [==============================] - 0s 953us/sample - loss: 0.4318 - accuracy: 0.8275 - val_loss: 0.4247 - val_accuracy: 0.8217\n",
      "Epoch 132/200\n",
      "172/172 [==============================] - 0s 861us/sample - loss: 0.4422 - accuracy: 0.8178 - val_loss: 0.4381 - val_accuracy: 0.8372\n",
      "Epoch 133/200\n",
      "172/172 [==============================] - 0s 853us/sample - loss: 0.4681 - accuracy: 0.8081 - val_loss: 0.4492 - val_accuracy: 0.7907\n",
      "Epoch 134/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.4606 - accuracy: 0.8140 - val_loss: 0.4713 - val_accuracy: 0.8217\n",
      "Epoch 135/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.4573 - accuracy: 0.8120 - val_loss: 0.4251 - val_accuracy: 0.8062\n",
      "Epoch 136/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4346 - accuracy: 0.8275 - val_loss: 0.4440 - val_accuracy: 0.8372\n",
      "Epoch 137/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4286 - accuracy: 0.8159 - val_loss: 0.4265 - val_accuracy: 0.8217\n",
      "Epoch 138/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 0.4359 - accuracy: 0.8372 - val_loss: 0.4215 - val_accuracy: 0.7984\n",
      "Epoch 139/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.4283 - accuracy: 0.8217 - val_loss: 0.4298 - val_accuracy: 0.8295\n",
      "Epoch 140/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.4319 - accuracy: 0.8353 - val_loss: 0.4233 - val_accuracy: 0.8140\n",
      "Epoch 141/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.4258 - accuracy: 0.8275 - val_loss: 0.4236 - val_accuracy: 0.8217\n",
      "Epoch 142/200\n",
      "172/172 [==============================] - 0s 864us/sample - loss: 0.4323 - accuracy: 0.8314 - val_loss: 0.4208 - val_accuracy: 0.8062\n",
      "Epoch 143/200\n",
      "172/172 [==============================] - 0s 861us/sample - loss: 0.4391 - accuracy: 0.8236 - val_loss: 0.4291 - val_accuracy: 0.8372\n",
      "Epoch 144/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.4245 - accuracy: 0.8295 - val_loss: 0.4201 - val_accuracy: 0.7907\n",
      "Epoch 145/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.4426 - accuracy: 0.8140 - val_loss: 0.4224 - val_accuracy: 0.8062\n",
      "Epoch 146/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 0.4267 - accuracy: 0.8198 - val_loss: 0.4209 - val_accuracy: 0.7984\n",
      "Epoch 147/200\n",
      "172/172 [==============================] - 0s 854us/sample - loss: 0.4293 - accuracy: 0.8372 - val_loss: 0.4229 - val_accuracy: 0.8140\n",
      "Epoch 148/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.4275 - accuracy: 0.8236 - val_loss: 0.4226 - val_accuracy: 0.8217\n",
      "Epoch 149/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.4266 - accuracy: 0.8295 - val_loss: 0.4263 - val_accuracy: 0.8295\n",
      "Epoch 150/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4317 - accuracy: 0.8295 - val_loss: 0.4204 - val_accuracy: 0.7984\n",
      "Epoch 151/200\n",
      "172/172 [==============================] - 0s 1000us/sample - loss: 0.4269 - accuracy: 0.8333 - val_loss: 0.4466 - val_accuracy: 0.8295\n",
      "Epoch 152/200\n",
      "172/172 [==============================] - 0s 860us/sample - loss: 0.4338 - accuracy: 0.8178 - val_loss: 0.4402 - val_accuracy: 0.8372\n",
      "Epoch 153/200\n",
      "172/172 [==============================] - 0s 849us/sample - loss: 0.4322 - accuracy: 0.8314 - val_loss: 0.4214 - val_accuracy: 0.8295\n",
      "Epoch 154/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.4268 - accuracy: 0.8333 - val_loss: 0.4304 - val_accuracy: 0.8372\n",
      "Epoch 155/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 884us/sample - loss: 0.4277 - accuracy: 0.8372 - val_loss: 0.4188 - val_accuracy: 0.7984\n",
      "Epoch 156/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 0.4220 - accuracy: 0.8295 - val_loss: 0.4427 - val_accuracy: 0.8450\n",
      "Epoch 157/200\n",
      "172/172 [==============================] - 0s 859us/sample - loss: 0.4187 - accuracy: 0.8372 - val_loss: 0.4213 - val_accuracy: 0.8295\n",
      "Epoch 158/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.4275 - accuracy: 0.8198 - val_loss: 0.4194 - val_accuracy: 0.8062\n",
      "Epoch 159/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.4231 - accuracy: 0.8256 - val_loss: 0.4230 - val_accuracy: 0.8295\n",
      "Epoch 160/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 0.4249 - accuracy: 0.8295 - val_loss: 0.4308 - val_accuracy: 0.8372\n",
      "Epoch 161/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.4233 - accuracy: 0.8314 - val_loss: 0.4217 - val_accuracy: 0.8295\n",
      "Epoch 162/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 0.4226 - accuracy: 0.8372 - val_loss: 0.4187 - val_accuracy: 0.8217\n",
      "Epoch 163/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 0.4220 - accuracy: 0.8275 - val_loss: 0.4215 - val_accuracy: 0.8295\n",
      "Epoch 164/200\n",
      "172/172 [==============================] - 0s 858us/sample - loss: 0.4160 - accuracy: 0.8353 - val_loss: 0.4227 - val_accuracy: 0.8295\n",
      "Epoch 165/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 0.4245 - accuracy: 0.8295 - val_loss: 0.4328 - val_accuracy: 0.8372\n",
      "Epoch 166/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 0.4584 - accuracy: 0.8004 - val_loss: 0.4228 - val_accuracy: 0.7984\n",
      "Epoch 167/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 0.4260 - accuracy: 0.8314 - val_loss: 0.4183 - val_accuracy: 0.7984\n",
      "Epoch 168/200\n",
      "172/172 [==============================] - 0s 820us/sample - loss: 0.4269 - accuracy: 0.8295 - val_loss: 0.4272 - val_accuracy: 0.8372\n",
      "Epoch 169/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 0.4223 - accuracy: 0.8333 - val_loss: 0.4181 - val_accuracy: 0.7907\n",
      "Epoch 170/200\n",
      "172/172 [==============================] - 0s 826us/sample - loss: 0.4264 - accuracy: 0.8217 - val_loss: 0.4185 - val_accuracy: 0.8140\n",
      "Epoch 171/200\n",
      "172/172 [==============================] - 0s 820us/sample - loss: 0.4160 - accuracy: 0.8353 - val_loss: 0.4210 - val_accuracy: 0.8295\n",
      "Epoch 172/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.4204 - accuracy: 0.8353 - val_loss: 0.4168 - val_accuracy: 0.7907\n",
      "Epoch 173/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.4247 - accuracy: 0.8295 - val_loss: 0.4175 - val_accuracy: 0.8295\n",
      "Epoch 174/200\n",
      "172/172 [==============================] - 0s 833us/sample - loss: 0.4316 - accuracy: 0.8140 - val_loss: 0.4901 - val_accuracy: 0.8062\n",
      "Epoch 175/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.4258 - accuracy: 0.8256 - val_loss: 0.4166 - val_accuracy: 0.7907\n",
      "Epoch 176/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.4281 - accuracy: 0.8217 - val_loss: 0.4162 - val_accuracy: 0.8217\n",
      "Epoch 177/200\n",
      "172/172 [==============================] - 0s 858us/sample - loss: 0.4207 - accuracy: 0.8372 - val_loss: 0.4428 - val_accuracy: 0.8450\n",
      "Epoch 178/200\n",
      "172/172 [==============================] - 0s 820us/sample - loss: 0.4273 - accuracy: 0.8372 - val_loss: 0.4337 - val_accuracy: 0.8372\n",
      "Epoch 179/200\n",
      "172/172 [==============================] - 0s 826us/sample - loss: 0.4212 - accuracy: 0.8372 - val_loss: 0.4201 - val_accuracy: 0.7907\n",
      "Epoch 180/200\n",
      "172/172 [==============================] - 0s 823us/sample - loss: 0.4339 - accuracy: 0.8120 - val_loss: 0.4344 - val_accuracy: 0.8372\n",
      "Epoch 181/200\n",
      "172/172 [==============================] - 0s 833us/sample - loss: 0.4296 - accuracy: 0.8178 - val_loss: 0.4251 - val_accuracy: 0.8450\n",
      "Epoch 182/200\n",
      "172/172 [==============================] - 0s 828us/sample - loss: 0.4159 - accuracy: 0.8295 - val_loss: 0.4166 - val_accuracy: 0.7829\n",
      "Epoch 183/200\n",
      "172/172 [==============================] - 0s 825us/sample - loss: 0.4181 - accuracy: 0.8295 - val_loss: 0.4163 - val_accuracy: 0.7984\n",
      "Epoch 184/200\n",
      "172/172 [==============================] - 0s 834us/sample - loss: 0.4198 - accuracy: 0.8353 - val_loss: 0.4308 - val_accuracy: 0.8372\n",
      "Epoch 185/200\n",
      "172/172 [==============================] - 0s 826us/sample - loss: 0.4285 - accuracy: 0.8236 - val_loss: 0.4163 - val_accuracy: 0.7907\n",
      "Epoch 186/200\n",
      "172/172 [==============================] - 0s 825us/sample - loss: 0.4124 - accuracy: 0.8372 - val_loss: 0.4427 - val_accuracy: 0.8450\n",
      "Epoch 187/200\n",
      "172/172 [==============================] - 0s 828us/sample - loss: 0.4147 - accuracy: 0.8333 - val_loss: 0.4154 - val_accuracy: 0.7984\n",
      "Epoch 188/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.4227 - accuracy: 0.8353 - val_loss: 0.4147 - val_accuracy: 0.8140\n",
      "Epoch 189/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.4089 - accuracy: 0.8372 - val_loss: 0.4217 - val_accuracy: 0.8372\n",
      "Epoch 190/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 0.4131 - accuracy: 0.8372 - val_loss: 0.4157 - val_accuracy: 0.8295\n",
      "Epoch 191/200\n",
      "172/172 [==============================] - 0s 834us/sample - loss: 0.4123 - accuracy: 0.8430 - val_loss: 0.4152 - val_accuracy: 0.7907\n",
      "Epoch 192/200\n",
      "172/172 [==============================] - 0s 825us/sample - loss: 0.4160 - accuracy: 0.8333 - val_loss: 0.4171 - val_accuracy: 0.8295\n",
      "Epoch 193/200\n",
      "172/172 [==============================] - 0s 827us/sample - loss: 0.4114 - accuracy: 0.8314 - val_loss: 0.4386 - val_accuracy: 0.8372\n",
      "Epoch 194/200\n",
      "172/172 [==============================] - 0s 834us/sample - loss: 0.4228 - accuracy: 0.8275 - val_loss: 0.4302 - val_accuracy: 0.8450\n",
      "Epoch 195/200\n",
      "172/172 [==============================] - 0s 826us/sample - loss: 0.4093 - accuracy: 0.8391 - val_loss: 0.4155 - val_accuracy: 0.8217\n",
      "Epoch 196/200\n",
      "172/172 [==============================] - 0s 823us/sample - loss: 0.4077 - accuracy: 0.8411 - val_loss: 0.4207 - val_accuracy: 0.8450\n",
      "Epoch 197/200\n",
      "172/172 [==============================] - 0s 825us/sample - loss: 0.4204 - accuracy: 0.8295 - val_loss: 0.4474 - val_accuracy: 0.8295\n",
      "Epoch 198/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 0.4190 - accuracy: 0.8353 - val_loss: 0.4250 - val_accuracy: 0.7984\n",
      "Epoch 199/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.4184 - accuracy: 0.8391 - val_loss: 0.4189 - val_accuracy: 0.8372\n",
      "Epoch 200/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.4148 - accuracy: 0.8353 - val_loss: 0.4152 - val_accuracy: 0.7984\n",
      "Beginning training for dr=0.100, l_lambda=1.0e-03, reg_type=l1, act: relu\n",
      "Train on 172 samples, validate on 43 samples\n",
      "Epoch 1/200\n",
      "172/172 [==============================] - 1s 8ms/sample - loss: 1.3281 - accuracy: 0.6667 - val_loss: 0.9545 - val_accuracy: 0.6667\n",
      "Epoch 2/200\n",
      "172/172 [==============================] - 0s 960us/sample - loss: 0.8169 - accuracy: 0.6667 - val_loss: 0.7255 - val_accuracy: 0.6667\n",
      "Epoch 3/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.6781 - accuracy: 0.6919 - val_loss: 0.6254 - val_accuracy: 0.7829\n",
      "Epoch 4/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.6087 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 5/200\n",
      "172/172 [==============================] - 0s 985us/sample - loss: 0.5705 - accuracy: 0.7791 - val_loss: 0.5503 - val_accuracy: 0.7829\n",
      "Epoch 6/200\n",
      "172/172 [==============================] - 0s 960us/sample - loss: 0.5499 - accuracy: 0.7791 - val_loss: 0.5347 - val_accuracy: 0.7829\n",
      "Epoch 7/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.5371 - accuracy: 0.7791 - val_loss: 0.5240 - val_accuracy: 0.7829\n",
      "Epoch 8/200\n",
      "172/172 [==============================] - 0s 959us/sample - loss: 0.5274 - accuracy: 0.7791 - val_loss: 0.5163 - val_accuracy: 0.7829\n",
      "Epoch 9/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5217 - accuracy: 0.7791 - val_loss: 0.5121 - val_accuracy: 0.7829\n",
      "Epoch 10/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.5200 - accuracy: 0.7791 - val_loss: 0.5107 - val_accuracy: 0.7829\n",
      "Epoch 11/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.5182 - accuracy: 0.7791 - val_loss: 0.5101 - val_accuracy: 0.7829\n",
      "Epoch 12/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.5178 - accuracy: 0.7791 - val_loss: 0.5097 - val_accuracy: 0.7829\n",
      "Epoch 13/200\n",
      "172/172 [==============================] - 0s 838us/sample - loss: 0.5169 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 14/200\n",
      "172/172 [==============================] - 0s 834us/sample - loss: 0.5171 - accuracy: 0.7791 - val_loss: 0.5097 - val_accuracy: 0.7829\n",
      "Epoch 15/200\n",
      "172/172 [==============================] - 0s 838us/sample - loss: 0.5169 - accuracy: 0.7791 - val_loss: 0.5096 - val_accuracy: 0.7829\n",
      "Epoch 16/200\n",
      "172/172 [==============================] - 0s 840us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 17/200\n",
      "172/172 [==============================] - 0s 833us/sample - loss: 0.5177 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 18/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.5172 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 19/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 20/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 21/200\n",
      "172/172 [==============================] - 0s 838us/sample - loss: 0.5171 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 22/200\n",
      "172/172 [==============================] - 0s 833us/sample - loss: 0.5179 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 23/200\n",
      "172/172 [==============================] - 0s 835us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 24/200\n",
      "172/172 [==============================] - 0s 836us/sample - loss: 0.5168 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 25/200\n",
      "172/172 [==============================] - 0s 833us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 26/200\n",
      "172/172 [==============================] - 0s 831us/sample - loss: 0.5172 - accuracy: 0.7791 - val_loss: 0.5101 - val_accuracy: 0.7829\n",
      "Epoch 27/200\n",
      "172/172 [==============================] - 0s 836us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 28/200\n",
      "172/172 [==============================] - 0s 833us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 29/200\n",
      "172/172 [==============================] - 0s 849us/sample - loss: 0.5173 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 30/200\n",
      "172/172 [==============================] - 0s 853us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 31/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 0.5175 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 32/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 0.5185 - accuracy: 0.7791 - val_loss: 0.5103 - val_accuracy: 0.7829\n",
      "Epoch 33/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5096 - val_accuracy: 0.7829\n",
      "Epoch 34/200\n",
      "172/172 [==============================] - 0s 850us/sample - loss: 0.5168 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 35/200\n",
      "172/172 [==============================] - 0s 836us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 36/200\n",
      "172/172 [==============================] - 0s 839us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5097 - val_accuracy: 0.7829\n",
      "Epoch 37/200\n",
      "172/172 [==============================] - 0s 836us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 38/200\n",
      "172/172 [==============================] - 0s 835us/sample - loss: 0.5170 - accuracy: 0.7791 - val_loss: 0.5101 - val_accuracy: 0.7829\n",
      "Epoch 39/200\n",
      "172/172 [==============================] - 0s 836us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5098 - val_accuracy: 0.7829\n",
      "Epoch 40/200\n",
      "172/172 [==============================] - 0s 839us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 41/200\n",
      "172/172 [==============================] - 0s 835us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5096 - val_accuracy: 0.7829\n",
      "Epoch 42/200\n",
      "172/172 [==============================] - 0s 837us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5098 - val_accuracy: 0.7829\n",
      "Epoch 43/200\n",
      "172/172 [==============================] - 0s 839us/sample - loss: 0.5174 - accuracy: 0.7791 - val_loss: 0.5109 - val_accuracy: 0.7829\n",
      "Epoch 44/200\n",
      "172/172 [==============================] - 0s 848us/sample - loss: 0.5168 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 45/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 46/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.5176 - accuracy: 0.7791 - val_loss: 0.5099 - val_accuracy: 0.7829\n",
      "Epoch 47/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.5190 - accuracy: 0.7791 - val_loss: 0.5110 - val_accuracy: 0.7829\n",
      "Epoch 48/200\n",
      "172/172 [==============================] - 0s 837us/sample - loss: 0.5191 - accuracy: 0.7791 - val_loss: 0.5100 - val_accuracy: 0.7829\n",
      "Epoch 49/200\n",
      "172/172 [==============================] - 0s 835us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5102 - val_accuracy: 0.7829\n",
      "Epoch 50/200\n",
      "172/172 [==============================] - 0s 838us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5104 - val_accuracy: 0.7829\n",
      "Epoch 51/200\n",
      "172/172 [==============================] - 0s 839us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5096 - val_accuracy: 0.7829\n",
      "Epoch 52/200\n",
      "172/172 [==============================] - 0s 843us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5097 - val_accuracy: 0.7829\n",
      "Epoch 53/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 54/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5097 - val_accuracy: 0.7829\n",
      "Epoch 55/200\n",
      "172/172 [==============================] - 0s 861us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 56/200\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 57/200\n",
      "172/172 [==============================] - 0s 865us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 58/200\n",
      "172/172 [==============================] - 0s 930us/sample - loss: 0.5158 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 59/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 60/200\n",
      "172/172 [==============================] - 0s 940us/sample - loss: 0.5187 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 61/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 62/200\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 0.5168 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 63/200\n",
      "172/172 [==============================] - 0s 864us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 64/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 869us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 65/200\n",
      "172/172 [==============================] - 0s 854us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 66/200\n",
      "172/172 [==============================] - 0s 862us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 67/200\n",
      "172/172 [==============================] - 0s 882us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 68/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.5169 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 69/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 70/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 71/200\n",
      "172/172 [==============================] - 0s 954us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 72/200\n",
      "172/172 [==============================] - 0s 959us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 73/200\n",
      "172/172 [==============================] - 0s 967us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 74/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 75/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 76/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 0.5170 - accuracy: 0.7791 - val_loss: 0.5103 - val_accuracy: 0.7829\n",
      "Epoch 77/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 78/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 79/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 80/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 81/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 82/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 0.5172 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 83/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 84/200\n",
      "172/172 [==============================] - 0s 978us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 85/200\n",
      "172/172 [==============================] - 0s 958us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 86/200\n",
      "172/172 [==============================] - 0s 954us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 87/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.5174 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 88/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 89/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 90/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.5169 - accuracy: 0.7791 - val_loss: 0.5103 - val_accuracy: 0.7829\n",
      "Epoch 91/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 92/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 93/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.5168 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 94/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 95/200\n",
      "172/172 [==============================] - 0s 937us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 96/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.5191 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 97/200\n",
      "172/172 [==============================] - 0s 988us/sample - loss: 0.5172 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 98/200\n",
      "172/172 [==============================] - 0s 962us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 99/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 0.5175 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 100/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.5181 - accuracy: 0.7791 - val_loss: 0.5096 - val_accuracy: 0.7829\n",
      "Epoch 101/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 102/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 103/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 104/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 105/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 106/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 107/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.5168 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 108/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.5168 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 109/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.5158 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 110/200\n",
      "172/172 [==============================] - 0s 977us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 111/200\n",
      "172/172 [==============================] - 0s 972us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 112/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 113/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 114/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5097 - val_accuracy: 0.7829\n",
      "Epoch 115/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.5175 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 116/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 117/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.5169 - accuracy: 0.7791 - val_loss: 0.5105 - val_accuracy: 0.7829\n",
      "Epoch 118/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.5190 - accuracy: 0.7791 - val_loss: 0.5096 - val_accuracy: 0.7829\n",
      "Epoch 119/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 896us/sample - loss: 0.5181 - accuracy: 0.7791 - val_loss: 0.5104 - val_accuracy: 0.7829\n",
      "Epoch 120/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 121/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 0.5158 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 122/200\n",
      "172/172 [==============================] - 0s 952us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 123/200\n",
      "172/172 [==============================] - 0s 966us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5096 - val_accuracy: 0.7829\n",
      "Epoch 124/200\n",
      "172/172 [==============================] - 0s 959us/sample - loss: 0.5170 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 125/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 126/200\n",
      "172/172 [==============================] - 0s 882us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5096 - val_accuracy: 0.7829\n",
      "Epoch 127/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 128/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 129/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.5171 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 130/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5099 - val_accuracy: 0.7829\n",
      "Epoch 131/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 132/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 0.5168 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 133/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5098 - val_accuracy: 0.7829\n",
      "Epoch 134/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 135/200\n",
      "172/172 [==============================] - 0s 956us/sample - loss: 0.5171 - accuracy: 0.7791 - val_loss: 0.5096 - val_accuracy: 0.7829\n",
      "Epoch 136/200\n",
      "172/172 [==============================] - 0s 940us/sample - loss: 0.5185 - accuracy: 0.7791 - val_loss: 0.5105 - val_accuracy: 0.7829\n",
      "Epoch 137/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.5169 - accuracy: 0.7791 - val_loss: 0.5101 - val_accuracy: 0.7829\n",
      "Epoch 138/200\n",
      "172/172 [==============================] - 0s 865us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 139/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5098 - val_accuracy: 0.7829\n",
      "Epoch 140/200\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 141/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 142/200\n",
      "172/172 [==============================] - 0s 858us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 143/200\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 144/200\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 145/200\n",
      "172/172 [==============================] - 0s 861us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 146/200\n",
      "172/172 [==============================] - 0s 865us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 147/200\n",
      "172/172 [==============================] - 0s 859us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 148/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 149/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 150/200\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 151/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.5171 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 152/200\n",
      "172/172 [==============================] - 0s 859us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 153/200\n",
      "172/172 [==============================] - 0s 860us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 154/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 155/200\n",
      "172/172 [==============================] - 0s 862us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 156/200\n",
      "172/172 [==============================] - 0s 865us/sample - loss: 0.5168 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 157/200\n",
      "172/172 [==============================] - 0s 848us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5085 - val_accuracy: 0.7829\n",
      "Epoch 158/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 159/200\n",
      "172/172 [==============================] - 0s 844us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 160/200\n",
      "172/172 [==============================] - 0s 838us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 161/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 162/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 163/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 164/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 165/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 166/200\n",
      "172/172 [==============================] - 0s 840us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 167/200\n",
      "172/172 [==============================] - 0s 840us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 168/200\n",
      "172/172 [==============================] - 0s 832us/sample - loss: 0.5169 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 169/200\n",
      "172/172 [==============================] - 0s 844us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 170/200\n",
      "172/172 [==============================] - 0s 843us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 171/200\n",
      "172/172 [==============================] - 0s 842us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 172/200\n",
      "172/172 [==============================] - 0s 841us/sample - loss: 0.5171 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 173/200\n",
      "172/172 [==============================] - 0s 841us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 174/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 843us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 175/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 176/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 177/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 178/200\n",
      "172/172 [==============================] - 0s 837us/sample - loss: 0.5170 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 179/200\n",
      "172/172 [==============================] - 0s 840us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 180/200\n",
      "172/172 [==============================] - 0s 834us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 181/200\n",
      "172/172 [==============================] - 0s 835us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 182/200\n",
      "172/172 [==============================] - 0s 841us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 183/200\n",
      "172/172 [==============================] - 0s 835us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 184/200\n",
      "172/172 [==============================] - 0s 865us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 185/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 186/200\n",
      "172/172 [==============================] - 0s 968us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 187/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 188/200\n",
      "172/172 [==============================] - 0s 960us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 189/200\n",
      "172/172 [==============================] - 0s 944us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 190/200\n",
      "172/172 [==============================] - 0s 966us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 191/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5096 - val_accuracy: 0.7829\n",
      "Epoch 192/200\n",
      "172/172 [==============================] - 0s 930us/sample - loss: 0.5216 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 193/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 194/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 195/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 196/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 197/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.5171 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 198/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.5158 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 199/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 200/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Beginning training for dr=0.100, l_lambda=1.0e-03, reg_type=l1, act: tanh\n",
      "Train on 172 samples, validate on 43 samples\n",
      "Epoch 1/200\n",
      "172/172 [==============================] - 1s 8ms/sample - loss: 1.3163 - accuracy: 0.6667 - val_loss: 0.9288 - val_accuracy: 0.6667\n",
      "Epoch 2/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 0.7862 - accuracy: 0.6860 - val_loss: 0.6817 - val_accuracy: 0.7829\n",
      "Epoch 3/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 0.6439 - accuracy: 0.7791 - val_loss: 0.6030 - val_accuracy: 0.7829\n",
      "Epoch 4/200\n",
      "172/172 [==============================] - 0s 983us/sample - loss: 0.5944 - accuracy: 0.7791 - val_loss: 0.5715 - val_accuracy: 0.7829\n",
      "Epoch 5/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 0.5696 - accuracy: 0.7791 - val_loss: 0.5525 - val_accuracy: 0.7829\n",
      "Epoch 6/200\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 0.5514 - accuracy: 0.7791 - val_loss: 0.5374 - val_accuracy: 0.7829\n",
      "Epoch 7/200\n",
      "172/172 [==============================] - 0s 861us/sample - loss: 0.5402 - accuracy: 0.7791 - val_loss: 0.5276 - val_accuracy: 0.7829\n",
      "Epoch 8/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 0.5282 - accuracy: 0.7791 - val_loss: 0.5177 - val_accuracy: 0.7829\n",
      "Epoch 9/200\n",
      "172/172 [==============================] - 0s 861us/sample - loss: 0.5232 - accuracy: 0.7791 - val_loss: 0.5129 - val_accuracy: 0.7829\n",
      "Epoch 10/200\n",
      "172/172 [==============================] - 0s 859us/sample - loss: 0.5197 - accuracy: 0.7791 - val_loss: 0.5104 - val_accuracy: 0.7829\n",
      "Epoch 11/200\n",
      "172/172 [==============================] - 0s 860us/sample - loss: 0.5176 - accuracy: 0.7791 - val_loss: 0.5104 - val_accuracy: 0.7829\n",
      "Epoch 12/200\n",
      "172/172 [==============================] - 0s 862us/sample - loss: 0.5169 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 13/200\n",
      "172/172 [==============================] - 0s 856us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5098 - val_accuracy: 0.7829\n",
      "Epoch 14/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 15/200\n",
      "172/172 [==============================] - 0s 958us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 16/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5171 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 17/200\n",
      "172/172 [==============================] - 0s 989us/sample - loss: 0.5172 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 18/200\n",
      "172/172 [==============================] - 0s 998us/sample - loss: 0.5174 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 19/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.5170 - accuracy: 0.7791 - val_loss: 0.5101 - val_accuracy: 0.7829\n",
      "Epoch 20/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 21/200\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5096 - val_accuracy: 0.7829\n",
      "Epoch 22/200\n",
      "172/172 [==============================] - 0s 838us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 23/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 0.5172 - accuracy: 0.7791 - val_loss: 0.5097 - val_accuracy: 0.7829\n",
      "Epoch 24/200\n",
      "172/172 [==============================] - 0s 834us/sample - loss: 0.5168 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 25/200\n",
      "172/172 [==============================] - 0s 826us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 26/200\n",
      "172/172 [==============================] - 0s 829us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5096 - val_accuracy: 0.7829\n",
      "Epoch 27/200\n",
      "172/172 [==============================] - 0s 833us/sample - loss: 0.5169 - accuracy: 0.7791 - val_loss: 0.5097 - val_accuracy: 0.7829\n",
      "Epoch 28/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 834us/sample - loss: 0.5180 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 29/200\n",
      "172/172 [==============================] - 0s 829us/sample - loss: 0.5169 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 30/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 31/200\n",
      "172/172 [==============================] - 0s 987us/sample - loss: 0.5176 - accuracy: 0.7791 - val_loss: 0.5098 - val_accuracy: 0.7829\n",
      "Epoch 32/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5174 - accuracy: 0.7791 - val_loss: 0.5118 - val_accuracy: 0.7829\n",
      "Epoch 33/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.5178 - accuracy: 0.7791 - val_loss: 0.5097 - val_accuracy: 0.7829\n",
      "Epoch 34/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5096 - val_accuracy: 0.7829\n",
      "Epoch 35/200\n",
      "172/172 [==============================] - 0s 857us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5096 - val_accuracy: 0.7829\n",
      "Epoch 36/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 37/200\n",
      "172/172 [==============================] - 0s 834us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 38/200\n",
      "172/172 [==============================] - 0s 829us/sample - loss: 0.5172 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 39/200\n",
      "172/172 [==============================] - 0s 834us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 40/200\n",
      "172/172 [==============================] - 0s 836us/sample - loss: 0.5173 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 41/200\n",
      "172/172 [==============================] - 0s 830us/sample - loss: 0.5199 - accuracy: 0.7791 - val_loss: 0.5118 - val_accuracy: 0.7829\n",
      "Epoch 42/200\n",
      "172/172 [==============================] - 0s 843us/sample - loss: 0.5172 - accuracy: 0.7791 - val_loss: 0.5098 - val_accuracy: 0.7829\n",
      "Epoch 43/200\n",
      "172/172 [==============================] - 0s 986us/sample - loss: 0.5170 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 44/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.5170 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 45/200\n",
      "172/172 [==============================] - 0s 940us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 46/200\n",
      "172/172 [==============================] - 0s 832us/sample - loss: 0.5169 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 47/200\n",
      "172/172 [==============================] - 0s 833us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 48/200\n",
      "172/172 [==============================] - 0s 829us/sample - loss: 0.5176 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 49/200\n",
      "172/172 [==============================] - 0s 834us/sample - loss: 0.5174 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 50/200\n",
      "172/172 [==============================] - 0s 832us/sample - loss: 0.5174 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 51/200\n",
      "172/172 [==============================] - 0s 831us/sample - loss: 0.5179 - accuracy: 0.7791 - val_loss: 0.5103 - val_accuracy: 0.7829\n",
      "Epoch 52/200\n",
      "172/172 [==============================] - 0s 832us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 53/200\n",
      "172/172 [==============================] - 0s 830us/sample - loss: 0.5169 - accuracy: 0.7791 - val_loss: 0.5096 - val_accuracy: 0.7829\n",
      "Epoch 54/200\n",
      "172/172 [==============================] - 0s 831us/sample - loss: 0.5178 - accuracy: 0.7791 - val_loss: 0.5099 - val_accuracy: 0.7829\n",
      "Epoch 55/200\n",
      "172/172 [==============================] - 0s 829us/sample - loss: 0.5177 - accuracy: 0.7791 - val_loss: 0.5110 - val_accuracy: 0.7829\n",
      "Epoch 56/200\n",
      "172/172 [==============================] - 0s 826us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5096 - val_accuracy: 0.7829\n",
      "Epoch 57/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.5170 - accuracy: 0.7791 - val_loss: 0.5099 - val_accuracy: 0.7829\n",
      "Epoch 58/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.5225 - accuracy: 0.7791 - val_loss: 0.5105 - val_accuracy: 0.7829\n",
      "Epoch 59/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 0.5179 - accuracy: 0.7791 - val_loss: 0.5103 - val_accuracy: 0.7829\n",
      "Epoch 60/200\n",
      "172/172 [==============================] - 0s 843us/sample - loss: 0.5169 - accuracy: 0.7791 - val_loss: 0.5098 - val_accuracy: 0.7829\n",
      "Epoch 61/200\n",
      "172/172 [==============================] - 0s 858us/sample - loss: 0.5153 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 62/200\n",
      "172/172 [==============================] - 0s 869us/sample - loss: 0.5168 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 63/200\n",
      "172/172 [==============================] - 0s 858us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 64/200\n",
      "172/172 [==============================] - 0s 858us/sample - loss: 0.5173 - accuracy: 0.7791 - val_loss: 0.5096 - val_accuracy: 0.7829\n",
      "Epoch 65/200\n",
      "172/172 [==============================] - 0s 856us/sample - loss: 0.5169 - accuracy: 0.7791 - val_loss: 0.5098 - val_accuracy: 0.7829\n",
      "Epoch 66/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 0.5169 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 67/200\n",
      "172/172 [==============================] - 0s 859us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 68/200\n",
      "172/172 [==============================] - 0s 859us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 69/200\n",
      "172/172 [==============================] - 0s 854us/sample - loss: 0.5174 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 70/200\n",
      "172/172 [==============================] - 0s 946us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 71/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 72/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 73/200\n",
      "172/172 [==============================] - 0s 858us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 74/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 75/200\n",
      "172/172 [==============================] - 0s 853us/sample - loss: 0.5185 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 76/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 0.5190 - accuracy: 0.7791 - val_loss: 0.5112 - val_accuracy: 0.7829\n",
      "Epoch 77/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 78/200\n",
      "172/172 [==============================] - 0s 854us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 79/200\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 80/200\n",
      "172/172 [==============================] - 0s 857us/sample - loss: 0.5179 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 81/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 82/200\n",
      "172/172 [==============================] - 0s 857us/sample - loss: 0.5174 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 83/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 961us/sample - loss: 0.5177 - accuracy: 0.7791 - val_loss: 0.5096 - val_accuracy: 0.7829\n",
      "Epoch 84/200\n",
      "172/172 [==============================] - 0s 941us/sample - loss: 0.5171 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 85/200\n",
      "172/172 [==============================] - 0s 946us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 86/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 87/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 88/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5173 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 89/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 90/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 91/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.5170 - accuracy: 0.7791 - val_loss: 0.5098 - val_accuracy: 0.7829\n",
      "Epoch 92/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 0.5175 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 93/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5178 - accuracy: 0.7791 - val_loss: 0.5100 - val_accuracy: 0.7829\n",
      "Epoch 94/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 95/200\n",
      "172/172 [==============================] - 0s 882us/sample - loss: 0.5156 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 96/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5175 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 97/200\n",
      "172/172 [==============================] - 0s 949us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 98/200\n",
      "172/172 [==============================] - 0s 954us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 99/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.5190 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 100/200\n",
      "172/172 [==============================] - 0s 971us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 101/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 102/200\n",
      "172/172 [==============================] - 0s 946us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 103/200\n",
      "172/172 [==============================] - 0s 957us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 104/200\n",
      "172/172 [==============================] - 0s 966us/sample - loss: 0.5169 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 105/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 106/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 107/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 0.5169 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 108/200\n",
      "172/172 [==============================] - 0s 979us/sample - loss: 0.5171 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 109/200\n",
      "172/172 [==============================] - 0s 986us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 110/200\n",
      "172/172 [==============================] - 0s 967us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 111/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5097 - val_accuracy: 0.7829\n",
      "Epoch 112/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5098 - val_accuracy: 0.7829\n",
      "Epoch 113/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 0.5173 - accuracy: 0.7791 - val_loss: 0.5118 - val_accuracy: 0.7829\n",
      "Epoch 114/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.5188 - accuracy: 0.7791 - val_loss: 0.5119 - val_accuracy: 0.7829\n",
      "Epoch 115/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 0.5183 - accuracy: 0.7791 - val_loss: 0.5120 - val_accuracy: 0.7829\n",
      "Epoch 116/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5098 - val_accuracy: 0.7829\n",
      "Epoch 117/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 118/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 119/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 0.5172 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 120/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.5174 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 121/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5170 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 122/200\n",
      "172/172 [==============================] - 0s 969us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 123/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 124/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.5169 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 125/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 126/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 127/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 128/200\n",
      "172/172 [==============================] - 0s 986us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 129/200\n",
      "172/172 [==============================] - 0s 998us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 130/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 131/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5188 - accuracy: 0.7791 - val_loss: 0.5107 - val_accuracy: 0.7829\n",
      "Epoch 132/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.5170 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 133/200\n",
      "172/172 [==============================] - 0s 968us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 134/200\n",
      "172/172 [==============================] - 0s 954us/sample - loss: 0.5169 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 135/200\n",
      "172/172 [==============================] - 0s 945us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 136/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 137/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 138/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 883us/sample - loss: 0.5172 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 139/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 0.5178 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 140/200\n",
      "172/172 [==============================] - 0s 845us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 141/200\n",
      "172/172 [==============================] - 0s 865us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 142/200\n",
      "172/172 [==============================] - 0s 848us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 143/200\n",
      "172/172 [==============================] - 0s 854us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 144/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 145/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 0.5168 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 146/200\n",
      "172/172 [==============================] - 0s 981us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 147/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5100 - val_accuracy: 0.7829\n",
      "Epoch 148/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.5177 - accuracy: 0.7791 - val_loss: 0.5105 - val_accuracy: 0.7829\n",
      "Epoch 149/200\n",
      "172/172 [==============================] - 0s 849us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5098 - val_accuracy: 0.7829\n",
      "Epoch 150/200\n",
      "172/172 [==============================] - 0s 850us/sample - loss: 0.5171 - accuracy: 0.7791 - val_loss: 0.5098 - val_accuracy: 0.7829\n",
      "Epoch 151/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 0.5179 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 152/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 153/200\n",
      "172/172 [==============================] - 0s 843us/sample - loss: 0.5177 - accuracy: 0.7791 - val_loss: 0.5106 - val_accuracy: 0.7829\n",
      "Epoch 154/200\n",
      "172/172 [==============================] - 0s 849us/sample - loss: 0.5172 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 155/200\n",
      "172/172 [==============================] - 0s 857us/sample - loss: 0.5169 - accuracy: 0.7791 - val_loss: 0.5097 - val_accuracy: 0.7829\n",
      "Epoch 156/200\n",
      "172/172 [==============================] - 0s 853us/sample - loss: 0.5161 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 157/200\n",
      "172/172 [==============================] - 0s 848us/sample - loss: 0.5172 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 158/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.5200 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 159/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 0.5187 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 160/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5190 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 161/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 162/200\n",
      "172/172 [==============================] - 0s 853us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5090 - val_accuracy: 0.7829\n",
      "Epoch 163/200\n",
      "172/172 [==============================] - 0s 853us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 164/200\n",
      "172/172 [==============================] - 0s 856us/sample - loss: 0.5170 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 165/200\n",
      "172/172 [==============================] - 0s 848us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 166/200\n",
      "172/172 [==============================] - 0s 850us/sample - loss: 0.5171 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 167/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5098 - val_accuracy: 0.7829\n",
      "Epoch 168/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 0.5176 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 169/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 170/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 171/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 0.5172 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 172/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 173/200\n",
      "172/172 [==============================] - 0s 949us/sample - loss: 0.5179 - accuracy: 0.7791 - val_loss: 0.5096 - val_accuracy: 0.7829\n",
      "Epoch 174/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.5175 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 175/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5101 - val_accuracy: 0.7829\n",
      "Epoch 176/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.5175 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 177/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5201 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 178/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.5185 - accuracy: 0.7791 - val_loss: 0.5102 - val_accuracy: 0.7829\n",
      "Epoch 179/200\n",
      "172/172 [==============================] - 0s 864us/sample - loss: 0.5191 - accuracy: 0.7791 - val_loss: 0.5099 - val_accuracy: 0.7829\n",
      "Epoch 180/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 181/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 182/200\n",
      "172/172 [==============================] - 0s 864us/sample - loss: 0.5176 - accuracy: 0.7791 - val_loss: 0.5097 - val_accuracy: 0.7829\n",
      "Epoch 183/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 184/200\n",
      "172/172 [==============================] - 0s 869us/sample - loss: 0.5168 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 185/200\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5101 - val_accuracy: 0.7829\n",
      "Epoch 186/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 187/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 188/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.5168 - accuracy: 0.7791 - val_loss: 0.5093 - val_accuracy: 0.7829\n",
      "Epoch 189/200\n",
      "172/172 [==============================] - 0s 865us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 190/200\n",
      "172/172 [==============================] - 0s 839us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 191/200\n",
      "172/172 [==============================] - 0s 842us/sample - loss: 0.5167 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 192/200\n",
      "172/172 [==============================] - 0s 853us/sample - loss: 0.5183 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7829\n",
      "Epoch 193/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 852us/sample - loss: 0.5164 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 194/200\n",
      "172/172 [==============================] - 0s 825us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5088 - val_accuracy: 0.7829\n",
      "Epoch 195/200\n",
      "172/172 [==============================] - 0s 835us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 196/200\n",
      "172/172 [==============================] - 0s 837us/sample - loss: 0.5168 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 197/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 0.5181 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 198/200\n",
      "172/172 [==============================] - 0s 832us/sample - loss: 0.5160 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 199/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 200/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Beginning training for dr=0.100, l_lambda=1.0e-02, reg_type=l2, act: relu\n",
      "Train on 172 samples, validate on 43 samples\n",
      "Epoch 1/200\n",
      "172/172 [==============================] - 1s 8ms/sample - loss: 0.8900 - accuracy: 0.6667 - val_loss: 0.7690 - val_accuracy: 0.6667\n",
      "Epoch 2/200\n",
      "172/172 [==============================] - 0s 840us/sample - loss: 0.7179 - accuracy: 0.6667 - val_loss: 0.6686 - val_accuracy: 0.6667\n",
      "Epoch 3/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.6397 - accuracy: 0.6860 - val_loss: 0.5989 - val_accuracy: 0.7829\n",
      "Epoch 4/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.5856 - accuracy: 0.7791 - val_loss: 0.5614 - val_accuracy: 0.7829\n",
      "Epoch 5/200\n",
      "172/172 [==============================] - 0s 848us/sample - loss: 0.5555 - accuracy: 0.7791 - val_loss: 0.5396 - val_accuracy: 0.7829\n",
      "Epoch 6/200\n",
      "172/172 [==============================] - 0s 792us/sample - loss: 0.5384 - accuracy: 0.7791 - val_loss: 0.5275 - val_accuracy: 0.7829\n",
      "Epoch 7/200\n",
      "172/172 [==============================] - 0s 794us/sample - loss: 0.5298 - accuracy: 0.7791 - val_loss: 0.5188 - val_accuracy: 0.7829\n",
      "Epoch 8/200\n",
      "172/172 [==============================] - 0s 801us/sample - loss: 0.5225 - accuracy: 0.7791 - val_loss: 0.5136 - val_accuracy: 0.7829\n",
      "Epoch 9/200\n",
      "172/172 [==============================] - 0s 793us/sample - loss: 0.5186 - accuracy: 0.7791 - val_loss: 0.5101 - val_accuracy: 0.7829\n",
      "Epoch 10/200\n",
      "172/172 [==============================] - 0s 803us/sample - loss: 0.5146 - accuracy: 0.7791 - val_loss: 0.5073 - val_accuracy: 0.7829\n",
      "Epoch 11/200\n",
      "172/172 [==============================] - 0s 793us/sample - loss: 0.5134 - accuracy: 0.7791 - val_loss: 0.5057 - val_accuracy: 0.7829\n",
      "Epoch 12/200\n",
      "172/172 [==============================] - 0s 812us/sample - loss: 0.5115 - accuracy: 0.7791 - val_loss: 0.5045 - val_accuracy: 0.7829\n",
      "Epoch 13/200\n",
      "172/172 [==============================] - 0s 796us/sample - loss: 0.5104 - accuracy: 0.7791 - val_loss: 0.5035 - val_accuracy: 0.7829\n",
      "Epoch 14/200\n",
      "172/172 [==============================] - 0s 790us/sample - loss: 0.5115 - accuracy: 0.7791 - val_loss: 0.5033 - val_accuracy: 0.7829\n",
      "Epoch 15/200\n",
      "172/172 [==============================] - 0s 797us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5029 - val_accuracy: 0.7829\n",
      "Epoch 16/200\n",
      "172/172 [==============================] - 0s 798us/sample - loss: 0.5113 - accuracy: 0.7791 - val_loss: 0.5028 - val_accuracy: 0.7829\n",
      "Epoch 17/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 0.5106 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 18/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 19/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 20/200\n",
      "172/172 [==============================] - 0s 802us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 21/200\n",
      "172/172 [==============================] - 0s 801us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5026 - val_accuracy: 0.7829\n",
      "Epoch 22/200\n",
      "172/172 [==============================] - 0s 789us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5026 - val_accuracy: 0.7829\n",
      "Epoch 23/200\n",
      "172/172 [==============================] - 0s 796us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 24/200\n",
      "172/172 [==============================] - 0s 801us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 25/200\n",
      "172/172 [==============================] - 0s 800us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 26/200\n",
      "172/172 [==============================] - 0s 809us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 27/200\n",
      "172/172 [==============================] - 0s 807us/sample - loss: 0.5118 - accuracy: 0.7791 - val_loss: 0.5028 - val_accuracy: 0.7829\n",
      "Epoch 28/200\n",
      "172/172 [==============================] - 0s 807us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 29/200\n",
      "172/172 [==============================] - 0s 802us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 30/200\n",
      "172/172 [==============================] - 0s 814us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 31/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 32/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 33/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 34/200\n",
      "172/172 [==============================] - 0s 831us/sample - loss: 0.5106 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 35/200\n",
      "172/172 [==============================] - 0s 835us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 36/200\n",
      "172/172 [==============================] - 0s 832us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 37/200\n",
      "172/172 [==============================] - 0s 835us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 38/200\n",
      "172/172 [==============================] - 0s 836us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 39/200\n",
      "172/172 [==============================] - 0s 831us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 40/200\n",
      "172/172 [==============================] - 0s 832us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 41/200\n",
      "172/172 [==============================] - 0s 837us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 42/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 43/200\n",
      "172/172 [==============================] - 0s 835us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 44/200\n",
      "172/172 [==============================] - 0s 857us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 45/200\n",
      "172/172 [==============================] - 0s 952us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 46/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 47/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 0.5104 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 49/200\n",
      "172/172 [==============================] - 0s 850us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 50/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 51/200\n",
      "172/172 [==============================] - 0s 850us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 52/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 53/200\n",
      "172/172 [==============================] - 0s 857us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 54/200\n",
      "172/172 [==============================] - 0s 854us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 55/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 0.5104 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 56/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 57/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 58/200\n",
      "172/172 [==============================] - 0s 965us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 59/200\n",
      "172/172 [==============================] - 0s 944us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 60/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 0.5119 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 61/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 0.5080 - accuracy: 0.7791 - val_loss: 0.5028 - val_accuracy: 0.7829\n",
      "Epoch 62/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 63/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 64/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 65/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 66/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 67/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 68/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 69/200\n",
      "172/172 [==============================] - 0s 948us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 70/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5026 - val_accuracy: 0.7829\n",
      "Epoch 71/200\n",
      "172/172 [==============================] - 0s 970us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 72/200\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 73/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 74/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 75/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 76/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 77/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 78/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 79/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.5106 - accuracy: 0.7791 - val_loss: 0.5028 - val_accuracy: 0.7829\n",
      "Epoch 80/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 81/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 82/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 83/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 84/200\n",
      "172/172 [==============================] - 0s 966us/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 85/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 0.5086 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 86/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 87/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5108 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 88/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.5102 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 89/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 90/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.5108 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 91/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 92/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 93/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 94/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 95/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 96/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 97/200\n",
      "172/172 [==============================] - 0s 987us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 98/200\n",
      "172/172 [==============================] - 0s 975us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 99/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.5102 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 100/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 101/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 102/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 103/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 888us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 104/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 105/200\n",
      "172/172 [==============================] - 0s 882us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 106/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 107/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 108/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 109/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 110/200\n",
      "172/172 [==============================] - 0s 952us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 111/200\n",
      "172/172 [==============================] - 0s 973us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 112/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 113/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 114/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.5104 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 115/200\n",
      "172/172 [==============================] - 0s 864us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 116/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 117/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 0.5084 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 118/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5014 - val_accuracy: 0.7829\n",
      "Epoch 119/200\n",
      "172/172 [==============================] - 0s 856us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 120/200\n",
      "172/172 [==============================] - 0s 848us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 121/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 122/200\n",
      "172/172 [==============================] - 0s 854us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 123/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 124/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 125/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 126/200\n",
      "172/172 [==============================] - 0s 850us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 127/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 128/200\n",
      "172/172 [==============================] - 0s 850us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 129/200\n",
      "172/172 [==============================] - 0s 830us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 130/200\n",
      "172/172 [==============================] - 0s 827us/sample - loss: 0.5112 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 131/200\n",
      "172/172 [==============================] - 0s 826us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 132/200\n",
      "172/172 [==============================] - 0s 826us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 133/200\n",
      "172/172 [==============================] - 0s 826us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 134/200\n",
      "172/172 [==============================] - 0s 835us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 135/200\n",
      "172/172 [==============================] - 0s 835us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 136/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 137/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 138/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 139/200\n",
      "172/172 [==============================] - 0s 828us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 140/200\n",
      "172/172 [==============================] - 0s 833us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 141/200\n",
      "172/172 [==============================] - 0s 823us/sample - loss: 0.5104 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 142/200\n",
      "172/172 [==============================] - 0s 829us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 143/200\n",
      "172/172 [==============================] - 0s 830us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 144/200\n",
      "172/172 [==============================] - 0s 826us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 145/200\n",
      "172/172 [==============================] - 0s 829us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 146/200\n",
      "172/172 [==============================] - 0s 830us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 147/200\n",
      "172/172 [==============================] - 0s 825us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 148/200\n",
      "172/172 [==============================] - 0s 840us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 149/200\n",
      "172/172 [==============================] - 0s 830us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 150/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 151/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 0.5086 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 152/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 153/200\n",
      "172/172 [==============================] - 0s 828us/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5034 - val_accuracy: 0.7829\n",
      "Epoch 154/200\n",
      "172/172 [==============================] - 0s 827us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 155/200\n",
      "172/172 [==============================] - 0s 829us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 156/200\n",
      "172/172 [==============================] - 0s 837us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 157/200\n",
      "172/172 [==============================] - 0s 831us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 158/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 839us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 159/200\n",
      "172/172 [==============================] - 0s 832us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5029 - val_accuracy: 0.7829\n",
      "Epoch 160/200\n",
      "172/172 [==============================] - 0s 831us/sample - loss: 0.5111 - accuracy: 0.7791 - val_loss: 0.5035 - val_accuracy: 0.7829\n",
      "Epoch 161/200\n",
      "172/172 [==============================] - 0s 827us/sample - loss: 0.5115 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 162/200\n",
      "172/172 [==============================] - 0s 824us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 163/200\n",
      "172/172 [==============================] - 0s 832us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 164/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 165/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5026 - val_accuracy: 0.7829\n",
      "Epoch 166/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 167/200\n",
      "172/172 [==============================] - 0s 823us/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5029 - val_accuracy: 0.7829\n",
      "Epoch 168/200\n",
      "172/172 [==============================] - 0s 821us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 169/200\n",
      "172/172 [==============================] - 0s 822us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 170/200\n",
      "172/172 [==============================] - 0s 830us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 171/200\n",
      "172/172 [==============================] - 0s 823us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 172/200\n",
      "172/172 [==============================] - 0s 826us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 173/200\n",
      "172/172 [==============================] - 0s 824us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 174/200\n",
      "172/172 [==============================] - 0s 822us/sample - loss: 0.5086 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 175/200\n",
      "172/172 [==============================] - 0s 825us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 176/200\n",
      "172/172 [==============================] - 0s 848us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 177/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 178/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 179/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 180/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 181/200\n",
      "172/172 [==============================] - 0s 854us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 182/200\n",
      "172/172 [==============================] - 0s 850us/sample - loss: 0.5109 - accuracy: 0.7791 - val_loss: 0.5026 - val_accuracy: 0.7829\n",
      "Epoch 183/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 184/200\n",
      "172/172 [==============================] - 0s 860us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 185/200\n",
      "172/172 [==============================] - 0s 862us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 186/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 187/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 188/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 0.5107 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 189/200\n",
      "172/172 [==============================] - 0s 853us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 190/200\n",
      "172/172 [==============================] - 0s 853us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 191/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 192/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 193/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 194/200\n",
      "172/172 [==============================] - 0s 849us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 195/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 196/200\n",
      "172/172 [==============================] - 0s 854us/sample - loss: 0.5086 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 197/200\n",
      "172/172 [==============================] - 0s 849us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 198/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 199/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 200/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Beginning training for dr=0.100, l_lambda=1.0e-02, reg_type=l2, act: tanh\n",
      "Train on 172 samples, validate on 43 samples\n",
      "Epoch 1/200\n",
      "172/172 [==============================] - 1s 8ms/sample - loss: 0.8644 - accuracy: 0.6667 - val_loss: 0.7235 - val_accuracy: 0.6667\n",
      "Epoch 2/200\n",
      "172/172 [==============================] - 0s 845us/sample - loss: 0.6637 - accuracy: 0.7345 - val_loss: 0.6093 - val_accuracy: 0.7829\n",
      "Epoch 3/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 0.5948 - accuracy: 0.7791 - val_loss: 0.5696 - val_accuracy: 0.7829\n",
      "Epoch 4/200\n",
      "172/172 [==============================] - 0s 850us/sample - loss: 0.5675 - accuracy: 0.7791 - val_loss: 0.5474 - val_accuracy: 0.7829\n",
      "Epoch 5/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.5459 - accuracy: 0.7791 - val_loss: 0.5322 - val_accuracy: 0.7829\n",
      "Epoch 6/200\n",
      "172/172 [==============================] - 0s 840us/sample - loss: 0.5365 - accuracy: 0.7791 - val_loss: 0.5221 - val_accuracy: 0.7829\n",
      "Epoch 7/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5318 - accuracy: 0.7791 - val_loss: 0.5156 - val_accuracy: 0.7829\n",
      "Epoch 8/200\n",
      "172/172 [==============================] - 0s 946us/sample - loss: 0.5220 - accuracy: 0.7791 - val_loss: 0.5107 - val_accuracy: 0.7829\n",
      "Epoch 9/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5079 - val_accuracy: 0.7829\n",
      "Epoch 10/200\n",
      "172/172 [==============================] - 0s 853us/sample - loss: 0.5141 - accuracy: 0.7791 - val_loss: 0.5055 - val_accuracy: 0.7829\n",
      "Epoch 11/200\n",
      "172/172 [==============================] - 0s 824us/sample - loss: 0.5126 - accuracy: 0.7791 - val_loss: 0.5040 - val_accuracy: 0.7829\n",
      "Epoch 12/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 826us/sample - loss: 0.5114 - accuracy: 0.7791 - val_loss: 0.5034 - val_accuracy: 0.7829\n",
      "Epoch 13/200\n",
      "172/172 [==============================] - 0s 830us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5029 - val_accuracy: 0.7829\n",
      "Epoch 14/200\n",
      "172/172 [==============================] - 0s 822us/sample - loss: 0.5102 - accuracy: 0.7791 - val_loss: 0.5030 - val_accuracy: 0.7829\n",
      "Epoch 15/200\n",
      "172/172 [==============================] - 0s 819us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5034 - val_accuracy: 0.7829\n",
      "Epoch 16/200\n",
      "172/172 [==============================] - 0s 831us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 17/200\n",
      "172/172 [==============================] - 0s 821us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 18/200\n",
      "172/172 [==============================] - 0s 834us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5014 - val_accuracy: 0.7829\n",
      "Epoch 19/200\n",
      "172/172 [==============================] - 0s 818us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 20/200\n",
      "172/172 [==============================] - 0s 836us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 21/200\n",
      "172/172 [==============================] - 0s 972us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 22/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 23/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 24/200\n",
      "172/172 [==============================] - 0s 818us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 25/200\n",
      "172/172 [==============================] - 0s 822us/sample - loss: 0.5105 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 26/200\n",
      "172/172 [==============================] - 0s 819us/sample - loss: 0.5115 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 27/200\n",
      "172/172 [==============================] - 0s 820us/sample - loss: 0.5083 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 28/200\n",
      "172/172 [==============================] - 0s 826us/sample - loss: 0.5102 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 29/200\n",
      "172/172 [==============================] - 0s 825us/sample - loss: 0.5108 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 30/200\n",
      "172/172 [==============================] - 0s 832us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5033 - val_accuracy: 0.7829\n",
      "Epoch 31/200\n",
      "172/172 [==============================] - 0s 816us/sample - loss: 0.5107 - accuracy: 0.7791 - val_loss: 0.5029 - val_accuracy: 0.7829\n",
      "Epoch 32/200\n",
      "172/172 [==============================] - 0s 823us/sample - loss: 0.5081 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 33/200\n",
      "172/172 [==============================] - 0s 817us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 34/200\n",
      "172/172 [==============================] - 0s 840us/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 35/200\n",
      "172/172 [==============================] - 0s 946us/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 36/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5086 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 37/200\n",
      "172/172 [==============================] - 0s 859us/sample - loss: 0.5132 - accuracy: 0.7791 - val_loss: 0.5043 - val_accuracy: 0.7829\n",
      "Epoch 38/200\n",
      "172/172 [==============================] - 0s 829us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 39/200\n",
      "172/172 [==============================] - 0s 825us/sample - loss: 0.5084 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 40/200\n",
      "172/172 [==============================] - 0s 823us/sample - loss: 0.5104 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 41/200\n",
      "172/172 [==============================] - 0s 823us/sample - loss: 0.5110 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 42/200\n",
      "172/172 [==============================] - 0s 827us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 43/200\n",
      "172/172 [==============================] - 0s 823us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 44/200\n",
      "172/172 [==============================] - 0s 820us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 45/200\n",
      "172/172 [==============================] - 0s 826us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 46/200\n",
      "172/172 [==============================] - 0s 824us/sample - loss: 0.5139 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 47/200\n",
      "172/172 [==============================] - 0s 824us/sample - loss: 0.5107 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 48/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 49/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 50/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.5112 - accuracy: 0.7791 - val_loss: 0.5029 - val_accuracy: 0.7829\n",
      "Epoch 51/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 52/200\n",
      "172/172 [==============================] - 0s 823us/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 53/200\n",
      "172/172 [==============================] - 0s 819us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 54/200\n",
      "172/172 [==============================] - 0s 833us/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 55/200\n",
      "172/172 [==============================] - 0s 825us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 56/200\n",
      "172/172 [==============================] - 0s 819us/sample - loss: 0.5102 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 57/200\n",
      "172/172 [==============================] - 0s 831us/sample - loss: 0.5108 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 58/200\n",
      "172/172 [==============================] - 0s 833us/sample - loss: 0.5110 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 59/200\n",
      "172/172 [==============================] - 0s 826us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 60/200\n",
      "172/172 [==============================] - 0s 841us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 61/200\n",
      "172/172 [==============================] - 0s 822us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 62/200\n",
      "172/172 [==============================] - 0s 941us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 63/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 64/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 65/200\n",
      "172/172 [==============================] - 0s 822us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5026 - val_accuracy: 0.7829\n",
      "Epoch 66/200\n",
      "172/172 [==============================] - 0s 829us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 67/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 852us/sample - loss: 0.5104 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 68/200\n",
      "172/172 [==============================] - 0s 843us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5014 - val_accuracy: 0.7829\n",
      "Epoch 69/200\n",
      "172/172 [==============================] - 0s 842us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5014 - val_accuracy: 0.7829\n",
      "Epoch 70/200\n",
      "172/172 [==============================] - 0s 841us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 71/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 72/200\n",
      "172/172 [==============================] - 0s 848us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 73/200\n",
      "172/172 [==============================] - 0s 849us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 74/200\n",
      "172/172 [==============================] - 0s 841us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 75/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 76/200\n",
      "172/172 [==============================] - 0s 973us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 77/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 78/200\n",
      "172/172 [==============================] - 0s 869us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 79/200\n",
      "172/172 [==============================] - 0s 843us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 80/200\n",
      "172/172 [==============================] - 0s 844us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 81/200\n",
      "172/172 [==============================] - 0s 835us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5014 - val_accuracy: 0.7829\n",
      "Epoch 82/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 83/200\n",
      "172/172 [==============================] - 0s 841us/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 84/200\n",
      "172/172 [==============================] - 0s 842us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 85/200\n",
      "172/172 [==============================] - 0s 843us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 86/200\n",
      "172/172 [==============================] - 0s 844us/sample - loss: 0.5105 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 87/200\n",
      "172/172 [==============================] - 0s 844us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 88/200\n",
      "172/172 [==============================] - 0s 861us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 89/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 90/200\n",
      "172/172 [==============================] - 0s 969us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5031 - val_accuracy: 0.7829\n",
      "Epoch 91/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 92/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 93/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 94/200\n",
      "172/172 [==============================] - 0s 865us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 95/200\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 96/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 97/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.5105 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 98/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 99/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5014 - val_accuracy: 0.7829\n",
      "Epoch 100/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 101/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 102/200\n",
      "172/172 [==============================] - 0s 989us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 103/200\n",
      "172/172 [==============================] - 0s 952us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 104/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.5109 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 105/200\n",
      "172/172 [==============================] - 0s 865us/sample - loss: 0.5105 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 106/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 107/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 108/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5106 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 109/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 0.5102 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 110/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 111/200\n",
      "172/172 [==============================] - 0s 864us/sample - loss: 0.5113 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 112/200\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 113/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 114/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 115/200\n",
      "172/172 [==============================] - 0s 981us/sample - loss: 0.5115 - accuracy: 0.7791 - val_loss: 0.5037 - val_accuracy: 0.7829\n",
      "Epoch 116/200\n",
      "172/172 [==============================] - 0s 959us/sample - loss: 0.5111 - accuracy: 0.7791 - val_loss: 0.5031 - val_accuracy: 0.7829\n",
      "Epoch 117/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.5105 - accuracy: 0.7791 - val_loss: 0.5014 - val_accuracy: 0.7829\n",
      "Epoch 118/200\n",
      "172/172 [==============================] - 0s 869us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 119/200\n",
      "172/172 [==============================] - 0s 869us/sample - loss: 0.5111 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 120/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5031 - val_accuracy: 0.7829\n",
      "Epoch 121/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 122/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 879us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 123/200\n",
      "172/172 [==============================] - 0s 869us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 124/200\n",
      "172/172 [==============================] - 0s 860us/sample - loss: 0.5086 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 125/200\n",
      "172/172 [==============================] - 0s 958us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 126/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 127/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.5139 - accuracy: 0.7791 - val_loss: 0.5047 - val_accuracy: 0.7829\n",
      "Epoch 128/200\n",
      "172/172 [==============================] - 0s 974us/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 129/200\n",
      "172/172 [==============================] - 0s 958us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 130/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 131/200\n",
      "172/172 [==============================] - 0s 869us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 132/200\n",
      "172/172 [==============================] - 0s 869us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 133/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 134/200\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 135/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 0.5104 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 136/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 137/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 138/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 139/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 140/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5014 - val_accuracy: 0.7829\n",
      "Epoch 141/200\n",
      "172/172 [==============================] - 0s 959us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 142/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 143/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 144/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5030 - val_accuracy: 0.7829\n",
      "Epoch 145/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 146/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 147/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 148/200\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 149/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 150/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 151/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 152/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.5107 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 153/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 0.5106 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 154/200\n",
      "172/172 [==============================] - 0s 965us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 155/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 156/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 157/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5014 - val_accuracy: 0.7829\n",
      "Epoch 158/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 159/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.5102 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 160/200\n",
      "172/172 [==============================] - 0s 862us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 161/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 162/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 0.5116 - accuracy: 0.7791 - val_loss: 0.5033 - val_accuracy: 0.7829\n",
      "Epoch 163/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5026 - val_accuracy: 0.7829\n",
      "Epoch 164/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 165/200\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 166/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 167/200\n",
      "172/172 [==============================] - 0s 941us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 168/200\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 169/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5029 - val_accuracy: 0.7829\n",
      "Epoch 170/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 171/200\n",
      "172/172 [==============================] - 0s 856us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 172/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 173/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 174/200\n",
      "172/172 [==============================] - 0s 862us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 175/200\n",
      "172/172 [==============================] - 0s 824us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 176/200\n",
      "172/172 [==============================] - 0s 817us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 177/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 820us/sample - loss: 0.5112 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 178/200\n",
      "172/172 [==============================] - 0s 812us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 179/200\n",
      "172/172 [==============================] - 0s 818us/sample - loss: 0.5108 - accuracy: 0.7791 - val_loss: 0.5030 - val_accuracy: 0.7829\n",
      "Epoch 180/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5028 - val_accuracy: 0.7829\n",
      "Epoch 181/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.5102 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 182/200\n",
      "172/172 [==============================] - 0s 857us/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 183/200\n",
      "172/172 [==============================] - 0s 818us/sample - loss: 0.5140 - accuracy: 0.7791 - val_loss: 0.5026 - val_accuracy: 0.7829\n",
      "Epoch 184/200\n",
      "172/172 [==============================] - 0s 817us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5014 - val_accuracy: 0.7829\n",
      "Epoch 185/200\n",
      "172/172 [==============================] - 0s 812us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 186/200\n",
      "172/172 [==============================] - 0s 820us/sample - loss: 0.5111 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 187/200\n",
      "172/172 [==============================] - 0s 816us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5014 - val_accuracy: 0.7829\n",
      "Epoch 188/200\n",
      "172/172 [==============================] - 0s 814us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5014 - val_accuracy: 0.7829\n",
      "Epoch 189/200\n",
      "172/172 [==============================] - 0s 820us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 190/200\n",
      "172/172 [==============================] - 0s 814us/sample - loss: 0.5125 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 191/200\n",
      "172/172 [==============================] - 0s 834us/sample - loss: 0.5081 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 192/200\n",
      "172/172 [==============================] - 0s 821us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 193/200\n",
      "172/172 [==============================] - 0s 830us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 194/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 195/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 196/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 0.5106 - accuracy: 0.7791 - val_loss: 0.5031 - val_accuracy: 0.7829\n",
      "Epoch 197/200\n",
      "172/172 [==============================] - 0s 842us/sample - loss: 0.5106 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 198/200\n",
      "172/172 [==============================] - 0s 837us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 199/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 200/200\n",
      "172/172 [==============================] - 0s 843us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Beginning training for dr=0.100, l_lambda=1.0e-02, reg_type=l1, act: relu\n",
      "Train on 172 samples, validate on 43 samples\n",
      "Epoch 1/200\n",
      "172/172 [==============================] - 1s 8ms/sample - loss: 7.7263 - accuracy: 0.6667 - val_loss: 4.1687 - val_accuracy: 0.6667\n",
      "Epoch 2/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 2.8986 - accuracy: 0.6667 - val_loss: 2.2108 - val_accuracy: 0.6667\n",
      "Epoch 3/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 1.8408 - accuracy: 0.6919 - val_loss: 1.5157 - val_accuracy: 0.7829\n",
      "Epoch 4/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 1.3577 - accuracy: 0.7791 - val_loss: 1.1908 - val_accuracy: 0.7829\n",
      "Epoch 5/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 1.0937 - accuracy: 0.7791 - val_loss: 0.9764 - val_accuracy: 0.7829\n",
      "Epoch 6/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.9068 - accuracy: 0.7791 - val_loss: 0.8167 - val_accuracy: 0.7829\n",
      "Epoch 7/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.7673 - accuracy: 0.7791 - val_loss: 0.7025 - val_accuracy: 0.7829\n",
      "Epoch 8/200\n",
      "172/172 [==============================] - 0s 971us/sample - loss: 0.6679 - accuracy: 0.7791 - val_loss: 0.6209 - val_accuracy: 0.7829\n",
      "Epoch 9/200\n",
      "172/172 [==============================] - 0s 961us/sample - loss: 0.6076 - accuracy: 0.7791 - val_loss: 0.5848 - val_accuracy: 0.7829\n",
      "Epoch 10/200\n",
      "172/172 [==============================] - 0s 968us/sample - loss: 0.5874 - accuracy: 0.7791 - val_loss: 0.5781 - val_accuracy: 0.7829\n",
      "Epoch 11/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.5840 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 12/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.5834 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 13/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.5820 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 14/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 15/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.5838 - accuracy: 0.7791 - val_loss: 0.5782 - val_accuracy: 0.7829\n",
      "Epoch 16/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5838 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 17/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 18/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 19/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 20/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 21/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5819 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 22/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5832 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 23/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5769 - val_accuracy: 0.7829\n",
      "Epoch 24/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.5835 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 25/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.5819 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 26/200\n",
      "172/172 [==============================] - 0s 857us/sample - loss: 0.5832 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 27/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 28/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 29/200\n",
      "172/172 [==============================] - 0s 857us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5770 - val_accuracy: 0.7829\n",
      "Epoch 30/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 31/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 842us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5752 - val_accuracy: 0.7829\n",
      "Epoch 32/200\n",
      "172/172 [==============================] - 0s 840us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 33/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 34/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 35/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5819 - accuracy: 0.7791 - val_loss: 0.5773 - val_accuracy: 0.7829\n",
      "Epoch 36/200\n",
      "172/172 [==============================] - 0s 864us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 37/200\n",
      "172/172 [==============================] - 0s 848us/sample - loss: 0.5841 - accuracy: 0.7791 - val_loss: 0.5769 - val_accuracy: 0.7829\n",
      "Epoch 38/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 39/200\n",
      "172/172 [==============================] - 0s 849us/sample - loss: 0.5820 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 40/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5751 - val_accuracy: 0.7829\n",
      "Epoch 41/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 42/200\n",
      "172/172 [==============================] - 0s 843us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 43/200\n",
      "172/172 [==============================] - 0s 844us/sample - loss: 0.5818 - accuracy: 0.7791 - val_loss: 0.5768 - val_accuracy: 0.7829\n",
      "Epoch 44/200\n",
      "172/172 [==============================] - 0s 839us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 45/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 46/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 47/200\n",
      "172/172 [==============================] - 0s 960us/sample - loss: 0.5833 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 48/200\n",
      "172/172 [==============================] - 0s 946us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 49/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5770 - val_accuracy: 0.7829\n",
      "Epoch 50/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 51/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.5864 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 52/200\n",
      "172/172 [==============================] - 0s 862us/sample - loss: 0.5815 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 53/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.5820 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 54/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5751 - val_accuracy: 0.7829\n",
      "Epoch 55/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5816 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 56/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.5840 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 57/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5768 - val_accuracy: 0.7829\n",
      "Epoch 58/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 59/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 60/200\n",
      "172/172 [==============================] - 0s 988us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 61/200\n",
      "172/172 [==============================] - 0s 985us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 62/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 63/200\n",
      "172/172 [==============================] - 0s 945us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5778 - val_accuracy: 0.7829\n",
      "Epoch 64/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 0.5842 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 65/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 66/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5749 - val_accuracy: 0.7829\n",
      "Epoch 67/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 68/200\n",
      "172/172 [==============================] - 0s 940us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 69/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 70/200\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 0.5834 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 71/200\n",
      "172/172 [==============================] - 0s 944us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 72/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5777 - val_accuracy: 0.7829\n",
      "Epoch 73/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5835 - accuracy: 0.7791 - val_loss: 0.5772 - val_accuracy: 0.7829\n",
      "Epoch 74/200\n",
      "172/172 [==============================] - 0s 966us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5768 - val_accuracy: 0.7829\n",
      "Epoch 75/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5768 - val_accuracy: 0.7829\n",
      "Epoch 76/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 77/200\n",
      "172/172 [==============================] - 0s 975us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5773 - val_accuracy: 0.7829\n",
      "Epoch 78/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 79/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 80/200\n",
      "172/172 [==============================] - 0s 960us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 81/200\n",
      "172/172 [==============================] - 0s 957us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 82/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5833 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 83/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5771 - val_accuracy: 0.7829\n",
      "Epoch 84/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 85/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5769 - val_accuracy: 0.7829\n",
      "Epoch 86/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 999us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 87/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 88/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 89/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 90/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5816 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 91/200\n",
      "172/172 [==============================] - 0s 973us/sample - loss: 0.5833 - accuracy: 0.7791 - val_loss: 0.5772 - val_accuracy: 0.7829\n",
      "Epoch 92/200\n",
      "172/172 [==============================] - 0s 989us/sample - loss: 0.5833 - accuracy: 0.7791 - val_loss: 0.5768 - val_accuracy: 0.7829\n",
      "Epoch 93/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 94/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 95/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 96/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5750 - val_accuracy: 0.7829\n",
      "Epoch 97/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5842 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 98/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5837 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 99/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5767 - val_accuracy: 0.7829\n",
      "Epoch 100/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 101/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 102/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5820 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 103/200\n",
      "172/172 [==============================] - 0s 971us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 104/200\n",
      "172/172 [==============================] - 0s 997us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 105/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5784 - val_accuracy: 0.7829\n",
      "Epoch 106/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 107/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5820 - accuracy: 0.7791 - val_loss: 0.5770 - val_accuracy: 0.7829\n",
      "Epoch 108/200\n",
      "172/172 [==============================] - 0s 989us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 109/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5820 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 110/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 111/200\n",
      "172/172 [==============================] - 0s 976us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 112/200\n",
      "172/172 [==============================] - 0s 960us/sample - loss: 0.5837 - accuracy: 0.7791 - val_loss: 0.5767 - val_accuracy: 0.7829\n",
      "Epoch 113/200\n",
      "172/172 [==============================] - 0s 960us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5771 - val_accuracy: 0.7829\n",
      "Epoch 114/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5767 - val_accuracy: 0.7829\n",
      "Epoch 115/200\n",
      "172/172 [==============================] - 0s 955us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 116/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 117/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5768 - val_accuracy: 0.7829\n",
      "Epoch 118/200\n",
      "172/172 [==============================] - 0s 988us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 119/200\n",
      "172/172 [==============================] - 0s 964us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 120/200\n",
      "172/172 [==============================] - 0s 959us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 121/200\n",
      "172/172 [==============================] - 0s 952us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 122/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 123/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5818 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 124/200\n",
      "172/172 [==============================] - 0s 951us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 125/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 126/200\n",
      "172/172 [==============================] - 0s 940us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 127/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5773 - val_accuracy: 0.7829\n",
      "Epoch 128/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5767 - val_accuracy: 0.7829\n",
      "Epoch 129/200\n",
      "172/172 [==============================] - 0s 942us/sample - loss: 0.5836 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 130/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 131/200\n",
      "172/172 [==============================] - 0s 959us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 132/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 133/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5776 - val_accuracy: 0.7829\n",
      "Epoch 134/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 135/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5772 - val_accuracy: 0.7829\n",
      "Epoch 136/200\n",
      "172/172 [==============================] - 0s 973us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 137/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 138/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 139/200\n",
      "172/172 [==============================] - 0s 998us/sample - loss: 0.5818 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 140/200\n",
      "172/172 [==============================] - 0s 988us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 141/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 998us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 142/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 143/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5834 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 144/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 145/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 146/200\n",
      "172/172 [==============================] - 0s 959us/sample - loss: 0.5832 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 147/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.5839 - accuracy: 0.7791 - val_loss: 0.5770 - val_accuracy: 0.7829\n",
      "Epoch 148/200\n",
      "172/172 [==============================] - 0s 944us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 149/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5768 - val_accuracy: 0.7829\n",
      "Epoch 150/200\n",
      "172/172 [==============================] - 0s 942us/sample - loss: 0.5833 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 151/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 152/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 153/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5771 - val_accuracy: 0.7829\n",
      "Epoch 154/200\n",
      "172/172 [==============================] - 0s 985us/sample - loss: 0.5834 - accuracy: 0.7791 - val_loss: 0.5771 - val_accuracy: 0.7829\n",
      "Epoch 155/200\n",
      "172/172 [==============================] - 0s 980us/sample - loss: 0.5844 - accuracy: 0.7791 - val_loss: 0.5769 - val_accuracy: 0.7829\n",
      "Epoch 156/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 157/200\n",
      "172/172 [==============================] - 0s 937us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 158/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.5833 - accuracy: 0.7791 - val_loss: 0.5769 - val_accuracy: 0.7829\n",
      "Epoch 159/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.5836 - accuracy: 0.7791 - val_loss: 0.5774 - val_accuracy: 0.7829\n",
      "Epoch 160/200\n",
      "172/172 [==============================] - 0s 930us/sample - loss: 0.5837 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 161/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5771 - val_accuracy: 0.7829\n",
      "Epoch 162/200\n",
      "172/172 [==============================] - 0s 997us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 163/200\n",
      "172/172 [==============================] - 0s 973us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5770 - val_accuracy: 0.7829\n",
      "Epoch 164/200\n",
      "172/172 [==============================] - 0s 987us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 165/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 166/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 167/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 168/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 169/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5834 - accuracy: 0.7791 - val_loss: 0.5768 - val_accuracy: 0.7829\n",
      "Epoch 170/200\n",
      "172/172 [==============================] - 0s 942us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 171/200\n",
      "172/172 [==============================] - 0s 982us/sample - loss: 0.5836 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 172/200\n",
      "172/172 [==============================] - 0s 967us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 173/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 174/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.5837 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 175/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.5818 - accuracy: 0.7791 - val_loss: 0.5778 - val_accuracy: 0.7829\n",
      "Epoch 176/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5835 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 177/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5767 - val_accuracy: 0.7829\n",
      "Epoch 178/200\n",
      "172/172 [==============================] - 0s 973us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 179/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 180/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 181/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 182/200\n",
      "172/172 [==============================] - 0s 956us/sample - loss: 0.5867 - accuracy: 0.7791 - val_loss: 0.5770 - val_accuracy: 0.7829\n",
      "Epoch 183/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5775 - val_accuracy: 0.7829\n",
      "Epoch 184/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 0.5820 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 185/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 186/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 0.5838 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 187/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 188/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 189/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5775 - val_accuracy: 0.7829\n",
      "Epoch 190/200\n",
      "172/172 [==============================] - 0s 966us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 191/200\n",
      "172/172 [==============================] - 0s 992us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 192/200\n",
      "172/172 [==============================] - 0s 942us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 193/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5776 - val_accuracy: 0.7829\n",
      "Epoch 194/200\n",
      "172/172 [==============================] - 0s 974us/sample - loss: 0.5834 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 195/200\n",
      "172/172 [==============================] - 0s 945us/sample - loss: 0.5820 - accuracy: 0.7791 - val_loss: 0.5771 - val_accuracy: 0.7829\n",
      "Epoch 196/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 898us/sample - loss: 0.5832 - accuracy: 0.7791 - val_loss: 0.5751 - val_accuracy: 0.7829\n",
      "Epoch 197/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 198/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 199/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5751 - val_accuracy: 0.7829\n",
      "Epoch 200/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Beginning training for dr=0.100, l_lambda=1.0e-02, reg_type=l1, act: tanh\n",
      "Train on 172 samples, validate on 43 samples\n",
      "Epoch 1/200\n",
      "172/172 [==============================] - 2s 9ms/sample - loss: 7.6627 - accuracy: 0.6667 - val_loss: 4.0984 - val_accuracy: 0.6667\n",
      "Epoch 2/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 2.8227 - accuracy: 0.7054 - val_loss: 2.1290 - val_accuracy: 0.7829\n",
      "Epoch 3/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.7711 - accuracy: 0.7791 - val_loss: 1.4592 - val_accuracy: 0.7829\n",
      "Epoch 4/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 1.3141 - accuracy: 0.7791 - val_loss: 1.1540 - val_accuracy: 0.7829\n",
      "Epoch 5/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 1.0639 - accuracy: 0.7791 - val_loss: 0.9537 - val_accuracy: 0.7829\n",
      "Epoch 6/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.8881 - accuracy: 0.7791 - val_loss: 0.8013 - val_accuracy: 0.7829\n",
      "Epoch 7/200\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 0.7557 - accuracy: 0.7791 - val_loss: 0.6928 - val_accuracy: 0.7829\n",
      "Epoch 8/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.6616 - accuracy: 0.7791 - val_loss: 0.6176 - val_accuracy: 0.7829\n",
      "Epoch 9/200\n",
      "172/172 [==============================] - 0s 947us/sample - loss: 0.6060 - accuracy: 0.7791 - val_loss: 0.5833 - val_accuracy: 0.7829\n",
      "Epoch 10/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5873 - accuracy: 0.7791 - val_loss: 0.5780 - val_accuracy: 0.7829\n",
      "Epoch 11/200\n",
      "172/172 [==============================] - 0s 960us/sample - loss: 0.5842 - accuracy: 0.7791 - val_loss: 0.5767 - val_accuracy: 0.7829\n",
      "Epoch 12/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.5838 - accuracy: 0.7791 - val_loss: 0.5767 - val_accuracy: 0.7829\n",
      "Epoch 13/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5776 - val_accuracy: 0.7829\n",
      "Epoch 14/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5832 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 15/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5838 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 16/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5854 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 17/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 18/200\n",
      "172/172 [==============================] - 0s 928us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 19/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 20/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5749 - val_accuracy: 0.7829\n",
      "Epoch 21/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 0.5841 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 22/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 0.5836 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 23/200\n",
      "172/172 [==============================] - 0s 869us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5771 - val_accuracy: 0.7829\n",
      "Epoch 24/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 25/200\n",
      "172/172 [==============================] - 0s 840us/sample - loss: 0.5820 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 26/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.5842 - accuracy: 0.7791 - val_loss: 0.5752 - val_accuracy: 0.7829\n",
      "Epoch 27/200\n",
      "172/172 [==============================] - 0s 977us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 28/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5749 - val_accuracy: 0.7829\n",
      "Epoch 29/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 30/200\n",
      "172/172 [==============================] - 0s 848us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5768 - val_accuracy: 0.7829\n",
      "Epoch 31/200\n",
      "172/172 [==============================] - 0s 865us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 32/200\n",
      "172/172 [==============================] - 0s 856us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 33/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 34/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 0.5837 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 35/200\n",
      "172/172 [==============================] - 0s 850us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5779 - val_accuracy: 0.7829\n",
      "Epoch 36/200\n",
      "172/172 [==============================] - 0s 860us/sample - loss: 0.5838 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 37/200\n",
      "172/172 [==============================] - 0s 853us/sample - loss: 0.5838 - accuracy: 0.7791 - val_loss: 0.5771 - val_accuracy: 0.7829\n",
      "Epoch 38/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 39/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5768 - val_accuracy: 0.7829\n",
      "Epoch 40/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 41/200\n",
      "172/172 [==============================] - 0s 973us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 42/200\n",
      "172/172 [==============================] - 0s 946us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 43/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5777 - val_accuracy: 0.7829\n",
      "Epoch 44/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.5834 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 45/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 46/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.5844 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 47/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 48/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5752 - val_accuracy: 0.7829\n",
      "Epoch 49/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.5840 - accuracy: 0.7791 - val_loss: 0.5769 - val_accuracy: 0.7829\n",
      "Epoch 50/200\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 0.5838 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 52/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.5847 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 53/200\n",
      "172/172 [==============================] - 0s 986us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 54/200\n",
      "172/172 [==============================] - 0s 968us/sample - loss: 0.5842 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 55/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5873 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 56/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5772 - val_accuracy: 0.7829\n",
      "Epoch 57/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5841 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 58/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5820 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 59/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.5839 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 60/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 61/200\n",
      "172/172 [==============================] - 0s 984us/sample - loss: 0.5845 - accuracy: 0.7791 - val_loss: 0.5781 - val_accuracy: 0.7829\n",
      "Epoch 62/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5850 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 63/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.5832 - accuracy: 0.7791 - val_loss: 0.5781 - val_accuracy: 0.7829\n",
      "Epoch 64/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 65/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 66/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 67/200\n",
      "172/172 [==============================] - 0s 981us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 68/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 69/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5819 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 70/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 71/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5832 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 72/200\n",
      "172/172 [==============================] - 0s 945us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 73/200\n",
      "172/172 [==============================] - 0s 941us/sample - loss: 0.5836 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 74/200\n",
      "172/172 [==============================] - 0s 957us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 75/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 76/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 77/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 78/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5832 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 79/200\n",
      "172/172 [==============================] - 0s 993us/sample - loss: 0.5836 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 80/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5751 - val_accuracy: 0.7829\n",
      "Epoch 81/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 82/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5862 - accuracy: 0.7791 - val_loss: 0.5783 - val_accuracy: 0.7829\n",
      "Epoch 83/200\n",
      "172/172 [==============================] - 0s 983us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5772 - val_accuracy: 0.7829\n",
      "Epoch 84/200\n",
      "172/172 [==============================] - 0s 978us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 85/200\n",
      "172/172 [==============================] - 0s 993us/sample - loss: 0.5833 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 86/200\n",
      "172/172 [==============================] - 0s 974us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 87/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 88/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 89/200\n",
      "172/172 [==============================] - 0s 973us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5751 - val_accuracy: 0.7829\n",
      "Epoch 90/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 91/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.5841 - accuracy: 0.7791 - val_loss: 0.5775 - val_accuracy: 0.7829\n",
      "Epoch 92/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 0.5845 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 93/200\n",
      "172/172 [==============================] - 0s 974us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 94/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 95/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 0.5833 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 96/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.5832 - accuracy: 0.7791 - val_loss: 0.5747 - val_accuracy: 0.7829\n",
      "Epoch 97/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 98/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 99/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5837 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 100/200\n",
      "172/172 [==============================] - 0s 994us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 101/200\n",
      "172/172 [==============================] - 0s 960us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5748 - val_accuracy: 0.7829\n",
      "Epoch 102/200\n",
      "172/172 [==============================] - 0s 937us/sample - loss: 0.5818 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 103/200\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 104/200\n",
      "172/172 [==============================] - 0s 860us/sample - loss: 0.5888 - accuracy: 0.7791 - val_loss: 0.5775 - val_accuracy: 0.7829\n",
      "Epoch 105/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5770 - val_accuracy: 0.7829\n",
      "Epoch 106/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 876us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5751 - val_accuracy: 0.7829\n",
      "Epoch 107/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 0.5839 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 108/200\n",
      "172/172 [==============================] - 0s 858us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 109/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5767 - val_accuracy: 0.7829\n",
      "Epoch 110/200\n",
      "172/172 [==============================] - 0s 856us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5750 - val_accuracy: 0.7829\n",
      "Epoch 111/200\n",
      "172/172 [==============================] - 0s 860us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 112/200\n",
      "172/172 [==============================] - 0s 859us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 113/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 114/200\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 0.5832 - accuracy: 0.7791 - val_loss: 0.5768 - val_accuracy: 0.7829\n",
      "Epoch 115/200\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 0.5833 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 116/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 0.5835 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 117/200\n",
      "172/172 [==============================] - 0s 859us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 118/200\n",
      "172/172 [==============================] - 0s 861us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5751 - val_accuracy: 0.7829\n",
      "Epoch 119/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 120/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 121/200\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5755 - val_accuracy: 0.7829\n",
      "Epoch 122/200\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 123/200\n",
      "172/172 [==============================] - 0s 864us/sample - loss: 0.5847 - accuracy: 0.7791 - val_loss: 0.5769 - val_accuracy: 0.7829\n",
      "Epoch 124/200\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 125/200\n",
      "172/172 [==============================] - 0s 858us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 126/200\n",
      "172/172 [==============================] - 0s 930us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5750 - val_accuracy: 0.7829\n",
      "Epoch 127/200\n",
      "172/172 [==============================] - 0s 944us/sample - loss: 0.5837 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 128/200\n",
      "172/172 [==============================] - 0s 941us/sample - loss: 0.5819 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 129/200\n",
      "172/172 [==============================] - 0s 865us/sample - loss: 0.5833 - accuracy: 0.7791 - val_loss: 0.5752 - val_accuracy: 0.7829\n",
      "Epoch 130/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.5832 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 131/200\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 0.5842 - accuracy: 0.7791 - val_loss: 0.5751 - val_accuracy: 0.7829\n",
      "Epoch 132/200\n",
      "172/172 [==============================] - 0s 869us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 133/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5787 - val_accuracy: 0.7829\n",
      "Epoch 134/200\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 135/200\n",
      "172/172 [==============================] - 0s 842us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 136/200\n",
      "172/172 [==============================] - 0s 835us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5747 - val_accuracy: 0.7829\n",
      "Epoch 137/200\n",
      "172/172 [==============================] - 0s 845us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 138/200\n",
      "172/172 [==============================] - 0s 856us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 139/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 140/200\n",
      "172/172 [==============================] - 0s 928us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5749 - val_accuracy: 0.7829\n",
      "Epoch 141/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5750 - val_accuracy: 0.7829\n",
      "Epoch 142/200\n",
      "172/172 [==============================] - 0s 857us/sample - loss: 0.5820 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 143/200\n",
      "172/172 [==============================] - 0s 838us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 144/200\n",
      "172/172 [==============================] - 0s 838us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 145/200\n",
      "172/172 [==============================] - 0s 837us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 146/200\n",
      "172/172 [==============================] - 0s 838us/sample - loss: 0.5842 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 147/200\n",
      "172/172 [==============================] - 0s 837us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5768 - val_accuracy: 0.7829\n",
      "Epoch 148/200\n",
      "172/172 [==============================] - 0s 829us/sample - loss: 0.5866 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 149/200\n",
      "172/172 [==============================] - 0s 839us/sample - loss: 0.5824 - accuracy: 0.7791 - val_loss: 0.5778 - val_accuracy: 0.7829\n",
      "Epoch 150/200\n",
      "172/172 [==============================] - 0s 840us/sample - loss: 0.5838 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 151/200\n",
      "172/172 [==============================] - 0s 832us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 152/200\n",
      "172/172 [==============================] - 0s 839us/sample - loss: 0.5844 - accuracy: 0.7791 - val_loss: 0.5752 - val_accuracy: 0.7829\n",
      "Epoch 153/200\n",
      "172/172 [==============================] - 0s 947us/sample - loss: 0.5816 - accuracy: 0.7791 - val_loss: 0.5775 - val_accuracy: 0.7829\n",
      "Epoch 154/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 155/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 0.5826 - accuracy: 0.7791 - val_loss: 0.5769 - val_accuracy: 0.7829\n",
      "Epoch 156/200\n",
      "172/172 [==============================] - 0s 838us/sample - loss: 0.5828 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 157/200\n",
      "172/172 [==============================] - 0s 836us/sample - loss: 0.5838 - accuracy: 0.7791 - val_loss: 0.5751 - val_accuracy: 0.7829\n",
      "Epoch 158/200\n",
      "172/172 [==============================] - 0s 835us/sample - loss: 0.5817 - accuracy: 0.7791 - val_loss: 0.5779 - val_accuracy: 0.7829\n",
      "Epoch 159/200\n",
      "172/172 [==============================] - 0s 840us/sample - loss: 0.5870 - accuracy: 0.7791 - val_loss: 0.5794 - val_accuracy: 0.7829\n",
      "Epoch 160/200\n",
      "172/172 [==============================] - 0s 840us/sample - loss: 0.5842 - accuracy: 0.7791 - val_loss: 0.5753 - val_accuracy: 0.7829\n",
      "Epoch 161/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 834us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5768 - val_accuracy: 0.7829\n",
      "Epoch 162/200\n",
      "172/172 [==============================] - 0s 831us/sample - loss: 0.5830 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 163/200\n",
      "172/172 [==============================] - 0s 835us/sample - loss: 0.5834 - accuracy: 0.7791 - val_loss: 0.5768 - val_accuracy: 0.7829\n",
      "Epoch 164/200\n",
      "172/172 [==============================] - 0s 830us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5777 - val_accuracy: 0.7829\n",
      "Epoch 165/200\n",
      "172/172 [==============================] - 0s 835us/sample - loss: 0.5834 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 166/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.5849 - accuracy: 0.7791 - val_loss: 0.5775 - val_accuracy: 0.7829\n",
      "Epoch 167/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.5843 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.7829\n",
      "Epoch 168/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 0.5821 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 169/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 170/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5750 - val_accuracy: 0.7829\n",
      "Epoch 171/200\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5751 - val_accuracy: 0.7829\n",
      "Epoch 172/200\n",
      "172/172 [==============================] - 0s 859us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 173/200\n",
      "172/172 [==============================] - 0s 861us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 174/200\n",
      "172/172 [==============================] - 0s 857us/sample - loss: 0.5832 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 175/200\n",
      "172/172 [==============================] - 0s 861us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5774 - val_accuracy: 0.7829\n",
      "Epoch 176/200\n",
      "172/172 [==============================] - 0s 859us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 177/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 178/200\n",
      "172/172 [==============================] - 0s 858us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 179/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 180/200\n",
      "172/172 [==============================] - 0s 953us/sample - loss: 0.5836 - accuracy: 0.7791 - val_loss: 0.5750 - val_accuracy: 0.7829\n",
      "Epoch 181/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.5819 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 182/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.5831 - accuracy: 0.7791 - val_loss: 0.5761 - val_accuracy: 0.7829\n",
      "Epoch 183/200\n",
      "172/172 [==============================] - 0s 865us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 184/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5764 - val_accuracy: 0.7829\n",
      "Epoch 185/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5757 - val_accuracy: 0.7829\n",
      "Epoch 186/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Epoch 187/200\n",
      "172/172 [==============================] - 0s 882us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5752 - val_accuracy: 0.7829\n",
      "Epoch 188/200\n",
      "172/172 [==============================] - 0s 882us/sample - loss: 0.5840 - accuracy: 0.7791 - val_loss: 0.5752 - val_accuracy: 0.7829\n",
      "Epoch 189/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 0.5836 - accuracy: 0.7791 - val_loss: 0.5782 - val_accuracy: 0.7829\n",
      "Epoch 190/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 0.5822 - accuracy: 0.7791 - val_loss: 0.5756 - val_accuracy: 0.7829\n",
      "Epoch 191/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 0.5833 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 192/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5765 - val_accuracy: 0.7829\n",
      "Epoch 193/200\n",
      "172/172 [==============================] - 0s 989us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5772 - val_accuracy: 0.7829\n",
      "Epoch 194/200\n",
      "172/172 [==============================] - 0s 960us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5762 - val_accuracy: 0.7829\n",
      "Epoch 195/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.5823 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.7829\n",
      "Epoch 196/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.5829 - accuracy: 0.7791 - val_loss: 0.5752 - val_accuracy: 0.7829\n",
      "Epoch 197/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.5825 - accuracy: 0.7791 - val_loss: 0.5760 - val_accuracy: 0.7829\n",
      "Epoch 198/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.5827 - accuracy: 0.7791 - val_loss: 0.5763 - val_accuracy: 0.7829\n",
      "Epoch 199/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 0.5834 - accuracy: 0.7791 - val_loss: 0.5754 - val_accuracy: 0.7829\n",
      "Epoch 200/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.5835 - accuracy: 0.7791 - val_loss: 0.5758 - val_accuracy: 0.7829\n",
      "Beginning training for dr=0.100, l_lambda=1.0e-01, reg_type=l2, act: relu\n",
      "Train on 172 samples, validate on 43 samples\n",
      "Epoch 1/200\n",
      "172/172 [==============================] - 1s 8ms/sample - loss: 3.2752 - accuracy: 0.6667 - val_loss: 2.2312 - val_accuracy: 0.6667\n",
      "Epoch 2/200\n",
      "172/172 [==============================] - 0s 860us/sample - loss: 1.8741 - accuracy: 0.6667 - val_loss: 1.5694 - val_accuracy: 0.6667\n",
      "Epoch 3/200\n",
      "172/172 [==============================] - 0s 857us/sample - loss: 1.4062 - accuracy: 0.6667 - val_loss: 1.2247 - val_accuracy: 0.7829\n",
      "Epoch 4/200\n",
      "172/172 [==============================] - 0s 856us/sample - loss: 1.1080 - accuracy: 0.7791 - val_loss: 0.9788 - val_accuracy: 0.7829\n",
      "Epoch 5/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.9046 - accuracy: 0.7791 - val_loss: 0.8180 - val_accuracy: 0.7829\n",
      "Epoch 6/200\n",
      "172/172 [==============================] - 0s 859us/sample - loss: 0.7726 - accuracy: 0.7791 - val_loss: 0.7106 - val_accuracy: 0.7829\n",
      "Epoch 7/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 0.6826 - accuracy: 0.7791 - val_loss: 0.6385 - val_accuracy: 0.7829\n",
      "Epoch 8/200\n",
      "172/172 [==============================] - 0s 857us/sample - loss: 0.6212 - accuracy: 0.7791 - val_loss: 0.5893 - val_accuracy: 0.7829\n",
      "Epoch 9/200\n",
      "172/172 [==============================] - 0s 975us/sample - loss: 0.5820 - accuracy: 0.7791 - val_loss: 0.5571 - val_accuracy: 0.7829\n",
      "Epoch 10/200\n",
      "172/172 [==============================] - 0s 949us/sample - loss: 0.5529 - accuracy: 0.7791 - val_loss: 0.5358 - val_accuracy: 0.7829\n",
      "Epoch 11/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 0.5360 - accuracy: 0.7791 - val_loss: 0.5224 - val_accuracy: 0.7829\n",
      "Epoch 12/200\n",
      "172/172 [==============================] - 0s 865us/sample - loss: 0.5254 - accuracy: 0.7791 - val_loss: 0.5142 - val_accuracy: 0.7829\n",
      "Epoch 13/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.5186 - accuracy: 0.7791 - val_loss: 0.5091 - val_accuracy: 0.7829\n",
      "Epoch 14/200\n",
      "172/172 [==============================] - 0s 857us/sample - loss: 0.5147 - accuracy: 0.7791 - val_loss: 0.5060 - val_accuracy: 0.7829\n",
      "Epoch 15/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 856us/sample - loss: 0.5119 - accuracy: 0.7791 - val_loss: 0.5041 - val_accuracy: 0.7829\n",
      "Epoch 16/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.5108 - accuracy: 0.7791 - val_loss: 0.5031 - val_accuracy: 0.7829\n",
      "Epoch 17/200\n",
      "172/172 [==============================] - 0s 837us/sample - loss: 0.5104 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 18/200\n",
      "172/172 [==============================] - 0s 830us/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 19/200\n",
      "172/172 [==============================] - 0s 825us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 20/200\n",
      "172/172 [==============================] - 0s 838us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 21/200\n",
      "172/172 [==============================] - 0s 837us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 22/200\n",
      "172/172 [==============================] - 0s 972us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 23/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 24/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 25/200\n",
      "172/172 [==============================] - 0s 809us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 26/200\n",
      "172/172 [==============================] - 0s 814us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 27/200\n",
      "172/172 [==============================] - 0s 803us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 28/200\n",
      "172/172 [==============================] - 0s 800us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 29/200\n",
      "172/172 [==============================] - 0s 805us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 30/200\n",
      "172/172 [==============================] - 0s 806us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 31/200\n",
      "172/172 [==============================] - 0s 806us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 32/200\n",
      "172/172 [==============================] - 0s 804us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 33/200\n",
      "172/172 [==============================] - 0s 801us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 34/200\n",
      "172/172 [==============================] - 0s 801us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 35/200\n",
      "172/172 [==============================] - 0s 803us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 36/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 37/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 38/200\n",
      "172/172 [==============================] - 0s 860us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 39/200\n",
      "172/172 [==============================] - 0s 803us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 40/200\n",
      "172/172 [==============================] - 0s 810us/sample - loss: 0.5108 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 41/200\n",
      "172/172 [==============================] - 0s 800us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 42/200\n",
      "172/172 [==============================] - 0s 808us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 43/200\n",
      "172/172 [==============================] - 0s 809us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 44/200\n",
      "172/172 [==============================] - 0s 826us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 45/200\n",
      "172/172 [==============================] - 0s 828us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 46/200\n",
      "172/172 [==============================] - 0s 828us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 47/200\n",
      "172/172 [==============================] - 0s 827us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 48/200\n",
      "172/172 [==============================] - 0s 829us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 49/200\n",
      "172/172 [==============================] - 0s 826us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 50/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5028 - val_accuracy: 0.7829\n",
      "Epoch 51/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 52/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 53/200\n",
      "172/172 [==============================] - 0s 832us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 54/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.5106 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 55/200\n",
      "172/172 [==============================] - 0s 850us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 56/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 57/200\n",
      "172/172 [==============================] - 0s 850us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 58/200\n",
      "172/172 [==============================] - 0s 853us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 59/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 60/200\n",
      "172/172 [==============================] - 0s 849us/sample - loss: 0.5086 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 61/200\n",
      "172/172 [==============================] - 0s 848us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 62/200\n",
      "172/172 [==============================] - 0s 865us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 63/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 64/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 65/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 66/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 67/200\n",
      "172/172 [==============================] - 0s 853us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 68/200\n",
      "172/172 [==============================] - 0s 864us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 69/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 70/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 917us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 71/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 72/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 73/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 74/200\n",
      "172/172 [==============================] - 0s 869us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 75/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 76/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 77/200\n",
      "172/172 [==============================] - 0s 953us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 78/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 79/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 80/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 81/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 82/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 83/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 84/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 85/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 86/200\n",
      "172/172 [==============================] - 0s 964us/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 87/200\n",
      "172/172 [==============================] - 0s 962us/sample - loss: 0.5118 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 88/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 89/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 90/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 91/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 92/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 93/200\n",
      "172/172 [==============================] - 0s 943us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 94/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 95/200\n",
      "172/172 [==============================] - 0s 958us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 96/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 97/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 98/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 99/200\n",
      "172/172 [==============================] - 0s 984us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 100/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 101/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 102/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 103/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 104/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 105/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 106/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 107/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 108/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.5104 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 109/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 110/200\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 111/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 112/200\n",
      "172/172 [==============================] - 0s 997us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 113/200\n",
      "172/172 [==============================] - 0s 994us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 114/200\n",
      "172/172 [==============================] - 0s 949us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 115/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 116/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 117/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.5086 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 118/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 119/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 120/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 121/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 122/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 123/200\n",
      "172/172 [==============================] - 0s 928us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 124/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5104 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 125/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 126/200\n",
      "172/172 [==============================] - 0s 979us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 127/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 128/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 129/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 130/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 131/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 132/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 133/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 134/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5030 - val_accuracy: 0.7829\n",
      "Epoch 135/200\n",
      "172/172 [==============================] - 0s 882us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 136/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.5102 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 137/200\n",
      "172/172 [==============================] - 0s 973us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5026 - val_accuracy: 0.7829\n",
      "Epoch 138/200\n",
      "172/172 [==============================] - 0s 964us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 139/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 140/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 141/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 142/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.5104 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 143/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 144/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 145/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 146/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 147/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 148/200\n",
      "172/172 [==============================] - 0s 858us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 149/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 150/200\n",
      "172/172 [==============================] - 0s 958us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 151/200\n",
      "172/172 [==============================] - 0s 943us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 152/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 153/200\n",
      "172/172 [==============================] - 0s 849us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 154/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 155/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 156/200\n",
      "172/172 [==============================] - 0s 850us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 157/200\n",
      "172/172 [==============================] - 0s 854us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 158/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 159/200\n",
      "172/172 [==============================] - 0s 856us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 160/200\n",
      "172/172 [==============================] - 0s 848us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 161/200\n",
      "172/172 [==============================] - 0s 850us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 162/200\n",
      "172/172 [==============================] - 0s 864us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 163/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 164/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 165/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 166/200\n",
      "172/172 [==============================] - 0s 850us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 167/200\n",
      "172/172 [==============================] - 0s 857us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 168/200\n",
      "172/172 [==============================] - 0s 858us/sample - loss: 0.5104 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 169/200\n",
      "172/172 [==============================] - 0s 827us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 170/200\n",
      "172/172 [==============================] - 0s 832us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 171/200\n",
      "172/172 [==============================] - 0s 840us/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 172/200\n",
      "172/172 [==============================] - 0s 835us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 173/200\n",
      "172/172 [==============================] - 0s 828us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5031 - val_accuracy: 0.7829\n",
      "Epoch 174/200\n",
      "172/172 [==============================] - 0s 838us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 175/200\n",
      "172/172 [==============================] - 0s 838us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5028 - val_accuracy: 0.7829\n",
      "Epoch 176/200\n",
      "172/172 [==============================] - 0s 958us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 177/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5030 - val_accuracy: 0.7829\n",
      "Epoch 178/200\n",
      "172/172 [==============================] - 0s 862us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5030 - val_accuracy: 0.7829\n",
      "Epoch 179/200\n",
      "172/172 [==============================] - 0s 808us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5033 - val_accuracy: 0.7829\n",
      "Epoch 180/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 815us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 181/200\n",
      "172/172 [==============================] - 0s 801us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 182/200\n",
      "172/172 [==============================] - 0s 798us/sample - loss: 0.5086 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 183/200\n",
      "172/172 [==============================] - 0s 803us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 184/200\n",
      "172/172 [==============================] - 0s 799us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 185/200\n",
      "172/172 [==============================] - 0s 802us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 186/200\n",
      "172/172 [==============================] - 0s 801us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 187/200\n",
      "172/172 [==============================] - 0s 804us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 188/200\n",
      "172/172 [==============================] - 0s 808us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 189/200\n",
      "172/172 [==============================] - 0s 805us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 190/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 191/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 192/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 193/200\n",
      "172/172 [==============================] - 0s 804us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5026 - val_accuracy: 0.7829\n",
      "Epoch 194/200\n",
      "172/172 [==============================] - 0s 815us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 195/200\n",
      "172/172 [==============================] - 0s 816us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5028 - val_accuracy: 0.7829\n",
      "Epoch 196/200\n",
      "172/172 [==============================] - 0s 821us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 197/200\n",
      "172/172 [==============================] - 0s 828us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 198/200\n",
      "172/172 [==============================] - 0s 819us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 199/200\n",
      "172/172 [==============================] - 0s 825us/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 200/200\n",
      "172/172 [==============================] - 0s 825us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Beginning training for dr=0.100, l_lambda=1.0e-01, reg_type=l2, act: tanh\n",
      "Train on 172 samples, validate on 43 samples\n",
      "Epoch 1/200\n",
      "172/172 [==============================] - 1s 8ms/sample - loss: 3.1840 - accuracy: 0.6667 - val_loss: 2.1233 - val_accuracy: 0.6667\n",
      "Epoch 2/200\n",
      "172/172 [==============================] - 0s 853us/sample - loss: 1.7639 - accuracy: 0.7054 - val_loss: 1.4560 - val_accuracy: 0.7829\n",
      "Epoch 3/200\n",
      "172/172 [==============================] - 0s 856us/sample - loss: 1.3151 - accuracy: 0.7791 - val_loss: 1.1440 - val_accuracy: 0.7829\n",
      "Epoch 4/200\n",
      "172/172 [==============================] - 0s 850us/sample - loss: 1.0496 - accuracy: 0.7791 - val_loss: 0.9338 - val_accuracy: 0.7829\n",
      "Epoch 5/200\n",
      "172/172 [==============================] - 0s 830us/sample - loss: 0.8728 - accuracy: 0.7791 - val_loss: 0.7897 - val_accuracy: 0.7829\n",
      "Epoch 6/200\n",
      "172/172 [==============================] - 0s 825us/sample - loss: 0.7508 - accuracy: 0.7791 - val_loss: 0.6921 - val_accuracy: 0.7829\n",
      "Epoch 7/200\n",
      "172/172 [==============================] - 0s 831us/sample - loss: 0.6668 - accuracy: 0.7791 - val_loss: 0.6248 - val_accuracy: 0.7829\n",
      "Epoch 8/200\n",
      "172/172 [==============================] - 0s 965us/sample - loss: 0.6138 - accuracy: 0.7791 - val_loss: 0.5803 - val_accuracy: 0.7829\n",
      "Epoch 9/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.5735 - accuracy: 0.7791 - val_loss: 0.5510 - val_accuracy: 0.7829\n",
      "Epoch 10/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.5496 - accuracy: 0.7791 - val_loss: 0.5319 - val_accuracy: 0.7829\n",
      "Epoch 11/200\n",
      "172/172 [==============================] - 0s 807us/sample - loss: 0.5332 - accuracy: 0.7791 - val_loss: 0.5202 - val_accuracy: 0.7829\n",
      "Epoch 12/200\n",
      "172/172 [==============================] - 0s 800us/sample - loss: 0.5269 - accuracy: 0.7791 - val_loss: 0.5136 - val_accuracy: 0.7829\n",
      "Epoch 13/200\n",
      "172/172 [==============================] - 0s 797us/sample - loss: 0.5201 - accuracy: 0.7791 - val_loss: 0.5081 - val_accuracy: 0.7829\n",
      "Epoch 14/200\n",
      "172/172 [==============================] - 0s 801us/sample - loss: 0.5142 - accuracy: 0.7791 - val_loss: 0.5052 - val_accuracy: 0.7829\n",
      "Epoch 15/200\n",
      "172/172 [==============================] - 0s 801us/sample - loss: 0.5117 - accuracy: 0.7791 - val_loss: 0.5040 - val_accuracy: 0.7829\n",
      "Epoch 16/200\n",
      "172/172 [==============================] - 0s 798us/sample - loss: 0.5107 - accuracy: 0.7791 - val_loss: 0.5029 - val_accuracy: 0.7829\n",
      "Epoch 17/200\n",
      "172/172 [==============================] - 0s 801us/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5029 - val_accuracy: 0.7829\n",
      "Epoch 18/200\n",
      "172/172 [==============================] - 0s 809us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 19/200\n",
      "172/172 [==============================] - 0s 800us/sample - loss: 0.5102 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 20/200\n",
      "172/172 [==============================] - 0s 799us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 21/200\n",
      "172/172 [==============================] - 0s 808us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 22/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 23/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 24/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 25/200\n",
      "172/172 [==============================] - 0s 810us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 26/200\n",
      "172/172 [==============================] - 0s 826us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 27/200\n",
      "172/172 [==============================] - 0s 820us/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 28/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 29/200\n",
      "172/172 [==============================] - 0s 824us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 30/200\n",
      "172/172 [==============================] - 0s 824us/sample - loss: 0.5106 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 31/200\n",
      "172/172 [==============================] - 0s 827us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 32/200\n",
      "172/172 [==============================] - 0s 821us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 33/200\n",
      "172/172 [==============================] - 0s 828us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 34/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 833us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 35/200\n",
      "172/172 [==============================] - 0s 819us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 36/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 37/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 38/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5035 - val_accuracy: 0.7829\n",
      "Epoch 39/200\n",
      "172/172 [==============================] - 0s 842us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5028 - val_accuracy: 0.7829\n",
      "Epoch 40/200\n",
      "172/172 [==============================] - 0s 844us/sample - loss: 0.5117 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 41/200\n",
      "172/172 [==============================] - 0s 842us/sample - loss: 0.5083 - accuracy: 0.7791 - val_loss: 0.5028 - val_accuracy: 0.7829\n",
      "Epoch 42/200\n",
      "172/172 [==============================] - 0s 845us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 43/200\n",
      "172/172 [==============================] - 0s 842us/sample - loss: 0.5107 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 44/200\n",
      "172/172 [==============================] - 0s 845us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 45/200\n",
      "172/172 [==============================] - 0s 841us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 46/200\n",
      "172/172 [==============================] - 0s 842us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 47/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.5102 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 48/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 49/200\n",
      "172/172 [==============================] - 0s 952us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5029 - val_accuracy: 0.7829\n",
      "Epoch 50/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.5104 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 51/200\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5029 - val_accuracy: 0.7829\n",
      "Epoch 52/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 53/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.5123 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 54/200\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 55/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 56/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 57/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 58/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 59/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 60/200\n",
      "172/172 [==============================] - 0s 869us/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 61/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 62/200\n",
      "172/172 [==============================] - 0s 982us/sample - loss: 0.5121 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 63/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 64/200\n",
      "172/172 [==============================] - 0s 947us/sample - loss: 0.5107 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 65/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 66/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 67/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 68/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 69/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.5102 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 70/200\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 71/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 72/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 0.5110 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 73/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 74/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 75/200\n",
      "172/172 [==============================] - 0s 963us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 76/200\n",
      "172/172 [==============================] - 0s 949us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5028 - val_accuracy: 0.7829\n",
      "Epoch 77/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 78/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 79/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 80/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 81/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 82/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 83/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5026 - val_accuracy: 0.7829\n",
      "Epoch 84/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 85/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.5111 - accuracy: 0.7791 - val_loss: 0.5033 - val_accuracy: 0.7829\n",
      "Epoch 86/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5034 - val_accuracy: 0.7829\n",
      "Epoch 87/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 88/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 89/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5031 - val_accuracy: 0.7829\n",
      "Epoch 90/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 91/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 92/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 93/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 94/200\n",
      "172/172 [==============================] - 0s 959us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 95/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 96/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 97/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 0.5107 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 98/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 99/200\n",
      "172/172 [==============================] - 0s 951us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 100/200\n",
      "172/172 [==============================] - 0s 998us/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 101/200\n",
      "172/172 [==============================] - 0s 989us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 102/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 103/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.5086 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 104/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 0.5111 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 105/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 106/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 107/200\n",
      "172/172 [==============================] - 0s 865us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 108/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 109/200\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 110/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5014 - val_accuracy: 0.7829\n",
      "Epoch 111/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 112/200\n",
      "172/172 [==============================] - 0s 966us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 113/200\n",
      "172/172 [==============================] - 0s 940us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5028 - val_accuracy: 0.7829\n",
      "Epoch 114/200\n",
      "172/172 [==============================] - 0s 940us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 115/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 116/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 117/200\n",
      "172/172 [==============================] - 0s 856us/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 118/200\n",
      "172/172 [==============================] - 0s 844us/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 119/200\n",
      "172/172 [==============================] - 0s 842us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 120/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 121/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 122/200\n",
      "172/172 [==============================] - 0s 849us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 123/200\n",
      "172/172 [==============================] - 0s 843us/sample - loss: 0.5119 - accuracy: 0.7791 - val_loss: 0.5040 - val_accuracy: 0.7829\n",
      "Epoch 124/200\n",
      "172/172 [==============================] - 0s 845us/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5026 - val_accuracy: 0.7829\n",
      "Epoch 125/200\n",
      "172/172 [==============================] - 0s 857us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5028 - val_accuracy: 0.7829\n",
      "Epoch 126/200\n",
      "172/172 [==============================] - 0s 956us/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 127/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 128/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 129/200\n",
      "172/172 [==============================] - 0s 848us/sample - loss: 0.5101 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 130/200\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 131/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 132/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 0.5104 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 133/200\n",
      "172/172 [==============================] - 0s 850us/sample - loss: 0.5107 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 134/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 135/200\n",
      "172/172 [==============================] - 0s 848us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 136/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 137/200\n",
      "172/172 [==============================] - 0s 841us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 138/200\n",
      "172/172 [==============================] - 0s 823us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 139/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 140/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.5109 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 141/200\n",
      "172/172 [==============================] - 0s 832us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 142/200\n",
      "172/172 [==============================] - 0s 807us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 143/200\n",
      "172/172 [==============================] - 0s 799us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 144/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 809us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 145/200\n",
      "172/172 [==============================] - 0s 797us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 146/200\n",
      "172/172 [==============================] - 0s 797us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 147/200\n",
      "172/172 [==============================] - 0s 795us/sample - loss: 0.5105 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 148/200\n",
      "172/172 [==============================] - 0s 791us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 149/200\n",
      "172/172 [==============================] - 0s 806us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 150/200\n",
      "172/172 [==============================] - 0s 810us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 151/200\n",
      "172/172 [==============================] - 0s 803us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 152/200\n",
      "172/172 [==============================] - 0s 797us/sample - loss: 0.5135 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 153/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5040 - val_accuracy: 0.7829\n",
      "Epoch 154/200\n",
      "172/172 [==============================] - 0s 882us/sample - loss: 0.5102 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 155/200\n",
      "172/172 [==============================] - 0s 859us/sample - loss: 0.5085 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 156/200\n",
      "172/172 [==============================] - 0s 801us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 157/200\n",
      "172/172 [==============================] - 0s 798us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 158/200\n",
      "172/172 [==============================] - 0s 796us/sample - loss: 0.5124 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 159/200\n",
      "172/172 [==============================] - 0s 812us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 160/200\n",
      "172/172 [==============================] - 0s 794us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 161/200\n",
      "172/172 [==============================] - 0s 801us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7829\n",
      "Epoch 162/200\n",
      "172/172 [==============================] - 0s 825us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 163/200\n",
      "172/172 [==============================] - 0s 819us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 164/200\n",
      "172/172 [==============================] - 0s 817us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 165/200\n",
      "172/172 [==============================] - 0s 823us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 166/200\n",
      "172/172 [==============================] - 0s 816us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 167/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 168/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 169/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5030 - val_accuracy: 0.7829\n",
      "Epoch 170/200\n",
      "172/172 [==============================] - 0s 820us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5030 - val_accuracy: 0.7829\n",
      "Epoch 171/200\n",
      "172/172 [==============================] - 0s 824us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 172/200\n",
      "172/172 [==============================] - 0s 840us/sample - loss: 0.5109 - accuracy: 0.7791 - val_loss: 0.5034 - val_accuracy: 0.7829\n",
      "Epoch 173/200\n",
      "172/172 [==============================] - 0s 844us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 174/200\n",
      "172/172 [==============================] - 0s 845us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 175/200\n",
      "172/172 [==============================] - 0s 838us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 176/200\n",
      "172/172 [==============================] - 0s 840us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 177/200\n",
      "172/172 [==============================] - 0s 840us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 178/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.5104 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 179/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7829\n",
      "Epoch 180/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 181/200\n",
      "172/172 [==============================] - 0s 930us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 182/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 0.5104 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 183/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 184/200\n",
      "172/172 [==============================] - 0s 844us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 185/200\n",
      "172/172 [==============================] - 0s 861us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 186/200\n",
      "172/172 [==============================] - 0s 861us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 187/200\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 188/200\n",
      "172/172 [==============================] - 0s 869us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 189/200\n",
      "172/172 [==============================] - 0s 869us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 190/200\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 191/200\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 192/200\n",
      "172/172 [==============================] - 0s 864us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 193/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 194/200\n",
      "172/172 [==============================] - 0s 948us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 195/200\n",
      "172/172 [==============================] - 0s 942us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 196/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.5091 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 197/200\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 0.5093 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7829\n",
      "Epoch 198/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5034 - val_accuracy: 0.7829\n",
      "Epoch 199/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 876us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 200/200\n",
      "172/172 [==============================] - 0s 869us/sample - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Beginning training for dr=0.100, l_lambda=1.0e-01, reg_type=l1, act: relu\n",
      "Train on 172 samples, validate on 43 samples\n",
      "Epoch 1/200\n",
      "172/172 [==============================] - 2s 10ms/sample - loss: 71.2993 - accuracy: 0.6667 - val_loss: 35.8559 - val_accuracy: 0.6667\n",
      "Epoch 2/200\n",
      "172/172 [==============================] - 0s 856us/sample - loss: 23.2877 - accuracy: 0.6667 - val_loss: 16.5967 - val_accuracy: 0.6667\n",
      "Epoch 3/200\n",
      "172/172 [==============================] - 0s 853us/sample - loss: 13.0367 - accuracy: 0.6996 - val_loss: 10.0293 - val_accuracy: 0.7829\n",
      "Epoch 4/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 8.5194 - accuracy: 0.7791 - val_loss: 6.9948 - val_accuracy: 0.7829\n",
      "Epoch 5/200\n",
      "172/172 [==============================] - 0s 849us/sample - loss: 6.0507 - accuracy: 0.7791 - val_loss: 5.0113 - val_accuracy: 0.7829\n",
      "Epoch 6/200\n",
      "172/172 [==============================] - 0s 849us/sample - loss: 4.2793 - accuracy: 0.7791 - val_loss: 3.4666 - val_accuracy: 0.7829\n",
      "Epoch 7/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 2.9392 - accuracy: 0.7791 - val_loss: 2.3833 - val_accuracy: 0.7829\n",
      "Epoch 8/200\n",
      "172/172 [==============================] - 0s 987us/sample - loss: 2.0151 - accuracy: 0.7791 - val_loss: 1.6523 - val_accuracy: 0.7829\n",
      "Epoch 9/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 1.4731 - accuracy: 0.7791 - val_loss: 1.3214 - val_accuracy: 0.7829\n",
      "Epoch 10/200\n",
      "172/172 [==============================] - 0s 854us/sample - loss: 1.2929 - accuracy: 0.7791 - val_loss: 1.2608 - val_accuracy: 0.7829\n",
      "Epoch 11/200\n",
      "172/172 [==============================] - 0s 825us/sample - loss: 1.2603 - accuracy: 0.7791 - val_loss: 1.2488 - val_accuracy: 0.7829\n",
      "Epoch 12/200\n",
      "172/172 [==============================] - 0s 821us/sample - loss: 1.2517 - accuracy: 0.7791 - val_loss: 1.2403 - val_accuracy: 0.7829\n",
      "Epoch 13/200\n",
      "172/172 [==============================] - 0s 820us/sample - loss: 1.2440 - accuracy: 0.7791 - val_loss: 1.2550 - val_accuracy: 0.7829\n",
      "Epoch 14/200\n",
      "172/172 [==============================] - 0s 819us/sample - loss: 1.2461 - accuracy: 0.7791 - val_loss: 1.2481 - val_accuracy: 0.7829\n",
      "Epoch 15/200\n",
      "172/172 [==============================] - 0s 822us/sample - loss: 1.2473 - accuracy: 0.7791 - val_loss: 1.2572 - val_accuracy: 0.7829\n",
      "Epoch 16/200\n",
      "172/172 [==============================] - 0s 826us/sample - loss: 1.2463 - accuracy: 0.7791 - val_loss: 1.2428 - val_accuracy: 0.7829\n",
      "Epoch 17/200\n",
      "172/172 [==============================] - 0s 819us/sample - loss: 1.2474 - accuracy: 0.7791 - val_loss: 1.2456 - val_accuracy: 0.7829\n",
      "Epoch 18/200\n",
      "172/172 [==============================] - 0s 818us/sample - loss: 1.2445 - accuracy: 0.7791 - val_loss: 1.2513 - val_accuracy: 0.7829\n",
      "Epoch 19/200\n",
      "172/172 [==============================] - 0s 819us/sample - loss: 1.2481 - accuracy: 0.7791 - val_loss: 1.2429 - val_accuracy: 0.7829\n",
      "Epoch 20/200\n",
      "172/172 [==============================] - 0s 816us/sample - loss: 1.2468 - accuracy: 0.7791 - val_loss: 1.2353 - val_accuracy: 0.7829\n",
      "Epoch 21/200\n",
      "172/172 [==============================] - 0s 834us/sample - loss: 1.2453 - accuracy: 0.7791 - val_loss: 1.2514 - val_accuracy: 0.7829\n",
      "Epoch 22/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 1.2469 - accuracy: 0.7791 - val_loss: 1.2425 - val_accuracy: 0.7829\n",
      "Epoch 23/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 1.2454 - accuracy: 0.7791 - val_loss: 1.2577 - val_accuracy: 0.7829\n",
      "Epoch 24/200\n",
      "172/172 [==============================] - 0s 848us/sample - loss: 1.2467 - accuracy: 0.7791 - val_loss: 1.2422 - val_accuracy: 0.7829\n",
      "Epoch 25/200\n",
      "172/172 [==============================] - 0s 822us/sample - loss: 1.2432 - accuracy: 0.7791 - val_loss: 1.2534 - val_accuracy: 0.7829\n",
      "Epoch 26/200\n",
      "172/172 [==============================] - 0s 823us/sample - loss: 1.2486 - accuracy: 0.7791 - val_loss: 1.2410 - val_accuracy: 0.7829\n",
      "Epoch 27/200\n",
      "172/172 [==============================] - 0s 821us/sample - loss: 1.2440 - accuracy: 0.7791 - val_loss: 1.2494 - val_accuracy: 0.7829\n",
      "Epoch 28/200\n",
      "172/172 [==============================] - 0s 825us/sample - loss: 1.2473 - accuracy: 0.7791 - val_loss: 1.2467 - val_accuracy: 0.7829\n",
      "Epoch 29/200\n",
      "172/172 [==============================] - 0s 823us/sample - loss: 1.2459 - accuracy: 0.7791 - val_loss: 1.2509 - val_accuracy: 0.7829\n",
      "Epoch 30/200\n",
      "172/172 [==============================] - 0s 835us/sample - loss: 1.2443 - accuracy: 0.7791 - val_loss: 1.2444 - val_accuracy: 0.7829\n",
      "Epoch 31/200\n",
      "172/172 [==============================] - 0s 826us/sample - loss: 1.2511 - accuracy: 0.7791 - val_loss: 1.2418 - val_accuracy: 0.7829\n",
      "Epoch 32/200\n",
      "172/172 [==============================] - 0s 818us/sample - loss: 1.2463 - accuracy: 0.7791 - val_loss: 1.2403 - val_accuracy: 0.7829\n",
      "Epoch 33/200\n",
      "172/172 [==============================] - 0s 828us/sample - loss: 1.2439 - accuracy: 0.7791 - val_loss: 1.2497 - val_accuracy: 0.7829\n",
      "Epoch 34/200\n",
      "172/172 [==============================] - 0s 832us/sample - loss: 1.2478 - accuracy: 0.7791 - val_loss: 1.2430 - val_accuracy: 0.7829\n",
      "Epoch 35/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 1.2419 - accuracy: 0.7791 - val_loss: 1.2620 - val_accuracy: 0.7829\n",
      "Epoch 36/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 1.2505 - accuracy: 0.7791 - val_loss: 1.2416 - val_accuracy: 0.7829\n",
      "Epoch 37/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 1.2455 - accuracy: 0.7791 - val_loss: 1.2530 - val_accuracy: 0.7829\n",
      "Epoch 38/200\n",
      "172/172 [==============================] - 0s 850us/sample - loss: 1.2480 - accuracy: 0.7791 - val_loss: 1.2432 - val_accuracy: 0.7829\n",
      "Epoch 39/200\n",
      "172/172 [==============================] - 0s 843us/sample - loss: 1.2451 - accuracy: 0.7791 - val_loss: 1.2509 - val_accuracy: 0.7829\n",
      "Epoch 40/200\n",
      "172/172 [==============================] - 0s 845us/sample - loss: 1.2484 - accuracy: 0.7791 - val_loss: 1.2393 - val_accuracy: 0.7829\n",
      "Epoch 41/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 1.2445 - accuracy: 0.7791 - val_loss: 1.2418 - val_accuracy: 0.7829\n",
      "Epoch 42/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 1.2468 - accuracy: 0.7791 - val_loss: 1.2436 - val_accuracy: 0.7829\n",
      "Epoch 43/200\n",
      "172/172 [==============================] - 0s 843us/sample - loss: 1.2478 - accuracy: 0.7791 - val_loss: 1.2565 - val_accuracy: 0.7829\n",
      "Epoch 44/200\n",
      "172/172 [==============================] - 0s 845us/sample - loss: 1.2462 - accuracy: 0.7791 - val_loss: 1.2466 - val_accuracy: 0.7829\n",
      "Epoch 45/200\n",
      "172/172 [==============================] - 0s 843us/sample - loss: 1.2463 - accuracy: 0.7791 - val_loss: 1.2473 - val_accuracy: 0.7829\n",
      "Epoch 46/200\n",
      "172/172 [==============================] - 0s 842us/sample - loss: 1.2439 - accuracy: 0.7791 - val_loss: 1.2466 - val_accuracy: 0.7829\n",
      "Epoch 47/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 1.2479 - accuracy: 0.7791 - val_loss: 1.2454 - val_accuracy: 0.7829\n",
      "Epoch 48/200\n",
      "172/172 [==============================] - 0s 864us/sample - loss: 1.2458 - accuracy: 0.7791 - val_loss: 1.2405 - val_accuracy: 0.7829\n",
      "Epoch 49/200\n",
      "172/172 [==============================] - 0s 968us/sample - loss: 1.2441 - accuracy: 0.7791 - val_loss: 1.2556 - val_accuracy: 0.7829\n",
      "Epoch 50/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 1.2455 - accuracy: 0.7791 - val_loss: 1.2429 - val_accuracy: 0.7829\n",
      "Epoch 51/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 1.2486 - accuracy: 0.7791 - val_loss: 1.2491 - val_accuracy: 0.7829\n",
      "Epoch 52/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 1.2478 - accuracy: 0.7791 - val_loss: 1.2390 - val_accuracy: 0.7829\n",
      "Epoch 53/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 1.2414 - accuracy: 0.7791 - val_loss: 1.2527 - val_accuracy: 0.7829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 1.2505 - accuracy: 0.7791 - val_loss: 1.2409 - val_accuracy: 0.7829\n",
      "Epoch 55/200\n",
      "172/172 [==============================] - 0s 865us/sample - loss: 1.2417 - accuracy: 0.7791 - val_loss: 1.2516 - val_accuracy: 0.7829\n",
      "Epoch 56/200\n",
      "172/172 [==============================] - 0s 865us/sample - loss: 1.2477 - accuracy: 0.7791 - val_loss: 1.2477 - val_accuracy: 0.7829\n",
      "Epoch 57/200\n",
      "172/172 [==============================] - 0s 869us/sample - loss: 1.2493 - accuracy: 0.7791 - val_loss: 1.2546 - val_accuracy: 0.7829\n",
      "Epoch 58/200\n",
      "172/172 [==============================] - 0s 862us/sample - loss: 1.2408 - accuracy: 0.7791 - val_loss: 1.2499 - val_accuracy: 0.7829\n",
      "Epoch 59/200\n",
      "172/172 [==============================] - 0s 865us/sample - loss: 1.2504 - accuracy: 0.7791 - val_loss: 1.2472 - val_accuracy: 0.7829\n",
      "Epoch 60/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 1.2447 - accuracy: 0.7791 - val_loss: 1.2417 - val_accuracy: 0.7829\n",
      "Epoch 61/200\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 1.2492 - accuracy: 0.7791 - val_loss: 1.2432 - val_accuracy: 0.7829\n",
      "Epoch 62/200\n",
      "172/172 [==============================] - 0s 981us/sample - loss: 1.2458 - accuracy: 0.7791 - val_loss: 1.2378 - val_accuracy: 0.7829\n",
      "Epoch 63/200\n",
      "172/172 [==============================] - 0s 971us/sample - loss: 1.2464 - accuracy: 0.7791 - val_loss: 1.2646 - val_accuracy: 0.7829\n",
      "Epoch 64/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 1.2495 - accuracy: 0.7791 - val_loss: 1.2418 - val_accuracy: 0.7829\n",
      "Epoch 65/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 1.2419 - accuracy: 0.7791 - val_loss: 1.2565 - val_accuracy: 0.7829\n",
      "Epoch 66/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 1.2496 - accuracy: 0.7791 - val_loss: 1.2395 - val_accuracy: 0.7829\n",
      "Epoch 67/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 1.2437 - accuracy: 0.7791 - val_loss: 1.2497 - val_accuracy: 0.7829\n",
      "Epoch 68/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 1.2482 - accuracy: 0.7791 - val_loss: 1.2420 - val_accuracy: 0.7829\n",
      "Epoch 69/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 1.2439 - accuracy: 0.7791 - val_loss: 1.2453 - val_accuracy: 0.7829\n",
      "Epoch 70/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 1.2442 - accuracy: 0.7791 - val_loss: 1.2468 - val_accuracy: 0.7829\n",
      "Epoch 71/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 1.2500 - accuracy: 0.7791 - val_loss: 1.2472 - val_accuracy: 0.7829\n",
      "Epoch 72/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 1.2444 - accuracy: 0.7791 - val_loss: 1.2409 - val_accuracy: 0.7829\n",
      "Epoch 73/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 1.2454 - accuracy: 0.7791 - val_loss: 1.2520 - val_accuracy: 0.7829\n",
      "Epoch 74/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 1.2464 - accuracy: 0.7791 - val_loss: 1.2467 - val_accuracy: 0.7829\n",
      "Epoch 75/200\n",
      "172/172 [==============================] - 0s 968us/sample - loss: 1.2438 - accuracy: 0.7791 - val_loss: 1.2462 - val_accuracy: 0.7829\n",
      "Epoch 76/200\n",
      "172/172 [==============================] - 0s 963us/sample - loss: 1.2488 - accuracy: 0.7791 - val_loss: 1.2366 - val_accuracy: 0.7829\n",
      "Epoch 77/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 1.2431 - accuracy: 0.7791 - val_loss: 1.2570 - val_accuracy: 0.7829\n",
      "Epoch 78/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 1.2466 - accuracy: 0.7791 - val_loss: 1.2485 - val_accuracy: 0.7829\n",
      "Epoch 79/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 1.2456 - accuracy: 0.7791 - val_loss: 1.2517 - val_accuracy: 0.7829\n",
      "Epoch 80/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 1.2469 - accuracy: 0.7791 - val_loss: 1.2370 - val_accuracy: 0.7829\n",
      "Epoch 81/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 1.2457 - accuracy: 0.7791 - val_loss: 1.2423 - val_accuracy: 0.7829\n",
      "Epoch 82/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 1.2470 - accuracy: 0.7791 - val_loss: 1.2405 - val_accuracy: 0.7829\n",
      "Epoch 83/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 1.2445 - accuracy: 0.7791 - val_loss: 1.2549 - val_accuracy: 0.7829\n",
      "Epoch 84/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 1.2468 - accuracy: 0.7791 - val_loss: 1.2453 - val_accuracy: 0.7829\n",
      "Epoch 85/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 1.2442 - accuracy: 0.7791 - val_loss: 1.2551 - val_accuracy: 0.7829\n",
      "Epoch 86/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 1.2466 - accuracy: 0.7791 - val_loss: 1.2464 - val_accuracy: 0.7829\n",
      "Epoch 87/200\n",
      "172/172 [==============================] - 0s 974us/sample - loss: 1.2473 - accuracy: 0.7791 - val_loss: 1.2449 - val_accuracy: 0.7829\n",
      "Epoch 88/200\n",
      "172/172 [==============================] - 0s 971us/sample - loss: 1.2444 - accuracy: 0.7791 - val_loss: 1.2504 - val_accuracy: 0.7829\n",
      "Epoch 89/200\n",
      "172/172 [==============================] - 0s 974us/sample - loss: 1.2485 - accuracy: 0.7791 - val_loss: 1.2430 - val_accuracy: 0.7829\n",
      "Epoch 90/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 1.2423 - accuracy: 0.7791 - val_loss: 1.2388 - val_accuracy: 0.7829\n",
      "Epoch 91/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 1.2476 - accuracy: 0.7791 - val_loss: 1.2561 - val_accuracy: 0.7829\n",
      "Epoch 92/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 1.2477 - accuracy: 0.7791 - val_loss: 1.2421 - val_accuracy: 0.7829\n",
      "Epoch 93/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 1.2437 - accuracy: 0.7791 - val_loss: 1.2546 - val_accuracy: 0.7829\n",
      "Epoch 94/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 1.2458 - accuracy: 0.7791 - val_loss: 1.2395 - val_accuracy: 0.7829\n",
      "Epoch 95/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 1.2441 - accuracy: 0.7791 - val_loss: 1.2562 - val_accuracy: 0.7829\n",
      "Epoch 96/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 1.2505 - accuracy: 0.7791 - val_loss: 1.2365 - val_accuracy: 0.7829\n",
      "Epoch 97/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 1.2407 - accuracy: 0.7791 - val_loss: 1.2465 - val_accuracy: 0.7829\n",
      "Epoch 98/200\n",
      "172/172 [==============================] - 0s 957us/sample - loss: 1.2464 - accuracy: 0.7791 - val_loss: 1.2506 - val_accuracy: 0.7829\n",
      "Epoch 99/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 1.2476 - accuracy: 0.7791 - val_loss: 1.2482 - val_accuracy: 0.7829\n",
      "Epoch 100/200\n",
      "172/172 [==============================] - 0s 992us/sample - loss: 1.2432 - accuracy: 0.7791 - val_loss: 1.2444 - val_accuracy: 0.7829\n",
      "Epoch 101/200\n",
      "172/172 [==============================] - 0s 969us/sample - loss: 1.2485 - accuracy: 0.7791 - val_loss: 1.2390 - val_accuracy: 0.7829\n",
      "Epoch 102/200\n",
      "172/172 [==============================] - 0s 942us/sample - loss: 1.2432 - accuracy: 0.7791 - val_loss: 1.2440 - val_accuracy: 0.7829\n",
      "Epoch 103/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 1.2465 - accuracy: 0.7791 - val_loss: 1.2521 - val_accuracy: 0.7829\n",
      "Epoch 104/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 1.2460 - accuracy: 0.7791 - val_loss: 1.2377 - val_accuracy: 0.7829\n",
      "Epoch 105/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 1.2420 - accuracy: 0.7791 - val_loss: 1.2652 - val_accuracy: 0.7829\n",
      "Epoch 106/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 1.2485 - accuracy: 0.7791 - val_loss: 1.2416 - val_accuracy: 0.7829\n",
      "Epoch 107/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 1.2437 - accuracy: 0.7791 - val_loss: 1.2507 - val_accuracy: 0.7829\n",
      "Epoch 108/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 1.2483 - accuracy: 0.7791 - val_loss: 1.2422 - val_accuracy: 0.7829\n",
      "Epoch 109/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 896us/sample - loss: 1.2440 - accuracy: 0.7791 - val_loss: 1.2474 - val_accuracy: 0.7829\n",
      "Epoch 110/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 1.2463 - accuracy: 0.7791 - val_loss: 1.2376 - val_accuracy: 0.7829\n",
      "Epoch 111/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 1.2453 - accuracy: 0.7791 - val_loss: 1.2445 - val_accuracy: 0.7829\n",
      "Epoch 112/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 1.2472 - accuracy: 0.7791 - val_loss: 1.2425 - val_accuracy: 0.7829\n",
      "Epoch 113/200\n",
      "172/172 [==============================] - 0s 970us/sample - loss: 1.2448 - accuracy: 0.7791 - val_loss: 1.2538 - val_accuracy: 0.7829\n",
      "Epoch 114/200\n",
      "172/172 [==============================] - 0s 975us/sample - loss: 1.2432 - accuracy: 0.7791 - val_loss: 1.2490 - val_accuracy: 0.7829\n",
      "Epoch 115/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 1.2480 - accuracy: 0.7791 - val_loss: 1.2502 - val_accuracy: 0.7829\n",
      "Epoch 116/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 1.2457 - accuracy: 0.7791 - val_loss: 1.2421 - val_accuracy: 0.7829\n",
      "Epoch 117/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 1.2436 - accuracy: 0.7791 - val_loss: 1.2472 - val_accuracy: 0.7829\n",
      "Epoch 118/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 1.2468 - accuracy: 0.7791 - val_loss: 1.2437 - val_accuracy: 0.7829\n",
      "Epoch 119/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 1.2442 - accuracy: 0.7791 - val_loss: 1.2541 - val_accuracy: 0.7829\n",
      "Epoch 120/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 1.2485 - accuracy: 0.7791 - val_loss: 1.2397 - val_accuracy: 0.7829\n",
      "Epoch 121/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 1.2463 - accuracy: 0.7791 - val_loss: 1.2458 - val_accuracy: 0.7829\n",
      "Epoch 122/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 1.2453 - accuracy: 0.7791 - val_loss: 1.2404 - val_accuracy: 0.7829\n",
      "Epoch 123/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 1.2446 - accuracy: 0.7791 - val_loss: 1.2489 - val_accuracy: 0.7829\n",
      "Epoch 124/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 1.2481 - accuracy: 0.7791 - val_loss: 1.2427 - val_accuracy: 0.7829\n",
      "Epoch 125/200\n",
      "172/172 [==============================] - 0s 969us/sample - loss: 1.2417 - accuracy: 0.7791 - val_loss: 1.2531 - val_accuracy: 0.7829\n",
      "Epoch 126/200\n",
      "172/172 [==============================] - 0s 958us/sample - loss: 1.2473 - accuracy: 0.7791 - val_loss: 1.2449 - val_accuracy: 0.7829\n",
      "Epoch 127/200\n",
      "172/172 [==============================] - 0s 971us/sample - loss: 1.2472 - accuracy: 0.7791 - val_loss: 1.2545 - val_accuracy: 0.7829\n",
      "Epoch 128/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 1.2440 - accuracy: 0.7791 - val_loss: 1.2482 - val_accuracy: 0.7829\n",
      "Epoch 129/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 1.2470 - accuracy: 0.7791 - val_loss: 1.2434 - val_accuracy: 0.7829\n",
      "Epoch 130/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 1.2428 - accuracy: 0.7791 - val_loss: 1.2449 - val_accuracy: 0.7829\n",
      "Epoch 131/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 1.2483 - accuracy: 0.7791 - val_loss: 1.2406 - val_accuracy: 0.7829\n",
      "Epoch 132/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 1.2464 - accuracy: 0.7791 - val_loss: 1.2370 - val_accuracy: 0.7829\n",
      "Epoch 133/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 1.2424 - accuracy: 0.7791 - val_loss: 1.2610 - val_accuracy: 0.7829\n",
      "Epoch 134/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 1.2479 - accuracy: 0.7791 - val_loss: 1.2451 - val_accuracy: 0.7829\n",
      "Epoch 135/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 1.2449 - accuracy: 0.7791 - val_loss: 1.2569 - val_accuracy: 0.7829\n",
      "Epoch 136/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 1.2481 - accuracy: 0.7791 - val_loss: 1.2353 - val_accuracy: 0.7829\n",
      "Epoch 137/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 1.2440 - accuracy: 0.7791 - val_loss: 1.2510 - val_accuracy: 0.7829\n",
      "Epoch 138/200\n",
      "172/172 [==============================] - 0s 983us/sample - loss: 1.2481 - accuracy: 0.7791 - val_loss: 1.2441 - val_accuracy: 0.7829\n",
      "Epoch 139/200\n",
      "172/172 [==============================] - 0s 966us/sample - loss: 1.2423 - accuracy: 0.7791 - val_loss: 1.2494 - val_accuracy: 0.7829\n",
      "Epoch 140/200\n",
      "172/172 [==============================] - 0s 947us/sample - loss: 1.2475 - accuracy: 0.7791 - val_loss: 1.2431 - val_accuracy: 0.7829\n",
      "Epoch 141/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 1.2484 - accuracy: 0.7791 - val_loss: 1.2427 - val_accuracy: 0.7829\n",
      "Epoch 142/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 1.2433 - accuracy: 0.7791 - val_loss: 1.2440 - val_accuracy: 0.7829\n",
      "Epoch 143/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 1.2489 - accuracy: 0.7791 - val_loss: 1.2542 - val_accuracy: 0.7829\n",
      "Epoch 144/200\n",
      "172/172 [==============================] - 0s 864us/sample - loss: 1.2467 - accuracy: 0.7791 - val_loss: 1.2438 - val_accuracy: 0.7829\n",
      "Epoch 145/200\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 1.2427 - accuracy: 0.7791 - val_loss: 1.2478 - val_accuracy: 0.7829\n",
      "Epoch 146/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 1.2471 - accuracy: 0.7791 - val_loss: 1.2385 - val_accuracy: 0.7829\n",
      "Epoch 147/200\n",
      "172/172 [==============================] - 0s 860us/sample - loss: 1.2461 - accuracy: 0.7791 - val_loss: 1.2598 - val_accuracy: 0.7829\n",
      "Epoch 148/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 1.2458 - accuracy: 0.7791 - val_loss: 1.2445 - val_accuracy: 0.7829\n",
      "Epoch 149/200\n",
      "172/172 [==============================] - 0s 864us/sample - loss: 1.2447 - accuracy: 0.7791 - val_loss: 1.2528 - val_accuracy: 0.7829\n",
      "Epoch 150/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 1.2478 - accuracy: 0.7791 - val_loss: 1.2397 - val_accuracy: 0.7829\n",
      "Epoch 151/200\n",
      "172/172 [==============================] - 0s 962us/sample - loss: 1.2452 - accuracy: 0.7791 - val_loss: 1.2407 - val_accuracy: 0.7829\n",
      "Epoch 152/200\n",
      "172/172 [==============================] - 0s 941us/sample - loss: 1.2494 - accuracy: 0.7791 - val_loss: 1.2376 - val_accuracy: 0.7829\n",
      "Epoch 153/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 1.2414 - accuracy: 0.7791 - val_loss: 1.2516 - val_accuracy: 0.7829\n",
      "Epoch 154/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 1.2470 - accuracy: 0.7791 - val_loss: 1.2512 - val_accuracy: 0.7829\n",
      "Epoch 155/200\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 1.2483 - accuracy: 0.7791 - val_loss: 1.2569 - val_accuracy: 0.7829\n",
      "Epoch 156/200\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 1.2454 - accuracy: 0.7791 - val_loss: 1.2457 - val_accuracy: 0.7829\n",
      "Epoch 157/200\n",
      "172/172 [==============================] - 0s 865us/sample - loss: 1.2476 - accuracy: 0.7791 - val_loss: 1.2447 - val_accuracy: 0.7829\n",
      "Epoch 158/200\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 1.2427 - accuracy: 0.7791 - val_loss: 1.2504 - val_accuracy: 0.7829\n",
      "Epoch 159/200\n",
      "172/172 [==============================] - 0s 860us/sample - loss: 1.2478 - accuracy: 0.7791 - val_loss: 1.2422 - val_accuracy: 0.7829\n",
      "Epoch 160/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 1.2456 - accuracy: 0.7791 - val_loss: 1.2367 - val_accuracy: 0.7829\n",
      "Epoch 161/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 1.2444 - accuracy: 0.7791 - val_loss: 1.2554 - val_accuracy: 0.7829\n",
      "Epoch 162/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 1.2467 - accuracy: 0.7791 - val_loss: 1.2416 - val_accuracy: 0.7829\n",
      "Epoch 163/200\n",
      "172/172 [==============================] - 0s 864us/sample - loss: 1.2439 - accuracy: 0.7791 - val_loss: 1.2586 - val_accuracy: 0.7829\n",
      "Epoch 164/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 935us/sample - loss: 1.2515 - accuracy: 0.7791 - val_loss: 1.2392 - val_accuracy: 0.7829\n",
      "Epoch 165/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 1.2400 - accuracy: 0.7791 - val_loss: 1.2485 - val_accuracy: 0.7829\n",
      "Epoch 166/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 1.2485 - accuracy: 0.7791 - val_loss: 1.2441 - val_accuracy: 0.7829\n",
      "Epoch 167/200\n",
      "172/172 [==============================] - 0s 840us/sample - loss: 1.2449 - accuracy: 0.7791 - val_loss: 1.2488 - val_accuracy: 0.7829\n",
      "Epoch 168/200\n",
      "172/172 [==============================] - 0s 839us/sample - loss: 1.2442 - accuracy: 0.7791 - val_loss: 1.2454 - val_accuracy: 0.7829\n",
      "Epoch 169/200\n",
      "172/172 [==============================] - 0s 839us/sample - loss: 1.2480 - accuracy: 0.7791 - val_loss: 1.2517 - val_accuracy: 0.7829\n",
      "Epoch 170/200\n",
      "172/172 [==============================] - 0s 841us/sample - loss: 1.2432 - accuracy: 0.7791 - val_loss: 1.2425 - val_accuracy: 0.7829\n",
      "Epoch 171/200\n",
      "172/172 [==============================] - 0s 835us/sample - loss: 1.2523 - accuracy: 0.7791 - val_loss: 1.2457 - val_accuracy: 0.7829\n",
      "Epoch 172/200\n",
      "172/172 [==============================] - 0s 839us/sample - loss: 1.2455 - accuracy: 0.7791 - val_loss: 1.2433 - val_accuracy: 0.7829\n",
      "Epoch 173/200\n",
      "172/172 [==============================] - 0s 844us/sample - loss: 1.2452 - accuracy: 0.7791 - val_loss: 1.2456 - val_accuracy: 0.7829\n",
      "Epoch 174/200\n",
      "172/172 [==============================] - 0s 835us/sample - loss: 1.2459 - accuracy: 0.7791 - val_loss: 1.2393 - val_accuracy: 0.7829\n",
      "Epoch 175/200\n",
      "172/172 [==============================] - 0s 835us/sample - loss: 1.2424 - accuracy: 0.7791 - val_loss: 1.2639 - val_accuracy: 0.7829\n",
      "Epoch 176/200\n",
      "172/172 [==============================] - 0s 834us/sample - loss: 1.2496 - accuracy: 0.7791 - val_loss: 1.2412 - val_accuracy: 0.7829\n",
      "Epoch 177/200\n",
      "172/172 [==============================] - 0s 849us/sample - loss: 1.2420 - accuracy: 0.7791 - val_loss: 1.2523 - val_accuracy: 0.7829\n",
      "Epoch 178/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 1.2470 - accuracy: 0.7791 - val_loss: 1.2450 - val_accuracy: 0.7829\n",
      "Epoch 179/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 1.2460 - accuracy: 0.7791 - val_loss: 1.2479 - val_accuracy: 0.7829\n",
      "Epoch 180/200\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 1.2473 - accuracy: 0.7791 - val_loss: 1.2356 - val_accuracy: 0.7829\n",
      "Epoch 181/200\n",
      "172/172 [==============================] - 0s 836us/sample - loss: 1.2444 - accuracy: 0.7791 - val_loss: 1.2451 - val_accuracy: 0.7829\n",
      "Epoch 182/200\n",
      "172/172 [==============================] - 0s 840us/sample - loss: 1.2462 - accuracy: 0.7791 - val_loss: 1.2442 - val_accuracy: 0.7829\n",
      "Epoch 183/200\n",
      "172/172 [==============================] - 0s 841us/sample - loss: 1.2457 - accuracy: 0.7791 - val_loss: 1.2565 - val_accuracy: 0.7829\n",
      "Epoch 184/200\n",
      "172/172 [==============================] - 0s 835us/sample - loss: 1.2465 - accuracy: 0.7791 - val_loss: 1.2460 - val_accuracy: 0.7829\n",
      "Epoch 185/200\n",
      "172/172 [==============================] - 0s 842us/sample - loss: 1.2446 - accuracy: 0.7791 - val_loss: 1.2468 - val_accuracy: 0.7829\n",
      "Epoch 186/200\n",
      "172/172 [==============================] - 0s 840us/sample - loss: 1.2466 - accuracy: 0.7791 - val_loss: 1.2432 - val_accuracy: 0.7829\n",
      "Epoch 187/200\n",
      "172/172 [==============================] - 0s 838us/sample - loss: 1.2466 - accuracy: 0.7791 - val_loss: 1.2436 - val_accuracy: 0.7829\n",
      "Epoch 188/200\n",
      "172/172 [==============================] - 0s 835us/sample - loss: 1.2472 - accuracy: 0.7791 - val_loss: 1.2408 - val_accuracy: 0.7829\n",
      "Epoch 189/200\n",
      "172/172 [==============================] - 0s 841us/sample - loss: 1.2444 - accuracy: 0.7791 - val_loss: 1.2585 - val_accuracy: 0.7829\n",
      "Epoch 190/200\n",
      "172/172 [==============================] - 0s 836us/sample - loss: 1.2453 - accuracy: 0.7791 - val_loss: 1.2410 - val_accuracy: 0.7829\n",
      "Epoch 191/200\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 1.2484 - accuracy: 0.7791 - val_loss: 1.2475 - val_accuracy: 0.7829\n",
      "Epoch 192/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 1.2484 - accuracy: 0.7791 - val_loss: 1.2372 - val_accuracy: 0.7829\n",
      "Epoch 193/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 1.2423 - accuracy: 0.7791 - val_loss: 1.2556 - val_accuracy: 0.7829\n",
      "Epoch 194/200\n",
      "172/172 [==============================] - 0s 840us/sample - loss: 1.2466 - accuracy: 0.7791 - val_loss: 1.2436 - val_accuracy: 0.7829\n",
      "Epoch 195/200\n",
      "172/172 [==============================] - 0s 839us/sample - loss: 1.2425 - accuracy: 0.7791 - val_loss: 1.2538 - val_accuracy: 0.7829\n",
      "Epoch 196/200\n",
      "172/172 [==============================] - 0s 869us/sample - loss: 1.2496 - accuracy: 0.7791 - val_loss: 1.2417 - val_accuracy: 0.7829\n",
      "Epoch 197/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 1.2437 - accuracy: 0.7791 - val_loss: 1.2480 - val_accuracy: 0.7829\n",
      "Epoch 198/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 1.2440 - accuracy: 0.7791 - val_loss: 1.2523 - val_accuracy: 0.7829\n",
      "Epoch 199/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 1.2497 - accuracy: 0.7791 - val_loss: 1.2420 - val_accuracy: 0.7829\n",
      "Epoch 200/200\n",
      "172/172 [==============================] - 0s 864us/sample - loss: 1.2423 - accuracy: 0.7791 - val_loss: 1.2458 - val_accuracy: 0.7829\n",
      "Beginning training for dr=0.100, l_lambda=1.0e-01, reg_type=l1, act: tanh\n",
      "Train on 172 samples, validate on 43 samples\n",
      "Epoch 1/200\n",
      "172/172 [==============================] - 1s 8ms/sample - loss: 71.4822 - accuracy: 0.6667 - val_loss: 36.0182 - val_accuracy: 0.6667\n",
      "Epoch 2/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 23.4424 - accuracy: 0.7093 - val_loss: 16.7373 - val_accuracy: 0.7829\n",
      "Epoch 3/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 13.1513 - accuracy: 0.7791 - val_loss: 10.1209 - val_accuracy: 0.7829\n",
      "Epoch 4/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 8.5809 - accuracy: 0.7791 - val_loss: 7.0207 - val_accuracy: 0.7829\n",
      "Epoch 5/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 6.0575 - accuracy: 0.7791 - val_loss: 5.0018 - val_accuracy: 0.7829\n",
      "Epoch 6/200\n",
      "172/172 [==============================] - 0s 862us/sample - loss: 4.2699 - accuracy: 0.7791 - val_loss: 3.4668 - val_accuracy: 0.7829\n",
      "Epoch 7/200\n",
      "172/172 [==============================] - 0s 859us/sample - loss: 2.9437 - accuracy: 0.7791 - val_loss: 2.3865 - val_accuracy: 0.7829\n",
      "Epoch 8/200\n",
      "172/172 [==============================] - 0s 986us/sample - loss: 2.0121 - accuracy: 0.7791 - val_loss: 1.6482 - val_accuracy: 0.7829\n",
      "Epoch 9/200\n",
      "172/172 [==============================] - 0s 953us/sample - loss: 1.4670 - accuracy: 0.7791 - val_loss: 1.3201 - val_accuracy: 0.7829\n",
      "Epoch 10/200\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 1.2896 - accuracy: 0.7791 - val_loss: 1.2591 - val_accuracy: 0.7829\n",
      "Epoch 11/200\n",
      "172/172 [==============================] - 0s 861us/sample - loss: 1.2576 - accuracy: 0.7791 - val_loss: 1.2480 - val_accuracy: 0.7829\n",
      "Epoch 12/200\n",
      "172/172 [==============================] - 0s 864us/sample - loss: 1.2484 - accuracy: 0.7791 - val_loss: 1.2433 - val_accuracy: 0.7829\n",
      "Epoch 13/200\n",
      "172/172 [==============================] - 0s 857us/sample - loss: 1.2390 - accuracy: 0.7791 - val_loss: 1.2460 - val_accuracy: 0.7829\n",
      "Epoch 14/200\n",
      "172/172 [==============================] - 0s 862us/sample - loss: 1.2427 - accuracy: 0.7791 - val_loss: 1.2452 - val_accuracy: 0.7829\n",
      "Epoch 15/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 1.2430 - accuracy: 0.7791 - val_loss: 1.2531 - val_accuracy: 0.7829\n",
      "Epoch 16/200\n",
      "172/172 [==============================] - 0s 858us/sample - loss: 1.2427 - accuracy: 0.7791 - val_loss: 1.2463 - val_accuracy: 0.7829\n",
      "Epoch 17/200\n",
      "172/172 [==============================] - 0s 859us/sample - loss: 1.2441 - accuracy: 0.7791 - val_loss: 1.2387 - val_accuracy: 0.7829\n",
      "Epoch 18/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 839us/sample - loss: 1.2394 - accuracy: 0.7791 - val_loss: 1.2471 - val_accuracy: 0.7829\n",
      "Epoch 19/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 1.2453 - accuracy: 0.7791 - val_loss: 1.2417 - val_accuracy: 0.7829\n",
      "Epoch 20/200\n",
      "172/172 [==============================] - 0s 840us/sample - loss: 1.2445 - accuracy: 0.7791 - val_loss: 1.2338 - val_accuracy: 0.7829\n",
      "Epoch 21/200\n",
      "172/172 [==============================] - 0s 948us/sample - loss: 1.2414 - accuracy: 0.7791 - val_loss: 1.2482 - val_accuracy: 0.7829\n",
      "Epoch 22/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 1.2449 - accuracy: 0.7791 - val_loss: 1.2412 - val_accuracy: 0.7829\n",
      "Epoch 23/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 1.2404 - accuracy: 0.7791 - val_loss: 1.2521 - val_accuracy: 0.7829\n",
      "Epoch 24/200\n",
      "172/172 [==============================] - 0s 814us/sample - loss: 1.2457 - accuracy: 0.7791 - val_loss: 1.2406 - val_accuracy: 0.7829\n",
      "Epoch 25/200\n",
      "172/172 [==============================] - 0s 818us/sample - loss: 1.2377 - accuracy: 0.7791 - val_loss: 1.2466 - val_accuracy: 0.7829\n",
      "Epoch 26/200\n",
      "172/172 [==============================] - 0s 813us/sample - loss: 1.2462 - accuracy: 0.7791 - val_loss: 1.2396 - val_accuracy: 0.7829\n",
      "Epoch 27/200\n",
      "172/172 [==============================] - 0s 816us/sample - loss: 1.2399 - accuracy: 0.7791 - val_loss: 1.2475 - val_accuracy: 0.7829\n",
      "Epoch 28/200\n",
      "172/172 [==============================] - 0s 817us/sample - loss: 1.2432 - accuracy: 0.7791 - val_loss: 1.2408 - val_accuracy: 0.7829\n",
      "Epoch 29/200\n",
      "172/172 [==============================] - 0s 814us/sample - loss: 1.2412 - accuracy: 0.7791 - val_loss: 1.2462 - val_accuracy: 0.7829\n",
      "Epoch 30/200\n",
      "172/172 [==============================] - 0s 816us/sample - loss: 1.2406 - accuracy: 0.7791 - val_loss: 1.2441 - val_accuracy: 0.7829\n",
      "Epoch 31/200\n",
      "172/172 [==============================] - 0s 813us/sample - loss: 1.2461 - accuracy: 0.7791 - val_loss: 1.2385 - val_accuracy: 0.7829\n",
      "Epoch 32/200\n",
      "172/172 [==============================] - 0s 804us/sample - loss: 1.2412 - accuracy: 0.7791 - val_loss: 1.2388 - val_accuracy: 0.7829\n",
      "Epoch 33/200\n",
      "172/172 [==============================] - 0s 825us/sample - loss: 1.2378 - accuracy: 0.7791 - val_loss: 1.2458 - val_accuracy: 0.7829\n",
      "Epoch 34/200\n",
      "172/172 [==============================] - 0s 815us/sample - loss: 1.2451 - accuracy: 0.7791 - val_loss: 1.2377 - val_accuracy: 0.7829\n",
      "Epoch 35/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 1.2375 - accuracy: 0.7791 - val_loss: 1.2575 - val_accuracy: 0.7829\n",
      "Epoch 36/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 1.2447 - accuracy: 0.7791 - val_loss: 1.2416 - val_accuracy: 0.7829\n",
      "Epoch 37/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 1.2412 - accuracy: 0.7791 - val_loss: 1.2474 - val_accuracy: 0.7829\n",
      "Epoch 38/200\n",
      "172/172 [==============================] - 0s 812us/sample - loss: 1.2420 - accuracy: 0.7791 - val_loss: 1.2357 - val_accuracy: 0.7829\n",
      "Epoch 39/200\n",
      "172/172 [==============================] - 0s 832us/sample - loss: 1.2412 - accuracy: 0.7791 - val_loss: 1.2452 - val_accuracy: 0.7829\n",
      "Epoch 40/200\n",
      "172/172 [==============================] - 0s 829us/sample - loss: 1.2443 - accuracy: 0.7791 - val_loss: 1.2387 - val_accuracy: 0.7829\n",
      "Epoch 41/200\n",
      "172/172 [==============================] - 0s 832us/sample - loss: 1.2389 - accuracy: 0.7791 - val_loss: 1.2374 - val_accuracy: 0.7829\n",
      "Epoch 42/200\n",
      "172/172 [==============================] - 0s 826us/sample - loss: 1.2426 - accuracy: 0.7791 - val_loss: 1.2400 - val_accuracy: 0.7829\n",
      "Epoch 43/200\n",
      "172/172 [==============================] - 0s 832us/sample - loss: 1.2413 - accuracy: 0.7791 - val_loss: 1.2503 - val_accuracy: 0.7829\n",
      "Epoch 44/200\n",
      "172/172 [==============================] - 0s 827us/sample - loss: 1.2413 - accuracy: 0.7791 - val_loss: 1.2465 - val_accuracy: 0.7829\n",
      "Epoch 45/200\n",
      "172/172 [==============================] - 0s 833us/sample - loss: 1.2412 - accuracy: 0.7791 - val_loss: 1.2390 - val_accuracy: 0.7829\n",
      "Epoch 46/200\n",
      "172/172 [==============================] - 0s 829us/sample - loss: 1.2390 - accuracy: 0.7791 - val_loss: 1.2435 - val_accuracy: 0.7829\n",
      "Epoch 47/200\n",
      "172/172 [==============================] - 0s 842us/sample - loss: 1.2429 - accuracy: 0.7791 - val_loss: 1.2430 - val_accuracy: 0.7829\n",
      "Epoch 48/200\n",
      "172/172 [==============================] - 0s 844us/sample - loss: 1.2436 - accuracy: 0.7791 - val_loss: 1.2361 - val_accuracy: 0.7829\n",
      "Epoch 49/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 1.2401 - accuracy: 0.7791 - val_loss: 1.2502 - val_accuracy: 0.7829\n",
      "Epoch 50/200\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 1.2408 - accuracy: 0.7791 - val_loss: 1.2414 - val_accuracy: 0.7829\n",
      "Epoch 51/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 1.2433 - accuracy: 0.7791 - val_loss: 1.2453 - val_accuracy: 0.7829\n",
      "Epoch 52/200\n",
      "172/172 [==============================] - 0s 861us/sample - loss: 1.2449 - accuracy: 0.7791 - val_loss: 1.2399 - val_accuracy: 0.7829\n",
      "Epoch 53/200\n",
      "172/172 [==============================] - 0s 859us/sample - loss: 1.2364 - accuracy: 0.7791 - val_loss: 1.2470 - val_accuracy: 0.7829\n",
      "Epoch 54/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 1.2460 - accuracy: 0.7791 - val_loss: 1.2381 - val_accuracy: 0.7829\n",
      "Epoch 55/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 1.2354 - accuracy: 0.7791 - val_loss: 1.2445 - val_accuracy: 0.7829\n",
      "Epoch 56/200\n",
      "172/172 [==============================] - 0s 861us/sample - loss: 1.2454 - accuracy: 0.7791 - val_loss: 1.2431 - val_accuracy: 0.7829\n",
      "Epoch 57/200\n",
      "172/172 [==============================] - 0s 860us/sample - loss: 1.2424 - accuracy: 0.7791 - val_loss: 1.2436 - val_accuracy: 0.7829\n",
      "Epoch 58/200\n",
      "172/172 [==============================] - 0s 857us/sample - loss: 1.2367 - accuracy: 0.7791 - val_loss: 1.2425 - val_accuracy: 0.7829\n",
      "Epoch 59/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 1.2448 - accuracy: 0.7791 - val_loss: 1.2418 - val_accuracy: 0.7829\n",
      "Epoch 60/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 1.2405 - accuracy: 0.7791 - val_loss: 1.2369 - val_accuracy: 0.7829\n",
      "Epoch 61/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 1.2413 - accuracy: 0.7791 - val_loss: 1.2376 - val_accuracy: 0.7829\n",
      "Epoch 62/200\n",
      "172/172 [==============================] - 0s 981us/sample - loss: 1.2420 - accuracy: 0.7791 - val_loss: 1.2364 - val_accuracy: 0.7829\n",
      "Epoch 63/200\n",
      "172/172 [==============================] - 0s 962us/sample - loss: 1.2392 - accuracy: 0.7791 - val_loss: 1.2582 - val_accuracy: 0.7829\n",
      "Epoch 64/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 1.2456 - accuracy: 0.7791 - val_loss: 1.2398 - val_accuracy: 0.7829\n",
      "Epoch 65/200\n",
      "172/172 [==============================] - 0s 882us/sample - loss: 1.2376 - accuracy: 0.7791 - val_loss: 1.2502 - val_accuracy: 0.7829\n",
      "Epoch 66/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 1.2460 - accuracy: 0.7791 - val_loss: 1.2356 - val_accuracy: 0.7829\n",
      "Epoch 67/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 1.2403 - accuracy: 0.7791 - val_loss: 1.2489 - val_accuracy: 0.7829\n",
      "Epoch 68/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 1.2453 - accuracy: 0.7791 - val_loss: 1.2400 - val_accuracy: 0.7829\n",
      "Epoch 69/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 1.2396 - accuracy: 0.7791 - val_loss: 1.2410 - val_accuracy: 0.7829\n",
      "Epoch 70/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 1.2388 - accuracy: 0.7791 - val_loss: 1.2396 - val_accuracy: 0.7829\n",
      "Epoch 71/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 1.2459 - accuracy: 0.7791 - val_loss: 1.2437 - val_accuracy: 0.7829\n",
      "Epoch 72/200\n",
      "172/172 [==============================] - 0s 882us/sample - loss: 1.2389 - accuracy: 0.7791 - val_loss: 1.2435 - val_accuracy: 0.7829\n",
      "Epoch 73/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 887us/sample - loss: 1.2431 - accuracy: 0.7791 - val_loss: 1.2430 - val_accuracy: 0.7829\n",
      "Epoch 74/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 1.2443 - accuracy: 0.7791 - val_loss: 1.2473 - val_accuracy: 0.7829\n",
      "Epoch 75/200\n",
      "172/172 [==============================] - 0s 976us/sample - loss: 1.2392 - accuracy: 0.7791 - val_loss: 1.2433 - val_accuracy: 0.7829\n",
      "Epoch 76/200\n",
      "172/172 [==============================] - 0s 952us/sample - loss: 1.2443 - accuracy: 0.7791 - val_loss: 1.2326 - val_accuracy: 0.7829\n",
      "Epoch 77/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 1.2399 - accuracy: 0.7791 - val_loss: 1.2513 - val_accuracy: 0.7829\n",
      "Epoch 78/200\n",
      "172/172 [==============================] - 0s 882us/sample - loss: 1.2410 - accuracy: 0.7791 - val_loss: 1.2424 - val_accuracy: 0.7829\n",
      "Epoch 79/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 1.2446 - accuracy: 0.7791 - val_loss: 1.2471 - val_accuracy: 0.7829\n",
      "Epoch 80/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 1.2432 - accuracy: 0.7791 - val_loss: 1.2352 - val_accuracy: 0.7829\n",
      "Epoch 81/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 1.2397 - accuracy: 0.7791 - val_loss: 1.2366 - val_accuracy: 0.7829\n",
      "Epoch 82/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 1.2431 - accuracy: 0.7791 - val_loss: 1.2396 - val_accuracy: 0.7829\n",
      "Epoch 83/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 1.2391 - accuracy: 0.7791 - val_loss: 1.2482 - val_accuracy: 0.7829\n",
      "Epoch 84/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 1.2413 - accuracy: 0.7791 - val_loss: 1.2429 - val_accuracy: 0.7829\n",
      "Epoch 85/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 1.2386 - accuracy: 0.7791 - val_loss: 1.2496 - val_accuracy: 0.7829\n",
      "Epoch 86/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 1.2425 - accuracy: 0.7791 - val_loss: 1.2450 - val_accuracy: 0.7829\n",
      "Epoch 87/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 1.2422 - accuracy: 0.7791 - val_loss: 1.2406 - val_accuracy: 0.7829\n",
      "Epoch 88/200\n",
      "172/172 [==============================] - 0s 966us/sample - loss: 1.2402 - accuracy: 0.7791 - val_loss: 1.2453 - val_accuracy: 0.7829\n",
      "Epoch 89/200\n",
      "172/172 [==============================] - 0s 954us/sample - loss: 1.2434 - accuracy: 0.7791 - val_loss: 1.2348 - val_accuracy: 0.7829\n",
      "Epoch 90/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 1.2382 - accuracy: 0.7791 - val_loss: 1.2337 - val_accuracy: 0.7829\n",
      "Epoch 91/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 1.2426 - accuracy: 0.7791 - val_loss: 1.2516 - val_accuracy: 0.7829\n",
      "Epoch 92/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 1.2434 - accuracy: 0.7791 - val_loss: 1.2381 - val_accuracy: 0.7829\n",
      "Epoch 93/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 1.2416 - accuracy: 0.7791 - val_loss: 1.2466 - val_accuracy: 0.7829\n",
      "Epoch 94/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 1.2473 - accuracy: 0.7791 - val_loss: 1.2368 - val_accuracy: 0.7829\n",
      "Epoch 95/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 1.2359 - accuracy: 0.7791 - val_loss: 1.2510 - val_accuracy: 0.7829\n",
      "Epoch 96/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 1.2470 - accuracy: 0.7791 - val_loss: 1.2356 - val_accuracy: 0.7829\n",
      "Epoch 97/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 1.2376 - accuracy: 0.7791 - val_loss: 1.2411 - val_accuracy: 0.7829\n",
      "Epoch 98/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 1.2436 - accuracy: 0.7791 - val_loss: 1.2425 - val_accuracy: 0.7829\n",
      "Epoch 99/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 1.2429 - accuracy: 0.7791 - val_loss: 1.2426 - val_accuracy: 0.7829\n",
      "Epoch 100/200\n",
      "172/172 [==============================] - 0s 962us/sample - loss: 1.2379 - accuracy: 0.7791 - val_loss: 1.2436 - val_accuracy: 0.7829\n",
      "Epoch 101/200\n",
      "172/172 [==============================] - 0s 952us/sample - loss: 1.2466 - accuracy: 0.7791 - val_loss: 1.2387 - val_accuracy: 0.7829\n",
      "Epoch 102/200\n",
      "172/172 [==============================] - 0s 957us/sample - loss: 1.2396 - accuracy: 0.7791 - val_loss: 1.2418 - val_accuracy: 0.7829\n",
      "Epoch 103/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 1.2428 - accuracy: 0.7791 - val_loss: 1.2454 - val_accuracy: 0.7829\n",
      "Epoch 104/200\n",
      "172/172 [==============================] - 0s 882us/sample - loss: 1.2415 - accuracy: 0.7791 - val_loss: 1.2348 - val_accuracy: 0.7829\n",
      "Epoch 105/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 1.2389 - accuracy: 0.7791 - val_loss: 1.2590 - val_accuracy: 0.7829\n",
      "Epoch 106/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 1.2442 - accuracy: 0.7791 - val_loss: 1.2379 - val_accuracy: 0.7829\n",
      "Epoch 107/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 1.2403 - accuracy: 0.7791 - val_loss: 1.2501 - val_accuracy: 0.7829\n",
      "Epoch 108/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 1.2425 - accuracy: 0.7791 - val_loss: 1.2357 - val_accuracy: 0.7829\n",
      "Epoch 109/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 1.2399 - accuracy: 0.7791 - val_loss: 1.2404 - val_accuracy: 0.7829\n",
      "Epoch 110/200\n",
      "172/172 [==============================] - 0s 882us/sample - loss: 1.2418 - accuracy: 0.7791 - val_loss: 1.2322 - val_accuracy: 0.7829\n",
      "Epoch 111/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 1.2405 - accuracy: 0.7791 - val_loss: 1.2427 - val_accuracy: 0.7829\n",
      "Epoch 112/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 1.2425 - accuracy: 0.7791 - val_loss: 1.2406 - val_accuracy: 0.7829\n",
      "Epoch 113/200\n",
      "172/172 [==============================] - 0s 963us/sample - loss: 1.2405 - accuracy: 0.7791 - val_loss: 1.2438 - val_accuracy: 0.7829\n",
      "Epoch 114/200\n",
      "172/172 [==============================] - 0s 955us/sample - loss: 1.2408 - accuracy: 0.7791 - val_loss: 1.2501 - val_accuracy: 0.7829\n",
      "Epoch 115/200\n",
      "172/172 [==============================] - 0s 946us/sample - loss: 1.2430 - accuracy: 0.7791 - val_loss: 1.2433 - val_accuracy: 0.7829\n",
      "Epoch 116/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 1.2408 - accuracy: 0.7791 - val_loss: 1.2430 - val_accuracy: 0.7829\n",
      "Epoch 117/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 1.2397 - accuracy: 0.7791 - val_loss: 1.2428 - val_accuracy: 0.7829\n",
      "Epoch 118/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 1.2452 - accuracy: 0.7791 - val_loss: 1.2385 - val_accuracy: 0.7829\n",
      "Epoch 119/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 1.2388 - accuracy: 0.7791 - val_loss: 1.2491 - val_accuracy: 0.7829\n",
      "Epoch 120/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 1.2421 - accuracy: 0.7791 - val_loss: 1.2381 - val_accuracy: 0.7829\n",
      "Epoch 121/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 1.2417 - accuracy: 0.7791 - val_loss: 1.2409 - val_accuracy: 0.7829\n",
      "Epoch 122/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 1.2433 - accuracy: 0.7791 - val_loss: 1.2394 - val_accuracy: 0.7829\n",
      "Epoch 123/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 1.2409 - accuracy: 0.7791 - val_loss: 1.2451 - val_accuracy: 0.7829\n",
      "Epoch 124/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 1.2441 - accuracy: 0.7791 - val_loss: 1.2422 - val_accuracy: 0.7829\n",
      "Epoch 125/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 1.2359 - accuracy: 0.7791 - val_loss: 1.2443 - val_accuracy: 0.7829\n",
      "Epoch 126/200\n",
      "172/172 [==============================] - 0s 988us/sample - loss: 1.2423 - accuracy: 0.7791 - val_loss: 1.2383 - val_accuracy: 0.7829\n",
      "Epoch 127/200\n",
      "172/172 [==============================] - 0s 954us/sample - loss: 1.2424 - accuracy: 0.7791 - val_loss: 1.2482 - val_accuracy: 0.7829\n",
      "Epoch 128/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 936us/sample - loss: 1.2379 - accuracy: 0.7791 - val_loss: 1.2438 - val_accuracy: 0.7829\n",
      "Epoch 129/200\n",
      "172/172 [==============================] - 0s 882us/sample - loss: 1.2423 - accuracy: 0.7791 - val_loss: 1.2364 - val_accuracy: 0.7829\n",
      "Epoch 130/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 1.2390 - accuracy: 0.7791 - val_loss: 1.2397 - val_accuracy: 0.7829\n",
      "Epoch 131/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 1.2432 - accuracy: 0.7791 - val_loss: 1.2401 - val_accuracy: 0.7829\n",
      "Epoch 132/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 1.2438 - accuracy: 0.7791 - val_loss: 1.2326 - val_accuracy: 0.7829\n",
      "Epoch 133/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 1.2347 - accuracy: 0.7791 - val_loss: 1.2553 - val_accuracy: 0.7829\n",
      "Epoch 134/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 1.2434 - accuracy: 0.7791 - val_loss: 1.2434 - val_accuracy: 0.7829\n",
      "Epoch 135/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 1.2384 - accuracy: 0.7791 - val_loss: 1.2523 - val_accuracy: 0.7829\n",
      "Epoch 136/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 1.2450 - accuracy: 0.7791 - val_loss: 1.2317 - val_accuracy: 0.7829\n",
      "Epoch 137/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 1.2396 - accuracy: 0.7791 - val_loss: 1.2449 - val_accuracy: 0.7829\n",
      "Epoch 138/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 1.2430 - accuracy: 0.7791 - val_loss: 1.2371 - val_accuracy: 0.7829\n",
      "Epoch 139/200\n",
      "172/172 [==============================] - 0s 981us/sample - loss: 1.2370 - accuracy: 0.7791 - val_loss: 1.2443 - val_accuracy: 0.7829\n",
      "Epoch 140/200\n",
      "172/172 [==============================] - 0s 952us/sample - loss: 1.2430 - accuracy: 0.7791 - val_loss: 1.2404 - val_accuracy: 0.7829\n",
      "Epoch 141/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 1.2451 - accuracy: 0.7791 - val_loss: 1.2375 - val_accuracy: 0.7829\n",
      "Epoch 142/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 1.2365 - accuracy: 0.7791 - val_loss: 1.2413 - val_accuracy: 0.7829\n",
      "Epoch 143/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 1.2419 - accuracy: 0.7791 - val_loss: 1.2453 - val_accuracy: 0.7829\n",
      "Epoch 144/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 1.2458 - accuracy: 0.7791 - val_loss: 1.2427 - val_accuracy: 0.7829\n",
      "Epoch 145/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 1.2367 - accuracy: 0.7791 - val_loss: 1.2409 - val_accuracy: 0.7829\n",
      "Epoch 146/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 1.2414 - accuracy: 0.7791 - val_loss: 1.2332 - val_accuracy: 0.7829\n",
      "Epoch 147/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 1.2395 - accuracy: 0.7791 - val_loss: 1.2545 - val_accuracy: 0.7829\n",
      "Epoch 148/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 1.2395 - accuracy: 0.7791 - val_loss: 1.2381 - val_accuracy: 0.7829\n",
      "Epoch 149/200\n",
      "172/172 [==============================] - 0s 940us/sample - loss: 1.2407 - accuracy: 0.7791 - val_loss: 1.2440 - val_accuracy: 0.7829\n",
      "Epoch 150/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 1.2412 - accuracy: 0.7791 - val_loss: 1.2382 - val_accuracy: 0.7829\n",
      "Epoch 151/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 1.2401 - accuracy: 0.7791 - val_loss: 1.2392 - val_accuracy: 0.7829\n",
      "Epoch 152/200\n",
      "172/172 [==============================] - 0s 971us/sample - loss: 1.2451 - accuracy: 0.7791 - val_loss: 1.2386 - val_accuracy: 0.7829\n",
      "Epoch 153/200\n",
      "172/172 [==============================] - 0s 959us/sample - loss: 1.2354 - accuracy: 0.7791 - val_loss: 1.2449 - val_accuracy: 0.7829\n",
      "Epoch 154/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 1.2433 - accuracy: 0.7791 - val_loss: 1.2434 - val_accuracy: 0.7829\n",
      "Epoch 155/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 1.2382 - accuracy: 0.7791 - val_loss: 1.2485 - val_accuracy: 0.7829\n",
      "Epoch 156/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 1.2409 - accuracy: 0.7791 - val_loss: 1.2441 - val_accuracy: 0.7829\n",
      "Epoch 157/200\n",
      "172/172 [==============================] - 0s 856us/sample - loss: 1.2432 - accuracy: 0.7791 - val_loss: 1.2381 - val_accuracy: 0.7829\n",
      "Epoch 158/200\n",
      "172/172 [==============================] - 0s 848us/sample - loss: 1.2373 - accuracy: 0.7791 - val_loss: 1.2445 - val_accuracy: 0.7829\n",
      "Epoch 159/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 1.2428 - accuracy: 0.7791 - val_loss: 1.2373 - val_accuracy: 0.7829\n",
      "Epoch 160/200\n",
      "172/172 [==============================] - 0s 853us/sample - loss: 1.2415 - accuracy: 0.7791 - val_loss: 1.2330 - val_accuracy: 0.7829\n",
      "Epoch 161/200\n",
      "172/172 [==============================] - 0s 859us/sample - loss: 1.2393 - accuracy: 0.7791 - val_loss: 1.2508 - val_accuracy: 0.7829\n",
      "Epoch 162/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 1.2410 - accuracy: 0.7791 - val_loss: 1.2400 - val_accuracy: 0.7829\n",
      "Epoch 163/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 1.2381 - accuracy: 0.7791 - val_loss: 1.2507 - val_accuracy: 0.7829\n",
      "Epoch 164/200\n",
      "172/172 [==============================] - 0s 857us/sample - loss: 1.2444 - accuracy: 0.7791 - val_loss: 1.2380 - val_accuracy: 0.7829\n",
      "Epoch 165/200\n",
      "172/172 [==============================] - 0s 963us/sample - loss: 1.2336 - accuracy: 0.7791 - val_loss: 1.2418 - val_accuracy: 0.7829\n",
      "Epoch 166/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 1.2454 - accuracy: 0.7791 - val_loss: 1.2421 - val_accuracy: 0.7829\n",
      "Epoch 167/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 1.2389 - accuracy: 0.7791 - val_loss: 1.2435 - val_accuracy: 0.7829\n",
      "Epoch 168/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 1.2393 - accuracy: 0.7791 - val_loss: 1.2379 - val_accuracy: 0.7829\n",
      "Epoch 169/200\n",
      "172/172 [==============================] - 0s 854us/sample - loss: 1.2427 - accuracy: 0.7791 - val_loss: 1.2441 - val_accuracy: 0.7829\n",
      "Epoch 170/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 1.2366 - accuracy: 0.7791 - val_loss: 1.2371 - val_accuracy: 0.7829\n",
      "Epoch 171/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 1.2451 - accuracy: 0.7791 - val_loss: 1.2376 - val_accuracy: 0.7829\n",
      "Epoch 172/200\n",
      "172/172 [==============================] - 0s 858us/sample - loss: 1.2382 - accuracy: 0.7791 - val_loss: 1.2440 - val_accuracy: 0.7829\n",
      "Epoch 173/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 1.2397 - accuracy: 0.7791 - val_loss: 1.2411 - val_accuracy: 0.7829\n",
      "Epoch 174/200\n",
      "172/172 [==============================] - 0s 849us/sample - loss: 1.2422 - accuracy: 0.7791 - val_loss: 1.2334 - val_accuracy: 0.7829\n",
      "Epoch 175/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 1.2371 - accuracy: 0.7791 - val_loss: 1.2596 - val_accuracy: 0.7829\n",
      "Epoch 176/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 1.2443 - accuracy: 0.7791 - val_loss: 1.2373 - val_accuracy: 0.7829\n",
      "Epoch 177/200\n",
      "172/172 [==============================] - 0s 857us/sample - loss: 1.2377 - accuracy: 0.7791 - val_loss: 1.2438 - val_accuracy: 0.7829\n",
      "Epoch 178/200\n",
      "172/172 [==============================] - 0s 957us/sample - loss: 1.2401 - accuracy: 0.7791 - val_loss: 1.2397 - val_accuracy: 0.7829\n",
      "Epoch 179/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 1.2468 - accuracy: 0.7791 - val_loss: 1.2450 - val_accuracy: 0.7829\n",
      "Epoch 180/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 1.2435 - accuracy: 0.7791 - val_loss: 1.2349 - val_accuracy: 0.7829\n",
      "Epoch 181/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 1.2397 - accuracy: 0.7791 - val_loss: 1.2392 - val_accuracy: 0.7829\n",
      "Epoch 182/200\n",
      "172/172 [==============================] - 0s 858us/sample - loss: 1.2418 - accuracy: 0.7791 - val_loss: 1.2417 - val_accuracy: 0.7829\n",
      "Epoch 183/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 860us/sample - loss: 1.2402 - accuracy: 0.7791 - val_loss: 1.2502 - val_accuracy: 0.7829\n",
      "Epoch 184/200\n",
      "172/172 [==============================] - 0s 857us/sample - loss: 1.2399 - accuracy: 0.7791 - val_loss: 1.2457 - val_accuracy: 0.7829\n",
      "Epoch 185/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 1.2392 - accuracy: 0.7791 - val_loss: 1.2388 - val_accuracy: 0.7829\n",
      "Epoch 186/200\n",
      "172/172 [==============================] - 0s 854us/sample - loss: 1.2400 - accuracy: 0.7791 - val_loss: 1.2421 - val_accuracy: 0.7829\n",
      "Epoch 187/200\n",
      "172/172 [==============================] - 0s 854us/sample - loss: 1.2394 - accuracy: 0.7791 - val_loss: 1.2392 - val_accuracy: 0.7829\n",
      "Epoch 188/200\n",
      "172/172 [==============================] - 0s 853us/sample - loss: 1.2422 - accuracy: 0.7791 - val_loss: 1.2380 - val_accuracy: 0.7829\n",
      "Epoch 189/200\n",
      "172/172 [==============================] - 0s 831us/sample - loss: 1.2402 - accuracy: 0.7791 - val_loss: 1.2521 - val_accuracy: 0.7829\n",
      "Epoch 190/200\n",
      "172/172 [==============================] - 0s 833us/sample - loss: 1.2396 - accuracy: 0.7791 - val_loss: 1.2353 - val_accuracy: 0.7829\n",
      "Epoch 191/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 1.2421 - accuracy: 0.7791 - val_loss: 1.2448 - val_accuracy: 0.7829\n",
      "Epoch 192/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 1.2437 - accuracy: 0.7791 - val_loss: 1.2369 - val_accuracy: 0.7829\n",
      "Epoch 193/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 1.2356 - accuracy: 0.7791 - val_loss: 1.2447 - val_accuracy: 0.7829\n",
      "Epoch 194/200\n",
      "172/172 [==============================] - 0s 834us/sample - loss: 1.2435 - accuracy: 0.7791 - val_loss: 1.2387 - val_accuracy: 0.7829\n",
      "Epoch 195/200\n",
      "172/172 [==============================] - 0s 830us/sample - loss: 1.2355 - accuracy: 0.7791 - val_loss: 1.2475 - val_accuracy: 0.7829\n",
      "Epoch 196/200\n",
      "172/172 [==============================] - 0s 829us/sample - loss: 1.2449 - accuracy: 0.7791 - val_loss: 1.2383 - val_accuracy: 0.7829\n",
      "Epoch 197/200\n",
      "172/172 [==============================] - 0s 836us/sample - loss: 1.2390 - accuracy: 0.7791 - val_loss: 1.2437 - val_accuracy: 0.7829\n",
      "Epoch 198/200\n",
      "172/172 [==============================] - 0s 825us/sample - loss: 1.2409 - accuracy: 0.7791 - val_loss: 1.2435 - val_accuracy: 0.7829\n",
      "Epoch 199/200\n",
      "172/172 [==============================] - 0s 829us/sample - loss: 1.2445 - accuracy: 0.7791 - val_loss: 1.2355 - val_accuracy: 0.7829\n",
      "Epoch 200/200\n",
      "172/172 [==============================] - 0s 829us/sample - loss: 1.2365 - accuracy: 0.7791 - val_loss: 1.2441 - val_accuracy: 0.7829\n"
     ]
    }
   ],
   "source": [
    "dropout_rates = [0.001, 0.01, 0.1]\n",
    "reg_types = ['l2', 'l1']\n",
    "reg_coeffs = [0.001, 0.01, 0.1]\n",
    "activations = ['relu', 'tanh']\n",
    "\n",
    "pbar = functools.partial(tqdm, leave=True, ncols='70%')\n",
    "pbars = [pbar() for _ in range(3)]\n",
    "\n",
    "grid_search_df = grid_search(dropout_rates=dropout_rates, reg_coeffs=reg_coeffs, reg_types=reg_types, \n",
    "                             pbars=pbars, activations=activations, num_epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row0_col0 {\n",
       "            background-color:  #fec88c;\n",
       "            color:  #000000;\n",
       "        }    #T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row0_col1 {\n",
       "            background-color:  #fea36f;\n",
       "            color:  #000000;\n",
       "        }    #T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row0_col2 {\n",
       "            background-color:  #000004;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row1_col0 {\n",
       "            background-color:  #fec88c;\n",
       "            color:  #000000;\n",
       "        }    #T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row1_col1 {\n",
       "            background-color:  #fea16e;\n",
       "            color:  #000000;\n",
       "        }    #T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row1_col2 {\n",
       "            background-color:  #000004;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row2_col0 {\n",
       "            background-color:  #fec88c;\n",
       "            color:  #000000;\n",
       "        }    #T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row2_col1 {\n",
       "            background-color:  #fea16e;\n",
       "            color:  #000000;\n",
       "        }    #T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row2_col2 {\n",
       "            background-color:  #000004;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row3_col0 {\n",
       "            background-color:  #fec88c;\n",
       "            color:  #000000;\n",
       "        }    #T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row3_col1 {\n",
       "            background-color:  #fea36f;\n",
       "            color:  #000000;\n",
       "        }    #T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row3_col2 {\n",
       "            background-color:  #000004;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row4_col0 {\n",
       "            background-color:  #fec88c;\n",
       "            color:  #000000;\n",
       "        }    #T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row4_col1 {\n",
       "            background-color:  #fea16e;\n",
       "            color:  #000000;\n",
       "        }    #T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row4_col2 {\n",
       "            background-color:  #000004;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row5_col0 {\n",
       "            background-color:  #fec88c;\n",
       "            color:  #000000;\n",
       "        }    #T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row5_col1 {\n",
       "            background-color:  #fea16e;\n",
       "            color:  #000000;\n",
       "        }    #T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row5_col2 {\n",
       "            background-color:  #010005;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row6_col0 {\n",
       "            background-color:  #fcf6b8;\n",
       "            color:  #000000;\n",
       "        }    #T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row6_col1 {\n",
       "            background-color:  #fecc8f;\n",
       "            color:  #000000;\n",
       "        }    #T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row6_col2 {\n",
       "            background-color:  #fecc8f;\n",
       "            color:  #000000;\n",
       "        }    #T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row7_col0 {\n",
       "            background-color:  #fcfdbf;\n",
       "            color:  #000000;\n",
       "        }    #T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row7_col1 {\n",
       "            background-color:  #fecc8f;\n",
       "            color:  #000000;\n",
       "        }    #T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row7_col2 {\n",
       "            background-color:  #fecc8f;\n",
       "            color:  #000000;\n",
       "        }    #T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row8_col0 {\n",
       "            background-color:  #fcf7b9;\n",
       "            color:  #000000;\n",
       "        }    #T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row8_col1 {\n",
       "            background-color:  #fecc8f;\n",
       "            color:  #000000;\n",
       "        }    #T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row8_col2 {\n",
       "            background-color:  #fecc8f;\n",
       "            color:  #000000;\n",
       "        }    #T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row9_col0 {\n",
       "            background-color:  #fcfdbf;\n",
       "            color:  #000000;\n",
       "        }    #T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row9_col1 {\n",
       "            background-color:  #fecc8f;\n",
       "            color:  #000000;\n",
       "        }    #T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row9_col2 {\n",
       "            background-color:  #fecc8f;\n",
       "            color:  #000000;\n",
       "        }    #T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row10_col0 {\n",
       "            background-color:  #fcf6b8;\n",
       "            color:  #000000;\n",
       "        }    #T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row10_col1 {\n",
       "            background-color:  #fecc8f;\n",
       "            color:  #000000;\n",
       "        }    #T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row10_col2 {\n",
       "            background-color:  #fecc8f;\n",
       "            color:  #000000;\n",
       "        }    #T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row11_col0 {\n",
       "            background-color:  #fcfdbf;\n",
       "            color:  #000000;\n",
       "        }    #T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row11_col1 {\n",
       "            background-color:  #fecc8f;\n",
       "            color:  #000000;\n",
       "        }    #T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row11_col2 {\n",
       "            background-color:  #fecc8f;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1\" ><thead>    <tr>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" colspan=3>validation loss</th>    </tr>    <tr>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"index_name level1\" >lambda</th>        <th class=\"col_heading level1 col0\" >0.001</th>        <th class=\"col_heading level1 col1\" >0.01</th>        <th class=\"col_heading level1 col2\" >0.1</th>    </tr>    <tr>        <th class=\"index_name level0\" >reg type</th>        <th class=\"index_name level1\" >dropout rate</th>        <th class=\"index_name level2\" >activation</th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1level0_row0\" class=\"row_heading level0 row0\" rowspan=6>l1</th>\n",
       "                        <th id=\"T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1level1_row0\" class=\"row_heading level1 row0\" rowspan=2>0.001</th>\n",
       "                        <th id=\"T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1level2_row0\" class=\"row_heading level2 row0\" >relu</th>\n",
       "                        <td id=\"T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row0_col0\" class=\"data row0 col0\" >0.508</td>\n",
       "                        <td id=\"T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row0_col1\" class=\"data row0 col1\" >0.574</td>\n",
       "                        <td id=\"T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row0_col2\" class=\"data row0 col2\" >1.235</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                        <th id=\"T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1level2_row1\" class=\"row_heading level2 row1\" >tanh</th>\n",
       "                        <td id=\"T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row1_col0\" class=\"data row1 col0\" >0.509</td>\n",
       "                        <td id=\"T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row1_col1\" class=\"data row1 col1\" >0.575</td>\n",
       "                        <td id=\"T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row1_col2\" class=\"data row1 col2\" >1.234</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1level1_row2\" class=\"row_heading level1 row2\" rowspan=2>0.01</th>\n",
       "                        <th id=\"T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1level2_row2\" class=\"row_heading level2 row2\" >relu</th>\n",
       "                        <td id=\"T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row2_col0\" class=\"data row2 col0\" >0.509</td>\n",
       "                        <td id=\"T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row2_col1\" class=\"data row2 col1\" >0.575</td>\n",
       "                        <td id=\"T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row2_col2\" class=\"data row2 col2\" >1.234</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                        <th id=\"T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1level2_row3\" class=\"row_heading level2 row3\" >tanh</th>\n",
       "                        <td id=\"T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row3_col0\" class=\"data row3 col0\" >0.508</td>\n",
       "                        <td id=\"T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row3_col1\" class=\"data row3 col1\" >0.574</td>\n",
       "                        <td id=\"T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row3_col2\" class=\"data row3 col2\" >1.234</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1level1_row4\" class=\"row_heading level1 row4\" rowspan=2>0.1</th>\n",
       "                        <th id=\"T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1level2_row4\" class=\"row_heading level2 row4\" >relu</th>\n",
       "                        <td id=\"T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row4_col0\" class=\"data row4 col0\" >0.509</td>\n",
       "                        <td id=\"T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row4_col1\" class=\"data row4 col1\" >0.575</td>\n",
       "                        <td id=\"T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row4_col2\" class=\"data row4 col2\" >1.235</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                        <th id=\"T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1level2_row5\" class=\"row_heading level2 row5\" >tanh</th>\n",
       "                        <td id=\"T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row5_col0\" class=\"data row5 col0\" >0.509</td>\n",
       "                        <td id=\"T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row5_col1\" class=\"data row5 col1\" >0.575</td>\n",
       "                        <td id=\"T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row5_col2\" class=\"data row5 col2\" >1.232</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1level0_row6\" class=\"row_heading level0 row6\" rowspan=6>l2</th>\n",
       "                        <th id=\"T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1level1_row6\" class=\"row_heading level1 row6\" rowspan=2>0.001</th>\n",
       "                        <th id=\"T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1level2_row6\" class=\"row_heading level2 row6\" >relu</th>\n",
       "                        <td id=\"T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row6_col0\" class=\"data row6 col0\" >0.429</td>\n",
       "                        <td id=\"T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row6_col1\" class=\"data row6 col1\" >0.502</td>\n",
       "                        <td id=\"T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row6_col2\" class=\"data row6 col2\" >0.501</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                        <th id=\"T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1level2_row7\" class=\"row_heading level2 row7\" >tanh</th>\n",
       "                        <td id=\"T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row7_col0\" class=\"data row7 col0\" >0.414</td>\n",
       "                        <td id=\"T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row7_col1\" class=\"data row7 col1\" >0.501</td>\n",
       "                        <td id=\"T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row7_col2\" class=\"data row7 col2\" >0.501</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1level1_row8\" class=\"row_heading level1 row8\" rowspan=2>0.01</th>\n",
       "                        <th id=\"T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1level2_row8\" class=\"row_heading level2 row8\" >relu</th>\n",
       "                        <td id=\"T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row8_col0\" class=\"data row8 col0\" >0.424</td>\n",
       "                        <td id=\"T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row8_col1\" class=\"data row8 col1\" >0.501</td>\n",
       "                        <td id=\"T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row8_col2\" class=\"data row8 col2\" >0.501</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                        <th id=\"T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1level2_row9\" class=\"row_heading level2 row9\" >tanh</th>\n",
       "                        <td id=\"T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row9_col0\" class=\"data row9 col0\" >0.414</td>\n",
       "                        <td id=\"T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row9_col1\" class=\"data row9 col1\" >0.501</td>\n",
       "                        <td id=\"T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row9_col2\" class=\"data row9 col2\" >0.501</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1level1_row10\" class=\"row_heading level1 row10\" rowspan=2>0.1</th>\n",
       "                        <th id=\"T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1level2_row10\" class=\"row_heading level2 row10\" >relu</th>\n",
       "                        <td id=\"T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row10_col0\" class=\"data row10 col0\" >0.428</td>\n",
       "                        <td id=\"T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row10_col1\" class=\"data row10 col1\" >0.501</td>\n",
       "                        <td id=\"T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row10_col2\" class=\"data row10 col2\" >0.502</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                        <th id=\"T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1level2_row11\" class=\"row_heading level2 row11\" >tanh</th>\n",
       "                        <td id=\"T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row11_col0\" class=\"data row11 col0\" >0.415</td>\n",
       "                        <td id=\"T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row11_col1\" class=\"data row11 col1\" >0.501</td>\n",
       "                        <td id=\"T_52bbc2c2_8dbb_11ea_a150_a683e795f3a1row11_col2\" class=\"data row11 col2\" >0.501</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x17fa65bd0>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_pivot = (grid_search_df\n",
    "                     .pivot_table(values=['validation loss'],\n",
    "                                  columns=['lambda'],\n",
    "                                  index=['reg type', 'dropout rate', 'activation']))\n",
    "grid_search_pivot.style.format('{:.3f}').background_gradient(cmap='magma_r',\n",
    "                                                             axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: activation: tanh, reg type: l2, lambda: 0.001, dropout rate: 0.001\n"
     ]
    }
   ],
   "source": [
    "print('Best parameters: activation: {}, reg type: {}, lambda: {}, ' \n",
    "      'dropout rate: {}'.format('tanh', 'l2', 0.001, 0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0647200bcd9e45c48af26e01e7f14191",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=1.0), HTML(value='')), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe4cc10771a64d03af011aed450c3856",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=1.0), HTML(value='')), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6bb65d744d841d889cd7e5ba48c55c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=1.0), HTML(value='')), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training for dr=0.001, l_lambda=1.0e-03, reg_type=l2, act: tanh\n",
      "Train on 172 samples, validate on 43 samples\n",
      "Epoch 1/200\n",
      "172/172 [==============================] - 1s 7ms/sample - loss: 0.6438 - accuracy: 0.6667 - val_loss: 0.6216 - val_accuracy: 0.6667\n",
      "Epoch 2/200\n",
      "172/172 [==============================] - 0s 787us/sample - loss: 0.6059 - accuracy: 0.6667 - val_loss: 0.5895 - val_accuracy: 0.6667\n",
      "Epoch 3/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 0.5760 - accuracy: 0.6667 - val_loss: 0.5600 - val_accuracy: 0.6589\n",
      "Epoch 4/200\n",
      "172/172 [==============================] - 0s 751us/sample - loss: 0.5498 - accuracy: 0.7733 - val_loss: 0.5373 - val_accuracy: 0.7829\n",
      "Epoch 5/200\n",
      "172/172 [==============================] - 0s 703us/sample - loss: 0.5337 - accuracy: 0.7791 - val_loss: 0.5241 - val_accuracy: 0.7829\n",
      "Epoch 6/200\n",
      "172/172 [==============================] - 0s 723us/sample - loss: 0.5261 - accuracy: 0.7791 - val_loss: 0.5197 - val_accuracy: 0.7829\n",
      "Epoch 7/200\n",
      "172/172 [==============================] - 0s 712us/sample - loss: 0.5234 - accuracy: 0.7791 - val_loss: 0.5158 - val_accuracy: 0.7829\n",
      "Epoch 8/200\n",
      "172/172 [==============================] - 0s 752us/sample - loss: 0.5216 - accuracy: 0.7791 - val_loss: 0.5153 - val_accuracy: 0.7829\n",
      "Epoch 9/200\n",
      "172/172 [==============================] - 0s 796us/sample - loss: 0.5201 - accuracy: 0.7791 - val_loss: 0.5133 - val_accuracy: 0.7829\n",
      "Epoch 10/200\n",
      "172/172 [==============================] - 0s 735us/sample - loss: 0.5193 - accuracy: 0.7791 - val_loss: 0.5122 - val_accuracy: 0.7829\n",
      "Epoch 11/200\n",
      "172/172 [==============================] - 0s 718us/sample - loss: 0.5181 - accuracy: 0.7791 - val_loss: 0.5111 - val_accuracy: 0.7829\n",
      "Epoch 12/200\n",
      "172/172 [==============================] - 0s 718us/sample - loss: 0.5171 - accuracy: 0.7791 - val_loss: 0.5105 - val_accuracy: 0.7829\n",
      "Epoch 13/200\n",
      "172/172 [==============================] - 0s 711us/sample - loss: 0.5170 - accuracy: 0.7791 - val_loss: 0.5099 - val_accuracy: 0.7829\n",
      "Epoch 14/200\n",
      "172/172 [==============================] - 0s 758us/sample - loss: 0.5168 - accuracy: 0.7791 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 15/200\n",
      "172/172 [==============================] - 0s 849us/sample - loss: 0.5162 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 16/200\n",
      "172/172 [==============================] - 0s 930us/sample - loss: 0.5158 - accuracy: 0.7791 - val_loss: 0.5082 - val_accuracy: 0.7829\n",
      "Epoch 17/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 0.5151 - accuracy: 0.7791 - val_loss: 0.5079 - val_accuracy: 0.7829\n",
      "Epoch 18/200\n",
      "172/172 [==============================] - 0s 788us/sample - loss: 0.5157 - accuracy: 0.7791 - val_loss: 0.5081 - val_accuracy: 0.7829\n",
      "Epoch 19/200\n",
      "172/172 [==============================] - 0s 771us/sample - loss: 0.5156 - accuracy: 0.7791 - val_loss: 0.5071 - val_accuracy: 0.7829\n",
      "Epoch 20/200\n",
      "172/172 [==============================] - 0s 716us/sample - loss: 0.5145 - accuracy: 0.7791 - val_loss: 0.5075 - val_accuracy: 0.7829\n",
      "Epoch 21/200\n",
      "172/172 [==============================] - 0s 785us/sample - loss: 0.5143 - accuracy: 0.7791 - val_loss: 0.5069 - val_accuracy: 0.7829\n",
      "Epoch 22/200\n",
      "172/172 [==============================] - 0s 759us/sample - loss: 0.5144 - accuracy: 0.7791 - val_loss: 0.5068 - val_accuracy: 0.7829\n",
      "Epoch 23/200\n",
      "172/172 [==============================] - 0s 720us/sample - loss: 0.5147 - accuracy: 0.7791 - val_loss: 0.5061 - val_accuracy: 0.7829\n",
      "Epoch 24/200\n",
      "172/172 [==============================] - 0s 720us/sample - loss: 0.5137 - accuracy: 0.7791 - val_loss: 0.5062 - val_accuracy: 0.7829\n",
      "Epoch 25/200\n",
      "172/172 [==============================] - 0s 718us/sample - loss: 0.5132 - accuracy: 0.7791 - val_loss: 0.5059 - val_accuracy: 0.7829\n",
      "Epoch 26/200\n",
      "172/172 [==============================] - 0s 715us/sample - loss: 0.5133 - accuracy: 0.7791 - val_loss: 0.5055 - val_accuracy: 0.7829\n",
      "Epoch 27/200\n",
      "172/172 [==============================] - 0s 756us/sample - loss: 0.5128 - accuracy: 0.7791 - val_loss: 0.5052 - val_accuracy: 0.7829\n",
      "Epoch 28/200\n",
      "172/172 [==============================] - 0s 738us/sample - loss: 0.5137 - accuracy: 0.7791 - val_loss: 0.5052 - val_accuracy: 0.7829\n",
      "Epoch 29/200\n",
      "172/172 [==============================] - 0s 744us/sample - loss: 0.5125 - accuracy: 0.7791 - val_loss: 0.5054 - val_accuracy: 0.7829\n",
      "Epoch 30/200\n",
      "172/172 [==============================] - 0s 802us/sample - loss: 0.5123 - accuracy: 0.7791 - val_loss: 0.5063 - val_accuracy: 0.7829\n",
      "Epoch 31/200\n",
      "172/172 [==============================] - 0s 800us/sample - loss: 0.5123 - accuracy: 0.7791 - val_loss: 0.5055 - val_accuracy: 0.7829\n",
      "Epoch 32/200\n",
      "172/172 [==============================] - 0s 840us/sample - loss: 0.5135 - accuracy: 0.7791 - val_loss: 0.5049 - val_accuracy: 0.7829\n",
      "Epoch 33/200\n",
      "172/172 [==============================] - 0s 816us/sample - loss: 0.5123 - accuracy: 0.7791 - val_loss: 0.5045 - val_accuracy: 0.7829\n",
      "Epoch 34/200\n",
      "172/172 [==============================] - 0s 807us/sample - loss: 0.5125 - accuracy: 0.7791 - val_loss: 0.5046 - val_accuracy: 0.7829\n",
      "Epoch 35/200\n",
      "172/172 [==============================] - 0s 743us/sample - loss: 0.5123 - accuracy: 0.7791 - val_loss: 0.5042 - val_accuracy: 0.7829\n",
      "Epoch 36/200\n",
      "172/172 [==============================] - 0s 762us/sample - loss: 0.5114 - accuracy: 0.7791 - val_loss: 0.5040 - val_accuracy: 0.7829\n",
      "Epoch 37/200\n",
      "172/172 [==============================] - 0s 777us/sample - loss: 0.5115 - accuracy: 0.7791 - val_loss: 0.5042 - val_accuracy: 0.7829\n",
      "Epoch 38/200\n",
      "172/172 [==============================] - 0s 789us/sample - loss: 0.5126 - accuracy: 0.7791 - val_loss: 0.5045 - val_accuracy: 0.7829\n",
      "Epoch 39/200\n",
      "172/172 [==============================] - 0s 808us/sample - loss: 0.5122 - accuracy: 0.7791 - val_loss: 0.5037 - val_accuracy: 0.7829\n",
      "Epoch 40/200\n",
      "172/172 [==============================] - 0s 794us/sample - loss: 0.5116 - accuracy: 0.7791 - val_loss: 0.5034 - val_accuracy: 0.7829\n",
      "Epoch 41/200\n",
      "172/172 [==============================] - 0s 815us/sample - loss: 0.5118 - accuracy: 0.7791 - val_loss: 0.5036 - val_accuracy: 0.7829\n",
      "Epoch 42/200\n",
      "172/172 [==============================] - 0s 815us/sample - loss: 0.5107 - accuracy: 0.7791 - val_loss: 0.5031 - val_accuracy: 0.7829\n",
      "Epoch 43/200\n",
      "172/172 [==============================] - 0s 822us/sample - loss: 0.5107 - accuracy: 0.7791 - val_loss: 0.5031 - val_accuracy: 0.7829\n",
      "Epoch 44/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 0.5117 - accuracy: 0.7791 - val_loss: 0.5031 - val_accuracy: 0.7829\n",
      "Epoch 45/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.5110 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 46/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.5111 - accuracy: 0.7791 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 47/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5021 - val_accuracy: 0.7829\n",
      "Epoch 48/200\n",
      "172/172 [==============================] - 0s 930us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 49/200\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 0.5102 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 50/200\n",
      "172/172 [==============================] - 0s 835us/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 51/200\n",
      "172/172 [==============================] - 0s 840us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5013 - val_accuracy: 0.7829\n",
      "Epoch 52/200\n",
      "172/172 [==============================] - 0s 836us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 53/200\n",
      "172/172 [==============================] - 0s 833us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 54/200\n",
      "172/172 [==============================] - 0s 837us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5011 - val_accuracy: 0.7829\n",
      "Epoch 55/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 875us/sample - loss: 0.5089 - accuracy: 0.7791 - val_loss: 0.5011 - val_accuracy: 0.7829\n",
      "Epoch 56/200\n",
      "172/172 [==============================] - 0s 837us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5008 - val_accuracy: 0.7829\n",
      "Epoch 57/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.5101 - accuracy: 0.7810 - val_loss: 0.5010 - val_accuracy: 0.7829\n",
      "Epoch 58/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.5097 - accuracy: 0.7810 - val_loss: 0.5008 - val_accuracy: 0.7829\n",
      "Epoch 59/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5000 - val_accuracy: 0.7829\n",
      "Epoch 60/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.5096 - accuracy: 0.7791 - val_loss: 0.4998 - val_accuracy: 0.7829\n",
      "Epoch 61/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.5091 - accuracy: 0.7810 - val_loss: 0.4998 - val_accuracy: 0.7829\n",
      "Epoch 62/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 0.5090 - accuracy: 0.7810 - val_loss: 0.4996 - val_accuracy: 0.7829\n",
      "Epoch 63/200\n",
      "172/172 [==============================] - 0s 825us/sample - loss: 0.5091 - accuracy: 0.7810 - val_loss: 0.5002 - val_accuracy: 0.7829\n",
      "Epoch 64/200\n",
      "172/172 [==============================] - 0s 806us/sample - loss: 0.5084 - accuracy: 0.7810 - val_loss: 0.5002 - val_accuracy: 0.7829\n",
      "Epoch 65/200\n",
      "172/172 [==============================] - 0s 798us/sample - loss: 0.5081 - accuracy: 0.7810 - val_loss: 0.5000 - val_accuracy: 0.7829\n",
      "Epoch 66/200\n",
      "172/172 [==============================] - 0s 806us/sample - loss: 0.5089 - accuracy: 0.7810 - val_loss: 0.4994 - val_accuracy: 0.7829\n",
      "Epoch 67/200\n",
      "172/172 [==============================] - 0s 806us/sample - loss: 0.5073 - accuracy: 0.7810 - val_loss: 0.4993 - val_accuracy: 0.7829\n",
      "Epoch 68/200\n",
      "172/172 [==============================] - 0s 805us/sample - loss: 0.5084 - accuracy: 0.7810 - val_loss: 0.4995 - val_accuracy: 0.7829\n",
      "Epoch 69/200\n",
      "172/172 [==============================] - 0s 808us/sample - loss: 0.5075 - accuracy: 0.7810 - val_loss: 0.4986 - val_accuracy: 0.7829\n",
      "Epoch 70/200\n",
      "172/172 [==============================] - 0s 803us/sample - loss: 0.5096 - accuracy: 0.7810 - val_loss: 0.4992 - val_accuracy: 0.7829\n",
      "Epoch 71/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.5077 - accuracy: 0.7810 - val_loss: 0.4984 - val_accuracy: 0.7829\n",
      "Epoch 72/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.5070 - accuracy: 0.7810 - val_loss: 0.4981 - val_accuracy: 0.7829\n",
      "Epoch 73/200\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 0.5066 - accuracy: 0.7810 - val_loss: 0.4979 - val_accuracy: 0.7829\n",
      "Epoch 74/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 0.5069 - accuracy: 0.7810 - val_loss: 0.4977 - val_accuracy: 0.7829\n",
      "Epoch 75/200\n",
      "172/172 [==============================] - 0s 856us/sample - loss: 0.5072 - accuracy: 0.7810 - val_loss: 0.4974 - val_accuracy: 0.7829\n",
      "Epoch 76/200\n",
      "172/172 [==============================] - 0s 804us/sample - loss: 0.5062 - accuracy: 0.7810 - val_loss: 0.4973 - val_accuracy: 0.7829\n",
      "Epoch 77/200\n",
      "172/172 [==============================] - 0s 817us/sample - loss: 0.5080 - accuracy: 0.7810 - val_loss: 0.4973 - val_accuracy: 0.7829\n",
      "Epoch 78/200\n",
      "172/172 [==============================] - 0s 807us/sample - loss: 0.5068 - accuracy: 0.7810 - val_loss: 0.4971 - val_accuracy: 0.7829\n",
      "Epoch 79/200\n",
      "172/172 [==============================] - 0s 793us/sample - loss: 0.5060 - accuracy: 0.7810 - val_loss: 0.4968 - val_accuracy: 0.7829\n",
      "Epoch 80/200\n",
      "172/172 [==============================] - 0s 779us/sample - loss: 0.5072 - accuracy: 0.7810 - val_loss: 0.4967 - val_accuracy: 0.7829\n",
      "Epoch 81/200\n",
      "172/172 [==============================] - 0s 784us/sample - loss: 0.5059 - accuracy: 0.7810 - val_loss: 0.4966 - val_accuracy: 0.7829\n",
      "Epoch 82/200\n",
      "172/172 [==============================] - 0s 777us/sample - loss: 0.5056 - accuracy: 0.7810 - val_loss: 0.4963 - val_accuracy: 0.7829\n",
      "Epoch 83/200\n",
      "172/172 [==============================] - 0s 782us/sample - loss: 0.5054 - accuracy: 0.7810 - val_loss: 0.4962 - val_accuracy: 0.7829\n",
      "Epoch 84/200\n",
      "172/172 [==============================] - 0s 790us/sample - loss: 0.5060 - accuracy: 0.7810 - val_loss: 0.4962 - val_accuracy: 0.7829\n",
      "Epoch 85/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.5054 - accuracy: 0.7810 - val_loss: 0.4971 - val_accuracy: 0.7829\n",
      "Epoch 86/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.5057 - accuracy: 0.7810 - val_loss: 0.4963 - val_accuracy: 0.7829\n",
      "Epoch 87/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.5051 - accuracy: 0.7810 - val_loss: 0.4964 - val_accuracy: 0.7829\n",
      "Epoch 88/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.5051 - accuracy: 0.7810 - val_loss: 0.4964 - val_accuracy: 0.7829\n",
      "Epoch 89/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.5049 - accuracy: 0.7810 - val_loss: 0.4958 - val_accuracy: 0.7829\n",
      "Epoch 90/200\n",
      "172/172 [==============================] - 0s 835us/sample - loss: 0.5044 - accuracy: 0.7810 - val_loss: 0.4949 - val_accuracy: 0.7829\n",
      "Epoch 91/200\n",
      "172/172 [==============================] - 0s 809us/sample - loss: 0.5039 - accuracy: 0.7810 - val_loss: 0.4948 - val_accuracy: 0.7829\n",
      "Epoch 92/200\n",
      "172/172 [==============================] - 0s 800us/sample - loss: 0.5044 - accuracy: 0.7810 - val_loss: 0.4944 - val_accuracy: 0.7829\n",
      "Epoch 93/200\n",
      "172/172 [==============================] - 0s 811us/sample - loss: 0.5048 - accuracy: 0.7810 - val_loss: 0.4946 - val_accuracy: 0.7829\n",
      "Epoch 94/200\n",
      "172/172 [==============================] - 0s 801us/sample - loss: 0.5037 - accuracy: 0.7810 - val_loss: 0.4940 - val_accuracy: 0.7829\n",
      "Epoch 95/200\n",
      "172/172 [==============================] - 0s 805us/sample - loss: 0.5039 - accuracy: 0.7810 - val_loss: 0.4939 - val_accuracy: 0.7829\n",
      "Epoch 96/200\n",
      "172/172 [==============================] - 0s 801us/sample - loss: 0.5034 - accuracy: 0.7810 - val_loss: 0.4935 - val_accuracy: 0.7829\n",
      "Epoch 97/200\n",
      "172/172 [==============================] - 0s 810us/sample - loss: 0.5044 - accuracy: 0.7810 - val_loss: 0.4946 - val_accuracy: 0.7829\n",
      "Epoch 98/200\n",
      "172/172 [==============================] - 0s 808us/sample - loss: 0.5034 - accuracy: 0.7810 - val_loss: 0.4932 - val_accuracy: 0.7829\n",
      "Epoch 99/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.5021 - accuracy: 0.7810 - val_loss: 0.4934 - val_accuracy: 0.7829\n",
      "Epoch 100/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 0.5025 - accuracy: 0.7791 - val_loss: 0.4938 - val_accuracy: 0.7829\n",
      "Epoch 101/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5042 - accuracy: 0.7791 - val_loss: 0.4939 - val_accuracy: 0.7829\n",
      "Epoch 102/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.5034 - accuracy: 0.7791 - val_loss: 0.4928 - val_accuracy: 0.7829\n",
      "Epoch 103/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.5018 - accuracy: 0.7791 - val_loss: 0.4930 - val_accuracy: 0.7829\n",
      "Epoch 104/200\n",
      "172/172 [==============================] - 0s 830us/sample - loss: 0.5026 - accuracy: 0.7791 - val_loss: 0.4920 - val_accuracy: 0.7829\n",
      "Epoch 105/200\n",
      "172/172 [==============================] - 0s 802us/sample - loss: 0.5023 - accuracy: 0.7791 - val_loss: 0.4919 - val_accuracy: 0.7829\n",
      "Epoch 106/200\n",
      "172/172 [==============================] - 0s 809us/sample - loss: 0.5030 - accuracy: 0.7810 - val_loss: 0.4913 - val_accuracy: 0.7829\n",
      "Epoch 107/200\n",
      "172/172 [==============================] - 0s 807us/sample - loss: 0.5014 - accuracy: 0.7810 - val_loss: 0.4910 - val_accuracy: 0.7829\n",
      "Epoch 108/200\n",
      "172/172 [==============================] - 0s 821us/sample - loss: 0.5011 - accuracy: 0.7791 - val_loss: 0.4906 - val_accuracy: 0.7829\n",
      "Epoch 109/200\n",
      "172/172 [==============================] - 0s 807us/sample - loss: 0.5009 - accuracy: 0.7791 - val_loss: 0.4903 - val_accuracy: 0.7829\n",
      "Epoch 110/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 820us/sample - loss: 0.5016 - accuracy: 0.7791 - val_loss: 0.4910 - val_accuracy: 0.7829\n",
      "Epoch 111/200\n",
      "172/172 [==============================] - 0s 801us/sample - loss: 0.5036 - accuracy: 0.7810 - val_loss: 0.4916 - val_accuracy: 0.7907\n",
      "Epoch 112/200\n",
      "172/172 [==============================] - 0s 810us/sample - loss: 0.5010 - accuracy: 0.7791 - val_loss: 0.4900 - val_accuracy: 0.7829\n",
      "Epoch 113/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.5008 - accuracy: 0.7791 - val_loss: 0.4893 - val_accuracy: 0.7829\n",
      "Epoch 114/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.4990 - accuracy: 0.7791 - val_loss: 0.4893 - val_accuracy: 0.7829\n",
      "Epoch 115/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.4985 - accuracy: 0.7791 - val_loss: 0.4909 - val_accuracy: 0.7907\n",
      "Epoch 116/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 0.5010 - accuracy: 0.7810 - val_loss: 0.4900 - val_accuracy: 0.7907\n",
      "Epoch 117/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 0.5030 - accuracy: 0.7791 - val_loss: 0.4880 - val_accuracy: 0.7829\n",
      "Epoch 118/200\n",
      "172/172 [==============================] - 0s 813us/sample - loss: 0.4987 - accuracy: 0.7791 - val_loss: 0.4878 - val_accuracy: 0.7829\n",
      "Epoch 119/200\n",
      "172/172 [==============================] - 0s 811us/sample - loss: 0.4999 - accuracy: 0.7791 - val_loss: 0.4879 - val_accuracy: 0.7907\n",
      "Epoch 120/200\n",
      "172/172 [==============================] - 0s 797us/sample - loss: 0.4980 - accuracy: 0.7791 - val_loss: 0.4868 - val_accuracy: 0.7829\n",
      "Epoch 121/200\n",
      "172/172 [==============================] - 0s 812us/sample - loss: 0.4988 - accuracy: 0.7791 - val_loss: 0.4870 - val_accuracy: 0.7907\n",
      "Epoch 122/200\n",
      "172/172 [==============================] - 0s 801us/sample - loss: 0.4985 - accuracy: 0.7810 - val_loss: 0.4884 - val_accuracy: 0.7907\n",
      "Epoch 123/200\n",
      "172/172 [==============================] - 0s 807us/sample - loss: 0.4970 - accuracy: 0.7810 - val_loss: 0.4855 - val_accuracy: 0.7907\n",
      "Epoch 124/200\n",
      "172/172 [==============================] - 0s 805us/sample - loss: 0.4968 - accuracy: 0.7791 - val_loss: 0.4851 - val_accuracy: 0.7907\n",
      "Epoch 125/200\n",
      "172/172 [==============================] - 0s 801us/sample - loss: 0.4965 - accuracy: 0.7791 - val_loss: 0.4849 - val_accuracy: 0.7907\n",
      "Epoch 126/200\n",
      "172/172 [==============================] - 0s 809us/sample - loss: 0.4970 - accuracy: 0.7791 - val_loss: 0.4848 - val_accuracy: 0.7907\n",
      "Epoch 127/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 0.4975 - accuracy: 0.7810 - val_loss: 0.4837 - val_accuracy: 0.7907\n",
      "Epoch 128/200\n",
      "172/172 [==============================] - 0s 859us/sample - loss: 0.4996 - accuracy: 0.7829 - val_loss: 0.4844 - val_accuracy: 0.7907\n",
      "Epoch 129/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.4953 - accuracy: 0.7829 - val_loss: 0.4836 - val_accuracy: 0.7907\n",
      "Epoch 130/200\n",
      "172/172 [==============================] - 0s 856us/sample - loss: 0.4948 - accuracy: 0.7829 - val_loss: 0.4841 - val_accuracy: 0.7907\n",
      "Epoch 131/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.4973 - accuracy: 0.7829 - val_loss: 0.4840 - val_accuracy: 0.7907\n",
      "Epoch 132/200\n",
      "172/172 [==============================] - 0s 800us/sample - loss: 0.4936 - accuracy: 0.7829 - val_loss: 0.4818 - val_accuracy: 0.7907\n",
      "Epoch 133/200\n",
      "172/172 [==============================] - 0s 786us/sample - loss: 0.4940 - accuracy: 0.7810 - val_loss: 0.4812 - val_accuracy: 0.7907\n",
      "Epoch 134/200\n",
      "172/172 [==============================] - 0s 782us/sample - loss: 0.4947 - accuracy: 0.7810 - val_loss: 0.4811 - val_accuracy: 0.7907\n",
      "Epoch 135/200\n",
      "172/172 [==============================] - 0s 778us/sample - loss: 0.4968 - accuracy: 0.7849 - val_loss: 0.4832 - val_accuracy: 0.7907\n",
      "Epoch 136/200\n",
      "172/172 [==============================] - 0s 789us/sample - loss: 0.4930 - accuracy: 0.7829 - val_loss: 0.4802 - val_accuracy: 0.7907\n",
      "Epoch 137/200\n",
      "172/172 [==============================] - 0s 784us/sample - loss: 0.5004 - accuracy: 0.7829 - val_loss: 0.4817 - val_accuracy: 0.7907\n",
      "Epoch 138/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.4963 - accuracy: 0.7810 - val_loss: 0.4797 - val_accuracy: 0.7907\n",
      "Epoch 139/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.4928 - accuracy: 0.7810 - val_loss: 0.4791 - val_accuracy: 0.7907\n",
      "Epoch 140/200\n",
      "172/172 [==============================] - 0s 864us/sample - loss: 0.4940 - accuracy: 0.7849 - val_loss: 0.4794 - val_accuracy: 0.7907\n",
      "Epoch 141/200\n",
      "172/172 [==============================] - 0s 973us/sample - loss: 0.4942 - accuracy: 0.7829 - val_loss: 0.4778 - val_accuracy: 0.7907\n",
      "Epoch 142/200\n",
      "172/172 [==============================] - 0s 943us/sample - loss: 0.4893 - accuracy: 0.7868 - val_loss: 0.4807 - val_accuracy: 0.7984\n",
      "Epoch 143/200\n",
      "172/172 [==============================] - 0s 972us/sample - loss: 0.4921 - accuracy: 0.7868 - val_loss: 0.4779 - val_accuracy: 0.7907\n",
      "Epoch 144/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 0.4905 - accuracy: 0.7849 - val_loss: 0.4764 - val_accuracy: 0.7907\n",
      "Epoch 145/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4901 - accuracy: 0.7868 - val_loss: 0.4782 - val_accuracy: 0.7984\n",
      "Epoch 146/200\n",
      "172/172 [==============================] - 0s 811us/sample - loss: 0.4910 - accuracy: 0.7829 - val_loss: 0.4753 - val_accuracy: 0.7907\n",
      "Epoch 147/200\n",
      "172/172 [==============================] - 0s 802us/sample - loss: 0.4893 - accuracy: 0.7829 - val_loss: 0.4791 - val_accuracy: 0.8062\n",
      "Epoch 148/200\n",
      "172/172 [==============================] - 0s 810us/sample - loss: 0.4883 - accuracy: 0.7829 - val_loss: 0.4750 - val_accuracy: 0.7907\n",
      "Epoch 149/200\n",
      "172/172 [==============================] - 0s 816us/sample - loss: 0.4880 - accuracy: 0.7849 - val_loss: 0.4740 - val_accuracy: 0.7907\n",
      "Epoch 150/200\n",
      "172/172 [==============================] - 0s 819us/sample - loss: 0.4889 - accuracy: 0.7868 - val_loss: 0.4738 - val_accuracy: 0.7984\n",
      "Epoch 151/200\n",
      "172/172 [==============================] - 0s 836us/sample - loss: 0.4866 - accuracy: 0.7868 - val_loss: 0.4733 - val_accuracy: 0.7984\n",
      "Epoch 152/200\n",
      "172/172 [==============================] - 0s 830us/sample - loss: 0.4875 - accuracy: 0.7868 - val_loss: 0.4749 - val_accuracy: 0.8062\n",
      "Epoch 153/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4876 - accuracy: 0.7849 - val_loss: 0.4717 - val_accuracy: 0.7984\n",
      "Epoch 154/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.4865 - accuracy: 0.7849 - val_loss: 0.4717 - val_accuracy: 0.7984\n",
      "Epoch 155/200\n",
      "172/172 [==============================] - 0s 989us/sample - loss: 0.4854 - accuracy: 0.7849 - val_loss: 0.4705 - val_accuracy: 0.7984\n",
      "Epoch 156/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4849 - accuracy: 0.7868 - val_loss: 0.4702 - val_accuracy: 0.7984\n",
      "Epoch 157/200\n",
      "172/172 [==============================] - 0s 977us/sample - loss: 0.4865 - accuracy: 0.7829 - val_loss: 0.4699 - val_accuracy: 0.7984\n",
      "Epoch 158/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.4947 - accuracy: 0.7829 - val_loss: 0.4688 - val_accuracy: 0.7984\n",
      "Epoch 159/200\n",
      "172/172 [==============================] - 0s 843us/sample - loss: 0.5004 - accuracy: 0.7946 - val_loss: 0.4740 - val_accuracy: 0.7907\n",
      "Epoch 160/200\n",
      "172/172 [==============================] - 0s 838us/sample - loss: 0.5030 - accuracy: 0.7829 - val_loss: 0.4688 - val_accuracy: 0.7907\n",
      "Epoch 161/200\n",
      "172/172 [==============================] - 0s 838us/sample - loss: 0.4859 - accuracy: 0.7926 - val_loss: 0.4746 - val_accuracy: 0.7984\n",
      "Epoch 162/200\n",
      "172/172 [==============================] - 0s 851us/sample - loss: 0.4881 - accuracy: 0.7868 - val_loss: 0.4674 - val_accuracy: 0.7984\n",
      "Epoch 163/200\n",
      "172/172 [==============================] - 0s 839us/sample - loss: 0.4832 - accuracy: 0.7888 - val_loss: 0.4685 - val_accuracy: 0.7984\n",
      "Epoch 164/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.4821 - accuracy: 0.7849 - val_loss: 0.4661 - val_accuracy: 0.7984\n",
      "Epoch 165/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 865us/sample - loss: 0.4802 - accuracy: 0.7849 - val_loss: 0.4673 - val_accuracy: 0.8062\n",
      "Epoch 166/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4841 - accuracy: 0.7926 - val_loss: 0.4676 - val_accuracy: 0.7907\n",
      "Epoch 167/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4815 - accuracy: 0.7888 - val_loss: 0.4649 - val_accuracy: 0.7984\n",
      "Epoch 168/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.4843 - accuracy: 0.7868 - val_loss: 0.4641 - val_accuracy: 0.7984\n",
      "Epoch 169/200\n",
      "172/172 [==============================] - 0s 967us/sample - loss: 0.4837 - accuracy: 0.7984 - val_loss: 0.4690 - val_accuracy: 0.8062\n",
      "Epoch 170/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4797 - accuracy: 0.7888 - val_loss: 0.4634 - val_accuracy: 0.8062\n",
      "Epoch 171/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 0.4783 - accuracy: 0.7926 - val_loss: 0.4625 - val_accuracy: 0.7984\n",
      "Epoch 172/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 0.4769 - accuracy: 0.7888 - val_loss: 0.4648 - val_accuracy: 0.7984\n",
      "Epoch 173/200\n",
      "172/172 [==============================] - 0s 807us/sample - loss: 0.4775 - accuracy: 0.7926 - val_loss: 0.4620 - val_accuracy: 0.7907\n",
      "Epoch 174/200\n",
      "172/172 [==============================] - 0s 807us/sample - loss: 0.4797 - accuracy: 0.7849 - val_loss: 0.4614 - val_accuracy: 0.7907\n",
      "Epoch 175/200\n",
      "172/172 [==============================] - 0s 807us/sample - loss: 0.4776 - accuracy: 0.7868 - val_loss: 0.4597 - val_accuracy: 0.7984\n",
      "Epoch 176/200\n",
      "172/172 [==============================] - 0s 832us/sample - loss: 0.4744 - accuracy: 0.7888 - val_loss: 0.4621 - val_accuracy: 0.7984\n",
      "Epoch 177/200\n",
      "172/172 [==============================] - 0s 817us/sample - loss: 0.4764 - accuracy: 0.7907 - val_loss: 0.4596 - val_accuracy: 0.8062\n",
      "Epoch 178/200\n",
      "172/172 [==============================] - 0s 849us/sample - loss: 0.4742 - accuracy: 0.7888 - val_loss: 0.4596 - val_accuracy: 0.7907\n",
      "Epoch 179/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4762 - accuracy: 0.7907 - val_loss: 0.4589 - val_accuracy: 0.7907\n",
      "Epoch 180/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 0.4730 - accuracy: 0.7907 - val_loss: 0.4598 - val_accuracy: 0.7984\n",
      "Epoch 181/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.4751 - accuracy: 0.8023 - val_loss: 0.4588 - val_accuracy: 0.7984\n",
      "Epoch 182/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.4729 - accuracy: 0.7888 - val_loss: 0.4566 - val_accuracy: 0.7984\n",
      "Epoch 183/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 0.4722 - accuracy: 0.7849 - val_loss: 0.4574 - val_accuracy: 0.7984\n",
      "Epoch 184/200\n",
      "172/172 [==============================] - 0s 835us/sample - loss: 0.4722 - accuracy: 0.7946 - val_loss: 0.4582 - val_accuracy: 0.7907\n",
      "Epoch 185/200\n",
      "172/172 [==============================] - 0s 805us/sample - loss: 0.4739 - accuracy: 0.7907 - val_loss: 0.4561 - val_accuracy: 0.7984\n",
      "Epoch 186/200\n",
      "172/172 [==============================] - 0s 814us/sample - loss: 0.4714 - accuracy: 0.7926 - val_loss: 0.4576 - val_accuracy: 0.8062\n",
      "Epoch 187/200\n",
      "172/172 [==============================] - 0s 956us/sample - loss: 0.4751 - accuracy: 0.8140 - val_loss: 0.4575 - val_accuracy: 0.8062\n",
      "Epoch 188/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.4706 - accuracy: 0.7888 - val_loss: 0.4542 - val_accuracy: 0.7984\n",
      "Epoch 189/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 0.4712 - accuracy: 0.8043 - val_loss: 0.4583 - val_accuracy: 0.8062\n",
      "Epoch 190/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 0.4695 - accuracy: 0.7965 - val_loss: 0.4548 - val_accuracy: 0.7907\n",
      "Epoch 191/200\n",
      "172/172 [==============================] - 0s 807us/sample - loss: 0.4707 - accuracy: 0.7888 - val_loss: 0.4578 - val_accuracy: 0.8062\n",
      "Epoch 192/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.4692 - accuracy: 0.8120 - val_loss: 0.4549 - val_accuracy: 0.8062\n",
      "Epoch 193/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4679 - accuracy: 0.7984 - val_loss: 0.4540 - val_accuracy: 0.8062\n",
      "Epoch 194/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4689 - accuracy: 0.7984 - val_loss: 0.4521 - val_accuracy: 0.7984\n",
      "Epoch 195/200\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 0.4684 - accuracy: 0.8023 - val_loss: 0.4521 - val_accuracy: 0.7907\n",
      "Epoch 196/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4672 - accuracy: 0.7965 - val_loss: 0.4523 - val_accuracy: 0.7907\n",
      "Epoch 197/200\n",
      "172/172 [==============================] - 0s 835us/sample - loss: 0.4666 - accuracy: 0.8004 - val_loss: 0.4535 - val_accuracy: 0.8062\n",
      "Epoch 198/200\n",
      "172/172 [==============================] - 0s 858us/sample - loss: 0.4712 - accuracy: 0.8004 - val_loss: 0.4508 - val_accuracy: 0.7984\n",
      "Epoch 199/200\n",
      "172/172 [==============================] - 0s 945us/sample - loss: 0.4659 - accuracy: 0.8062 - val_loss: 0.4557 - val_accuracy: 0.8062\n",
      "Epoch 200/200\n",
      "172/172 [==============================] - 0s 844us/sample - loss: 0.4670 - accuracy: 0.7984 - val_loss: 0.4511 - val_accuracy: 0.8062\n",
      "Beginning training for dr=0.001, l_lambda=1.0e-03, reg_type=l2, act: tanh\n",
      "Train on 172 samples, validate on 43 samples\n",
      "Epoch 1/200\n",
      "172/172 [==============================] - 2s 10ms/sample - loss: 0.6371 - accuracy: 0.6667 - val_loss: 0.5870 - val_accuracy: 0.6667\n",
      "Epoch 2/200\n",
      "172/172 [==============================] - 0s 774us/sample - loss: 0.5564 - accuracy: 0.7248 - val_loss: 0.5240 - val_accuracy: 0.7829\n",
      "Epoch 3/200\n",
      "172/172 [==============================] - 0s 849us/sample - loss: 0.5255 - accuracy: 0.7791 - val_loss: 0.5151 - val_accuracy: 0.7829\n",
      "Epoch 4/200\n",
      "172/172 [==============================] - 0s 827us/sample - loss: 0.5195 - accuracy: 0.7791 - val_loss: 0.5114 - val_accuracy: 0.7829\n",
      "Epoch 5/200\n",
      "172/172 [==============================] - 0s 791us/sample - loss: 0.5175 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7829\n",
      "Epoch 6/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 0.5170 - accuracy: 0.7791 - val_loss: 0.5084 - val_accuracy: 0.7829\n",
      "Epoch 7/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.5151 - accuracy: 0.7791 - val_loss: 0.5072 - val_accuracy: 0.7829\n",
      "Epoch 8/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.5148 - accuracy: 0.7791 - val_loss: 0.5060 - val_accuracy: 0.7829\n",
      "Epoch 9/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.5136 - accuracy: 0.7791 - val_loss: 0.5052 - val_accuracy: 0.7829\n",
      "Epoch 10/200\n",
      "172/172 [==============================] - 0s 869us/sample - loss: 0.5138 - accuracy: 0.7791 - val_loss: 0.5046 - val_accuracy: 0.7829\n",
      "Epoch 11/200\n",
      "172/172 [==============================] - 0s 804us/sample - loss: 0.5122 - accuracy: 0.7791 - val_loss: 0.5038 - val_accuracy: 0.7829\n",
      "Epoch 12/200\n",
      "172/172 [==============================] - 0s 840us/sample - loss: 0.5115 - accuracy: 0.7791 - val_loss: 0.5031 - val_accuracy: 0.7829\n",
      "Epoch 13/200\n",
      "172/172 [==============================] - 0s 805us/sample - loss: 0.5111 - accuracy: 0.7791 - val_loss: 0.5025 - val_accuracy: 0.7829\n",
      "Epoch 14/200\n",
      "172/172 [==============================] - 0s 809us/sample - loss: 0.5120 - accuracy: 0.7791 - val_loss: 0.5028 - val_accuracy: 0.7829\n",
      "Epoch 15/200\n",
      "172/172 [==============================] - 0s 821us/sample - loss: 0.5140 - accuracy: 0.7791 - val_loss: 0.5023 - val_accuracy: 0.7829\n",
      "Epoch 16/200\n",
      "172/172 [==============================] - 0s 798us/sample - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.5010 - val_accuracy: 0.7829\n",
      "Epoch 17/200\n",
      "172/172 [==============================] - 0s 799us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5011 - val_accuracy: 0.7829\n",
      "Epoch 18/200\n",
      "172/172 [==============================] - 0s 805us/sample - loss: 0.5102 - accuracy: 0.7791 - val_loss: 0.5028 - val_accuracy: 0.7829\n",
      "Epoch 19/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 817us/sample - loss: 0.5074 - accuracy: 0.7791 - val_loss: 0.5000 - val_accuracy: 0.7829\n",
      "Epoch 20/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.5072 - accuracy: 0.7791 - val_loss: 0.4997 - val_accuracy: 0.7829\n",
      "Epoch 21/200\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 0.5095 - accuracy: 0.7791 - val_loss: 0.4986 - val_accuracy: 0.7829\n",
      "Epoch 22/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5063 - accuracy: 0.7791 - val_loss: 0.4978 - val_accuracy: 0.7829\n",
      "Epoch 23/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.5079 - accuracy: 0.7791 - val_loss: 0.4969 - val_accuracy: 0.7829\n",
      "Epoch 24/200\n",
      "172/172 [==============================] - 0s 906us/sample - loss: 0.5066 - accuracy: 0.7791 - val_loss: 0.4964 - val_accuracy: 0.7829\n",
      "Epoch 25/200\n",
      "172/172 [==============================] - 0s 842us/sample - loss: 0.5062 - accuracy: 0.7791 - val_loss: 0.4956 - val_accuracy: 0.7829\n",
      "Epoch 26/200\n",
      "172/172 [==============================] - 0s 836us/sample - loss: 0.5067 - accuracy: 0.7791 - val_loss: 0.4945 - val_accuracy: 0.7829\n",
      "Epoch 27/200\n",
      "172/172 [==============================] - 0s 860us/sample - loss: 0.5028 - accuracy: 0.7791 - val_loss: 0.4936 - val_accuracy: 0.7829\n",
      "Epoch 28/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 0.5063 - accuracy: 0.7810 - val_loss: 0.4934 - val_accuracy: 0.7829\n",
      "Epoch 29/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.5070 - accuracy: 0.7810 - val_loss: 0.4924 - val_accuracy: 0.7829\n",
      "Epoch 30/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.5019 - accuracy: 0.7810 - val_loss: 0.4910 - val_accuracy: 0.7829\n",
      "Epoch 31/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.5002 - accuracy: 0.7810 - val_loss: 0.4917 - val_accuracy: 0.7829\n",
      "Epoch 32/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.4980 - accuracy: 0.7791 - val_loss: 0.4878 - val_accuracy: 0.7829\n",
      "Epoch 33/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4977 - accuracy: 0.7810 - val_loss: 0.4863 - val_accuracy: 0.7829\n",
      "Epoch 34/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 0.4982 - accuracy: 0.7791 - val_loss: 0.4844 - val_accuracy: 0.7829\n",
      "Epoch 35/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4943 - accuracy: 0.7791 - val_loss: 0.4825 - val_accuracy: 0.7907\n",
      "Epoch 36/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4940 - accuracy: 0.7791 - val_loss: 0.4818 - val_accuracy: 0.7907\n",
      "Epoch 37/200\n",
      "172/172 [==============================] - 0s 957us/sample - loss: 0.4900 - accuracy: 0.7791 - val_loss: 0.4781 - val_accuracy: 0.7907\n",
      "Epoch 38/200\n",
      "172/172 [==============================] - 0s 862us/sample - loss: 0.4930 - accuracy: 0.7829 - val_loss: 0.4757 - val_accuracy: 0.7907\n",
      "Epoch 39/200\n",
      "172/172 [==============================] - 0s 860us/sample - loss: 0.4880 - accuracy: 0.7829 - val_loss: 0.4737 - val_accuracy: 0.7907\n",
      "Epoch 40/200\n",
      "172/172 [==============================] - 0s 860us/sample - loss: 0.4912 - accuracy: 0.7810 - val_loss: 0.4722 - val_accuracy: 0.7984\n",
      "Epoch 41/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.4860 - accuracy: 0.7849 - val_loss: 0.4710 - val_accuracy: 0.8062\n",
      "Epoch 42/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 0.4821 - accuracy: 0.7849 - val_loss: 0.4678 - val_accuracy: 0.7984\n",
      "Epoch 43/200\n",
      "172/172 [==============================] - 0s 835us/sample - loss: 0.4802 - accuracy: 0.7868 - val_loss: 0.4673 - val_accuracy: 0.7984\n",
      "Epoch 44/200\n",
      "172/172 [==============================] - 0s 838us/sample - loss: 0.4867 - accuracy: 0.8004 - val_loss: 0.4640 - val_accuracy: 0.7984\n",
      "Epoch 45/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.4807 - accuracy: 0.7984 - val_loss: 0.4680 - val_accuracy: 0.8062\n",
      "Epoch 46/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.4771 - accuracy: 0.7868 - val_loss: 0.4590 - val_accuracy: 0.7984\n",
      "Epoch 47/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.4752 - accuracy: 0.8081 - val_loss: 0.4589 - val_accuracy: 0.7907\n",
      "Epoch 48/200\n",
      "172/172 [==============================] - 0s 971us/sample - loss: 0.4733 - accuracy: 0.7888 - val_loss: 0.4558 - val_accuracy: 0.7907\n",
      "Epoch 49/200\n",
      "172/172 [==============================] - 0s 951us/sample - loss: 0.4743 - accuracy: 0.8062 - val_loss: 0.4557 - val_accuracy: 0.7984\n",
      "Epoch 50/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.4846 - accuracy: 0.7810 - val_loss: 0.4627 - val_accuracy: 0.8062\n",
      "Epoch 51/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.4727 - accuracy: 0.8120 - val_loss: 0.4523 - val_accuracy: 0.7984\n",
      "Epoch 52/200\n",
      "172/172 [==============================] - 0s 841us/sample - loss: 0.4690 - accuracy: 0.7868 - val_loss: 0.4568 - val_accuracy: 0.8062\n",
      "Epoch 53/200\n",
      "172/172 [==============================] - 0s 835us/sample - loss: 0.4747 - accuracy: 0.8043 - val_loss: 0.4512 - val_accuracy: 0.7984\n",
      "Epoch 54/200\n",
      "172/172 [==============================] - 0s 839us/sample - loss: 0.4680 - accuracy: 0.7965 - val_loss: 0.4534 - val_accuracy: 0.8062\n",
      "Epoch 55/200\n",
      "172/172 [==============================] - 0s 835us/sample - loss: 0.4670 - accuracy: 0.8062 - val_loss: 0.4493 - val_accuracy: 0.7984\n",
      "Epoch 56/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.4838 - accuracy: 0.7868 - val_loss: 0.4760 - val_accuracy: 0.8217\n",
      "Epoch 57/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 0.4790 - accuracy: 0.8062 - val_loss: 0.4494 - val_accuracy: 0.8062\n",
      "Epoch 58/200\n",
      "172/172 [==============================] - 0s 947us/sample - loss: 0.4646 - accuracy: 0.8004 - val_loss: 0.4529 - val_accuracy: 0.8062\n",
      "Epoch 59/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.4594 - accuracy: 0.8198 - val_loss: 0.4466 - val_accuracy: 0.7984\n",
      "Epoch 60/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 0.4741 - accuracy: 0.7888 - val_loss: 0.4601 - val_accuracy: 0.8140\n",
      "Epoch 61/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.4641 - accuracy: 0.8101 - val_loss: 0.4452 - val_accuracy: 0.7984\n",
      "Epoch 62/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.4635 - accuracy: 0.8120 - val_loss: 0.4521 - val_accuracy: 0.8062\n",
      "Epoch 63/200\n",
      "172/172 [==============================] - 0s 864us/sample - loss: 0.4640 - accuracy: 0.7984 - val_loss: 0.4470 - val_accuracy: 0.8062\n",
      "Epoch 64/200\n",
      "172/172 [==============================] - 0s 842us/sample - loss: 0.4591 - accuracy: 0.8178 - val_loss: 0.4450 - val_accuracy: 0.8062\n",
      "Epoch 65/200\n",
      "172/172 [==============================] - 0s 850us/sample - loss: 0.4600 - accuracy: 0.8023 - val_loss: 0.4498 - val_accuracy: 0.8140\n",
      "Epoch 66/200\n",
      "172/172 [==============================] - 0s 834us/sample - loss: 0.4558 - accuracy: 0.8314 - val_loss: 0.4417 - val_accuracy: 0.7984\n",
      "Epoch 67/200\n",
      "172/172 [==============================] - 0s 828us/sample - loss: 0.4863 - accuracy: 0.7907 - val_loss: 0.4798 - val_accuracy: 0.8217\n",
      "Epoch 68/200\n",
      "172/172 [==============================] - 0s 962us/sample - loss: 0.5075 - accuracy: 0.7965 - val_loss: 0.4483 - val_accuracy: 0.7984\n",
      "Epoch 69/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.4655 - accuracy: 0.7946 - val_loss: 0.4482 - val_accuracy: 0.8062\n",
      "Epoch 70/200\n",
      "172/172 [==============================] - 0s 843us/sample - loss: 0.4581 - accuracy: 0.8081 - val_loss: 0.4434 - val_accuracy: 0.8062\n",
      "Epoch 71/200\n",
      "172/172 [==============================] - 0s 952us/sample - loss: 0.4616 - accuracy: 0.8178 - val_loss: 0.4407 - val_accuracy: 0.8062\n",
      "Epoch 72/200\n",
      "172/172 [==============================] - 0s 981us/sample - loss: 0.4544 - accuracy: 0.8043 - val_loss: 0.4440 - val_accuracy: 0.8140\n",
      "Epoch 73/200\n",
      "172/172 [==============================] - 0s 975us/sample - loss: 0.4574 - accuracy: 0.8140 - val_loss: 0.4380 - val_accuracy: 0.7984\n",
      "Epoch 74/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4551 - accuracy: 0.8043 - val_loss: 0.4484 - val_accuracy: 0.8140\n",
      "Epoch 75/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.4566 - accuracy: 0.8198 - val_loss: 0.4373 - val_accuracy: 0.8062\n",
      "Epoch 76/200\n",
      "172/172 [==============================] - 0s 858us/sample - loss: 0.4533 - accuracy: 0.8178 - val_loss: 0.4397 - val_accuracy: 0.8140\n",
      "Epoch 77/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.4525 - accuracy: 0.8062 - val_loss: 0.4427 - val_accuracy: 0.8140\n",
      "Epoch 78/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4526 - accuracy: 0.8236 - val_loss: 0.4408 - val_accuracy: 0.8140\n",
      "Epoch 79/200\n",
      "172/172 [==============================] - 0s 941us/sample - loss: 0.4560 - accuracy: 0.8081 - val_loss: 0.4403 - val_accuracy: 0.8140\n",
      "Epoch 80/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.4509 - accuracy: 0.8140 - val_loss: 0.4442 - val_accuracy: 0.8140\n",
      "Epoch 81/200\n",
      "172/172 [==============================] - 0s 843us/sample - loss: 0.4556 - accuracy: 0.8120 - val_loss: 0.4336 - val_accuracy: 0.7984\n",
      "Epoch 82/200\n",
      "172/172 [==============================] - 0s 834us/sample - loss: 0.4541 - accuracy: 0.8101 - val_loss: 0.4333 - val_accuracy: 0.7984\n",
      "Epoch 83/200\n",
      "172/172 [==============================] - 0s 859us/sample - loss: 0.4526 - accuracy: 0.8081 - val_loss: 0.4399 - val_accuracy: 0.8062\n",
      "Epoch 84/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4497 - accuracy: 0.8120 - val_loss: 0.4329 - val_accuracy: 0.7984\n",
      "Epoch 85/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4477 - accuracy: 0.8198 - val_loss: 0.4372 - val_accuracy: 0.8062\n",
      "Epoch 86/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4478 - accuracy: 0.8159 - val_loss: 0.4340 - val_accuracy: 0.8062\n",
      "Epoch 87/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4480 - accuracy: 0.8236 - val_loss: 0.4312 - val_accuracy: 0.7984\n",
      "Epoch 88/200\n",
      "172/172 [==============================] - 0s 965us/sample - loss: 0.4502 - accuracy: 0.8120 - val_loss: 0.4313 - val_accuracy: 0.8062\n",
      "Epoch 89/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.4563 - accuracy: 0.8081 - val_loss: 0.4433 - val_accuracy: 0.8295\n",
      "Epoch 90/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.4520 - accuracy: 0.8101 - val_loss: 0.4388 - val_accuracy: 0.8062\n",
      "Epoch 91/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4460 - accuracy: 0.8178 - val_loss: 0.4328 - val_accuracy: 0.8062\n",
      "Epoch 92/200\n",
      "172/172 [==============================] - 0s 865us/sample - loss: 0.4438 - accuracy: 0.8256 - val_loss: 0.4305 - val_accuracy: 0.8062\n",
      "Epoch 93/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 0.4486 - accuracy: 0.8081 - val_loss: 0.4421 - val_accuracy: 0.8295\n",
      "Epoch 94/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.4450 - accuracy: 0.8198 - val_loss: 0.4345 - val_accuracy: 0.8062\n",
      "Epoch 95/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4481 - accuracy: 0.8101 - val_loss: 0.4414 - val_accuracy: 0.8372\n",
      "Epoch 96/200\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 0.4438 - accuracy: 0.8198 - val_loss: 0.4322 - val_accuracy: 0.8062\n",
      "Epoch 97/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.4455 - accuracy: 0.8198 - val_loss: 0.4434 - val_accuracy: 0.8450\n",
      "Epoch 98/200\n",
      "172/172 [==============================] - 0s 961us/sample - loss: 0.4497 - accuracy: 0.8159 - val_loss: 0.4358 - val_accuracy: 0.8217\n",
      "Epoch 99/200\n",
      "172/172 [==============================] - 0s 995us/sample - loss: 0.4421 - accuracy: 0.8256 - val_loss: 0.4284 - val_accuracy: 0.8062\n",
      "Epoch 100/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4471 - accuracy: 0.8120 - val_loss: 0.4390 - val_accuracy: 0.8450\n",
      "Epoch 101/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.4438 - accuracy: 0.8081 - val_loss: 0.4368 - val_accuracy: 0.8450\n",
      "Epoch 102/200\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 0.4493 - accuracy: 0.8198 - val_loss: 0.4274 - val_accuracy: 0.7907\n",
      "Epoch 103/200\n",
      "172/172 [==============================] - 0s 856us/sample - loss: 0.4429 - accuracy: 0.8120 - val_loss: 0.4310 - val_accuracy: 0.8062\n",
      "Epoch 104/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 0.4399 - accuracy: 0.8217 - val_loss: 0.4301 - val_accuracy: 0.8062\n",
      "Epoch 105/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.4498 - accuracy: 0.8101 - val_loss: 0.4396 - val_accuracy: 0.8372\n",
      "Epoch 106/200\n",
      "172/172 [==============================] - 0s 861us/sample - loss: 0.4401 - accuracy: 0.8120 - val_loss: 0.4337 - val_accuracy: 0.8217\n",
      "Epoch 107/200\n",
      "172/172 [==============================] - 0s 826us/sample - loss: 0.4431 - accuracy: 0.8236 - val_loss: 0.4269 - val_accuracy: 0.8062\n",
      "Epoch 108/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.4386 - accuracy: 0.8236 - val_loss: 0.4417 - val_accuracy: 0.8527\n",
      "Epoch 109/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.4470 - accuracy: 0.8140 - val_loss: 0.4387 - val_accuracy: 0.8372\n",
      "Epoch 110/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.4417 - accuracy: 0.8236 - val_loss: 0.4285 - val_accuracy: 0.8062\n",
      "Epoch 111/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.4370 - accuracy: 0.8256 - val_loss: 0.4251 - val_accuracy: 0.8062\n",
      "Epoch 112/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.4477 - accuracy: 0.8043 - val_loss: 0.4619 - val_accuracy: 0.8372\n",
      "Epoch 113/200\n",
      "172/172 [==============================] - 0s 859us/sample - loss: 0.4482 - accuracy: 0.8140 - val_loss: 0.4300 - val_accuracy: 0.8217\n",
      "Epoch 114/200\n",
      "172/172 [==============================] - 0s 839us/sample - loss: 0.4402 - accuracy: 0.8217 - val_loss: 0.4249 - val_accuracy: 0.7907\n",
      "Epoch 115/200\n",
      "172/172 [==============================] - 0s 850us/sample - loss: 0.4406 - accuracy: 0.8043 - val_loss: 0.4356 - val_accuracy: 0.8372\n",
      "Epoch 116/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.4379 - accuracy: 0.8159 - val_loss: 0.4285 - val_accuracy: 0.8140\n",
      "Epoch 117/200\n",
      "172/172 [==============================] - 0s 860us/sample - loss: 0.4386 - accuracy: 0.8198 - val_loss: 0.4285 - val_accuracy: 0.8295\n",
      "Epoch 118/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 0.4351 - accuracy: 0.8256 - val_loss: 0.4259 - val_accuracy: 0.8140\n",
      "Epoch 119/200\n",
      "172/172 [==============================] - 0s 859us/sample - loss: 0.4457 - accuracy: 0.8217 - val_loss: 0.4215 - val_accuracy: 0.7984\n",
      "Epoch 120/200\n",
      "172/172 [==============================] - 0s 845us/sample - loss: 0.4337 - accuracy: 0.8256 - val_loss: 0.4235 - val_accuracy: 0.8140\n",
      "Epoch 121/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.4395 - accuracy: 0.8178 - val_loss: 0.4347 - val_accuracy: 0.8372\n",
      "Epoch 122/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.4322 - accuracy: 0.8275 - val_loss: 0.4222 - val_accuracy: 0.7907\n",
      "Epoch 123/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.4367 - accuracy: 0.8140 - val_loss: 0.4333 - val_accuracy: 0.8372\n",
      "Epoch 124/200\n",
      "172/172 [==============================] - 0s 942us/sample - loss: 0.4347 - accuracy: 0.8236 - val_loss: 0.4210 - val_accuracy: 0.7984\n",
      "Epoch 125/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 0.4338 - accuracy: 0.8295 - val_loss: 0.4217 - val_accuracy: 0.8062\n",
      "Epoch 126/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.4314 - accuracy: 0.8256 - val_loss: 0.4234 - val_accuracy: 0.8062\n",
      "Epoch 127/200\n",
      "172/172 [==============================] - 0s 842us/sample - loss: 0.4298 - accuracy: 0.8295 - val_loss: 0.4226 - val_accuracy: 0.8062\n",
      "Epoch 128/200\n",
      "172/172 [==============================] - 0s 846us/sample - loss: 0.4320 - accuracy: 0.8217 - val_loss: 0.4319 - val_accuracy: 0.8372\n",
      "Epoch 129/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 933us/sample - loss: 0.4300 - accuracy: 0.8236 - val_loss: 0.4202 - val_accuracy: 0.7984\n",
      "Epoch 130/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4384 - accuracy: 0.8295 - val_loss: 0.4208 - val_accuracy: 0.8062\n",
      "Epoch 131/200\n",
      "172/172 [==============================] - 0s 982us/sample - loss: 0.4370 - accuracy: 0.8062 - val_loss: 0.4482 - val_accuracy: 0.8450\n",
      "Epoch 132/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4409 - accuracy: 0.8314 - val_loss: 0.4256 - val_accuracy: 0.7984\n",
      "Epoch 133/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.4357 - accuracy: 0.8178 - val_loss: 0.4321 - val_accuracy: 0.8372\n",
      "Epoch 134/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 0.4557 - accuracy: 0.8081 - val_loss: 0.4651 - val_accuracy: 0.8295\n",
      "Epoch 135/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4537 - accuracy: 0.8043 - val_loss: 0.4512 - val_accuracy: 0.8295\n",
      "Epoch 136/200\n",
      "172/172 [==============================] - 0s 962us/sample - loss: 0.4429 - accuracy: 0.8275 - val_loss: 0.4217 - val_accuracy: 0.8062\n",
      "Epoch 137/200\n",
      "172/172 [==============================] - 0s 971us/sample - loss: 0.4408 - accuracy: 0.8101 - val_loss: 0.4457 - val_accuracy: 0.8372\n",
      "Epoch 138/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4308 - accuracy: 0.8217 - val_loss: 0.4202 - val_accuracy: 0.7984\n",
      "Epoch 139/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 0.4376 - accuracy: 0.8198 - val_loss: 0.4192 - val_accuracy: 0.7984\n",
      "Epoch 140/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.4386 - accuracy: 0.8120 - val_loss: 0.4229 - val_accuracy: 0.8295\n",
      "Epoch 141/200\n",
      "172/172 [==============================] - 0s 949us/sample - loss: 0.4293 - accuracy: 0.8236 - val_loss: 0.4250 - val_accuracy: 0.8295\n",
      "Epoch 142/200\n",
      "172/172 [==============================] - 0s 959us/sample - loss: 0.4386 - accuracy: 0.8256 - val_loss: 0.4209 - val_accuracy: 0.7984\n",
      "Epoch 143/200\n",
      "172/172 [==============================] - 0s 869us/sample - loss: 0.4317 - accuracy: 0.8140 - val_loss: 0.4322 - val_accuracy: 0.8372\n",
      "Epoch 144/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.4270 - accuracy: 0.8275 - val_loss: 0.4240 - val_accuracy: 0.8295\n",
      "Epoch 145/200\n",
      "172/172 [==============================] - 0s 993us/sample - loss: 0.4250 - accuracy: 0.8333 - val_loss: 0.4187 - val_accuracy: 0.8140\n",
      "Epoch 146/200\n",
      "172/172 [==============================] - 0s 974us/sample - loss: 0.4257 - accuracy: 0.8295 - val_loss: 0.4202 - val_accuracy: 0.8295\n",
      "Epoch 147/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.4243 - accuracy: 0.8333 - val_loss: 0.4239 - val_accuracy: 0.8295\n",
      "Epoch 148/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4265 - accuracy: 0.8333 - val_loss: 0.4191 - val_accuracy: 0.8140\n",
      "Epoch 149/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4238 - accuracy: 0.8314 - val_loss: 0.4191 - val_accuracy: 0.8062\n",
      "Epoch 150/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4262 - accuracy: 0.8236 - val_loss: 0.4426 - val_accuracy: 0.8450\n",
      "Epoch 151/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4319 - accuracy: 0.8217 - val_loss: 0.4317 - val_accuracy: 0.8372\n",
      "Epoch 152/200\n",
      "172/172 [==============================] - 0s 948us/sample - loss: 0.4308 - accuracy: 0.8275 - val_loss: 0.4285 - val_accuracy: 0.8372\n",
      "Epoch 153/200\n",
      "172/172 [==============================] - 0s 956us/sample - loss: 0.4322 - accuracy: 0.8236 - val_loss: 0.4275 - val_accuracy: 0.8372\n",
      "Epoch 154/200\n",
      "172/172 [==============================] - 0s 955us/sample - loss: 0.4214 - accuracy: 0.8333 - val_loss: 0.4176 - val_accuracy: 0.7984\n",
      "Epoch 155/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.4339 - accuracy: 0.8159 - val_loss: 0.4373 - val_accuracy: 0.8372\n",
      "Epoch 156/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 0.4295 - accuracy: 0.8275 - val_loss: 0.4169 - val_accuracy: 0.7984\n",
      "Epoch 157/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 0.4248 - accuracy: 0.8333 - val_loss: 0.4175 - val_accuracy: 0.7984\n",
      "Epoch 158/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4235 - accuracy: 0.8256 - val_loss: 0.4249 - val_accuracy: 0.8372\n",
      "Epoch 159/200\n",
      "172/172 [==============================] - 0s 986us/sample - loss: 0.4249 - accuracy: 0.8314 - val_loss: 0.4225 - val_accuracy: 0.8372\n",
      "Epoch 160/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4218 - accuracy: 0.8217 - val_loss: 0.4548 - val_accuracy: 0.8450\n",
      "Epoch 161/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4322 - accuracy: 0.8275 - val_loss: 0.4168 - val_accuracy: 0.8217\n",
      "Epoch 162/200\n",
      "172/172 [==============================] - 0s 909us/sample - loss: 0.4196 - accuracy: 0.8333 - val_loss: 0.4278 - val_accuracy: 0.8450\n",
      "Epoch 163/200\n",
      "172/172 [==============================] - 0s 882us/sample - loss: 0.4260 - accuracy: 0.8295 - val_loss: 0.4149 - val_accuracy: 0.7984\n",
      "Epoch 164/200\n",
      "172/172 [==============================] - 0s 944us/sample - loss: 0.4204 - accuracy: 0.8314 - val_loss: 0.4239 - val_accuracy: 0.8372\n",
      "Epoch 165/200\n",
      "172/172 [==============================] - 0s 951us/sample - loss: 0.4223 - accuracy: 0.8333 - val_loss: 0.4262 - val_accuracy: 0.8450\n",
      "Epoch 166/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.4238 - accuracy: 0.8275 - val_loss: 0.4188 - val_accuracy: 0.7907\n",
      "Epoch 167/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.4203 - accuracy: 0.8314 - val_loss: 0.4164 - val_accuracy: 0.8295\n",
      "Epoch 168/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.4267 - accuracy: 0.8256 - val_loss: 0.4162 - val_accuracy: 0.8295\n",
      "Epoch 169/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.4218 - accuracy: 0.8275 - val_loss: 0.4299 - val_accuracy: 0.8450\n",
      "Epoch 170/200\n",
      "172/172 [==============================] - 0s 994us/sample - loss: 0.4314 - accuracy: 0.8217 - val_loss: 0.4159 - val_accuracy: 0.8140\n",
      "Epoch 171/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 0.4315 - accuracy: 0.8314 - val_loss: 0.4191 - val_accuracy: 0.8295\n",
      "Epoch 172/200\n",
      "172/172 [==============================] - 0s 969us/sample - loss: 0.4286 - accuracy: 0.8275 - val_loss: 0.4334 - val_accuracy: 0.7907\n",
      "Epoch 173/200\n",
      "172/172 [==============================] - 0s 937us/sample - loss: 0.4553 - accuracy: 0.8120 - val_loss: 0.4170 - val_accuracy: 0.7907\n",
      "Epoch 174/200\n",
      "172/172 [==============================] - 0s 965us/sample - loss: 0.4210 - accuracy: 0.8469 - val_loss: 0.4166 - val_accuracy: 0.8140\n",
      "Epoch 175/200\n",
      "172/172 [==============================] - 0s 856us/sample - loss: 0.4207 - accuracy: 0.8333 - val_loss: 0.4429 - val_accuracy: 0.8450\n",
      "Epoch 176/200\n",
      "172/172 [==============================] - 0s 947us/sample - loss: 0.4371 - accuracy: 0.8314 - val_loss: 0.4274 - val_accuracy: 0.7907\n",
      "Epoch 177/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.4230 - accuracy: 0.8295 - val_loss: 0.4303 - val_accuracy: 0.8372\n",
      "Epoch 178/200\n",
      "172/172 [==============================] - 0s 853us/sample - loss: 0.4199 - accuracy: 0.8333 - val_loss: 0.4186 - val_accuracy: 0.8295\n",
      "Epoch 179/200\n",
      "172/172 [==============================] - 0s 844us/sample - loss: 0.4165 - accuracy: 0.8411 - val_loss: 0.4165 - val_accuracy: 0.7907\n",
      "Epoch 180/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.4220 - accuracy: 0.8333 - val_loss: 0.4143 - val_accuracy: 0.7984\n",
      "Epoch 181/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 0.4200 - accuracy: 0.8333 - val_loss: 0.4196 - val_accuracy: 0.8372\n",
      "Epoch 182/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4189 - accuracy: 0.8333 - val_loss: 0.4337 - val_accuracy: 0.8372\n",
      "Epoch 183/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4237 - accuracy: 0.8275 - val_loss: 0.4412 - val_accuracy: 0.8450\n",
      "Epoch 184/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 945us/sample - loss: 0.4308 - accuracy: 0.8217 - val_loss: 0.4231 - val_accuracy: 0.8372\n",
      "Epoch 185/200\n",
      "172/172 [==============================] - 0s 954us/sample - loss: 0.4154 - accuracy: 0.8333 - val_loss: 0.4299 - val_accuracy: 0.8372\n",
      "Epoch 186/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4137 - accuracy: 0.8469 - val_loss: 0.4158 - val_accuracy: 0.8062\n",
      "Epoch 187/200\n",
      "172/172 [==============================] - 0s 958us/sample - loss: 0.4140 - accuracy: 0.8353 - val_loss: 0.4281 - val_accuracy: 0.8450\n",
      "Epoch 188/200\n",
      "172/172 [==============================] - 0s 854us/sample - loss: 0.4113 - accuracy: 0.8430 - val_loss: 0.4168 - val_accuracy: 0.8295\n",
      "Epoch 189/200\n",
      "172/172 [==============================] - 0s 968us/sample - loss: 0.4135 - accuracy: 0.8333 - val_loss: 0.4134 - val_accuracy: 0.7984\n",
      "Epoch 190/200\n",
      "172/172 [==============================] - 0s 945us/sample - loss: 0.4178 - accuracy: 0.8314 - val_loss: 0.4249 - val_accuracy: 0.8372\n",
      "Epoch 191/200\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 0.4136 - accuracy: 0.8353 - val_loss: 0.4152 - val_accuracy: 0.8295\n",
      "Epoch 192/200\n",
      "172/172 [==============================] - 0s 859us/sample - loss: 0.4136 - accuracy: 0.8372 - val_loss: 0.4174 - val_accuracy: 0.8450\n",
      "Epoch 193/200\n",
      "172/172 [==============================] - 0s 940us/sample - loss: 0.4155 - accuracy: 0.8411 - val_loss: 0.4176 - val_accuracy: 0.8450\n",
      "Epoch 194/200\n",
      "172/172 [==============================] - 0s 955us/sample - loss: 0.4219 - accuracy: 0.8217 - val_loss: 0.4160 - val_accuracy: 0.8295\n",
      "Epoch 195/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.4130 - accuracy: 0.8372 - val_loss: 0.4147 - val_accuracy: 0.8217\n",
      "Epoch 196/200\n",
      "172/172 [==============================] - 0s 991us/sample - loss: 0.4127 - accuracy: 0.8391 - val_loss: 0.4142 - val_accuracy: 0.8062\n",
      "Epoch 197/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4180 - accuracy: 0.8295 - val_loss: 0.4181 - val_accuracy: 0.8372\n",
      "Epoch 198/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4136 - accuracy: 0.8372 - val_loss: 0.4151 - val_accuracy: 0.8217\n",
      "Epoch 199/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 0.4260 - accuracy: 0.8217 - val_loss: 0.4634 - val_accuracy: 0.8217\n",
      "Epoch 200/200\n",
      "172/172 [==============================] - 0s 856us/sample - loss: 0.4033 - accuracy: 0.8333 - val_loss: 0.4225 - val_accuracy: 0.7984\n"
     ]
    }
   ],
   "source": [
    "dropout_rates = [0.001]\n",
    "reg_types = ['l2']\n",
    "reg_coeffs = [0.001]\n",
    "activations = ['tanh']\n",
    "units=[10, 200]\n",
    "\n",
    "pbar = functools.partial(tqdm, leave=True, ncols='70%')\n",
    "pbars = [pbar() for _ in range(3)]\n",
    "\n",
    "grid_search_df2 = grid_search(dropout_rates=dropout_rates, reg_coeffs=reg_coeffs, reg_types=reg_types, \n",
    "                             pbars=pbars, activations=activations, num_epochs=200, units=units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dropout rate</th>\n",
       "      <th>reg type</th>\n",
       "      <th>lambda</th>\n",
       "      <th>activation</th>\n",
       "      <th>units</th>\n",
       "      <th>validation loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>tanh</td>\n",
       "      <td>10</td>\n",
       "      <td>0.450787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>tanh</td>\n",
       "      <td>200</td>\n",
       "      <td>0.413438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dropout rate reg type  lambda activation  units  validation loss\n",
       "0         0.001       l2   0.001       tanh     10         0.450787\n",
       "1         0.001       l2   0.001       tanh    200         0.413438"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_eaea621e_8dbc_11ea_a150_a683e795f3a1row0_col0 {\n",
       "            background-color:  #000004;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_eaea621e_8dbc_11ea_a150_a683e795f3a1row1_col0 {\n",
       "            background-color:  #fcfdbf;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_eaea621e_8dbc_11ea_a150_a683e795f3a1\" ><thead>    <tr>        <th class=\"blank\" ></th>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >validation loss</th>    </tr>    <tr>        <th class=\"blank\" ></th>        <th class=\"index_name level1\" >lambda</th>        <th class=\"col_heading level1 col0\" >0.001</th>    </tr>    <tr>        <th class=\"index_name level0\" >reg type</th>        <th class=\"index_name level1\" >units</th>        <th class=\"blank\" ></th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_eaea621e_8dbc_11ea_a150_a683e795f3a1level0_row0\" class=\"row_heading level0 row0\" rowspan=2>l2</th>\n",
       "                        <th id=\"T_eaea621e_8dbc_11ea_a150_a683e795f3a1level1_row0\" class=\"row_heading level1 row0\" >10</th>\n",
       "                        <td id=\"T_eaea621e_8dbc_11ea_a150_a683e795f3a1row0_col0\" class=\"data row0 col0\" >0.451</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_eaea621e_8dbc_11ea_a150_a683e795f3a1level1_row1\" class=\"row_heading level1 row1\" >200</th>\n",
       "                        <td id=\"T_eaea621e_8dbc_11ea_a150_a683e795f3a1row1_col0\" class=\"data row1 col0\" >0.413</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x19b0f1c90>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_pivot2 = (grid_search_df2\n",
    "                     .pivot_table(values=['validation loss'],\n",
    "                                  columns=['lambda'],\n",
    "                                  index=['reg type', 'units']))\n",
    "grid_search_pivot2.style.format('{:.3f}').background_gradient(cmap='magma_r',\n",
    "                                                             axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51d8d07d2af24395bc594a88dacefd87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=1.0), HTML(value='')), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f90d96b71b384f029067017fae4b34a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=1.0), HTML(value='')), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec930d4fc8274c59af231e19316c423d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=1.0), HTML(value='')), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training for dr=0.001, l_lambda=1.0e-03, reg_type=l2, act: tanh\n",
      "Train on 172 samples, validate on 43 samples\n",
      "Epoch 1/200\n",
      "172/172 [==============================] - 1s 8ms/sample - loss: 0.6390 - accuracy: 0.6667 - val_loss: 0.6082 - val_accuracy: 0.6667\n",
      "Epoch 2/200\n",
      "172/172 [==============================] - 0s 766us/sample - loss: 0.5916 - accuracy: 0.6667 - val_loss: 0.5654 - val_accuracy: 0.6667\n",
      "Epoch 3/200\n",
      "172/172 [==============================] - 0s 802us/sample - loss: 0.5545 - accuracy: 0.7384 - val_loss: 0.5383 - val_accuracy: 0.7829\n",
      "Epoch 4/200\n",
      "172/172 [==============================] - 0s 764us/sample - loss: 0.5346 - accuracy: 0.7791 - val_loss: 0.5242 - val_accuracy: 0.7829\n",
      "Epoch 5/200\n",
      "172/172 [==============================] - 0s 807us/sample - loss: 0.5245 - accuracy: 0.7791 - val_loss: 0.5181 - val_accuracy: 0.7829\n",
      "Epoch 6/200\n",
      "172/172 [==============================] - 0s 802us/sample - loss: 0.5226 - accuracy: 0.7791 - val_loss: 0.5156 - val_accuracy: 0.7829\n",
      "Epoch 7/200\n",
      "172/172 [==============================] - 0s 733us/sample - loss: 0.5212 - accuracy: 0.7791 - val_loss: 0.5148 - val_accuracy: 0.7829\n",
      "Epoch 8/200\n",
      "172/172 [==============================] - 0s 739us/sample - loss: 0.5191 - accuracy: 0.7791 - val_loss: 0.5130 - val_accuracy: 0.7829\n",
      "Epoch 9/200\n",
      "172/172 [==============================] - 0s 742us/sample - loss: 0.5183 - accuracy: 0.7791 - val_loss: 0.5121 - val_accuracy: 0.7829\n",
      "Epoch 10/200\n",
      "172/172 [==============================] - 0s 816us/sample - loss: 0.5175 - accuracy: 0.7791 - val_loss: 0.5110 - val_accuracy: 0.7829\n",
      "Epoch 11/200\n",
      "172/172 [==============================] - 0s 865us/sample - loss: 0.5173 - accuracy: 0.7791 - val_loss: 0.5102 - val_accuracy: 0.7829\n",
      "Epoch 12/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 0.5159 - accuracy: 0.7791 - val_loss: 0.5098 - val_accuracy: 0.7829\n",
      "Epoch 13/200\n",
      "172/172 [==============================] - 0s 825us/sample - loss: 0.5151 - accuracy: 0.7791 - val_loss: 0.5089 - val_accuracy: 0.7829\n",
      "Epoch 14/200\n",
      "172/172 [==============================] - 0s 811us/sample - loss: 0.5140 - accuracy: 0.7791 - val_loss: 0.5083 - val_accuracy: 0.7829\n",
      "Epoch 15/200\n",
      "172/172 [==============================] - 0s 774us/sample - loss: 0.5140 - accuracy: 0.7791 - val_loss: 0.5074 - val_accuracy: 0.7829\n",
      "Epoch 16/200\n",
      "172/172 [==============================] - 0s 740us/sample - loss: 0.5141 - accuracy: 0.7791 - val_loss: 0.5067 - val_accuracy: 0.7829\n",
      "Epoch 17/200\n",
      "172/172 [==============================] - 0s 736us/sample - loss: 0.5136 - accuracy: 0.7791 - val_loss: 0.5062 - val_accuracy: 0.7829\n",
      "Epoch 18/200\n",
      "172/172 [==============================] - 0s 752us/sample - loss: 0.5128 - accuracy: 0.7791 - val_loss: 0.5059 - val_accuracy: 0.7829\n",
      "Epoch 19/200\n",
      "172/172 [==============================] - 0s 752us/sample - loss: 0.5123 - accuracy: 0.7791 - val_loss: 0.5052 - val_accuracy: 0.7829\n",
      "Epoch 20/200\n",
      "172/172 [==============================] - 0s 750us/sample - loss: 0.5122 - accuracy: 0.7791 - val_loss: 0.5055 - val_accuracy: 0.7829\n",
      "Epoch 21/200\n",
      "172/172 [==============================] - 0s 743us/sample - loss: 0.5130 - accuracy: 0.7791 - val_loss: 0.5043 - val_accuracy: 0.7829\n",
      "Epoch 22/200\n",
      "172/172 [==============================] - 0s 749us/sample - loss: 0.5114 - accuracy: 0.7791 - val_loss: 0.5039 - val_accuracy: 0.7829\n",
      "Epoch 23/200\n",
      "172/172 [==============================] - 0s 752us/sample - loss: 0.5123 - accuracy: 0.7791 - val_loss: 0.5036 - val_accuracy: 0.7829\n",
      "Epoch 24/200\n",
      "172/172 [==============================] - 0s 758us/sample - loss: 0.5121 - accuracy: 0.7791 - val_loss: 0.5030 - val_accuracy: 0.7829\n",
      "Epoch 25/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 0.5105 - accuracy: 0.7791 - val_loss: 0.5029 - val_accuracy: 0.7829\n",
      "Epoch 26/200\n",
      "172/172 [==============================] - 0s 823us/sample - loss: 0.5107 - accuracy: 0.7791 - val_loss: 0.5024 - val_accuracy: 0.7829\n",
      "Epoch 27/200\n",
      "172/172 [==============================] - 0s 825us/sample - loss: 0.5099 - accuracy: 0.7791 - val_loss: 0.5022 - val_accuracy: 0.7829\n",
      "Epoch 28/200\n",
      "172/172 [==============================] - 0s 848us/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.5018 - val_accuracy: 0.7829\n",
      "Epoch 29/200\n",
      "172/172 [==============================] - 0s 829us/sample - loss: 0.5103 - accuracy: 0.7791 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 30/200\n",
      "172/172 [==============================] - 0s 813us/sample - loss: 0.5090 - accuracy: 0.7791 - val_loss: 0.5012 - val_accuracy: 0.7829\n",
      "Epoch 31/200\n",
      "172/172 [==============================] - 0s 802us/sample - loss: 0.5088 - accuracy: 0.7791 - val_loss: 0.5014 - val_accuracy: 0.7829\n",
      "Epoch 32/200\n",
      "172/172 [==============================] - 0s 825us/sample - loss: 0.5087 - accuracy: 0.7791 - val_loss: 0.5007 - val_accuracy: 0.7829\n",
      "Epoch 33/200\n",
      "172/172 [==============================] - 0s 853us/sample - loss: 0.5092 - accuracy: 0.7791 - val_loss: 0.5002 - val_accuracy: 0.7829\n",
      "Epoch 34/200\n",
      "172/172 [==============================] - 0s 838us/sample - loss: 0.5085 - accuracy: 0.7791 - val_loss: 0.5006 - val_accuracy: 0.7829\n",
      "Epoch 35/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.5072 - accuracy: 0.7810 - val_loss: 0.5000 - val_accuracy: 0.7829\n",
      "Epoch 36/200\n",
      "172/172 [==============================] - 0s 833us/sample - loss: 0.5077 - accuracy: 0.7791 - val_loss: 0.4994 - val_accuracy: 0.7829\n",
      "Epoch 37/200\n",
      "172/172 [==============================] - 0s 834us/sample - loss: 0.5075 - accuracy: 0.7791 - val_loss: 0.4993 - val_accuracy: 0.7829\n",
      "Epoch 38/200\n",
      "172/172 [==============================] - 0s 832us/sample - loss: 0.5067 - accuracy: 0.7810 - val_loss: 0.4985 - val_accuracy: 0.7829\n",
      "Epoch 39/200\n",
      "172/172 [==============================] - 0s 946us/sample - loss: 0.5084 - accuracy: 0.7791 - val_loss: 0.4982 - val_accuracy: 0.7829\n",
      "Epoch 40/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.5068 - accuracy: 0.7791 - val_loss: 0.4979 - val_accuracy: 0.7829\n",
      "Epoch 41/200\n",
      "172/172 [==============================] - 0s 991us/sample - loss: 0.5092 - accuracy: 0.7810 - val_loss: 0.4989 - val_accuracy: 0.7829\n",
      "Epoch 42/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 0.5068 - accuracy: 0.7791 - val_loss: 0.4977 - val_accuracy: 0.7829\n",
      "Epoch 43/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.5090 - accuracy: 0.7810 - val_loss: 0.4990 - val_accuracy: 0.7829\n",
      "Epoch 44/200\n",
      "172/172 [==============================] - 0s 951us/sample - loss: 0.5049 - accuracy: 0.7810 - val_loss: 0.4969 - val_accuracy: 0.7829\n",
      "Epoch 45/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.5056 - accuracy: 0.7810 - val_loss: 0.4966 - val_accuracy: 0.7829\n",
      "Epoch 46/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.5051 - accuracy: 0.7810 - val_loss: 0.4962 - val_accuracy: 0.7829\n",
      "Epoch 47/200\n",
      "172/172 [==============================] - 0s 951us/sample - loss: 0.5050 - accuracy: 0.7810 - val_loss: 0.4959 - val_accuracy: 0.7829\n",
      "Epoch 48/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.5048 - accuracy: 0.7810 - val_loss: 0.4959 - val_accuracy: 0.7829\n",
      "Epoch 49/200\n",
      "172/172 [==============================] - 0s 865us/sample - loss: 0.5058 - accuracy: 0.7810 - val_loss: 0.4952 - val_accuracy: 0.7829\n",
      "Epoch 50/200\n",
      "172/172 [==============================] - 0s 864us/sample - loss: 0.5040 - accuracy: 0.7810 - val_loss: 0.4949 - val_accuracy: 0.7829\n",
      "Epoch 51/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 0.5042 - accuracy: 0.7810 - val_loss: 0.4946 - val_accuracy: 0.7829\n",
      "Epoch 52/200\n",
      "172/172 [==============================] - 0s 969us/sample - loss: 0.5038 - accuracy: 0.7810 - val_loss: 0.4939 - val_accuracy: 0.7829\n",
      "Epoch 53/200\n",
      "172/172 [==============================] - 0s 946us/sample - loss: 0.5057 - accuracy: 0.7791 - val_loss: 0.4951 - val_accuracy: 0.7829\n",
      "Epoch 54/200\n",
      "172/172 [==============================] - 0s 971us/sample - loss: 0.5024 - accuracy: 0.7810 - val_loss: 0.4936 - val_accuracy: 0.7829\n",
      "Epoch 55/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 958us/sample - loss: 0.5026 - accuracy: 0.7810 - val_loss: 0.4931 - val_accuracy: 0.7829\n",
      "Epoch 56/200\n",
      "172/172 [==============================] - 0s 912us/sample - loss: 0.5034 - accuracy: 0.7810 - val_loss: 0.4927 - val_accuracy: 0.7829\n",
      "Epoch 57/200\n",
      "172/172 [==============================] - 0s 843us/sample - loss: 0.5019 - accuracy: 0.7810 - val_loss: 0.4924 - val_accuracy: 0.7829\n",
      "Epoch 58/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5016 - accuracy: 0.7810 - val_loss: 0.4925 - val_accuracy: 0.7829\n",
      "Epoch 59/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.5020 - accuracy: 0.7791 - val_loss: 0.4937 - val_accuracy: 0.7829\n",
      "Epoch 60/200\n",
      "172/172 [==============================] - 0s 858us/sample - loss: 0.5010 - accuracy: 0.7791 - val_loss: 0.4911 - val_accuracy: 0.7829\n",
      "Epoch 61/200\n",
      "172/172 [==============================] - 0s 840us/sample - loss: 0.5001 - accuracy: 0.7810 - val_loss: 0.4905 - val_accuracy: 0.7829\n",
      "Epoch 62/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.5012 - accuracy: 0.7810 - val_loss: 0.4900 - val_accuracy: 0.7829\n",
      "Epoch 63/200\n",
      "172/172 [==============================] - 0s 825us/sample - loss: 0.5006 - accuracy: 0.7810 - val_loss: 0.4895 - val_accuracy: 0.7829\n",
      "Epoch 64/200\n",
      "172/172 [==============================] - 0s 995us/sample - loss: 0.4989 - accuracy: 0.7791 - val_loss: 0.4896 - val_accuracy: 0.7829\n",
      "Epoch 65/200\n",
      "172/172 [==============================] - 0s 903us/sample - loss: 0.4984 - accuracy: 0.7791 - val_loss: 0.4885 - val_accuracy: 0.7829\n",
      "Epoch 66/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.4979 - accuracy: 0.7791 - val_loss: 0.4881 - val_accuracy: 0.7829\n",
      "Epoch 67/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.4973 - accuracy: 0.7791 - val_loss: 0.4875 - val_accuracy: 0.7829\n",
      "Epoch 68/200\n",
      "172/172 [==============================] - 0s 930us/sample - loss: 0.4990 - accuracy: 0.7791 - val_loss: 0.4869 - val_accuracy: 0.7829\n",
      "Epoch 69/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.4978 - accuracy: 0.7791 - val_loss: 0.4872 - val_accuracy: 0.7907\n",
      "Epoch 70/200\n",
      "172/172 [==============================] - 0s 835us/sample - loss: 0.4999 - accuracy: 0.7791 - val_loss: 0.4857 - val_accuracy: 0.7829\n",
      "Epoch 71/200\n",
      "172/172 [==============================] - 0s 823us/sample - loss: 0.4984 - accuracy: 0.7791 - val_loss: 0.4869 - val_accuracy: 0.7907\n",
      "Epoch 72/200\n",
      "172/172 [==============================] - 0s 832us/sample - loss: 0.4963 - accuracy: 0.7791 - val_loss: 0.4851 - val_accuracy: 0.7907\n",
      "Epoch 73/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.4950 - accuracy: 0.7791 - val_loss: 0.4842 - val_accuracy: 0.7907\n",
      "Epoch 74/200\n",
      "172/172 [==============================] - 0s 845us/sample - loss: 0.4946 - accuracy: 0.7791 - val_loss: 0.4835 - val_accuracy: 0.7829\n",
      "Epoch 75/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.4971 - accuracy: 0.7810 - val_loss: 0.4850 - val_accuracy: 0.7907\n",
      "Epoch 76/200\n",
      "172/172 [==============================] - 0s 858us/sample - loss: 0.4935 - accuracy: 0.7810 - val_loss: 0.4823 - val_accuracy: 0.7907\n",
      "Epoch 77/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.4935 - accuracy: 0.7791 - val_loss: 0.4817 - val_accuracy: 0.7829\n",
      "Epoch 78/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.4958 - accuracy: 0.7810 - val_loss: 0.4819 - val_accuracy: 0.7907\n",
      "Epoch 79/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.4933 - accuracy: 0.7829 - val_loss: 0.4810 - val_accuracy: 0.7907\n",
      "Epoch 80/200\n",
      "172/172 [==============================] - 0s 928us/sample - loss: 0.4923 - accuracy: 0.7791 - val_loss: 0.4798 - val_accuracy: 0.7907\n",
      "Epoch 81/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.4936 - accuracy: 0.7810 - val_loss: 0.4793 - val_accuracy: 0.7907\n",
      "Epoch 82/200\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 0.4912 - accuracy: 0.7791 - val_loss: 0.4785 - val_accuracy: 0.7907\n",
      "Epoch 83/200\n",
      "172/172 [==============================] - 0s 827us/sample - loss: 0.4899 - accuracy: 0.7829 - val_loss: 0.4779 - val_accuracy: 0.7907\n",
      "Epoch 84/200\n",
      "172/172 [==============================] - 0s 830us/sample - loss: 0.4897 - accuracy: 0.7849 - val_loss: 0.4774 - val_accuracy: 0.7907\n",
      "Epoch 85/200\n",
      "172/172 [==============================] - 0s 828us/sample - loss: 0.4900 - accuracy: 0.7829 - val_loss: 0.4767 - val_accuracy: 0.7907\n",
      "Epoch 86/200\n",
      "172/172 [==============================] - 0s 825us/sample - loss: 0.4890 - accuracy: 0.7829 - val_loss: 0.4767 - val_accuracy: 0.7907\n",
      "Epoch 87/200\n",
      "172/172 [==============================] - 0s 832us/sample - loss: 0.4892 - accuracy: 0.7829 - val_loss: 0.4784 - val_accuracy: 0.7984\n",
      "Epoch 88/200\n",
      "172/172 [==============================] - 0s 844us/sample - loss: 0.4902 - accuracy: 0.7849 - val_loss: 0.4752 - val_accuracy: 0.7984\n",
      "Epoch 89/200\n",
      "172/172 [==============================] - 0s 840us/sample - loss: 0.4864 - accuracy: 0.7868 - val_loss: 0.4741 - val_accuracy: 0.7984\n",
      "Epoch 90/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.4887 - accuracy: 0.7868 - val_loss: 0.4743 - val_accuracy: 0.7984\n",
      "Epoch 91/200\n",
      "172/172 [==============================] - 0s 982us/sample - loss: 0.4910 - accuracy: 0.7849 - val_loss: 0.4723 - val_accuracy: 0.7907\n",
      "Epoch 92/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.4854 - accuracy: 0.7849 - val_loss: 0.4729 - val_accuracy: 0.7984\n",
      "Epoch 93/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.4862 - accuracy: 0.7907 - val_loss: 0.4742 - val_accuracy: 0.7984\n",
      "Epoch 94/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.4852 - accuracy: 0.7849 - val_loss: 0.4711 - val_accuracy: 0.7984\n",
      "Epoch 95/200\n",
      "172/172 [==============================] - 0s 930us/sample - loss: 0.4828 - accuracy: 0.7868 - val_loss: 0.4699 - val_accuracy: 0.7984\n",
      "Epoch 96/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 0.4836 - accuracy: 0.7849 - val_loss: 0.4691 - val_accuracy: 0.7984\n",
      "Epoch 97/200\n",
      "172/172 [==============================] - 0s 856us/sample - loss: 0.4829 - accuracy: 0.7868 - val_loss: 0.4692 - val_accuracy: 0.7984\n",
      "Epoch 98/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.4835 - accuracy: 0.7946 - val_loss: 0.4694 - val_accuracy: 0.7984\n",
      "Epoch 99/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 0.4817 - accuracy: 0.7888 - val_loss: 0.4677 - val_accuracy: 0.7984\n",
      "Epoch 100/200\n",
      "172/172 [==============================] - 0s 836us/sample - loss: 0.4815 - accuracy: 0.7868 - val_loss: 0.4677 - val_accuracy: 0.8062\n",
      "Epoch 101/200\n",
      "172/172 [==============================] - 0s 837us/sample - loss: 0.4814 - accuracy: 0.7907 - val_loss: 0.4659 - val_accuracy: 0.8062\n",
      "Epoch 102/200\n",
      "172/172 [==============================] - 0s 832us/sample - loss: 0.4835 - accuracy: 0.7849 - val_loss: 0.4652 - val_accuracy: 0.8062\n",
      "Epoch 103/200\n",
      "172/172 [==============================] - 0s 838us/sample - loss: 0.4787 - accuracy: 0.7926 - val_loss: 0.4673 - val_accuracy: 0.7907\n",
      "Epoch 104/200\n",
      "172/172 [==============================] - 0s 953us/sample - loss: 0.4783 - accuracy: 0.7926 - val_loss: 0.4648 - val_accuracy: 0.8140\n",
      "Epoch 105/200\n",
      "172/172 [==============================] - 0s 907us/sample - loss: 0.4783 - accuracy: 0.7868 - val_loss: 0.4632 - val_accuracy: 0.7984\n",
      "Epoch 106/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.4784 - accuracy: 0.7868 - val_loss: 0.4647 - val_accuracy: 0.7984\n",
      "Epoch 107/200\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 0.4814 - accuracy: 0.7868 - val_loss: 0.4624 - val_accuracy: 0.7984\n",
      "Epoch 108/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 0.4782 - accuracy: 0.7849 - val_loss: 0.4635 - val_accuracy: 0.7907\n",
      "Epoch 109/200\n",
      "172/172 [==============================] - 0s 842us/sample - loss: 0.4759 - accuracy: 0.7946 - val_loss: 0.4647 - val_accuracy: 0.8062\n",
      "Epoch 110/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 840us/sample - loss: 0.4817 - accuracy: 0.8081 - val_loss: 0.4614 - val_accuracy: 0.7984\n",
      "Epoch 111/200\n",
      "172/172 [==============================] - 0s 835us/sample - loss: 0.4788 - accuracy: 0.7849 - val_loss: 0.4600 - val_accuracy: 0.7984\n",
      "Epoch 112/200\n",
      "172/172 [==============================] - 0s 842us/sample - loss: 0.4743 - accuracy: 0.7888 - val_loss: 0.4607 - val_accuracy: 0.7984\n",
      "Epoch 113/200\n",
      "172/172 [==============================] - 0s 860us/sample - loss: 0.4756 - accuracy: 0.7907 - val_loss: 0.4597 - val_accuracy: 0.7907\n",
      "Epoch 114/200\n",
      "172/172 [==============================] - 0s 860us/sample - loss: 0.4734 - accuracy: 0.7907 - val_loss: 0.4597 - val_accuracy: 0.7984\n",
      "Epoch 115/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 0.4739 - accuracy: 0.7984 - val_loss: 0.4599 - val_accuracy: 0.7984\n",
      "Epoch 116/200\n",
      "172/172 [==============================] - 0s 869us/sample - loss: 0.4715 - accuracy: 0.7907 - val_loss: 0.4583 - val_accuracy: 0.7984\n",
      "Epoch 117/200\n",
      "172/172 [==============================] - 0s 976us/sample - loss: 0.4717 - accuracy: 0.7965 - val_loss: 0.4641 - val_accuracy: 0.8062\n",
      "Epoch 118/200\n",
      "172/172 [==============================] - 0s 956us/sample - loss: 0.4746 - accuracy: 0.7946 - val_loss: 0.4585 - val_accuracy: 0.8062\n",
      "Epoch 119/200\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 0.4714 - accuracy: 0.7946 - val_loss: 0.4568 - val_accuracy: 0.7984\n",
      "Epoch 120/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.4743 - accuracy: 0.7888 - val_loss: 0.4569 - val_accuracy: 0.7984\n",
      "Epoch 121/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.4740 - accuracy: 0.7868 - val_loss: 0.4551 - val_accuracy: 0.7984\n",
      "Epoch 122/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.4705 - accuracy: 0.7946 - val_loss: 0.4588 - val_accuracy: 0.8062\n",
      "Epoch 123/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 0.4702 - accuracy: 0.7946 - val_loss: 0.4550 - val_accuracy: 0.7984\n",
      "Epoch 124/200\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 0.4707 - accuracy: 0.7984 - val_loss: 0.4561 - val_accuracy: 0.7984\n",
      "Epoch 125/200\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 0.4693 - accuracy: 0.7926 - val_loss: 0.4533 - val_accuracy: 0.7984\n",
      "Epoch 126/200\n",
      "172/172 [==============================] - 0s 983us/sample - loss: 0.4695 - accuracy: 0.7926 - val_loss: 0.4565 - val_accuracy: 0.8062\n",
      "Epoch 127/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4704 - accuracy: 0.8081 - val_loss: 0.4529 - val_accuracy: 0.7984\n",
      "Epoch 128/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.4699 - accuracy: 0.7888 - val_loss: 0.4523 - val_accuracy: 0.7984\n",
      "Epoch 129/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4726 - accuracy: 0.8023 - val_loss: 0.4545 - val_accuracy: 0.8062\n",
      "Epoch 130/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4680 - accuracy: 0.7984 - val_loss: 0.4554 - val_accuracy: 0.8062\n",
      "Epoch 131/200\n",
      "172/172 [==============================] - 0s 981us/sample - loss: 0.4696 - accuracy: 0.8120 - val_loss: 0.4565 - val_accuracy: 0.8062\n",
      "Epoch 132/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4681 - accuracy: 0.7888 - val_loss: 0.4509 - val_accuracy: 0.7984\n",
      "Epoch 133/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4663 - accuracy: 0.7965 - val_loss: 0.4513 - val_accuracy: 0.7984\n",
      "Epoch 134/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 0.4649 - accuracy: 0.7946 - val_loss: 0.4515 - val_accuracy: 0.8062\n",
      "Epoch 135/200\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 0.4634 - accuracy: 0.7984 - val_loss: 0.4525 - val_accuracy: 0.8062\n",
      "Epoch 136/200\n",
      "172/172 [==============================] - 0s 848us/sample - loss: 0.4637 - accuracy: 0.8062 - val_loss: 0.4515 - val_accuracy: 0.8062\n",
      "Epoch 137/200\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 0.4634 - accuracy: 0.8043 - val_loss: 0.4488 - val_accuracy: 0.7907\n",
      "Epoch 138/200\n",
      "172/172 [==============================] - 0s 850us/sample - loss: 0.4631 - accuracy: 0.8043 - val_loss: 0.4528 - val_accuracy: 0.8062\n",
      "Epoch 139/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 0.4655 - accuracy: 0.8043 - val_loss: 0.4478 - val_accuracy: 0.7984\n",
      "Epoch 140/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 0.4628 - accuracy: 0.8140 - val_loss: 0.4553 - val_accuracy: 0.8062\n",
      "Epoch 141/200\n",
      "172/172 [==============================] - 0s 860us/sample - loss: 0.4659 - accuracy: 0.7926 - val_loss: 0.4477 - val_accuracy: 0.7984\n",
      "Epoch 142/200\n",
      "172/172 [==============================] - 0s 971us/sample - loss: 0.4656 - accuracy: 0.8023 - val_loss: 0.4523 - val_accuracy: 0.8062\n",
      "Epoch 143/200\n",
      "172/172 [==============================] - 0s 910us/sample - loss: 0.4661 - accuracy: 0.8004 - val_loss: 0.4480 - val_accuracy: 0.8062\n",
      "Epoch 144/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.4645 - accuracy: 0.8081 - val_loss: 0.4473 - val_accuracy: 0.7984\n",
      "Epoch 145/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.4641 - accuracy: 0.7946 - val_loss: 0.4496 - val_accuracy: 0.8062\n",
      "Epoch 146/200\n",
      "172/172 [==============================] - 0s 905us/sample - loss: 0.4636 - accuracy: 0.7926 - val_loss: 0.4467 - val_accuracy: 0.7984\n",
      "Epoch 147/200\n",
      "172/172 [==============================] - 0s 850us/sample - loss: 0.4594 - accuracy: 0.8062 - val_loss: 0.4510 - val_accuracy: 0.8062\n",
      "Epoch 148/200\n",
      "172/172 [==============================] - 0s 854us/sample - loss: 0.4596 - accuracy: 0.8101 - val_loss: 0.4469 - val_accuracy: 0.8062\n",
      "Epoch 149/200\n",
      "172/172 [==============================] - 0s 861us/sample - loss: 0.4595 - accuracy: 0.8101 - val_loss: 0.4458 - val_accuracy: 0.7984\n",
      "Epoch 150/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.4605 - accuracy: 0.8023 - val_loss: 0.4468 - val_accuracy: 0.8062\n",
      "Epoch 151/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.4598 - accuracy: 0.7984 - val_loss: 0.4462 - val_accuracy: 0.8062\n",
      "Epoch 152/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.4637 - accuracy: 0.8140 - val_loss: 0.4450 - val_accuracy: 0.8062\n",
      "Epoch 153/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.4595 - accuracy: 0.8004 - val_loss: 0.4461 - val_accuracy: 0.8062\n",
      "Epoch 154/200\n",
      "172/172 [==============================] - 0s 862us/sample - loss: 0.4662 - accuracy: 0.8178 - val_loss: 0.4473 - val_accuracy: 0.8062\n",
      "Epoch 155/200\n",
      "172/172 [==============================] - 0s 970us/sample - loss: 0.4630 - accuracy: 0.7965 - val_loss: 0.4465 - val_accuracy: 0.8062\n",
      "Epoch 156/200\n",
      "172/172 [==============================] - 0s 944us/sample - loss: 0.4592 - accuracy: 0.8198 - val_loss: 0.4480 - val_accuracy: 0.8062\n",
      "Epoch 157/200\n",
      "172/172 [==============================] - 0s 947us/sample - loss: 0.4584 - accuracy: 0.8178 - val_loss: 0.4473 - val_accuracy: 0.8062\n",
      "Epoch 158/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.4609 - accuracy: 0.8081 - val_loss: 0.4463 - val_accuracy: 0.8062\n",
      "Epoch 159/200\n",
      "172/172 [==============================] - 0s 948us/sample - loss: 0.4572 - accuracy: 0.8023 - val_loss: 0.4442 - val_accuracy: 0.8062\n",
      "Epoch 160/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 0.4572 - accuracy: 0.8159 - val_loss: 0.4493 - val_accuracy: 0.8062\n",
      "Epoch 161/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.4574 - accuracy: 0.8159 - val_loss: 0.4444 - val_accuracy: 0.8062\n",
      "Epoch 162/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 0.4571 - accuracy: 0.8043 - val_loss: 0.4431 - val_accuracy: 0.8062\n",
      "Epoch 163/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 0.4576 - accuracy: 0.8120 - val_loss: 0.4455 - val_accuracy: 0.8062\n",
      "Epoch 164/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.4557 - accuracy: 0.8062 - val_loss: 0.4424 - val_accuracy: 0.8062\n",
      "Epoch 165/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 877us/sample - loss: 0.4574 - accuracy: 0.8043 - val_loss: 0.4492 - val_accuracy: 0.8062\n",
      "Epoch 166/200\n",
      "172/172 [==============================] - 0s 865us/sample - loss: 0.4546 - accuracy: 0.8178 - val_loss: 0.4409 - val_accuracy: 0.7984\n",
      "Epoch 167/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.4562 - accuracy: 0.7984 - val_loss: 0.4445 - val_accuracy: 0.8062\n",
      "Epoch 168/200\n",
      "172/172 [==============================] - 0s 947us/sample - loss: 0.4568 - accuracy: 0.8198 - val_loss: 0.4448 - val_accuracy: 0.8062\n",
      "Epoch 169/200\n",
      "172/172 [==============================] - 0s 951us/sample - loss: 0.4562 - accuracy: 0.8178 - val_loss: 0.4458 - val_accuracy: 0.8062\n",
      "Epoch 170/200\n",
      "172/172 [==============================] - 0s 976us/sample - loss: 0.4569 - accuracy: 0.8101 - val_loss: 0.4413 - val_accuracy: 0.8062\n",
      "Epoch 171/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.4694 - accuracy: 0.8178 - val_loss: 0.4437 - val_accuracy: 0.8062\n",
      "Epoch 172/200\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 0.4546 - accuracy: 0.8217 - val_loss: 0.4409 - val_accuracy: 0.8062\n",
      "Epoch 173/200\n",
      "172/172 [==============================] - 0s 857us/sample - loss: 0.4528 - accuracy: 0.8120 - val_loss: 0.4423 - val_accuracy: 0.8062\n",
      "Epoch 174/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 0.4592 - accuracy: 0.8236 - val_loss: 0.4428 - val_accuracy: 0.8062\n",
      "Epoch 175/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 0.4553 - accuracy: 0.8023 - val_loss: 0.4400 - val_accuracy: 0.8062\n",
      "Epoch 176/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 0.4507 - accuracy: 0.8140 - val_loss: 0.4446 - val_accuracy: 0.8062\n",
      "Epoch 177/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 0.4520 - accuracy: 0.8236 - val_loss: 0.4399 - val_accuracy: 0.8062\n",
      "Epoch 178/200\n",
      "172/172 [==============================] - 0s 857us/sample - loss: 0.4527 - accuracy: 0.8023 - val_loss: 0.4382 - val_accuracy: 0.7984\n",
      "Epoch 179/200\n",
      "172/172 [==============================] - 0s 852us/sample - loss: 0.4524 - accuracy: 0.8178 - val_loss: 0.4436 - val_accuracy: 0.8062\n",
      "Epoch 180/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.4532 - accuracy: 0.8198 - val_loss: 0.4414 - val_accuracy: 0.8062\n",
      "Epoch 181/200\n",
      "172/172 [==============================] - 0s 942us/sample - loss: 0.4519 - accuracy: 0.8198 - val_loss: 0.4401 - val_accuracy: 0.8062\n",
      "Epoch 182/200\n",
      "172/172 [==============================] - 0s 951us/sample - loss: 0.4502 - accuracy: 0.8159 - val_loss: 0.4413 - val_accuracy: 0.8062\n",
      "Epoch 183/200\n",
      "172/172 [==============================] - 0s 969us/sample - loss: 0.4494 - accuracy: 0.8217 - val_loss: 0.4386 - val_accuracy: 0.8062\n",
      "Epoch 184/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.4548 - accuracy: 0.7965 - val_loss: 0.4413 - val_accuracy: 0.8062\n",
      "Epoch 185/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.4536 - accuracy: 0.8314 - val_loss: 0.4486 - val_accuracy: 0.8140\n",
      "Epoch 186/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 0.4498 - accuracy: 0.8198 - val_loss: 0.4413 - val_accuracy: 0.8062\n",
      "Epoch 187/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.4517 - accuracy: 0.8140 - val_loss: 0.4437 - val_accuracy: 0.8062\n",
      "Epoch 188/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 0.4504 - accuracy: 0.8198 - val_loss: 0.4389 - val_accuracy: 0.8062\n",
      "Epoch 189/200\n",
      "172/172 [==============================] - 0s 880us/sample - loss: 0.4545 - accuracy: 0.8081 - val_loss: 0.4394 - val_accuracy: 0.8062\n",
      "Epoch 190/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.4597 - accuracy: 0.8198 - val_loss: 0.4377 - val_accuracy: 0.8062\n",
      "Epoch 191/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.4508 - accuracy: 0.8023 - val_loss: 0.4405 - val_accuracy: 0.8062\n",
      "Epoch 192/200\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 0.4614 - accuracy: 0.8295 - val_loss: 0.4364 - val_accuracy: 0.8062\n",
      "Epoch 193/200\n",
      "172/172 [==============================] - 0s 968us/sample - loss: 0.4574 - accuracy: 0.7965 - val_loss: 0.4378 - val_accuracy: 0.8062\n",
      "Epoch 194/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.4475 - accuracy: 0.8217 - val_loss: 0.4426 - val_accuracy: 0.8062\n",
      "Epoch 195/200\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 0.4484 - accuracy: 0.8217 - val_loss: 0.4359 - val_accuracy: 0.7984\n",
      "Epoch 196/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 0.4542 - accuracy: 0.7984 - val_loss: 0.4403 - val_accuracy: 0.8062\n",
      "Epoch 197/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 0.4523 - accuracy: 0.8256 - val_loss: 0.4453 - val_accuracy: 0.8062\n",
      "Epoch 198/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.4466 - accuracy: 0.8236 - val_loss: 0.4369 - val_accuracy: 0.8062\n",
      "Epoch 199/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4478 - accuracy: 0.8256 - val_loss: 0.4367 - val_accuracy: 0.8062\n",
      "Epoch 200/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 0.4466 - accuracy: 0.8159 - val_loss: 0.4359 - val_accuracy: 0.8062\n",
      "Beginning training for dr=0.001, l_lambda=1.0e-03, reg_type=l2, act: tanh\n",
      "Train on 172 samples, validate on 43 samples\n",
      "Epoch 1/200\n",
      "172/172 [==============================] - 2s 10ms/sample - loss: 0.6475 - accuracy: 0.6667 - val_loss: 0.6162 - val_accuracy: 0.6667\n",
      "Epoch 2/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 0.5938 - accuracy: 0.6667 - val_loss: 0.5685 - val_accuracy: 0.6667\n",
      "Epoch 3/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.5598 - accuracy: 0.7539 - val_loss: 0.5348 - val_accuracy: 0.7829\n",
      "Epoch 4/200\n",
      "172/172 [==============================] - 0s 860us/sample - loss: 0.5356 - accuracy: 0.7791 - val_loss: 0.5262 - val_accuracy: 0.7829\n",
      "Epoch 5/200\n",
      "172/172 [==============================] - 0s 854us/sample - loss: 0.5312 - accuracy: 0.7791 - val_loss: 0.5240 - val_accuracy: 0.7829\n",
      "Epoch 6/200\n",
      "172/172 [==============================] - 0s 855us/sample - loss: 0.5281 - accuracy: 0.7791 - val_loss: 0.5215 - val_accuracy: 0.7829\n",
      "Epoch 7/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5267 - accuracy: 0.7791 - val_loss: 0.5203 - val_accuracy: 0.7829\n",
      "Epoch 8/200\n",
      "172/172 [==============================] - 0s 956us/sample - loss: 0.5260 - accuracy: 0.7791 - val_loss: 0.5190 - val_accuracy: 0.7829\n",
      "Epoch 9/200\n",
      "172/172 [==============================] - 0s 950us/sample - loss: 0.5251 - accuracy: 0.7791 - val_loss: 0.5177 - val_accuracy: 0.7829\n",
      "Epoch 10/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.5236 - accuracy: 0.7791 - val_loss: 0.5170 - val_accuracy: 0.7829\n",
      "Epoch 11/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 0.5232 - accuracy: 0.7791 - val_loss: 0.5165 - val_accuracy: 0.7829\n",
      "Epoch 12/200\n",
      "172/172 [==============================] - 0s 847us/sample - loss: 0.5229 - accuracy: 0.7791 - val_loss: 0.5164 - val_accuracy: 0.7829\n",
      "Epoch 13/200\n",
      "172/172 [==============================] - 0s 836us/sample - loss: 0.5232 - accuracy: 0.7791 - val_loss: 0.5151 - val_accuracy: 0.7829\n",
      "Epoch 14/200\n",
      "172/172 [==============================] - 0s 841us/sample - loss: 0.5208 - accuracy: 0.7791 - val_loss: 0.5144 - val_accuracy: 0.7829\n",
      "Epoch 15/200\n",
      "172/172 [==============================] - 0s 845us/sample - loss: 0.5210 - accuracy: 0.7791 - val_loss: 0.5142 - val_accuracy: 0.7829\n",
      "Epoch 16/200\n",
      "172/172 [==============================] - 0s 835us/sample - loss: 0.5219 - accuracy: 0.7791 - val_loss: 0.5132 - val_accuracy: 0.7829\n",
      "Epoch 17/200\n",
      "172/172 [==============================] - 0s 848us/sample - loss: 0.5200 - accuracy: 0.7791 - val_loss: 0.5125 - val_accuracy: 0.7829\n",
      "Epoch 18/200\n",
      "172/172 [==============================] - 0s 845us/sample - loss: 0.5213 - accuracy: 0.7791 - val_loss: 0.5121 - val_accuracy: 0.7829\n",
      "Epoch 19/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 844us/sample - loss: 0.5189 - accuracy: 0.7791 - val_loss: 0.5123 - val_accuracy: 0.7829\n",
      "Epoch 20/200\n",
      "172/172 [==============================] - 0s 946us/sample - loss: 0.5198 - accuracy: 0.7791 - val_loss: 0.5114 - val_accuracy: 0.7829\n",
      "Epoch 21/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 0.5184 - accuracy: 0.7791 - val_loss: 0.5110 - val_accuracy: 0.7829\n",
      "Epoch 22/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.5188 - accuracy: 0.7791 - val_loss: 0.5101 - val_accuracy: 0.7829\n",
      "Epoch 23/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 0.5182 - accuracy: 0.7791 - val_loss: 0.5096 - val_accuracy: 0.7829\n",
      "Epoch 24/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.5183 - accuracy: 0.7791 - val_loss: 0.5096 - val_accuracy: 0.7829\n",
      "Epoch 25/200\n",
      "172/172 [==============================] - 0s 861us/sample - loss: 0.5171 - accuracy: 0.7791 - val_loss: 0.5086 - val_accuracy: 0.7829\n",
      "Epoch 26/200\n",
      "172/172 [==============================] - 0s 838us/sample - loss: 0.5166 - accuracy: 0.7791 - val_loss: 0.5082 - val_accuracy: 0.7829\n",
      "Epoch 27/200\n",
      "172/172 [==============================] - 0s 853us/sample - loss: 0.5163 - accuracy: 0.7791 - val_loss: 0.5077 - val_accuracy: 0.7829\n",
      "Epoch 28/200\n",
      "172/172 [==============================] - 0s 838us/sample - loss: 0.5156 - accuracy: 0.7791 - val_loss: 0.5069 - val_accuracy: 0.7829\n",
      "Epoch 29/200\n",
      "172/172 [==============================] - 0s 837us/sample - loss: 0.5172 - accuracy: 0.7791 - val_loss: 0.5074 - val_accuracy: 0.7829\n",
      "Epoch 30/200\n",
      "172/172 [==============================] - 0s 840us/sample - loss: 0.5150 - accuracy: 0.7791 - val_loss: 0.5065 - val_accuracy: 0.7829\n",
      "Epoch 31/200\n",
      "172/172 [==============================] - 0s 850us/sample - loss: 0.5140 - accuracy: 0.7791 - val_loss: 0.5053 - val_accuracy: 0.7829\n",
      "Epoch 32/200\n",
      "172/172 [==============================] - 0s 844us/sample - loss: 0.5147 - accuracy: 0.7791 - val_loss: 0.5052 - val_accuracy: 0.7829\n",
      "Epoch 33/200\n",
      "172/172 [==============================] - 0s 973us/sample - loss: 0.5138 - accuracy: 0.7791 - val_loss: 0.5049 - val_accuracy: 0.7829\n",
      "Epoch 34/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 0.5123 - accuracy: 0.7791 - val_loss: 0.5037 - val_accuracy: 0.7829\n",
      "Epoch 35/200\n",
      "172/172 [==============================] - 0s 930us/sample - loss: 0.5120 - accuracy: 0.7810 - val_loss: 0.5031 - val_accuracy: 0.7829\n",
      "Epoch 36/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.5120 - accuracy: 0.7810 - val_loss: 0.5029 - val_accuracy: 0.7829\n",
      "Epoch 37/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 0.5132 - accuracy: 0.7810 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 38/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.5112 - accuracy: 0.7810 - val_loss: 0.5013 - val_accuracy: 0.7829\n",
      "Epoch 39/200\n",
      "172/172 [==============================] - 0s 860us/sample - loss: 0.5107 - accuracy: 0.7810 - val_loss: 0.5011 - val_accuracy: 0.7829\n",
      "Epoch 40/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 0.5089 - accuracy: 0.7810 - val_loss: 0.4996 - val_accuracy: 0.7829\n",
      "Epoch 41/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.5084 - accuracy: 0.7810 - val_loss: 0.4989 - val_accuracy: 0.7829\n",
      "Epoch 42/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.5085 - accuracy: 0.7810 - val_loss: 0.4992 - val_accuracy: 0.7829\n",
      "Epoch 43/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 0.5098 - accuracy: 0.7810 - val_loss: 0.4973 - val_accuracy: 0.7829\n",
      "Epoch 44/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.5065 - accuracy: 0.7791 - val_loss: 0.4989 - val_accuracy: 0.7829\n",
      "Epoch 45/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.5056 - accuracy: 0.7791 - val_loss: 0.4957 - val_accuracy: 0.7829\n",
      "Epoch 46/200\n",
      "172/172 [==============================] - 0s 991us/sample - loss: 0.5050 - accuracy: 0.7810 - val_loss: 0.4942 - val_accuracy: 0.7829\n",
      "Epoch 47/200\n",
      "172/172 [==============================] - 0s 965us/sample - loss: 0.5039 - accuracy: 0.7791 - val_loss: 0.4932 - val_accuracy: 0.7829\n",
      "Epoch 48/200\n",
      "172/172 [==============================] - 0s 963us/sample - loss: 0.5052 - accuracy: 0.7791 - val_loss: 0.4918 - val_accuracy: 0.7829\n",
      "Epoch 49/200\n",
      "172/172 [==============================] - 0s 971us/sample - loss: 0.5045 - accuracy: 0.7810 - val_loss: 0.4906 - val_accuracy: 0.7829\n",
      "Epoch 50/200\n",
      "172/172 [==============================] - 0s 961us/sample - loss: 0.5010 - accuracy: 0.7791 - val_loss: 0.4934 - val_accuracy: 0.7907\n",
      "Epoch 51/200\n",
      "172/172 [==============================] - 0s 899us/sample - loss: 0.5017 - accuracy: 0.7810 - val_loss: 0.4885 - val_accuracy: 0.7907\n",
      "Epoch 52/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.5010 - accuracy: 0.7810 - val_loss: 0.4868 - val_accuracy: 0.7907\n",
      "Epoch 53/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.4971 - accuracy: 0.7810 - val_loss: 0.4852 - val_accuracy: 0.7907\n",
      "Epoch 54/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.4954 - accuracy: 0.7810 - val_loss: 0.4832 - val_accuracy: 0.7907\n",
      "Epoch 55/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.4940 - accuracy: 0.7810 - val_loss: 0.4819 - val_accuracy: 0.7907\n",
      "Epoch 56/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.4925 - accuracy: 0.7810 - val_loss: 0.4804 - val_accuracy: 0.7907\n",
      "Epoch 57/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.4906 - accuracy: 0.7829 - val_loss: 0.4787 - val_accuracy: 0.7984\n",
      "Epoch 58/200\n",
      "172/172 [==============================] - 0s 964us/sample - loss: 0.4957 - accuracy: 0.7849 - val_loss: 0.4761 - val_accuracy: 0.7984\n",
      "Epoch 59/200\n",
      "172/172 [==============================] - 0s 963us/sample - loss: 0.4920 - accuracy: 0.7829 - val_loss: 0.4742 - val_accuracy: 0.7984\n",
      "Epoch 60/200\n",
      "172/172 [==============================] - 0s 957us/sample - loss: 0.4894 - accuracy: 0.7888 - val_loss: 0.4753 - val_accuracy: 0.8062\n",
      "Epoch 61/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4862 - accuracy: 0.7829 - val_loss: 0.4700 - val_accuracy: 0.7984\n",
      "Epoch 62/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4836 - accuracy: 0.7888 - val_loss: 0.4698 - val_accuracy: 0.7984\n",
      "Epoch 63/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.4809 - accuracy: 0.7907 - val_loss: 0.4660 - val_accuracy: 0.7984\n",
      "Epoch 64/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 0.4793 - accuracy: 0.7849 - val_loss: 0.4659 - val_accuracy: 0.7984\n",
      "Epoch 65/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 0.4766 - accuracy: 0.7984 - val_loss: 0.4636 - val_accuracy: 0.7984\n",
      "Epoch 66/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.4771 - accuracy: 0.7907 - val_loss: 0.4618 - val_accuracy: 0.7984\n",
      "Epoch 67/200\n",
      "172/172 [==============================] - 0s 908us/sample - loss: 0.4790 - accuracy: 0.8023 - val_loss: 0.4587 - val_accuracy: 0.8062\n",
      "Epoch 68/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 0.4750 - accuracy: 0.7946 - val_loss: 0.4592 - val_accuracy: 0.7984\n",
      "Epoch 69/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.4712 - accuracy: 0.7984 - val_loss: 0.4557 - val_accuracy: 0.7984\n",
      "Epoch 70/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.4681 - accuracy: 0.8004 - val_loss: 0.4559 - val_accuracy: 0.8062\n",
      "Epoch 71/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4674 - accuracy: 0.7946 - val_loss: 0.4552 - val_accuracy: 0.8062\n",
      "Epoch 72/200\n",
      "172/172 [==============================] - 0s 961us/sample - loss: 0.4675 - accuracy: 0.7965 - val_loss: 0.4515 - val_accuracy: 0.8062\n",
      "Epoch 73/200\n",
      "172/172 [==============================] - 0s 949us/sample - loss: 0.4648 - accuracy: 0.8004 - val_loss: 0.4503 - val_accuracy: 0.8062\n",
      "Epoch 74/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 940us/sample - loss: 0.4652 - accuracy: 0.8081 - val_loss: 0.4580 - val_accuracy: 0.8062\n",
      "Epoch 75/200\n",
      "172/172 [==============================] - 0s 956us/sample - loss: 0.4652 - accuracy: 0.8004 - val_loss: 0.4490 - val_accuracy: 0.8062\n",
      "Epoch 76/200\n",
      "172/172 [==============================] - 0s 865us/sample - loss: 0.4655 - accuracy: 0.8023 - val_loss: 0.4462 - val_accuracy: 0.8062\n",
      "Epoch 77/200\n",
      "172/172 [==============================] - 0s 858us/sample - loss: 0.4604 - accuracy: 0.8140 - val_loss: 0.4467 - val_accuracy: 0.8062\n",
      "Epoch 78/200\n",
      "172/172 [==============================] - 0s 860us/sample - loss: 0.4653 - accuracy: 0.8023 - val_loss: 0.4589 - val_accuracy: 0.8217\n",
      "Epoch 79/200\n",
      "172/172 [==============================] - 0s 861us/sample - loss: 0.4566 - accuracy: 0.8198 - val_loss: 0.4425 - val_accuracy: 0.7984\n",
      "Epoch 80/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4574 - accuracy: 0.8120 - val_loss: 0.4472 - val_accuracy: 0.8062\n",
      "Epoch 81/200\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 0.4597 - accuracy: 0.8081 - val_loss: 0.4421 - val_accuracy: 0.8062\n",
      "Epoch 82/200\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 0.4543 - accuracy: 0.8101 - val_loss: 0.4481 - val_accuracy: 0.8062\n",
      "Epoch 83/200\n",
      "172/172 [==============================] - 0s 996us/sample - loss: 0.4528 - accuracy: 0.8198 - val_loss: 0.4398 - val_accuracy: 0.7984\n",
      "Epoch 84/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.4617 - accuracy: 0.8004 - val_loss: 0.4549 - val_accuracy: 0.8295\n",
      "Epoch 85/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.4512 - accuracy: 0.8217 - val_loss: 0.4391 - val_accuracy: 0.7984\n",
      "Epoch 86/200\n",
      "172/172 [==============================] - 0s 948us/sample - loss: 0.4513 - accuracy: 0.8140 - val_loss: 0.4680 - val_accuracy: 0.8295\n",
      "Epoch 87/200\n",
      "172/172 [==============================] - 0s 959us/sample - loss: 0.4502 - accuracy: 0.8159 - val_loss: 0.4368 - val_accuracy: 0.7907\n",
      "Epoch 88/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.4544 - accuracy: 0.8062 - val_loss: 0.4647 - val_accuracy: 0.8295\n",
      "Epoch 89/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 0.4529 - accuracy: 0.8159 - val_loss: 0.4362 - val_accuracy: 0.8062\n",
      "Epoch 90/200\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 0.4527 - accuracy: 0.8140 - val_loss: 0.4353 - val_accuracy: 0.8062\n",
      "Epoch 91/200\n",
      "172/172 [==============================] - 0s 864us/sample - loss: 0.4552 - accuracy: 0.8198 - val_loss: 0.4347 - val_accuracy: 0.7907\n",
      "Epoch 92/200\n",
      "172/172 [==============================] - 0s 865us/sample - loss: 0.4570 - accuracy: 0.8023 - val_loss: 0.4523 - val_accuracy: 0.8450\n",
      "Epoch 93/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 0.4471 - accuracy: 0.8236 - val_loss: 0.4350 - val_accuracy: 0.8062\n",
      "Epoch 94/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.4467 - accuracy: 0.8217 - val_loss: 0.4362 - val_accuracy: 0.8062\n",
      "Epoch 95/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.4504 - accuracy: 0.8159 - val_loss: 0.4409 - val_accuracy: 0.8295\n",
      "Epoch 96/200\n",
      "172/172 [==============================] - 0s 981us/sample - loss: 0.4633 - accuracy: 0.8062 - val_loss: 0.4520 - val_accuracy: 0.8450\n",
      "Epoch 97/200\n",
      "172/172 [==============================] - 0s 995us/sample - loss: 0.4571 - accuracy: 0.8081 - val_loss: 0.4474 - val_accuracy: 0.8450\n",
      "Epoch 98/200\n",
      "172/172 [==============================] - 0s 944us/sample - loss: 0.4464 - accuracy: 0.8178 - val_loss: 0.4349 - val_accuracy: 0.8062\n",
      "Epoch 99/200\n",
      "172/172 [==============================] - 0s 963us/sample - loss: 0.4428 - accuracy: 0.8256 - val_loss: 0.4339 - val_accuracy: 0.8062\n",
      "Epoch 100/200\n",
      "172/172 [==============================] - 0s 964us/sample - loss: 0.4454 - accuracy: 0.8198 - val_loss: 0.4303 - val_accuracy: 0.7984\n",
      "Epoch 101/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.4525 - accuracy: 0.8101 - val_loss: 0.4439 - val_accuracy: 0.8450\n",
      "Epoch 102/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.4421 - accuracy: 0.8236 - val_loss: 0.4294 - val_accuracy: 0.8062\n",
      "Epoch 103/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.4432 - accuracy: 0.8256 - val_loss: 0.4309 - val_accuracy: 0.8062\n",
      "Epoch 104/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.4409 - accuracy: 0.8256 - val_loss: 0.4294 - val_accuracy: 0.8062\n",
      "Epoch 105/200\n",
      "172/172 [==============================] - 0s 889us/sample - loss: 0.4416 - accuracy: 0.8256 - val_loss: 0.4565 - val_accuracy: 0.8450\n",
      "Epoch 106/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.4505 - accuracy: 0.8198 - val_loss: 0.4281 - val_accuracy: 0.8062\n",
      "Epoch 107/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.4444 - accuracy: 0.8178 - val_loss: 0.4284 - val_accuracy: 0.8062\n",
      "Epoch 108/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.4582 - accuracy: 0.8062 - val_loss: 0.4433 - val_accuracy: 0.8372\n",
      "Epoch 109/200\n",
      "172/172 [==============================] - 0s 971us/sample - loss: 0.4377 - accuracy: 0.8372 - val_loss: 0.4285 - val_accuracy: 0.7907\n",
      "Epoch 110/200\n",
      "172/172 [==============================] - 0s 978us/sample - loss: 0.4366 - accuracy: 0.8217 - val_loss: 0.4353 - val_accuracy: 0.8295\n",
      "Epoch 111/200\n",
      "172/172 [==============================] - 0s 1000us/sample - loss: 0.4371 - accuracy: 0.8198 - val_loss: 0.4283 - val_accuracy: 0.8062\n",
      "Epoch 112/200\n",
      "172/172 [==============================] - 0s 940us/sample - loss: 0.4389 - accuracy: 0.8275 - val_loss: 0.4342 - val_accuracy: 0.8295\n",
      "Epoch 113/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.4401 - accuracy: 0.8217 - val_loss: 0.4289 - val_accuracy: 0.8217\n",
      "Epoch 114/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 0.4363 - accuracy: 0.8217 - val_loss: 0.4268 - val_accuracy: 0.8062\n",
      "Epoch 115/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 0.4377 - accuracy: 0.8256 - val_loss: 0.4269 - val_accuracy: 0.8062\n",
      "Epoch 116/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.4471 - accuracy: 0.8043 - val_loss: 0.4862 - val_accuracy: 0.8140\n",
      "Epoch 117/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 0.4537 - accuracy: 0.8120 - val_loss: 0.4265 - val_accuracy: 0.7984\n",
      "Epoch 118/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 0.4386 - accuracy: 0.8140 - val_loss: 0.4392 - val_accuracy: 0.8372\n",
      "Epoch 119/200\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 0.4348 - accuracy: 0.8256 - val_loss: 0.4294 - val_accuracy: 0.7984\n",
      "Epoch 120/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.4440 - accuracy: 0.8159 - val_loss: 0.4289 - val_accuracy: 0.8295\n",
      "Epoch 121/200\n",
      "172/172 [==============================] - 0s 948us/sample - loss: 0.4359 - accuracy: 0.8256 - val_loss: 0.4275 - val_accuracy: 0.8217\n",
      "Epoch 122/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.4346 - accuracy: 0.8353 - val_loss: 0.4245 - val_accuracy: 0.8062\n",
      "Epoch 123/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.4329 - accuracy: 0.8236 - val_loss: 0.4357 - val_accuracy: 0.8372\n",
      "Epoch 124/200\n",
      "172/172 [==============================] - 0s 949us/sample - loss: 0.4331 - accuracy: 0.8236 - val_loss: 0.4369 - val_accuracy: 0.8295\n",
      "Epoch 125/200\n",
      "172/172 [==============================] - 0s 949us/sample - loss: 0.4576 - accuracy: 0.8295 - val_loss: 0.4327 - val_accuracy: 0.7984\n",
      "Epoch 126/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.4452 - accuracy: 0.8081 - val_loss: 0.4519 - val_accuracy: 0.8450\n",
      "Epoch 127/200\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 0.4329 - accuracy: 0.8295 - val_loss: 0.4274 - val_accuracy: 0.8217\n",
      "Epoch 128/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 0.4315 - accuracy: 0.8372 - val_loss: 0.4254 - val_accuracy: 0.8140\n",
      "Epoch 129/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 866us/sample - loss: 0.4301 - accuracy: 0.8256 - val_loss: 0.4246 - val_accuracy: 0.8140\n",
      "Epoch 130/200\n",
      "172/172 [==============================] - 0s 857us/sample - loss: 0.4385 - accuracy: 0.8217 - val_loss: 0.4344 - val_accuracy: 0.8372\n",
      "Epoch 131/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.4350 - accuracy: 0.8178 - val_loss: 0.4430 - val_accuracy: 0.8372\n",
      "Epoch 132/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.4345 - accuracy: 0.8256 - val_loss: 0.4351 - val_accuracy: 0.8372\n",
      "Epoch 133/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.4323 - accuracy: 0.8353 - val_loss: 0.4278 - val_accuracy: 0.7984\n",
      "Epoch 134/200\n",
      "172/172 [==============================] - 0s 969us/sample - loss: 0.4416 - accuracy: 0.8236 - val_loss: 0.4396 - val_accuracy: 0.8372\n",
      "Epoch 135/200\n",
      "172/172 [==============================] - 0s 956us/sample - loss: 0.4278 - accuracy: 0.8295 - val_loss: 0.4264 - val_accuracy: 0.7984\n",
      "Epoch 136/200\n",
      "172/172 [==============================] - 0s 967us/sample - loss: 0.4303 - accuracy: 0.8333 - val_loss: 0.4331 - val_accuracy: 0.8372\n",
      "Epoch 137/200\n",
      "172/172 [==============================] - 0s 969us/sample - loss: 0.4275 - accuracy: 0.8372 - val_loss: 0.4241 - val_accuracy: 0.7907\n",
      "Epoch 138/200\n",
      "172/172 [==============================] - 0s 955us/sample - loss: 0.4280 - accuracy: 0.8256 - val_loss: 0.4297 - val_accuracy: 0.8372\n",
      "Epoch 139/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 0.4247 - accuracy: 0.8333 - val_loss: 0.4257 - val_accuracy: 0.7907\n",
      "Epoch 140/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.4347 - accuracy: 0.8275 - val_loss: 0.4216 - val_accuracy: 0.8140\n",
      "Epoch 141/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.4290 - accuracy: 0.8236 - val_loss: 0.4417 - val_accuracy: 0.8372\n",
      "Epoch 142/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.4264 - accuracy: 0.8314 - val_loss: 0.4239 - val_accuracy: 0.8295\n",
      "Epoch 143/200\n",
      "172/172 [==============================] - 0s 885us/sample - loss: 0.4267 - accuracy: 0.8372 - val_loss: 0.4214 - val_accuracy: 0.8295\n",
      "Epoch 144/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.4229 - accuracy: 0.8314 - val_loss: 0.4279 - val_accuracy: 0.8372\n",
      "Epoch 145/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.4214 - accuracy: 0.8391 - val_loss: 0.4235 - val_accuracy: 0.8295\n",
      "Epoch 146/200\n",
      "172/172 [==============================] - 0s 913us/sample - loss: 0.4235 - accuracy: 0.8353 - val_loss: 0.4242 - val_accuracy: 0.8295\n",
      "Epoch 147/200\n",
      "172/172 [==============================] - 0s 964us/sample - loss: 0.4230 - accuracy: 0.8314 - val_loss: 0.4317 - val_accuracy: 0.8372\n",
      "Epoch 148/200\n",
      "172/172 [==============================] - 0s 953us/sample - loss: 0.4271 - accuracy: 0.8275 - val_loss: 0.4327 - val_accuracy: 0.7984\n",
      "Epoch 149/200\n",
      "172/172 [==============================] - 0s 983us/sample - loss: 0.4533 - accuracy: 0.8062 - val_loss: 0.4295 - val_accuracy: 0.8372\n",
      "Epoch 150/200\n",
      "172/172 [==============================] - 0s 961us/sample - loss: 0.4278 - accuracy: 0.8256 - val_loss: 0.4421 - val_accuracy: 0.8450\n",
      "Epoch 151/200\n",
      "172/172 [==============================] - 0s 957us/sample - loss: 0.4212 - accuracy: 0.8372 - val_loss: 0.4238 - val_accuracy: 0.7907\n",
      "Epoch 152/200\n",
      "172/172 [==============================] - 0s 864us/sample - loss: 0.4266 - accuracy: 0.8295 - val_loss: 0.4285 - val_accuracy: 0.8372\n",
      "Epoch 153/200\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 0.4213 - accuracy: 0.8333 - val_loss: 0.4303 - val_accuracy: 0.7984\n",
      "Epoch 154/200\n",
      "172/172 [==============================] - 0s 870us/sample - loss: 0.4419 - accuracy: 0.8140 - val_loss: 0.4419 - val_accuracy: 0.8372\n",
      "Epoch 155/200\n",
      "172/172 [==============================] - 0s 864us/sample - loss: 0.4220 - accuracy: 0.8353 - val_loss: 0.4340 - val_accuracy: 0.8450\n",
      "Epoch 156/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 0.4281 - accuracy: 0.8391 - val_loss: 0.4243 - val_accuracy: 0.7829\n",
      "Epoch 157/200\n",
      "172/172 [==============================] - 0s 861us/sample - loss: 0.4213 - accuracy: 0.8314 - val_loss: 0.4402 - val_accuracy: 0.8450\n",
      "Epoch 158/200\n",
      "172/172 [==============================] - 0s 862us/sample - loss: 0.4242 - accuracy: 0.8353 - val_loss: 0.4278 - val_accuracy: 0.8372\n",
      "Epoch 159/200\n",
      "172/172 [==============================] - 0s 942us/sample - loss: 0.4174 - accuracy: 0.8450 - val_loss: 0.4221 - val_accuracy: 0.8295\n",
      "Epoch 160/200\n",
      "172/172 [==============================] - 0s 947us/sample - loss: 0.4243 - accuracy: 0.8275 - val_loss: 0.4227 - val_accuracy: 0.8295\n",
      "Epoch 161/200\n",
      "172/172 [==============================] - 0s 982us/sample - loss: 0.4204 - accuracy: 0.8372 - val_loss: 0.4219 - val_accuracy: 0.8295\n",
      "Epoch 162/200\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 0.4213 - accuracy: 0.8372 - val_loss: 0.4234 - val_accuracy: 0.8295\n",
      "Epoch 163/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.4232 - accuracy: 0.8295 - val_loss: 0.4453 - val_accuracy: 0.8450\n",
      "Epoch 164/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.4207 - accuracy: 0.8353 - val_loss: 0.4316 - val_accuracy: 0.8372\n",
      "Epoch 165/200\n",
      "172/172 [==============================] - 0s 864us/sample - loss: 0.4188 - accuracy: 0.8353 - val_loss: 0.4263 - val_accuracy: 0.7907\n",
      "Epoch 166/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 0.4174 - accuracy: 0.8236 - val_loss: 0.4486 - val_accuracy: 0.8295\n",
      "Epoch 167/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 0.4324 - accuracy: 0.8236 - val_loss: 0.4234 - val_accuracy: 0.8295\n",
      "Epoch 168/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 0.4155 - accuracy: 0.8450 - val_loss: 0.4237 - val_accuracy: 0.8217\n",
      "Epoch 169/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.4119 - accuracy: 0.8469 - val_loss: 0.4238 - val_accuracy: 0.8295\n",
      "Epoch 170/200\n",
      "172/172 [==============================] - 0s 863us/sample - loss: 0.4142 - accuracy: 0.8353 - val_loss: 0.4294 - val_accuracy: 0.8372\n",
      "Epoch 171/200\n",
      "172/172 [==============================] - 0s 864us/sample - loss: 0.4162 - accuracy: 0.8411 - val_loss: 0.4366 - val_accuracy: 0.7907\n",
      "Epoch 172/200\n",
      "172/172 [==============================] - 0s 941us/sample - loss: 0.4587 - accuracy: 0.8101 - val_loss: 0.4907 - val_accuracy: 0.8140\n",
      "Epoch 173/200\n",
      "172/172 [==============================] - 0s 947us/sample - loss: 0.4346 - accuracy: 0.8178 - val_loss: 0.4410 - val_accuracy: 0.8450\n",
      "Epoch 174/200\n",
      "172/172 [==============================] - 0s 967us/sample - loss: 0.4197 - accuracy: 0.8333 - val_loss: 0.4223 - val_accuracy: 0.7907\n",
      "Epoch 175/200\n",
      "172/172 [==============================] - 0s 964us/sample - loss: 0.4145 - accuracy: 0.8430 - val_loss: 0.4230 - val_accuracy: 0.8217\n",
      "Epoch 176/200\n",
      "172/172 [==============================] - 0s 962us/sample - loss: 0.4133 - accuracy: 0.8372 - val_loss: 0.4256 - val_accuracy: 0.8295\n",
      "Epoch 177/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.4116 - accuracy: 0.8430 - val_loss: 0.4341 - val_accuracy: 0.8450\n",
      "Epoch 178/200\n",
      "172/172 [==============================] - 0s 928us/sample - loss: 0.4136 - accuracy: 0.8391 - val_loss: 0.4303 - val_accuracy: 0.8295\n",
      "Epoch 179/200\n",
      "172/172 [==============================] - 0s 971us/sample - loss: 0.4143 - accuracy: 0.8469 - val_loss: 0.4251 - val_accuracy: 0.7907\n",
      "Epoch 180/200\n",
      "172/172 [==============================] - 0s 930us/sample - loss: 0.4138 - accuracy: 0.8547 - val_loss: 0.4273 - val_accuracy: 0.8295\n",
      "Epoch 181/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.4180 - accuracy: 0.8391 - val_loss: 0.4449 - val_accuracy: 0.8372\n",
      "Epoch 182/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.4128 - accuracy: 0.8469 - val_loss: 0.4236 - val_accuracy: 0.8217\n",
      "Epoch 183/200\n",
      "172/172 [==============================] - 0s 929us/sample - loss: 0.4105 - accuracy: 0.8430 - val_loss: 0.4241 - val_accuracy: 0.8217\n",
      "Epoch 184/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 958us/sample - loss: 0.4149 - accuracy: 0.8333 - val_loss: 0.4241 - val_accuracy: 0.8217\n",
      "Epoch 185/200\n",
      "172/172 [==============================] - 0s 964us/sample - loss: 0.4246 - accuracy: 0.8178 - val_loss: 0.4695 - val_accuracy: 0.8217\n",
      "Epoch 186/200\n",
      "172/172 [==============================] - 0s 949us/sample - loss: 0.4219 - accuracy: 0.8314 - val_loss: 0.4288 - val_accuracy: 0.8295\n",
      "Epoch 187/200\n",
      "172/172 [==============================] - 0s 994us/sample - loss: 0.4062 - accuracy: 0.8450 - val_loss: 0.4224 - val_accuracy: 0.8140\n",
      "Epoch 188/200\n",
      "172/172 [==============================] - 0s 960us/sample - loss: 0.4097 - accuracy: 0.8391 - val_loss: 0.4271 - val_accuracy: 0.8295\n",
      "Epoch 189/200\n",
      "172/172 [==============================] - 0s 930us/sample - loss: 0.4067 - accuracy: 0.8372 - val_loss: 0.4222 - val_accuracy: 0.8140\n",
      "Epoch 190/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.4072 - accuracy: 0.8469 - val_loss: 0.4427 - val_accuracy: 0.8372\n",
      "Epoch 191/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.4039 - accuracy: 0.8450 - val_loss: 0.4219 - val_accuracy: 0.8140\n",
      "Epoch 192/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.4101 - accuracy: 0.8353 - val_loss: 0.4389 - val_accuracy: 0.8450\n",
      "Epoch 193/200\n",
      "172/172 [==============================] - 0s 883us/sample - loss: 0.4020 - accuracy: 0.8411 - val_loss: 0.4222 - val_accuracy: 0.8140\n",
      "Epoch 194/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 0.4135 - accuracy: 0.8295 - val_loss: 0.4421 - val_accuracy: 0.8372\n",
      "Epoch 195/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.4051 - accuracy: 0.8430 - val_loss: 0.4331 - val_accuracy: 0.8295\n",
      "Epoch 196/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.4105 - accuracy: 0.8295 - val_loss: 0.4202 - val_accuracy: 0.8140\n",
      "Epoch 197/200\n",
      "172/172 [==============================] - 0s 981us/sample - loss: 0.4092 - accuracy: 0.8275 - val_loss: 0.4254 - val_accuracy: 0.8295\n",
      "Epoch 198/200\n",
      "172/172 [==============================] - 0s 967us/sample - loss: 0.4231 - accuracy: 0.8333 - val_loss: 0.4376 - val_accuracy: 0.8372\n",
      "Epoch 199/200\n",
      "172/172 [==============================] - 0s 952us/sample - loss: 0.4091 - accuracy: 0.8333 - val_loss: 0.4469 - val_accuracy: 0.8217\n",
      "Epoch 200/200\n",
      "172/172 [==============================] - 0s 960us/sample - loss: 0.4288 - accuracy: 0.8314 - val_loss: 0.4574 - val_accuracy: 0.7829\n",
      "Beginning training for dr=0.001, l_lambda=1.0e-03, reg_type=l2, act: tanh\n",
      "Train on 172 samples, validate on 43 samples\n",
      "Epoch 1/200\n",
      "172/172 [==============================] - 2s 10ms/sample - loss: 0.6480 - accuracy: 0.6667 - val_loss: 0.6042 - val_accuracy: 0.6667\n",
      "Epoch 2/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.5782 - accuracy: 0.7112 - val_loss: 0.5484 - val_accuracy: 0.7829\n",
      "Epoch 3/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.5481 - accuracy: 0.7791 - val_loss: 0.5326 - val_accuracy: 0.7829\n",
      "Epoch 4/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.5387 - accuracy: 0.7791 - val_loss: 0.5301 - val_accuracy: 0.7829\n",
      "Epoch 5/200\n",
      "172/172 [==============================] - 0s 882us/sample - loss: 0.5371 - accuracy: 0.7791 - val_loss: 0.5286 - val_accuracy: 0.7829\n",
      "Epoch 6/200\n",
      "172/172 [==============================] - 0s 857us/sample - loss: 0.5348 - accuracy: 0.7791 - val_loss: 0.5277 - val_accuracy: 0.7829\n",
      "Epoch 7/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.5343 - accuracy: 0.7791 - val_loss: 0.5263 - val_accuracy: 0.7829\n",
      "Epoch 8/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 0.5333 - accuracy: 0.7791 - val_loss: 0.5255 - val_accuracy: 0.7829\n",
      "Epoch 9/200\n",
      "172/172 [==============================] - 0s 853us/sample - loss: 0.5315 - accuracy: 0.7791 - val_loss: 0.5258 - val_accuracy: 0.7829\n",
      "Epoch 10/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.5308 - accuracy: 0.7791 - val_loss: 0.5237 - val_accuracy: 0.7829\n",
      "Epoch 11/200\n",
      "172/172 [==============================] - 0s 966us/sample - loss: 0.5302 - accuracy: 0.7791 - val_loss: 0.5227 - val_accuracy: 0.7829\n",
      "Epoch 12/200\n",
      "172/172 [==============================] - 0s 946us/sample - loss: 0.5330 - accuracy: 0.7791 - val_loss: 0.5216 - val_accuracy: 0.7829\n",
      "Epoch 13/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.5286 - accuracy: 0.7791 - val_loss: 0.5215 - val_accuracy: 0.7829\n",
      "Epoch 14/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 0.5301 - accuracy: 0.7791 - val_loss: 0.5201 - val_accuracy: 0.7829\n",
      "Epoch 15/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.5268 - accuracy: 0.7791 - val_loss: 0.5197 - val_accuracy: 0.7829\n",
      "Epoch 16/200\n",
      "172/172 [==============================] - 0s 867us/sample - loss: 0.5289 - accuracy: 0.7791 - val_loss: 0.5183 - val_accuracy: 0.7829\n",
      "Epoch 17/200\n",
      "172/172 [==============================] - 0s 865us/sample - loss: 0.5271 - accuracy: 0.7791 - val_loss: 0.5178 - val_accuracy: 0.7829\n",
      "Epoch 18/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.5272 - accuracy: 0.7791 - val_loss: 0.5194 - val_accuracy: 0.7829\n",
      "Epoch 19/200\n",
      "172/172 [==============================] - 0s 859us/sample - loss: 0.5248 - accuracy: 0.7791 - val_loss: 0.5165 - val_accuracy: 0.7829\n",
      "Epoch 20/200\n",
      "172/172 [==============================] - 0s 875us/sample - loss: 0.5223 - accuracy: 0.7791 - val_loss: 0.5157 - val_accuracy: 0.7829\n",
      "Epoch 21/200\n",
      "172/172 [==============================] - 0s 860us/sample - loss: 0.5236 - accuracy: 0.7791 - val_loss: 0.5149 - val_accuracy: 0.7829\n",
      "Epoch 22/200\n",
      "172/172 [==============================] - 0s 871us/sample - loss: 0.5245 - accuracy: 0.7791 - val_loss: 0.5144 - val_accuracy: 0.7829\n",
      "Epoch 23/200\n",
      "172/172 [==============================] - 0s 857us/sample - loss: 0.5233 - accuracy: 0.7791 - val_loss: 0.5133 - val_accuracy: 0.7829\n",
      "Epoch 24/200\n",
      "172/172 [==============================] - 0s 966us/sample - loss: 0.5206 - accuracy: 0.7791 - val_loss: 0.5129 - val_accuracy: 0.7829\n",
      "Epoch 25/200\n",
      "172/172 [==============================] - 0s 954us/sample - loss: 0.5210 - accuracy: 0.7791 - val_loss: 0.5124 - val_accuracy: 0.7829\n",
      "Epoch 26/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.5200 - accuracy: 0.7791 - val_loss: 0.5106 - val_accuracy: 0.7829\n",
      "Epoch 27/200\n",
      "172/172 [==============================] - 0s 868us/sample - loss: 0.5183 - accuracy: 0.7810 - val_loss: 0.5102 - val_accuracy: 0.7829\n",
      "Epoch 28/200\n",
      "172/172 [==============================] - 0s 881us/sample - loss: 0.5165 - accuracy: 0.7810 - val_loss: 0.5087 - val_accuracy: 0.7829\n",
      "Epoch 29/200\n",
      "172/172 [==============================] - 0s 869us/sample - loss: 0.5173 - accuracy: 0.7810 - val_loss: 0.5078 - val_accuracy: 0.7829\n",
      "Epoch 30/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.5153 - accuracy: 0.7810 - val_loss: 0.5076 - val_accuracy: 0.7829\n",
      "Epoch 31/200\n",
      "172/172 [==============================] - 0s 882us/sample - loss: 0.5186 - accuracy: 0.7791 - val_loss: 0.5043 - val_accuracy: 0.7829\n",
      "Epoch 32/200\n",
      "172/172 [==============================] - 0s 873us/sample - loss: 0.5161 - accuracy: 0.7810 - val_loss: 0.5028 - val_accuracy: 0.7829\n",
      "Epoch 33/200\n",
      "172/172 [==============================] - 0s 879us/sample - loss: 0.5109 - accuracy: 0.7810 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 34/200\n",
      "172/172 [==============================] - 0s 866us/sample - loss: 0.5102 - accuracy: 0.7791 - val_loss: 0.5010 - val_accuracy: 0.7829\n",
      "Epoch 35/200\n",
      "172/172 [==============================] - 0s 986us/sample - loss: 0.5108 - accuracy: 0.7791 - val_loss: 0.4970 - val_accuracy: 0.7829\n",
      "Epoch 36/200\n",
      "172/172 [==============================] - 0s 961us/sample - loss: 0.5067 - accuracy: 0.7791 - val_loss: 0.4954 - val_accuracy: 0.7907\n",
      "Epoch 37/200\n",
      "172/172 [==============================] - 0s 979us/sample - loss: 0.5075 - accuracy: 0.7829 - val_loss: 0.4948 - val_accuracy: 0.7907\n",
      "Epoch 38/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 967us/sample - loss: 0.5035 - accuracy: 0.7810 - val_loss: 0.4887 - val_accuracy: 0.7907\n",
      "Epoch 39/200\n",
      "172/172 [==============================] - 0s 911us/sample - loss: 0.5007 - accuracy: 0.7791 - val_loss: 0.4875 - val_accuracy: 0.7984\n",
      "Epoch 40/200\n",
      "172/172 [==============================] - 0s 872us/sample - loss: 0.5016 - accuracy: 0.7926 - val_loss: 0.4826 - val_accuracy: 0.7907\n",
      "Epoch 41/200\n",
      "172/172 [==============================] - 0s 877us/sample - loss: 0.5065 - accuracy: 0.7829 - val_loss: 0.4811 - val_accuracy: 0.7984\n",
      "Epoch 42/200\n",
      "172/172 [==============================] - 0s 888us/sample - loss: 0.5030 - accuracy: 0.8120 - val_loss: 0.4783 - val_accuracy: 0.7984\n",
      "Epoch 43/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.4921 - accuracy: 0.7810 - val_loss: 0.4760 - val_accuracy: 0.7907\n",
      "Epoch 44/200\n",
      "172/172 [==============================] - 0s 874us/sample - loss: 0.4860 - accuracy: 0.7810 - val_loss: 0.4724 - val_accuracy: 0.7984\n",
      "Epoch 45/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.4920 - accuracy: 0.7907 - val_loss: 0.4687 - val_accuracy: 0.7984\n",
      "Epoch 46/200\n",
      "172/172 [==============================] - 0s 878us/sample - loss: 0.4784 - accuracy: 0.8062 - val_loss: 0.4666 - val_accuracy: 0.8062\n",
      "Epoch 47/200\n",
      "172/172 [==============================] - 0s 882us/sample - loss: 0.4844 - accuracy: 0.7888 - val_loss: 0.4635 - val_accuracy: 0.7984\n",
      "Epoch 48/200\n",
      "172/172 [==============================] - 0s 876us/sample - loss: 0.4735 - accuracy: 0.8023 - val_loss: 0.4660 - val_accuracy: 0.8062\n",
      "Epoch 49/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 0.4687 - accuracy: 0.8004 - val_loss: 0.4577 - val_accuracy: 0.8062\n",
      "Epoch 50/200\n",
      "172/172 [==============================] - 0s 969us/sample - loss: 0.4645 - accuracy: 0.8004 - val_loss: 0.4580 - val_accuracy: 0.8062\n",
      "Epoch 51/200\n",
      "172/172 [==============================] - 0s 984us/sample - loss: 0.4641 - accuracy: 0.8120 - val_loss: 0.4616 - val_accuracy: 0.8062\n",
      "Epoch 52/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 0.4615 - accuracy: 0.8198 - val_loss: 0.4495 - val_accuracy: 0.7907\n",
      "Epoch 53/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.4628 - accuracy: 0.8140 - val_loss: 0.4470 - val_accuracy: 0.8062\n",
      "Epoch 54/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.4704 - accuracy: 0.8043 - val_loss: 0.4586 - val_accuracy: 0.8217\n",
      "Epoch 55/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.4564 - accuracy: 0.8101 - val_loss: 0.4527 - val_accuracy: 0.8140\n",
      "Epoch 56/200\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 0.4604 - accuracy: 0.8062 - val_loss: 0.4431 - val_accuracy: 0.8062\n",
      "Epoch 57/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.4726 - accuracy: 0.8081 - val_loss: 0.4460 - val_accuracy: 0.7984\n",
      "Epoch 58/200\n",
      "172/172 [==============================] - 0s 969us/sample - loss: 0.4563 - accuracy: 0.8217 - val_loss: 0.4424 - val_accuracy: 0.8062\n",
      "Epoch 59/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.4528 - accuracy: 0.8120 - val_loss: 0.4449 - val_accuracy: 0.8062\n",
      "Epoch 60/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.4577 - accuracy: 0.8178 - val_loss: 0.4442 - val_accuracy: 0.7984\n",
      "Epoch 61/200\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 0.4567 - accuracy: 0.8062 - val_loss: 0.4620 - val_accuracy: 0.8217\n",
      "Epoch 62/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4525 - accuracy: 0.8140 - val_loss: 0.4489 - val_accuracy: 0.8295\n",
      "Epoch 63/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4520 - accuracy: 0.8081 - val_loss: 0.4399 - val_accuracy: 0.8140\n",
      "Epoch 64/200\n",
      "172/172 [==============================] - 0s 988us/sample - loss: 0.4496 - accuracy: 0.8140 - val_loss: 0.4768 - val_accuracy: 0.8295\n",
      "Epoch 65/200\n",
      "172/172 [==============================] - 0s 961us/sample - loss: 0.4561 - accuracy: 0.8004 - val_loss: 0.4469 - val_accuracy: 0.8372\n",
      "Epoch 66/200\n",
      "172/172 [==============================] - 0s 952us/sample - loss: 0.4587 - accuracy: 0.8101 - val_loss: 0.4343 - val_accuracy: 0.8062\n",
      "Epoch 67/200\n",
      "172/172 [==============================] - 0s 954us/sample - loss: 0.4462 - accuracy: 0.8198 - val_loss: 0.4363 - val_accuracy: 0.8140\n",
      "Epoch 68/200\n",
      "172/172 [==============================] - 0s 955us/sample - loss: 0.4389 - accuracy: 0.8314 - val_loss: 0.4517 - val_accuracy: 0.8372\n",
      "Epoch 69/200\n",
      "172/172 [==============================] - 0s 962us/sample - loss: 0.4413 - accuracy: 0.8198 - val_loss: 0.4310 - val_accuracy: 0.8062\n",
      "Epoch 70/200\n",
      "172/172 [==============================] - 0s 949us/sample - loss: 0.4386 - accuracy: 0.8178 - val_loss: 0.4324 - val_accuracy: 0.8140\n",
      "Epoch 71/200\n",
      "172/172 [==============================] - 0s 927us/sample - loss: 0.4370 - accuracy: 0.8217 - val_loss: 0.4500 - val_accuracy: 0.8372\n",
      "Epoch 72/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 0.4450 - accuracy: 0.8217 - val_loss: 0.4553 - val_accuracy: 0.8372\n",
      "Epoch 73/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.4372 - accuracy: 0.8178 - val_loss: 0.4290 - val_accuracy: 0.7907\n",
      "Epoch 74/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4382 - accuracy: 0.8236 - val_loss: 0.4277 - val_accuracy: 0.8062\n",
      "Epoch 75/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4608 - accuracy: 0.8043 - val_loss: 0.4276 - val_accuracy: 0.8140\n",
      "Epoch 76/200\n",
      "172/172 [==============================] - 0s 960us/sample - loss: 0.4559 - accuracy: 0.8120 - val_loss: 0.5196 - val_accuracy: 0.7907\n",
      "Epoch 77/200\n",
      "172/172 [==============================] - 0s 931us/sample - loss: 0.4875 - accuracy: 0.7888 - val_loss: 0.4422 - val_accuracy: 0.8372\n",
      "Epoch 78/200\n",
      "172/172 [==============================] - 0s 901us/sample - loss: 0.4531 - accuracy: 0.8159 - val_loss: 0.4320 - val_accuracy: 0.7907\n",
      "Epoch 79/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.4472 - accuracy: 0.8101 - val_loss: 0.4461 - val_accuracy: 0.8372\n",
      "Epoch 80/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.4370 - accuracy: 0.8217 - val_loss: 0.4394 - val_accuracy: 0.8372\n",
      "Epoch 81/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.4697 - accuracy: 0.8101 - val_loss: 0.4405 - val_accuracy: 0.7829\n",
      "Epoch 82/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 0.4378 - accuracy: 0.8198 - val_loss: 0.4646 - val_accuracy: 0.8295\n",
      "Epoch 83/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.4480 - accuracy: 0.8120 - val_loss: 0.4300 - val_accuracy: 0.8140\n",
      "Epoch 84/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.4364 - accuracy: 0.8256 - val_loss: 0.4336 - val_accuracy: 0.8295\n",
      "Epoch 85/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.4287 - accuracy: 0.8295 - val_loss: 0.4301 - val_accuracy: 0.8295\n",
      "Epoch 86/200\n",
      "172/172 [==============================] - 0s 968us/sample - loss: 0.4296 - accuracy: 0.8275 - val_loss: 0.4284 - val_accuracy: 0.8295\n",
      "Epoch 87/200\n",
      "172/172 [==============================] - 0s 971us/sample - loss: 0.4360 - accuracy: 0.8236 - val_loss: 0.4449 - val_accuracy: 0.8372\n",
      "Epoch 88/200\n",
      "172/172 [==============================] - 0s 970us/sample - loss: 0.4258 - accuracy: 0.8236 - val_loss: 0.4241 - val_accuracy: 0.8062\n",
      "Epoch 89/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.4383 - accuracy: 0.8217 - val_loss: 0.4981 - val_accuracy: 0.8217\n",
      "Epoch 90/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.4442 - accuracy: 0.8120 - val_loss: 0.4360 - val_accuracy: 0.7984\n",
      "Epoch 91/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.4353 - accuracy: 0.8275 - val_loss: 0.4305 - val_accuracy: 0.8295\n",
      "Epoch 92/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.4305 - accuracy: 0.8314 - val_loss: 0.4310 - val_accuracy: 0.8295\n",
      "Epoch 93/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 895us/sample - loss: 0.4248 - accuracy: 0.8256 - val_loss: 0.4298 - val_accuracy: 0.8295\n",
      "Epoch 94/200\n",
      "172/172 [==============================] - 0s 886us/sample - loss: 0.4323 - accuracy: 0.8295 - val_loss: 0.4249 - val_accuracy: 0.8217\n",
      "Epoch 95/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.4266 - accuracy: 0.8275 - val_loss: 0.4309 - val_accuracy: 0.8372\n",
      "Epoch 96/200\n",
      "172/172 [==============================] - 0s 890us/sample - loss: 0.4202 - accuracy: 0.8333 - val_loss: 0.4239 - val_accuracy: 0.8217\n",
      "Epoch 97/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 0.4205 - accuracy: 0.8256 - val_loss: 0.4361 - val_accuracy: 0.8372\n",
      "Epoch 98/200\n",
      "172/172 [==============================] - 0s 884us/sample - loss: 0.4275 - accuracy: 0.8295 - val_loss: 0.4267 - val_accuracy: 0.8295\n",
      "Epoch 99/200\n",
      "172/172 [==============================] - 0s 975us/sample - loss: 0.4245 - accuracy: 0.8295 - val_loss: 0.4260 - val_accuracy: 0.8217\n",
      "Epoch 100/200\n",
      "172/172 [==============================] - 0s 973us/sample - loss: 0.4197 - accuracy: 0.8333 - val_loss: 0.4320 - val_accuracy: 0.8372\n",
      "Epoch 101/200\n",
      "172/172 [==============================] - 0s 956us/sample - loss: 0.4169 - accuracy: 0.8314 - val_loss: 0.4261 - val_accuracy: 0.8217\n",
      "Epoch 102/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.4168 - accuracy: 0.8295 - val_loss: 0.4242 - val_accuracy: 0.7907\n",
      "Epoch 103/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.4211 - accuracy: 0.8333 - val_loss: 0.4256 - val_accuracy: 0.7907\n",
      "Epoch 104/200\n",
      "172/172 [==============================] - 0s 916us/sample - loss: 0.4287 - accuracy: 0.8256 - val_loss: 0.4267 - val_accuracy: 0.8217\n",
      "Epoch 105/200\n",
      "172/172 [==============================] - 0s 915us/sample - loss: 0.4178 - accuracy: 0.8314 - val_loss: 0.4451 - val_accuracy: 0.8450\n",
      "Epoch 106/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.4176 - accuracy: 0.8353 - val_loss: 0.4279 - val_accuracy: 0.8372\n",
      "Epoch 107/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.4162 - accuracy: 0.8372 - val_loss: 0.4220 - val_accuracy: 0.8062\n",
      "Epoch 108/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.4203 - accuracy: 0.8314 - val_loss: 0.4279 - val_accuracy: 0.8372\n",
      "Epoch 109/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.4153 - accuracy: 0.8314 - val_loss: 0.4217 - val_accuracy: 0.8217\n",
      "Epoch 110/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 0.4163 - accuracy: 0.8333 - val_loss: 0.4229 - val_accuracy: 0.8217\n",
      "Epoch 111/200\n",
      "172/172 [==============================] - 0s 978us/sample - loss: 0.4099 - accuracy: 0.8450 - val_loss: 0.4203 - val_accuracy: 0.8217\n",
      "Epoch 112/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.4174 - accuracy: 0.8411 - val_loss: 0.4235 - val_accuracy: 0.7907\n",
      "Epoch 113/200\n",
      "172/172 [==============================] - 0s 984us/sample - loss: 0.4219 - accuracy: 0.8411 - val_loss: 0.4192 - val_accuracy: 0.8140\n",
      "Epoch 114/200\n",
      "172/172 [==============================] - 0s 922us/sample - loss: 0.4135 - accuracy: 0.8391 - val_loss: 0.4232 - val_accuracy: 0.8295\n",
      "Epoch 115/200\n",
      "172/172 [==============================] - 0s 925us/sample - loss: 0.4081 - accuracy: 0.8411 - val_loss: 0.4354 - val_accuracy: 0.8450\n",
      "Epoch 116/200\n",
      "172/172 [==============================] - 0s 919us/sample - loss: 0.4137 - accuracy: 0.8353 - val_loss: 0.4364 - val_accuracy: 0.7984\n",
      "Epoch 117/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.4172 - accuracy: 0.8236 - val_loss: 0.4299 - val_accuracy: 0.8295\n",
      "Epoch 118/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 0.4097 - accuracy: 0.8391 - val_loss: 0.4362 - val_accuracy: 0.8372\n",
      "Epoch 119/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.4049 - accuracy: 0.8430 - val_loss: 0.4211 - val_accuracy: 0.8217\n",
      "Epoch 120/200\n",
      "172/172 [==============================] - 0s 893us/sample - loss: 0.4197 - accuracy: 0.8275 - val_loss: 0.4189 - val_accuracy: 0.8140\n",
      "Epoch 121/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 0.4177 - accuracy: 0.8295 - val_loss: 0.4324 - val_accuracy: 0.8372\n",
      "Epoch 122/200\n",
      "172/172 [==============================] - 0s 887us/sample - loss: 0.4022 - accuracy: 0.8411 - val_loss: 0.4232 - val_accuracy: 0.7984\n",
      "Epoch 123/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.4120 - accuracy: 0.8353 - val_loss: 0.4288 - val_accuracy: 0.8295\n",
      "Epoch 124/200\n",
      "172/172 [==============================] - 0s 979us/sample - loss: 0.3970 - accuracy: 0.8469 - val_loss: 0.4224 - val_accuracy: 0.8062\n",
      "Epoch 125/200\n",
      "172/172 [==============================] - 0s 969us/sample - loss: 0.4061 - accuracy: 0.8333 - val_loss: 0.4254 - val_accuracy: 0.8295\n",
      "Epoch 126/200\n",
      "172/172 [==============================] - 0s 930us/sample - loss: 0.4046 - accuracy: 0.8411 - val_loss: 0.4366 - val_accuracy: 0.8372\n",
      "Epoch 127/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.4189 - accuracy: 0.8256 - val_loss: 0.4202 - val_accuracy: 0.8140\n",
      "Epoch 128/200\n",
      "172/172 [==============================] - 0s 896us/sample - loss: 0.4251 - accuracy: 0.8275 - val_loss: 0.4224 - val_accuracy: 0.8295\n",
      "Epoch 129/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.4122 - accuracy: 0.8353 - val_loss: 0.4245 - val_accuracy: 0.8295\n",
      "Epoch 130/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.4011 - accuracy: 0.8430 - val_loss: 0.4255 - val_accuracy: 0.8295\n",
      "Epoch 131/200\n",
      "172/172 [==============================] - 0s 902us/sample - loss: 0.4034 - accuracy: 0.8372 - val_loss: 0.4386 - val_accuracy: 0.8372\n",
      "Epoch 132/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 0.4080 - accuracy: 0.8314 - val_loss: 0.4382 - val_accuracy: 0.7907\n",
      "Epoch 133/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.4072 - accuracy: 0.8391 - val_loss: 0.4601 - val_accuracy: 0.8217\n",
      "Epoch 134/200\n",
      "172/172 [==============================] - 0s 897us/sample - loss: 0.4125 - accuracy: 0.8275 - val_loss: 0.4234 - val_accuracy: 0.8295\n",
      "Epoch 135/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 0.3993 - accuracy: 0.8372 - val_loss: 0.4262 - val_accuracy: 0.7984\n",
      "Epoch 136/200\n",
      "172/172 [==============================] - 0s 949us/sample - loss: 0.4126 - accuracy: 0.8256 - val_loss: 0.4278 - val_accuracy: 0.8295\n",
      "Epoch 137/200\n",
      "172/172 [==============================] - 0s 981us/sample - loss: 0.4207 - accuracy: 0.8217 - val_loss: 0.4375 - val_accuracy: 0.8372\n",
      "Epoch 138/200\n",
      "172/172 [==============================] - 0s 986us/sample - loss: 0.4050 - accuracy: 0.8275 - val_loss: 0.5263 - val_accuracy: 0.7984\n",
      "Epoch 139/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 0.4199 - accuracy: 0.8295 - val_loss: 0.4474 - val_accuracy: 0.8372\n",
      "Epoch 140/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.3925 - accuracy: 0.8353 - val_loss: 0.4346 - val_accuracy: 0.7984\n",
      "Epoch 141/200\n",
      "172/172 [==============================] - 0s 900us/sample - loss: 0.4215 - accuracy: 0.8236 - val_loss: 0.4215 - val_accuracy: 0.8140\n",
      "Epoch 142/200\n",
      "172/172 [==============================] - 0s 898us/sample - loss: 0.3978 - accuracy: 0.8353 - val_loss: 0.4234 - val_accuracy: 0.8062\n",
      "Epoch 143/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.4002 - accuracy: 0.8469 - val_loss: 0.4428 - val_accuracy: 0.8372\n",
      "Epoch 144/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.4035 - accuracy: 0.8295 - val_loss: 0.4501 - val_accuracy: 0.8295\n",
      "Epoch 145/200\n",
      "172/172 [==============================] - 0s 926us/sample - loss: 0.3987 - accuracy: 0.8430 - val_loss: 0.4230 - val_accuracy: 0.8295\n",
      "Epoch 146/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 0.3932 - accuracy: 0.8391 - val_loss: 0.4287 - val_accuracy: 0.8295\n",
      "Epoch 147/200\n",
      "172/172 [==============================] - 0s 928us/sample - loss: 0.3966 - accuracy: 0.8333 - val_loss: 0.4654 - val_accuracy: 0.8295\n",
      "Epoch 148/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 926us/sample - loss: 0.3943 - accuracy: 0.8372 - val_loss: 0.4282 - val_accuracy: 0.8295\n",
      "Epoch 149/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.3911 - accuracy: 0.8430 - val_loss: 0.4305 - val_accuracy: 0.8217\n",
      "Epoch 150/200\n",
      "172/172 [==============================] - 0s 988us/sample - loss: 0.4001 - accuracy: 0.8411 - val_loss: 0.4440 - val_accuracy: 0.8372\n",
      "Epoch 151/200\n",
      "172/172 [==============================] - 0s 961us/sample - loss: 0.3912 - accuracy: 0.8391 - val_loss: 0.4247 - val_accuracy: 0.8140\n",
      "Epoch 152/200\n",
      "172/172 [==============================] - 0s 924us/sample - loss: 0.3873 - accuracy: 0.8411 - val_loss: 0.4241 - val_accuracy: 0.8217\n",
      "Epoch 153/200\n",
      "172/172 [==============================] - 0s 918us/sample - loss: 0.3959 - accuracy: 0.8353 - val_loss: 0.4256 - val_accuracy: 0.8217\n",
      "Epoch 154/200\n",
      "172/172 [==============================] - 0s 920us/sample - loss: 0.3930 - accuracy: 0.8469 - val_loss: 0.4256 - val_accuracy: 0.8217\n",
      "Epoch 155/200\n",
      "172/172 [==============================] - 0s 923us/sample - loss: 0.3858 - accuracy: 0.8372 - val_loss: 0.4493 - val_accuracy: 0.8372\n",
      "Epoch 156/200\n",
      "172/172 [==============================] - 0s 921us/sample - loss: 0.3906 - accuracy: 0.8411 - val_loss: 0.4323 - val_accuracy: 0.8450\n",
      "Epoch 157/200\n",
      "172/172 [==============================] - 0s 891us/sample - loss: 0.3898 - accuracy: 0.8333 - val_loss: 0.4288 - val_accuracy: 0.8372\n",
      "Epoch 158/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 0.4298 - accuracy: 0.8217 - val_loss: 0.4377 - val_accuracy: 0.8372\n",
      "Epoch 159/200\n",
      "172/172 [==============================] - 0s 917us/sample - loss: 0.4056 - accuracy: 0.8236 - val_loss: 0.4256 - val_accuracy: 0.8295\n",
      "Epoch 160/200\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 0.3957 - accuracy: 0.8411 - val_loss: 0.4620 - val_accuracy: 0.8295\n",
      "Epoch 161/200\n",
      "172/172 [==============================] - 0s 954us/sample - loss: 0.3859 - accuracy: 0.8430 - val_loss: 0.4318 - val_accuracy: 0.8372\n",
      "Epoch 162/200\n",
      "172/172 [==============================] - 0s 961us/sample - loss: 0.3832 - accuracy: 0.8469 - val_loss: 0.4435 - val_accuracy: 0.8062\n",
      "Epoch 163/200\n",
      "172/172 [==============================] - 0s 967us/sample - loss: 0.4204 - accuracy: 0.8295 - val_loss: 0.4338 - val_accuracy: 0.7984\n",
      "Epoch 164/200\n",
      "172/172 [==============================] - 0s 904us/sample - loss: 0.4021 - accuracy: 0.8353 - val_loss: 0.4942 - val_accuracy: 0.8140\n",
      "Epoch 165/200\n",
      "172/172 [==============================] - 0s 892us/sample - loss: 0.3917 - accuracy: 0.8314 - val_loss: 0.4716 - val_accuracy: 0.8217\n",
      "Epoch 166/200\n",
      "172/172 [==============================] - 0s 894us/sample - loss: 0.3973 - accuracy: 0.8353 - val_loss: 0.4522 - val_accuracy: 0.8295\n",
      "Epoch 167/200\n",
      "172/172 [==============================] - 0s 895us/sample - loss: 0.3875 - accuracy: 0.8391 - val_loss: 0.4448 - val_accuracy: 0.8372\n",
      "Epoch 168/200\n",
      "172/172 [==============================] - 0s 943us/sample - loss: 0.3758 - accuracy: 0.8508 - val_loss: 0.4601 - val_accuracy: 0.7829\n",
      "Epoch 169/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 0.4110 - accuracy: 0.8275 - val_loss: 0.4487 - val_accuracy: 0.7984\n",
      "Epoch 170/200\n",
      "172/172 [==============================] - 0s 935us/sample - loss: 0.3864 - accuracy: 0.8411 - val_loss: 0.4562 - val_accuracy: 0.8295\n",
      "Epoch 171/200\n",
      "172/172 [==============================] - 0s 936us/sample - loss: 0.3918 - accuracy: 0.8372 - val_loss: 0.4366 - val_accuracy: 0.8372\n",
      "Epoch 172/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.3760 - accuracy: 0.8450 - val_loss: 0.4392 - val_accuracy: 0.8062\n",
      "Epoch 173/200\n",
      "172/172 [==============================] - 0s 933us/sample - loss: 0.3978 - accuracy: 0.8430 - val_loss: 0.4284 - val_accuracy: 0.8140\n",
      "Epoch 174/200\n",
      "172/172 [==============================] - 0s 990us/sample - loss: 0.4128 - accuracy: 0.8353 - val_loss: 0.4270 - val_accuracy: 0.8295\n",
      "Epoch 175/200\n",
      "172/172 [==============================] - 0s 983us/sample - loss: 0.3867 - accuracy: 0.8333 - val_loss: 0.4250 - val_accuracy: 0.8295\n",
      "Epoch 176/200\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 0.3770 - accuracy: 0.8430 - val_loss: 0.4249 - val_accuracy: 0.8295\n",
      "Epoch 177/200\n",
      "172/172 [==============================] - 0s 914us/sample - loss: 0.3907 - accuracy: 0.8391 - val_loss: 0.4359 - val_accuracy: 0.8140\n",
      "Epoch 178/200\n",
      "172/172 [==============================] - 0s 932us/sample - loss: 0.4005 - accuracy: 0.8411 - val_loss: 0.4401 - val_accuracy: 0.8062\n",
      "Epoch 179/200\n",
      "172/172 [==============================] - 0s 946us/sample - loss: 0.3963 - accuracy: 0.8411 - val_loss: 0.4288 - val_accuracy: 0.8295\n",
      "Epoch 180/200\n",
      "172/172 [==============================] - 0s 938us/sample - loss: 0.3790 - accuracy: 0.8430 - val_loss: 0.4288 - val_accuracy: 0.8140\n",
      "Epoch 181/200\n",
      "172/172 [==============================] - 0s 934us/sample - loss: 0.3935 - accuracy: 0.8372 - val_loss: 0.4517 - val_accuracy: 0.7907\n",
      "Epoch 182/200\n",
      "172/172 [==============================] - 0s 944us/sample - loss: 0.3917 - accuracy: 0.8314 - val_loss: 0.4339 - val_accuracy: 0.8372\n",
      "Epoch 183/200\n",
      "172/172 [==============================] - 0s 939us/sample - loss: 0.4102 - accuracy: 0.8295 - val_loss: 0.4285 - val_accuracy: 0.8140\n",
      "Epoch 184/200\n",
      "172/172 [==============================] - 0s 945us/sample - loss: 0.3913 - accuracy: 0.8411 - val_loss: 0.4357 - val_accuracy: 0.8372\n",
      "Epoch 185/200\n",
      "172/172 [==============================] - 0s 942us/sample - loss: 0.3907 - accuracy: 0.8372 - val_loss: 0.5233 - val_accuracy: 0.8062\n",
      "Epoch 186/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.3898 - accuracy: 0.8295 - val_loss: 0.4333 - val_accuracy: 0.8372\n",
      "Epoch 187/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.3721 - accuracy: 0.8450 - val_loss: 0.4622 - val_accuracy: 0.8295\n",
      "Epoch 188/200\n",
      "172/172 [==============================] - 0s 975us/sample - loss: 0.4188 - accuracy: 0.8372 - val_loss: 0.4372 - val_accuracy: 0.8372\n",
      "Epoch 189/200\n",
      "172/172 [==============================] - 0s 945us/sample - loss: 0.3877 - accuracy: 0.8353 - val_loss: 0.4565 - val_accuracy: 0.8295\n",
      "Epoch 190/200\n",
      "172/172 [==============================] - 0s 948us/sample - loss: 0.3903 - accuracy: 0.8372 - val_loss: 0.4496 - val_accuracy: 0.8295\n",
      "Epoch 191/200\n",
      "172/172 [==============================] - 0s 952us/sample - loss: 0.3844 - accuracy: 0.8372 - val_loss: 0.4437 - val_accuracy: 0.8372\n",
      "Epoch 192/200\n",
      "172/172 [==============================] - 0s 951us/sample - loss: 0.3811 - accuracy: 0.8372 - val_loss: 0.4335 - val_accuracy: 0.8372\n",
      "Epoch 193/200\n",
      "172/172 [==============================] - 0s 951us/sample - loss: 0.3756 - accuracy: 0.8391 - val_loss: 0.4292 - val_accuracy: 0.8372\n",
      "Epoch 194/200\n",
      "172/172 [==============================] - 0s 949us/sample - loss: 0.3749 - accuracy: 0.8372 - val_loss: 0.4460 - val_accuracy: 0.8372\n",
      "Epoch 195/200\n",
      "172/172 [==============================] - 0s 942us/sample - loss: 0.3755 - accuracy: 0.8450 - val_loss: 0.4372 - val_accuracy: 0.8140\n",
      "Epoch 196/200\n",
      "172/172 [==============================] - 0s 954us/sample - loss: 0.3702 - accuracy: 0.8430 - val_loss: 0.4261 - val_accuracy: 0.8295\n",
      "Epoch 197/200\n",
      "172/172 [==============================] - 0s 942us/sample - loss: 0.3700 - accuracy: 0.8450 - val_loss: 0.4271 - val_accuracy: 0.8217\n",
      "Epoch 198/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.3798 - accuracy: 0.8430 - val_loss: 0.4467 - val_accuracy: 0.8372\n",
      "Epoch 199/200\n",
      "172/172 [==============================] - 0s 1ms/sample - loss: 0.3756 - accuracy: 0.8450 - val_loss: 0.4387 - val_accuracy: 0.8372\n",
      "Epoch 200/200\n",
      "172/172 [==============================] - 0s 979us/sample - loss: 0.3638 - accuracy: 0.8469 - val_loss: 0.4337 - val_accuracy: 0.8295\n",
      "Beginning training for dr=0.001, l_lambda=1.0e-03, reg_type=l2, act: tanh\n",
      "Train on 172 samples, validate on 43 samples\n",
      "Epoch 1/200\n",
      "172/172 [==============================] - 2s 14ms/sample - loss: 0.9374 - accuracy: 0.6938 - val_loss: 0.6936 - val_accuracy: 0.7829\n",
      "Epoch 2/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.6597 - accuracy: 0.7791 - val_loss: 0.6087 - val_accuracy: 0.7829\n",
      "Epoch 3/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.6188 - accuracy: 0.7791 - val_loss: 0.5892 - val_accuracy: 0.7829\n",
      "Epoch 4/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.5753 - accuracy: 0.7791 - val_loss: 0.5587 - val_accuracy: 0.7829\n",
      "Epoch 5/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.5668 - accuracy: 0.7791 - val_loss: 0.5444 - val_accuracy: 0.7829\n",
      "Epoch 6/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.5515 - accuracy: 0.7791 - val_loss: 0.5355 - val_accuracy: 0.7829\n",
      "Epoch 7/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.5380 - accuracy: 0.7791 - val_loss: 0.5240 - val_accuracy: 0.7829\n",
      "Epoch 8/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.5310 - accuracy: 0.7791 - val_loss: 0.5175 - val_accuracy: 0.7829\n",
      "Epoch 9/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.5254 - accuracy: 0.7791 - val_loss: 0.5130 - val_accuracy: 0.7829\n",
      "Epoch 10/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.5289 - accuracy: 0.7810 - val_loss: 0.5111 - val_accuracy: 0.7829\n",
      "Epoch 11/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.5215 - accuracy: 0.7791 - val_loss: 0.5074 - val_accuracy: 0.7829\n",
      "Epoch 12/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.5141 - accuracy: 0.7791 - val_loss: 0.5046 - val_accuracy: 0.7829\n",
      "Epoch 13/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.5165 - accuracy: 0.7791 - val_loss: 0.5035 - val_accuracy: 0.7829\n",
      "Epoch 14/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.5157 - accuracy: 0.7810 - val_loss: 0.5005 - val_accuracy: 0.7829\n",
      "Epoch 15/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.5119 - accuracy: 0.7810 - val_loss: 0.4982 - val_accuracy: 0.7829\n",
      "Epoch 16/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.5117 - accuracy: 0.7810 - val_loss: 0.4976 - val_accuracy: 0.7829\n",
      "Epoch 17/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.5097 - accuracy: 0.7791 - val_loss: 0.4972 - val_accuracy: 0.7829\n",
      "Epoch 18/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.5084 - accuracy: 0.7810 - val_loss: 0.4939 - val_accuracy: 0.7829\n",
      "Epoch 19/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.5100 - accuracy: 0.7791 - val_loss: 0.4932 - val_accuracy: 0.7829\n",
      "Epoch 20/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.5171 - accuracy: 0.7791 - val_loss: 0.4990 - val_accuracy: 0.7907\n",
      "Epoch 21/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.5045 - accuracy: 0.7791 - val_loss: 0.4913 - val_accuracy: 0.7829\n",
      "Epoch 22/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.5020 - accuracy: 0.7791 - val_loss: 0.4898 - val_accuracy: 0.7829\n",
      "Epoch 23/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.5096 - accuracy: 0.7810 - val_loss: 0.4912 - val_accuracy: 0.7829\n",
      "Epoch 24/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.5097 - accuracy: 0.7810 - val_loss: 0.4934 - val_accuracy: 0.7907\n",
      "Epoch 25/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4988 - accuracy: 0.7791 - val_loss: 0.4859 - val_accuracy: 0.7829\n",
      "Epoch 26/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4988 - accuracy: 0.7810 - val_loss: 0.4851 - val_accuracy: 0.7829\n",
      "Epoch 27/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.5065 - accuracy: 0.7791 - val_loss: 0.5032 - val_accuracy: 0.7984\n",
      "Epoch 28/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.5103 - accuracy: 0.7984 - val_loss: 0.4882 - val_accuracy: 0.7829\n",
      "Epoch 29/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.5012 - accuracy: 0.7791 - val_loss: 0.4821 - val_accuracy: 0.7907\n",
      "Epoch 30/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4952 - accuracy: 0.7829 - val_loss: 0.4806 - val_accuracy: 0.7907\n",
      "Epoch 31/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.5184 - accuracy: 0.7829 - val_loss: 0.4874 - val_accuracy: 0.8062\n",
      "Epoch 32/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.5006 - accuracy: 0.7810 - val_loss: 0.4836 - val_accuracy: 0.7907\n",
      "Epoch 33/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.5058 - accuracy: 0.7868 - val_loss: 0.4811 - val_accuracy: 0.7907\n",
      "Epoch 34/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4934 - accuracy: 0.7829 - val_loss: 0.4809 - val_accuracy: 0.7984\n",
      "Epoch 35/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4960 - accuracy: 0.7810 - val_loss: 0.4804 - val_accuracy: 0.8062\n",
      "Epoch 36/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4967 - accuracy: 0.7849 - val_loss: 0.4750 - val_accuracy: 0.7907\n",
      "Epoch 37/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4939 - accuracy: 0.7984 - val_loss: 0.4784 - val_accuracy: 0.7907\n",
      "Epoch 38/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4934 - accuracy: 0.7868 - val_loss: 0.4723 - val_accuracy: 0.7907\n",
      "Epoch 39/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4959 - accuracy: 0.7810 - val_loss: 0.4723 - val_accuracy: 0.7984\n",
      "Epoch 40/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4851 - accuracy: 0.7849 - val_loss: 0.4758 - val_accuracy: 0.7984\n",
      "Epoch 41/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4845 - accuracy: 0.8023 - val_loss: 0.4681 - val_accuracy: 0.7907\n",
      "Epoch 42/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4935 - accuracy: 0.7868 - val_loss: 0.4815 - val_accuracy: 0.8062\n",
      "Epoch 43/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4896 - accuracy: 0.7868 - val_loss: 0.4789 - val_accuracy: 0.8062\n",
      "Epoch 44/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4848 - accuracy: 0.7907 - val_loss: 0.4648 - val_accuracy: 0.7907\n",
      "Epoch 45/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4823 - accuracy: 0.8101 - val_loss: 0.4894 - val_accuracy: 0.7907\n",
      "Epoch 46/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4858 - accuracy: 0.7965 - val_loss: 0.4618 - val_accuracy: 0.7984\n",
      "Epoch 47/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4861 - accuracy: 0.7965 - val_loss: 0.4672 - val_accuracy: 0.8062\n",
      "Epoch 48/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4893 - accuracy: 0.7926 - val_loss: 0.4937 - val_accuracy: 0.8295\n",
      "Epoch 49/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4853 - accuracy: 0.7829 - val_loss: 0.4705 - val_accuracy: 0.8062\n",
      "Epoch 50/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4872 - accuracy: 0.7888 - val_loss: 0.4588 - val_accuracy: 0.7984\n",
      "Epoch 51/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4764 - accuracy: 0.7926 - val_loss: 0.4591 - val_accuracy: 0.8062\n",
      "Epoch 52/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4817 - accuracy: 0.7984 - val_loss: 0.4560 - val_accuracy: 0.7984\n",
      "Epoch 53/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.5007 - accuracy: 0.7965 - val_loss: 0.5080 - val_accuracy: 0.8062\n",
      "Epoch 54/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.5154 - accuracy: 0.7868 - val_loss: 0.4881 - val_accuracy: 0.8062\n",
      "Epoch 55/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4771 - accuracy: 0.7926 - val_loss: 0.4580 - val_accuracy: 0.7984\n",
      "Epoch 56/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4767 - accuracy: 0.7907 - val_loss: 0.4567 - val_accuracy: 0.7984\n",
      "Epoch 57/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4743 - accuracy: 0.7926 - val_loss: 0.4849 - val_accuracy: 0.8295\n",
      "Epoch 58/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4887 - accuracy: 0.8023 - val_loss: 0.4536 - val_accuracy: 0.7984\n",
      "Epoch 59/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4716 - accuracy: 0.8004 - val_loss: 0.4523 - val_accuracy: 0.8062\n",
      "Epoch 60/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4701 - accuracy: 0.8081 - val_loss: 0.4781 - val_accuracy: 0.8295\n",
      "Epoch 61/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4791 - accuracy: 0.7868 - val_loss: 0.4789 - val_accuracy: 0.8217\n",
      "Epoch 62/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4690 - accuracy: 0.8081 - val_loss: 0.4520 - val_accuracy: 0.8062\n",
      "Epoch 63/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4713 - accuracy: 0.7965 - val_loss: 0.4515 - val_accuracy: 0.8062\n",
      "Epoch 64/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4772 - accuracy: 0.8081 - val_loss: 0.4495 - val_accuracy: 0.7984\n",
      "Epoch 65/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4680 - accuracy: 0.8004 - val_loss: 0.4585 - val_accuracy: 0.8062\n",
      "Epoch 66/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4656 - accuracy: 0.8198 - val_loss: 0.4592 - val_accuracy: 0.8062\n",
      "Epoch 67/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4711 - accuracy: 0.8081 - val_loss: 0.4535 - val_accuracy: 0.8062\n",
      "Epoch 68/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4787 - accuracy: 0.7984 - val_loss: 0.4834 - val_accuracy: 0.8295\n",
      "Epoch 69/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4674 - accuracy: 0.8043 - val_loss: 0.4651 - val_accuracy: 0.8140\n",
      "Epoch 70/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4773 - accuracy: 0.8081 - val_loss: 0.4541 - val_accuracy: 0.8062\n",
      "Epoch 71/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4780 - accuracy: 0.8004 - val_loss: 0.4752 - val_accuracy: 0.8217\n",
      "Epoch 72/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4839 - accuracy: 0.7984 - val_loss: 0.4640 - val_accuracy: 0.8140\n",
      "Epoch 73/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4757 - accuracy: 0.8062 - val_loss: 0.4705 - val_accuracy: 0.8217\n",
      "Epoch 74/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4695 - accuracy: 0.7984 - val_loss: 0.4543 - val_accuracy: 0.8062\n",
      "Epoch 75/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4599 - accuracy: 0.8043 - val_loss: 0.4455 - val_accuracy: 0.7984\n",
      "Epoch 76/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4632 - accuracy: 0.8062 - val_loss: 0.4486 - val_accuracy: 0.8062\n",
      "Epoch 77/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4989 - accuracy: 0.7984 - val_loss: 0.4503 - val_accuracy: 0.8062\n",
      "Epoch 78/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4646 - accuracy: 0.8004 - val_loss: 0.4469 - val_accuracy: 0.8062\n",
      "Epoch 79/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4654 - accuracy: 0.7907 - val_loss: 0.5033 - val_accuracy: 0.8295\n",
      "Epoch 80/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4630 - accuracy: 0.8023 - val_loss: 0.4458 - val_accuracy: 0.8062\n",
      "Epoch 81/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4620 - accuracy: 0.8101 - val_loss: 0.4512 - val_accuracy: 0.8062\n",
      "Epoch 82/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4762 - accuracy: 0.8159 - val_loss: 0.4500 - val_accuracy: 0.7984\n",
      "Epoch 83/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4533 - accuracy: 0.8120 - val_loss: 0.4858 - val_accuracy: 0.8295\n",
      "Epoch 84/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4910 - accuracy: 0.7907 - val_loss: 0.4482 - val_accuracy: 0.8062\n",
      "Epoch 85/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4594 - accuracy: 0.8140 - val_loss: 0.4583 - val_accuracy: 0.8372\n",
      "Epoch 86/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4532 - accuracy: 0.8178 - val_loss: 0.4582 - val_accuracy: 0.8062\n",
      "Epoch 87/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4783 - accuracy: 0.8120 - val_loss: 0.4513 - val_accuracy: 0.7984\n",
      "Epoch 88/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4601 - accuracy: 0.8043 - val_loss: 0.5110 - val_accuracy: 0.8295\n",
      "Epoch 89/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4796 - accuracy: 0.8081 - val_loss: 0.4444 - val_accuracy: 0.8062\n",
      "Epoch 90/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4679 - accuracy: 0.8043 - val_loss: 0.4410 - val_accuracy: 0.7984\n",
      "Epoch 91/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4589 - accuracy: 0.8120 - val_loss: 0.4379 - val_accuracy: 0.7907\n",
      "Epoch 92/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4576 - accuracy: 0.8043 - val_loss: 0.4609 - val_accuracy: 0.8295\n",
      "Epoch 93/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4611 - accuracy: 0.8081 - val_loss: 0.4513 - val_accuracy: 0.8372\n",
      "Epoch 94/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4576 - accuracy: 0.8178 - val_loss: 0.4374 - val_accuracy: 0.7907\n",
      "Epoch 95/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4514 - accuracy: 0.8198 - val_loss: 0.4379 - val_accuracy: 0.7984\n",
      "Epoch 96/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4604 - accuracy: 0.8140 - val_loss: 0.4586 - val_accuracy: 0.8295\n",
      "Epoch 97/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4565 - accuracy: 0.8043 - val_loss: 0.4542 - val_accuracy: 0.8372\n",
      "Epoch 98/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4577 - accuracy: 0.8140 - val_loss: 0.4343 - val_accuracy: 0.7984\n",
      "Epoch 99/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4781 - accuracy: 0.7965 - val_loss: 0.4395 - val_accuracy: 0.7984\n",
      "Epoch 100/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4488 - accuracy: 0.8101 - val_loss: 0.4822 - val_accuracy: 0.8217\n",
      "Epoch 101/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4642 - accuracy: 0.8178 - val_loss: 0.4471 - val_accuracy: 0.8372\n",
      "Epoch 102/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4602 - accuracy: 0.8178 - val_loss: 0.4361 - val_accuracy: 0.8062\n",
      "Epoch 103/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4553 - accuracy: 0.8178 - val_loss: 0.4425 - val_accuracy: 0.7984\n",
      "Epoch 104/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4540 - accuracy: 0.8140 - val_loss: 0.4452 - val_accuracy: 0.8295\n",
      "Epoch 105/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4529 - accuracy: 0.8101 - val_loss: 0.4343 - val_accuracy: 0.8062\n",
      "Epoch 106/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4475 - accuracy: 0.8236 - val_loss: 0.4351 - val_accuracy: 0.8062\n",
      "Epoch 107/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4485 - accuracy: 0.8140 - val_loss: 0.4356 - val_accuracy: 0.8062\n",
      "Epoch 108/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4533 - accuracy: 0.8140 - val_loss: 0.4571 - val_accuracy: 0.8295\n",
      "Epoch 109/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4614 - accuracy: 0.8101 - val_loss: 0.4406 - val_accuracy: 0.8062\n",
      "Epoch 110/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4413 - accuracy: 0.8198 - val_loss: 0.4456 - val_accuracy: 0.8372\n",
      "Epoch 111/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4533 - accuracy: 0.8140 - val_loss: 0.4496 - val_accuracy: 0.8372\n",
      "Epoch 112/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4601 - accuracy: 0.8159 - val_loss: 0.4365 - val_accuracy: 0.8217\n",
      "Epoch 113/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4473 - accuracy: 0.8353 - val_loss: 0.4648 - val_accuracy: 0.7907\n",
      "Epoch 114/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4575 - accuracy: 0.8120 - val_loss: 0.4597 - val_accuracy: 0.8295\n",
      "Epoch 115/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4378 - accuracy: 0.8275 - val_loss: 0.4294 - val_accuracy: 0.7984\n",
      "Epoch 116/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4446 - accuracy: 0.8178 - val_loss: 0.4360 - val_accuracy: 0.8295\n",
      "Epoch 117/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4483 - accuracy: 0.8198 - val_loss: 0.4347 - val_accuracy: 0.8295\n",
      "Epoch 118/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4415 - accuracy: 0.8159 - val_loss: 0.4467 - val_accuracy: 0.8372\n",
      "Epoch 119/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4469 - accuracy: 0.8198 - val_loss: 0.4329 - val_accuracy: 0.8062\n",
      "Epoch 120/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4437 - accuracy: 0.8159 - val_loss: 0.4309 - val_accuracy: 0.8062\n",
      "Epoch 121/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4393 - accuracy: 0.8217 - val_loss: 0.4288 - val_accuracy: 0.8062\n",
      "Epoch 122/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4479 - accuracy: 0.8178 - val_loss: 0.4289 - val_accuracy: 0.8062\n",
      "Epoch 123/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4365 - accuracy: 0.8275 - val_loss: 0.4291 - val_accuracy: 0.8062\n",
      "Epoch 124/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4324 - accuracy: 0.8256 - val_loss: 0.4799 - val_accuracy: 0.8217\n",
      "Epoch 125/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4624 - accuracy: 0.8043 - val_loss: 0.4332 - val_accuracy: 0.8295\n",
      "Epoch 126/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4353 - accuracy: 0.8236 - val_loss: 0.4319 - val_accuracy: 0.8217\n",
      "Epoch 127/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4384 - accuracy: 0.8314 - val_loss: 0.4346 - val_accuracy: 0.8295\n",
      "Epoch 128/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4408 - accuracy: 0.8178 - val_loss: 0.4304 - val_accuracy: 0.8062\n",
      "Epoch 129/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4436 - accuracy: 0.8198 - val_loss: 0.4288 - val_accuracy: 0.8062\n",
      "Epoch 130/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4415 - accuracy: 0.8333 - val_loss: 0.4288 - val_accuracy: 0.8140\n",
      "Epoch 131/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4467 - accuracy: 0.8256 - val_loss: 0.4307 - val_accuracy: 0.7984\n",
      "Epoch 132/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4385 - accuracy: 0.8256 - val_loss: 0.4290 - val_accuracy: 0.7907\n",
      "Epoch 133/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4324 - accuracy: 0.8256 - val_loss: 0.4259 - val_accuracy: 0.7984\n",
      "Epoch 134/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4436 - accuracy: 0.8062 - val_loss: 0.4489 - val_accuracy: 0.8295\n",
      "Epoch 135/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4516 - accuracy: 0.8178 - val_loss: 0.4291 - val_accuracy: 0.7984\n",
      "Epoch 136/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4615 - accuracy: 0.8120 - val_loss: 0.4445 - val_accuracy: 0.8295\n",
      "Epoch 137/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4616 - accuracy: 0.8178 - val_loss: 0.4382 - val_accuracy: 0.7907\n",
      "Epoch 138/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4537 - accuracy: 0.8120 - val_loss: 0.4299 - val_accuracy: 0.7907\n",
      "Epoch 139/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4429 - accuracy: 0.8295 - val_loss: 0.4376 - val_accuracy: 0.7984\n",
      "Epoch 140/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4441 - accuracy: 0.8236 - val_loss: 0.4248 - val_accuracy: 0.8062\n",
      "Epoch 141/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4346 - accuracy: 0.8295 - val_loss: 0.4244 - val_accuracy: 0.7984\n",
      "Epoch 142/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4427 - accuracy: 0.8178 - val_loss: 0.4281 - val_accuracy: 0.8217\n",
      "Epoch 143/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4407 - accuracy: 0.8353 - val_loss: 0.4238 - val_accuracy: 0.7984\n",
      "Epoch 144/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4357 - accuracy: 0.8275 - val_loss: 0.4274 - val_accuracy: 0.7984\n",
      "Epoch 145/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4529 - accuracy: 0.8159 - val_loss: 0.4649 - val_accuracy: 0.7907\n",
      "Epoch 146/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4530 - accuracy: 0.8295 - val_loss: 0.4301 - val_accuracy: 0.7829\n",
      "Epoch 147/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4421 - accuracy: 0.8236 - val_loss: 0.4272 - val_accuracy: 0.7829\n",
      "Epoch 148/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4353 - accuracy: 0.8295 - val_loss: 0.4265 - val_accuracy: 0.7829\n",
      "Epoch 149/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4345 - accuracy: 0.8198 - val_loss: 0.4296 - val_accuracy: 0.8295\n",
      "Epoch 150/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4303 - accuracy: 0.8236 - val_loss: 0.4307 - val_accuracy: 0.8295\n",
      "Epoch 151/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4325 - accuracy: 0.8372 - val_loss: 0.4234 - val_accuracy: 0.8062\n",
      "Epoch 152/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4367 - accuracy: 0.8198 - val_loss: 0.4237 - val_accuracy: 0.8140\n",
      "Epoch 153/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4293 - accuracy: 0.8314 - val_loss: 0.4248 - val_accuracy: 0.8217\n",
      "Epoch 154/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4247 - accuracy: 0.8314 - val_loss: 0.4243 - val_accuracy: 0.8295\n",
      "Epoch 155/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4271 - accuracy: 0.8295 - val_loss: 0.4243 - val_accuracy: 0.8295\n",
      "Epoch 156/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4472 - accuracy: 0.8159 - val_loss: 0.4468 - val_accuracy: 0.8295\n",
      "Epoch 157/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4299 - accuracy: 0.8372 - val_loss: 0.4299 - val_accuracy: 0.7984\n",
      "Epoch 158/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4335 - accuracy: 0.8101 - val_loss: 0.4237 - val_accuracy: 0.7907\n",
      "Epoch 159/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4323 - accuracy: 0.8275 - val_loss: 0.4239 - val_accuracy: 0.8217\n",
      "Epoch 160/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4256 - accuracy: 0.8314 - val_loss: 0.4605 - val_accuracy: 0.8450\n",
      "Epoch 161/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4364 - accuracy: 0.8314 - val_loss: 0.4497 - val_accuracy: 0.7829\n",
      "Epoch 162/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4424 - accuracy: 0.8178 - val_loss: 0.4409 - val_accuracy: 0.8372\n",
      "Epoch 163/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4278 - accuracy: 0.8217 - val_loss: 0.4253 - val_accuracy: 0.8062\n",
      "Epoch 164/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4319 - accuracy: 0.8275 - val_loss: 0.4233 - val_accuracy: 0.7984\n",
      "Epoch 165/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4312 - accuracy: 0.8295 - val_loss: 0.4433 - val_accuracy: 0.7907\n",
      "Epoch 166/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4395 - accuracy: 0.8140 - val_loss: 0.4250 - val_accuracy: 0.7907\n",
      "Epoch 167/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4299 - accuracy: 0.8353 - val_loss: 0.4282 - val_accuracy: 0.7984\n",
      "Epoch 168/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4345 - accuracy: 0.8275 - val_loss: 0.4231 - val_accuracy: 0.7829\n",
      "Epoch 169/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4400 - accuracy: 0.8198 - val_loss: 0.4383 - val_accuracy: 0.8372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4344 - accuracy: 0.8101 - val_loss: 0.4271 - val_accuracy: 0.7984\n",
      "Epoch 171/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4271 - accuracy: 0.8295 - val_loss: 0.4539 - val_accuracy: 0.8450\n",
      "Epoch 172/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4441 - accuracy: 0.8198 - val_loss: 0.4250 - val_accuracy: 0.7907\n",
      "Epoch 173/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4298 - accuracy: 0.8256 - val_loss: 0.4527 - val_accuracy: 0.8450\n",
      "Epoch 174/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4275 - accuracy: 0.8295 - val_loss: 0.4218 - val_accuracy: 0.7907\n",
      "Epoch 175/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4425 - accuracy: 0.8236 - val_loss: 0.4235 - val_accuracy: 0.8295\n",
      "Epoch 176/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4199 - accuracy: 0.8372 - val_loss: 0.4240 - val_accuracy: 0.7829\n",
      "Epoch 177/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4226 - accuracy: 0.8353 - val_loss: 0.4407 - val_accuracy: 0.7907\n",
      "Epoch 178/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4245 - accuracy: 0.8217 - val_loss: 0.4895 - val_accuracy: 0.7984\n",
      "Epoch 179/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4686 - accuracy: 0.8023 - val_loss: 0.4993 - val_accuracy: 0.8062\n",
      "Epoch 180/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4348 - accuracy: 0.8198 - val_loss: 0.5242 - val_accuracy: 0.7907\n",
      "Epoch 181/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4767 - accuracy: 0.8004 - val_loss: 0.4699 - val_accuracy: 0.8372\n",
      "Epoch 182/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4395 - accuracy: 0.8295 - val_loss: 0.4267 - val_accuracy: 0.8217\n",
      "Epoch 183/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4309 - accuracy: 0.8256 - val_loss: 0.4620 - val_accuracy: 0.8217\n",
      "Epoch 184/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4295 - accuracy: 0.8217 - val_loss: 0.4236 - val_accuracy: 0.8217\n",
      "Epoch 185/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4223 - accuracy: 0.8353 - val_loss: 0.4198 - val_accuracy: 0.8140\n",
      "Epoch 186/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4248 - accuracy: 0.8275 - val_loss: 0.4204 - val_accuracy: 0.8140\n",
      "Epoch 187/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4162 - accuracy: 0.8391 - val_loss: 0.4200 - val_accuracy: 0.8062\n",
      "Epoch 188/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4165 - accuracy: 0.8353 - val_loss: 0.4203 - val_accuracy: 0.8217\n",
      "Epoch 189/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4172 - accuracy: 0.8314 - val_loss: 0.4438 - val_accuracy: 0.8450\n",
      "Epoch 190/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4236 - accuracy: 0.8275 - val_loss: 0.4393 - val_accuracy: 0.8450\n",
      "Epoch 191/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4292 - accuracy: 0.8391 - val_loss: 0.4200 - val_accuracy: 0.7907\n",
      "Epoch 192/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4243 - accuracy: 0.8256 - val_loss: 0.5060 - val_accuracy: 0.7829\n",
      "Epoch 193/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4533 - accuracy: 0.8256 - val_loss: 0.4308 - val_accuracy: 0.7984\n",
      "Epoch 194/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4593 - accuracy: 0.8120 - val_loss: 0.4287 - val_accuracy: 0.8217\n",
      "Epoch 195/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4245 - accuracy: 0.8372 - val_loss: 0.4218 - val_accuracy: 0.7829\n",
      "Epoch 196/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4280 - accuracy: 0.8178 - val_loss: 0.4196 - val_accuracy: 0.7984\n",
      "Epoch 197/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4164 - accuracy: 0.8391 - val_loss: 0.4211 - val_accuracy: 0.8217\n",
      "Epoch 198/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4156 - accuracy: 0.8372 - val_loss: 0.4205 - val_accuracy: 0.7907\n",
      "Epoch 199/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4138 - accuracy: 0.8275 - val_loss: 0.4392 - val_accuracy: 0.8450\n",
      "Epoch 200/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4367 - accuracy: 0.8256 - val_loss: 0.4232 - val_accuracy: 0.8295\n",
      "Beginning training for dr=0.001, l_lambda=1.0e-03, reg_type=l2, act: tanh\n",
      "Train on 172 samples, validate on 43 samples\n",
      "Epoch 1/200\n",
      "172/172 [==============================] - 2s 11ms/sample - loss: 1.0933 - accuracy: 0.7248 - val_loss: 0.8283 - val_accuracy: 0.7829\n",
      "Epoch 2/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.7744 - accuracy: 0.7791 - val_loss: 0.7068 - val_accuracy: 0.7829\n",
      "Epoch 3/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.6992 - accuracy: 0.7791 - val_loss: 0.6536 - val_accuracy: 0.7829\n",
      "Epoch 4/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.6456 - accuracy: 0.7791 - val_loss: 0.6141 - val_accuracy: 0.7829\n",
      "Epoch 5/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.6220 - accuracy: 0.7791 - val_loss: 0.5871 - val_accuracy: 0.7829\n",
      "Epoch 6/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.5918 - accuracy: 0.7791 - val_loss: 0.5666 - val_accuracy: 0.7829\n",
      "Epoch 7/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.5742 - accuracy: 0.7791 - val_loss: 0.5489 - val_accuracy: 0.7829\n",
      "Epoch 8/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.5585 - accuracy: 0.7791 - val_loss: 0.5450 - val_accuracy: 0.7829\n",
      "Epoch 9/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.5507 - accuracy: 0.7810 - val_loss: 0.5306 - val_accuracy: 0.7829\n",
      "Epoch 10/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.5335 - accuracy: 0.7810 - val_loss: 0.5159 - val_accuracy: 0.7829\n",
      "Epoch 11/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.5314 - accuracy: 0.7810 - val_loss: 0.5108 - val_accuracy: 0.7829\n",
      "Epoch 12/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.5274 - accuracy: 0.7791 - val_loss: 0.5016 - val_accuracy: 0.7907\n",
      "Epoch 13/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.5131 - accuracy: 0.7810 - val_loss: 0.5051 - val_accuracy: 0.8062\n",
      "Epoch 14/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.5051 - accuracy: 0.7888 - val_loss: 0.4924 - val_accuracy: 0.8062\n",
      "Epoch 15/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4969 - accuracy: 0.8023 - val_loss: 0.4753 - val_accuracy: 0.8062\n",
      "Epoch 16/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4893 - accuracy: 0.8023 - val_loss: 0.4671 - val_accuracy: 0.8062\n",
      "Epoch 17/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4852 - accuracy: 0.7965 - val_loss: 0.4592 - val_accuracy: 0.7907\n",
      "Epoch 18/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4717 - accuracy: 0.8062 - val_loss: 0.4550 - val_accuracy: 0.8062\n",
      "Epoch 19/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4793 - accuracy: 0.8081 - val_loss: 0.4681 - val_accuracy: 0.8372\n",
      "Epoch 20/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4669 - accuracy: 0.8101 - val_loss: 0.4966 - val_accuracy: 0.8217\n",
      "Epoch 21/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4945 - accuracy: 0.7946 - val_loss: 0.4542 - val_accuracy: 0.8062\n",
      "Epoch 22/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4637 - accuracy: 0.8062 - val_loss: 0.4483 - val_accuracy: 0.8062\n",
      "Epoch 23/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.5016 - accuracy: 0.7868 - val_loss: 0.4977 - val_accuracy: 0.8062\n",
      "Epoch 24/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.5323 - accuracy: 0.7888 - val_loss: 0.4661 - val_accuracy: 0.8062\n",
      "Epoch 25/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4760 - accuracy: 0.8062 - val_loss: 0.4538 - val_accuracy: 0.7984\n",
      "Epoch 26/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4726 - accuracy: 0.8004 - val_loss: 0.4658 - val_accuracy: 0.8217\n",
      "Epoch 27/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4633 - accuracy: 0.8043 - val_loss: 0.4454 - val_accuracy: 0.8062\n",
      "Epoch 28/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4547 - accuracy: 0.8217 - val_loss: 0.4445 - val_accuracy: 0.8062\n",
      "Epoch 29/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4626 - accuracy: 0.8159 - val_loss: 0.4381 - val_accuracy: 0.7907\n",
      "Epoch 30/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4504 - accuracy: 0.8178 - val_loss: 0.4662 - val_accuracy: 0.7907\n",
      "Epoch 31/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4664 - accuracy: 0.8120 - val_loss: 0.4626 - val_accuracy: 0.7907\n",
      "Epoch 32/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4466 - accuracy: 0.8159 - val_loss: 0.4806 - val_accuracy: 0.8217\n",
      "Epoch 33/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4564 - accuracy: 0.8140 - val_loss: 0.4420 - val_accuracy: 0.8372\n",
      "Epoch 34/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4716 - accuracy: 0.8101 - val_loss: 0.4511 - val_accuracy: 0.8217\n",
      "Epoch 35/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4557 - accuracy: 0.8120 - val_loss: 0.4575 - val_accuracy: 0.8372\n",
      "Epoch 36/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4499 - accuracy: 0.8236 - val_loss: 0.4347 - val_accuracy: 0.8062\n",
      "Epoch 37/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4520 - accuracy: 0.8236 - val_loss: 0.4359 - val_accuracy: 0.7984\n",
      "Epoch 38/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4688 - accuracy: 0.8062 - val_loss: 0.4322 - val_accuracy: 0.8062\n",
      "Epoch 39/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4597 - accuracy: 0.8120 - val_loss: 0.4435 - val_accuracy: 0.7907\n",
      "Epoch 40/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4449 - accuracy: 0.8198 - val_loss: 0.4595 - val_accuracy: 0.8295\n",
      "Epoch 41/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4730 - accuracy: 0.8120 - val_loss: 0.4868 - val_accuracy: 0.8217\n",
      "Epoch 42/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4941 - accuracy: 0.7849 - val_loss: 0.4715 - val_accuracy: 0.8295\n",
      "Epoch 43/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4683 - accuracy: 0.8101 - val_loss: 0.4942 - val_accuracy: 0.8217\n",
      "Epoch 44/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4621 - accuracy: 0.8256 - val_loss: 0.4637 - val_accuracy: 0.8295\n",
      "Epoch 45/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4477 - accuracy: 0.8178 - val_loss: 0.4429 - val_accuracy: 0.8372\n",
      "Epoch 46/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4509 - accuracy: 0.8217 - val_loss: 0.4400 - val_accuracy: 0.8295\n",
      "Epoch 47/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4469 - accuracy: 0.8159 - val_loss: 0.4388 - val_accuracy: 0.8062\n",
      "Epoch 48/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4407 - accuracy: 0.8236 - val_loss: 0.4653 - val_accuracy: 0.8372\n",
      "Epoch 49/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4436 - accuracy: 0.8236 - val_loss: 0.4590 - val_accuracy: 0.8372\n",
      "Epoch 50/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4400 - accuracy: 0.8295 - val_loss: 0.4279 - val_accuracy: 0.7907\n",
      "Epoch 51/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4370 - accuracy: 0.8217 - val_loss: 0.4302 - val_accuracy: 0.7829\n",
      "Epoch 52/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4505 - accuracy: 0.8295 - val_loss: 0.4405 - val_accuracy: 0.7907\n",
      "Epoch 53/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4789 - accuracy: 0.8140 - val_loss: 0.4388 - val_accuracy: 0.8062\n",
      "Epoch 54/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4519 - accuracy: 0.8004 - val_loss: 0.4423 - val_accuracy: 0.8372\n",
      "Epoch 55/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4451 - accuracy: 0.8159 - val_loss: 0.4366 - val_accuracy: 0.7984\n",
      "Epoch 56/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4428 - accuracy: 0.8198 - val_loss: 0.4801 - val_accuracy: 0.8372\n",
      "Epoch 57/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4748 - accuracy: 0.8101 - val_loss: 0.4316 - val_accuracy: 0.7984\n",
      "Epoch 58/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.5141 - accuracy: 0.7984 - val_loss: 0.4724 - val_accuracy: 0.8217\n",
      "Epoch 59/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4674 - accuracy: 0.8023 - val_loss: 0.4455 - val_accuracy: 0.8295\n",
      "Epoch 60/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4450 - accuracy: 0.8081 - val_loss: 0.4384 - val_accuracy: 0.8372\n",
      "Epoch 61/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4231 - accuracy: 0.8430 - val_loss: 0.4931 - val_accuracy: 0.7829\n",
      "Epoch 62/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4542 - accuracy: 0.8159 - val_loss: 0.4875 - val_accuracy: 0.7829\n",
      "Epoch 63/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4872 - accuracy: 0.7946 - val_loss: 0.4384 - val_accuracy: 0.7907\n",
      "Epoch 64/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4455 - accuracy: 0.8198 - val_loss: 0.4327 - val_accuracy: 0.8295\n",
      "Epoch 65/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4414 - accuracy: 0.8236 - val_loss: 0.4255 - val_accuracy: 0.7984\n",
      "Epoch 66/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4362 - accuracy: 0.8295 - val_loss: 0.4287 - val_accuracy: 0.7907\n",
      "Epoch 67/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4377 - accuracy: 0.8236 - val_loss: 0.4238 - val_accuracy: 0.8295\n",
      "Epoch 68/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4361 - accuracy: 0.8140 - val_loss: 0.4999 - val_accuracy: 0.7984\n",
      "Epoch 69/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4665 - accuracy: 0.8004 - val_loss: 0.6017 - val_accuracy: 0.7519\n",
      "Epoch 70/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4696 - accuracy: 0.8081 - val_loss: 0.4332 - val_accuracy: 0.7829\n",
      "Epoch 71/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4625 - accuracy: 0.8236 - val_loss: 0.4558 - val_accuracy: 0.7829\n",
      "Epoch 72/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4510 - accuracy: 0.8062 - val_loss: 0.4660 - val_accuracy: 0.8372\n",
      "Epoch 73/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4506 - accuracy: 0.8159 - val_loss: 0.4674 - val_accuracy: 0.8372\n",
      "Epoch 74/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4561 - accuracy: 0.8159 - val_loss: 0.4266 - val_accuracy: 0.7984\n",
      "Epoch 75/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4521 - accuracy: 0.8236 - val_loss: 0.4315 - val_accuracy: 0.8295\n",
      "Epoch 76/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4528 - accuracy: 0.8178 - val_loss: 0.4315 - val_accuracy: 0.8372\n",
      "Epoch 77/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4598 - accuracy: 0.8120 - val_loss: 0.4561 - val_accuracy: 0.8372\n",
      "Epoch 78/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4351 - accuracy: 0.8159 - val_loss: 0.4793 - val_accuracy: 0.8295\n",
      "Epoch 79/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4432 - accuracy: 0.8295 - val_loss: 0.4454 - val_accuracy: 0.8372\n",
      "Epoch 80/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4258 - accuracy: 0.8353 - val_loss: 0.4247 - val_accuracy: 0.8217\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4245 - accuracy: 0.8275 - val_loss: 0.5054 - val_accuracy: 0.7984\n",
      "Epoch 82/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.5116 - accuracy: 0.7674 - val_loss: 0.4506 - val_accuracy: 0.8372\n",
      "Epoch 83/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4581 - accuracy: 0.8140 - val_loss: 0.4432 - val_accuracy: 0.7907\n",
      "Epoch 84/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4286 - accuracy: 0.8411 - val_loss: 0.4389 - val_accuracy: 0.7984\n",
      "Epoch 85/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4446 - accuracy: 0.8140 - val_loss: 0.4277 - val_accuracy: 0.7984\n",
      "Epoch 86/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4389 - accuracy: 0.8217 - val_loss: 0.4432 - val_accuracy: 0.8372\n",
      "Epoch 87/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4270 - accuracy: 0.8430 - val_loss: 0.4545 - val_accuracy: 0.8372\n",
      "Epoch 88/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4270 - accuracy: 0.8256 - val_loss: 0.5036 - val_accuracy: 0.8140\n",
      "Epoch 89/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4409 - accuracy: 0.8295 - val_loss: 0.5076 - val_accuracy: 0.8062\n",
      "Epoch 90/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4395 - accuracy: 0.8178 - val_loss: 0.4321 - val_accuracy: 0.8217\n",
      "Epoch 91/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4180 - accuracy: 0.8295 - val_loss: 0.4896 - val_accuracy: 0.8217\n",
      "Epoch 92/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4362 - accuracy: 0.8178 - val_loss: 0.4396 - val_accuracy: 0.8372\n",
      "Epoch 93/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4239 - accuracy: 0.8256 - val_loss: 0.4831 - val_accuracy: 0.8295\n",
      "Epoch 94/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4259 - accuracy: 0.8236 - val_loss: 0.4258 - val_accuracy: 0.8295\n",
      "Epoch 95/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4273 - accuracy: 0.8314 - val_loss: 0.4222 - val_accuracy: 0.8062\n",
      "Epoch 96/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4172 - accuracy: 0.8314 - val_loss: 0.4307 - val_accuracy: 0.7984\n",
      "Epoch 97/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4168 - accuracy: 0.8372 - val_loss: 0.4310 - val_accuracy: 0.8372\n",
      "Epoch 98/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4181 - accuracy: 0.8353 - val_loss: 0.4750 - val_accuracy: 0.8140\n",
      "Epoch 99/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4284 - accuracy: 0.8256 - val_loss: 0.5164 - val_accuracy: 0.7907\n",
      "Epoch 100/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4453 - accuracy: 0.8120 - val_loss: 0.4570 - val_accuracy: 0.8372\n",
      "Epoch 101/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4268 - accuracy: 0.8295 - val_loss: 0.4303 - val_accuracy: 0.8295\n",
      "Epoch 102/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4144 - accuracy: 0.8353 - val_loss: 0.4321 - val_accuracy: 0.8295\n",
      "Epoch 103/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4164 - accuracy: 0.8372 - val_loss: 0.4455 - val_accuracy: 0.8450\n",
      "Epoch 104/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4253 - accuracy: 0.8256 - val_loss: 0.4231 - val_accuracy: 0.8062\n",
      "Epoch 105/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4413 - accuracy: 0.8140 - val_loss: 0.4448 - val_accuracy: 0.7907\n",
      "Epoch 106/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4355 - accuracy: 0.8198 - val_loss: 0.4238 - val_accuracy: 0.8062\n",
      "Epoch 107/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4451 - accuracy: 0.8217 - val_loss: 0.4272 - val_accuracy: 0.8217\n",
      "Epoch 108/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4175 - accuracy: 0.8430 - val_loss: 0.4239 - val_accuracy: 0.8217\n",
      "Epoch 109/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4066 - accuracy: 0.8333 - val_loss: 0.5062 - val_accuracy: 0.8217\n",
      "Epoch 110/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4283 - accuracy: 0.8198 - val_loss: 0.5429 - val_accuracy: 0.7907\n",
      "Epoch 111/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4503 - accuracy: 0.8043 - val_loss: 0.4382 - val_accuracy: 0.8295\n",
      "Epoch 112/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4285 - accuracy: 0.8333 - val_loss: 0.4333 - val_accuracy: 0.7984\n",
      "Epoch 113/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4196 - accuracy: 0.8217 - val_loss: 0.4264 - val_accuracy: 0.8295\n",
      "Epoch 114/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4123 - accuracy: 0.8372 - val_loss: 0.4364 - val_accuracy: 0.8295\n",
      "Epoch 115/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4469 - accuracy: 0.8178 - val_loss: 0.4814 - val_accuracy: 0.8295\n",
      "Epoch 116/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4152 - accuracy: 0.8391 - val_loss: 0.4321 - val_accuracy: 0.8295\n",
      "Epoch 117/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4183 - accuracy: 0.8217 - val_loss: 0.4272 - val_accuracy: 0.7907\n",
      "Epoch 118/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4538 - accuracy: 0.8004 - val_loss: 0.5259 - val_accuracy: 0.7829\n",
      "Epoch 119/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4667 - accuracy: 0.8043 - val_loss: 0.4798 - val_accuracy: 0.7907\n",
      "Epoch 120/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4350 - accuracy: 0.8159 - val_loss: 0.4301 - val_accuracy: 0.7907\n",
      "Epoch 121/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4072 - accuracy: 0.8450 - val_loss: 0.4266 - val_accuracy: 0.7907\n",
      "Epoch 122/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4069 - accuracy: 0.8372 - val_loss: 0.4261 - val_accuracy: 0.8062\n",
      "Epoch 123/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4058 - accuracy: 0.8372 - val_loss: 0.4299 - val_accuracy: 0.7984\n",
      "Epoch 124/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4095 - accuracy: 0.8256 - val_loss: 0.5260 - val_accuracy: 0.7984\n",
      "Epoch 125/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4663 - accuracy: 0.8081 - val_loss: 0.4991 - val_accuracy: 0.7907\n",
      "Epoch 126/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4332 - accuracy: 0.8140 - val_loss: 0.4305 - val_accuracy: 0.8295\n",
      "Epoch 127/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4130 - accuracy: 0.8450 - val_loss: 0.4231 - val_accuracy: 0.8062\n",
      "Epoch 128/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4150 - accuracy: 0.8353 - val_loss: 0.4245 - val_accuracy: 0.7984\n",
      "Epoch 129/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4050 - accuracy: 0.8353 - val_loss: 0.4197 - val_accuracy: 0.8140\n",
      "Epoch 130/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.5019 - accuracy: 0.7965 - val_loss: 0.4344 - val_accuracy: 0.7984\n",
      "Epoch 131/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4717 - accuracy: 0.7888 - val_loss: 0.4689 - val_accuracy: 0.8372\n",
      "Epoch 132/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4385 - accuracy: 0.8198 - val_loss: 0.4284 - val_accuracy: 0.7907\n",
      "Epoch 133/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4162 - accuracy: 0.8333 - val_loss: 0.4511 - val_accuracy: 0.8372\n",
      "Epoch 134/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4204 - accuracy: 0.8372 - val_loss: 0.4347 - val_accuracy: 0.8295\n",
      "Epoch 135/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4033 - accuracy: 0.8430 - val_loss: 0.4212 - val_accuracy: 0.8295\n",
      "Epoch 136/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4029 - accuracy: 0.8450 - val_loss: 0.4686 - val_accuracy: 0.8140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 137/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.3986 - accuracy: 0.8411 - val_loss: 0.4236 - val_accuracy: 0.7984\n",
      "Epoch 138/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4139 - accuracy: 0.8314 - val_loss: 0.4278 - val_accuracy: 0.8372\n",
      "Epoch 139/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4392 - accuracy: 0.8120 - val_loss: 0.4459 - val_accuracy: 0.7907\n",
      "Epoch 140/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4790 - accuracy: 0.8062 - val_loss: 0.4304 - val_accuracy: 0.7907\n",
      "Epoch 141/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4169 - accuracy: 0.8333 - val_loss: 0.4564 - val_accuracy: 0.8372\n",
      "Epoch 142/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4197 - accuracy: 0.8391 - val_loss: 0.4541 - val_accuracy: 0.8372\n",
      "Epoch 143/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4197 - accuracy: 0.8256 - val_loss: 0.4311 - val_accuracy: 0.8295\n",
      "Epoch 144/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4002 - accuracy: 0.8391 - val_loss: 0.4245 - val_accuracy: 0.7984\n",
      "Epoch 145/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4037 - accuracy: 0.8333 - val_loss: 0.4306 - val_accuracy: 0.7984\n",
      "Epoch 146/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4099 - accuracy: 0.8391 - val_loss: 0.4491 - val_accuracy: 0.7907\n",
      "Epoch 147/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4206 - accuracy: 0.8295 - val_loss: 0.4600 - val_accuracy: 0.7829\n",
      "Epoch 148/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4244 - accuracy: 0.8236 - val_loss: 0.4215 - val_accuracy: 0.8295\n",
      "Epoch 149/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.3949 - accuracy: 0.8469 - val_loss: 0.4648 - val_accuracy: 0.8217\n",
      "Epoch 150/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4319 - accuracy: 0.8236 - val_loss: 0.4220 - val_accuracy: 0.8217\n",
      "Epoch 151/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4103 - accuracy: 0.8295 - val_loss: 0.4720 - val_accuracy: 0.8217\n",
      "Epoch 152/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.3953 - accuracy: 0.8450 - val_loss: 0.4377 - val_accuracy: 0.8372\n",
      "Epoch 153/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.3985 - accuracy: 0.8295 - val_loss: 0.4496 - val_accuracy: 0.7907\n",
      "Epoch 154/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4152 - accuracy: 0.8275 - val_loss: 0.4311 - val_accuracy: 0.8372\n",
      "Epoch 155/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4048 - accuracy: 0.8430 - val_loss: 0.4375 - val_accuracy: 0.8450\n",
      "Epoch 156/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.3916 - accuracy: 0.8353 - val_loss: 0.4411 - val_accuracy: 0.7984\n",
      "Epoch 157/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4192 - accuracy: 0.8198 - val_loss: 0.4326 - val_accuracy: 0.8372\n",
      "Epoch 158/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4052 - accuracy: 0.8314 - val_loss: 0.6087 - val_accuracy: 0.7829\n",
      "Epoch 159/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.5862 - accuracy: 0.7965 - val_loss: 0.4720 - val_accuracy: 0.7829\n",
      "Epoch 160/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4429 - accuracy: 0.8140 - val_loss: 0.4372 - val_accuracy: 0.7984\n",
      "Epoch 161/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4172 - accuracy: 0.8275 - val_loss: 0.4560 - val_accuracy: 0.8295\n",
      "Epoch 162/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4018 - accuracy: 0.8372 - val_loss: 0.4248 - val_accuracy: 0.8295\n",
      "Epoch 163/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4024 - accuracy: 0.8333 - val_loss: 0.4245 - val_accuracy: 0.8295\n",
      "Epoch 164/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4068 - accuracy: 0.8275 - val_loss: 0.4436 - val_accuracy: 0.8450\n",
      "Epoch 165/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.3993 - accuracy: 0.8333 - val_loss: 0.4683 - val_accuracy: 0.8217\n",
      "Epoch 166/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.3916 - accuracy: 0.8488 - val_loss: 0.4617 - val_accuracy: 0.7829\n",
      "Epoch 167/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4284 - accuracy: 0.8101 - val_loss: 0.4234 - val_accuracy: 0.8217\n",
      "Epoch 168/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4087 - accuracy: 0.8314 - val_loss: 0.4224 - val_accuracy: 0.8217\n",
      "Epoch 169/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.4114 - accuracy: 0.8353 - val_loss: 0.4258 - val_accuracy: 0.8062\n",
      "Epoch 170/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.3970 - accuracy: 0.8333 - val_loss: 0.4252 - val_accuracy: 0.8295\n",
      "Epoch 171/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.3943 - accuracy: 0.8411 - val_loss: 0.4262 - val_accuracy: 0.8140\n",
      "Epoch 172/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.3990 - accuracy: 0.8353 - val_loss: 0.4458 - val_accuracy: 0.8372\n",
      "Epoch 173/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4029 - accuracy: 0.8372 - val_loss: 0.4294 - val_accuracy: 0.8140\n",
      "Epoch 174/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4075 - accuracy: 0.8236 - val_loss: 0.4352 - val_accuracy: 0.8372\n",
      "Epoch 175/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4024 - accuracy: 0.8295 - val_loss: 0.4564 - val_accuracy: 0.8295\n",
      "Epoch 176/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.3957 - accuracy: 0.8333 - val_loss: 0.4290 - val_accuracy: 0.8372\n",
      "Epoch 177/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.3917 - accuracy: 0.8391 - val_loss: 0.4752 - val_accuracy: 0.8217\n",
      "Epoch 178/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.3889 - accuracy: 0.8372 - val_loss: 0.4768 - val_accuracy: 0.7829\n",
      "Epoch 179/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4492 - accuracy: 0.8062 - val_loss: 0.5027 - val_accuracy: 0.7907\n",
      "Epoch 180/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4257 - accuracy: 0.8217 - val_loss: 0.4365 - val_accuracy: 0.8372\n",
      "Epoch 181/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4133 - accuracy: 0.8295 - val_loss: 0.4815 - val_accuracy: 0.8062\n",
      "Epoch 182/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.3963 - accuracy: 0.8372 - val_loss: 0.4268 - val_accuracy: 0.8140\n",
      "Epoch 183/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.3954 - accuracy: 0.8353 - val_loss: 0.4414 - val_accuracy: 0.8295\n",
      "Epoch 184/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.3885 - accuracy: 0.8527 - val_loss: 0.4261 - val_accuracy: 0.8140\n",
      "Epoch 185/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.3851 - accuracy: 0.8411 - val_loss: 0.4250 - val_accuracy: 0.8217\n",
      "Epoch 186/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.3869 - accuracy: 0.8469 - val_loss: 0.4304 - val_accuracy: 0.8372\n",
      "Epoch 187/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.3829 - accuracy: 0.8469 - val_loss: 0.4393 - val_accuracy: 0.8217\n",
      "Epoch 188/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.3821 - accuracy: 0.8469 - val_loss: 0.4511 - val_accuracy: 0.8140\n",
      "Epoch 189/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.3825 - accuracy: 0.8469 - val_loss: 0.4342 - val_accuracy: 0.8450\n",
      "Epoch 190/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.3936 - accuracy: 0.8295 - val_loss: 0.4402 - val_accuracy: 0.8062\n",
      "Epoch 191/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.3813 - accuracy: 0.8411 - val_loss: 0.4325 - val_accuracy: 0.8372\n",
      "Epoch 192/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.3837 - accuracy: 0.8469 - val_loss: 0.4565 - val_accuracy: 0.7907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4615 - accuracy: 0.8236 - val_loss: 0.4467 - val_accuracy: 0.8372\n",
      "Epoch 194/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4110 - accuracy: 0.8217 - val_loss: 0.4720 - val_accuracy: 0.8140\n",
      "Epoch 195/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4194 - accuracy: 0.8275 - val_loss: 0.4540 - val_accuracy: 0.8217\n",
      "Epoch 196/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.3935 - accuracy: 0.8430 - val_loss: 0.4968 - val_accuracy: 0.7984\n",
      "Epoch 197/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.3962 - accuracy: 0.8411 - val_loss: 0.5173 - val_accuracy: 0.7984\n",
      "Epoch 198/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4030 - accuracy: 0.8391 - val_loss: 0.4347 - val_accuracy: 0.8295\n",
      "Epoch 199/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.3894 - accuracy: 0.8353 - val_loss: 0.4389 - val_accuracy: 0.8450\n",
      "Epoch 200/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.3999 - accuracy: 0.8372 - val_loss: 0.4293 - val_accuracy: 0.8140\n",
      "Beginning training for dr=0.001, l_lambda=1.0e-03, reg_type=l2, act: tanh\n",
      "Train on 172 samples, validate on 43 samples\n",
      "Epoch 1/200\n",
      "172/172 [==============================] - 2s 13ms/sample - loss: 1.2562 - accuracy: 0.7364 - val_loss: 0.9722 - val_accuracy: 0.7829\n",
      "Epoch 2/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.9186 - accuracy: 0.7791 - val_loss: 0.8227 - val_accuracy: 0.7829\n",
      "Epoch 3/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.8009 - accuracy: 0.7791 - val_loss: 0.7540 - val_accuracy: 0.7829\n",
      "Epoch 4/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.7273 - accuracy: 0.7791 - val_loss: 0.6807 - val_accuracy: 0.7829\n",
      "Epoch 5/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.6684 - accuracy: 0.7791 - val_loss: 0.6402 - val_accuracy: 0.7829\n",
      "Epoch 6/200\n",
      "172/172 [==============================] - 0s 3ms/sample - loss: 0.6301 - accuracy: 0.7791 - val_loss: 0.6009 - val_accuracy: 0.7829\n",
      "Epoch 7/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.6008 - accuracy: 0.7791 - val_loss: 0.5747 - val_accuracy: 0.7829\n",
      "Epoch 8/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.5815 - accuracy: 0.7791 - val_loss: 0.5562 - val_accuracy: 0.7829\n",
      "Epoch 9/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.5570 - accuracy: 0.7810 - val_loss: 0.5348 - val_accuracy: 0.7907\n",
      "Epoch 10/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.5488 - accuracy: 0.7849 - val_loss: 0.5650 - val_accuracy: 0.8140\n",
      "Epoch 11/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.5578 - accuracy: 0.7829 - val_loss: 0.5527 - val_accuracy: 0.8062\n",
      "Epoch 12/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.5237 - accuracy: 0.7810 - val_loss: 0.4892 - val_accuracy: 0.7984\n",
      "Epoch 13/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.5043 - accuracy: 0.7926 - val_loss: 0.5072 - val_accuracy: 0.7907\n",
      "Epoch 14/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.5869 - accuracy: 0.7849 - val_loss: 0.5077 - val_accuracy: 0.7829\n",
      "Epoch 15/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.5304 - accuracy: 0.7810 - val_loss: 0.5037 - val_accuracy: 0.7829\n",
      "Epoch 16/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.5019 - accuracy: 0.7946 - val_loss: 0.4736 - val_accuracy: 0.7907\n",
      "Epoch 17/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4914 - accuracy: 0.7888 - val_loss: 0.5087 - val_accuracy: 0.7907\n",
      "Epoch 18/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4991 - accuracy: 0.8004 - val_loss: 0.5058 - val_accuracy: 0.7829\n",
      "Epoch 19/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4882 - accuracy: 0.8081 - val_loss: 0.5506 - val_accuracy: 0.7829\n",
      "Epoch 20/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.5111 - accuracy: 0.7810 - val_loss: 0.4615 - val_accuracy: 0.8062\n",
      "Epoch 21/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4688 - accuracy: 0.8004 - val_loss: 0.4923 - val_accuracy: 0.8140\n",
      "Epoch 22/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4883 - accuracy: 0.8198 - val_loss: 0.4386 - val_accuracy: 0.8062\n",
      "Epoch 23/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4667 - accuracy: 0.8043 - val_loss: 0.4367 - val_accuracy: 0.8062\n",
      "Epoch 24/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4546 - accuracy: 0.8159 - val_loss: 0.4568 - val_accuracy: 0.8450\n",
      "Epoch 25/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4601 - accuracy: 0.8120 - val_loss: 0.4302 - val_accuracy: 0.7984\n",
      "Epoch 26/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4579 - accuracy: 0.8023 - val_loss: 0.4693 - val_accuracy: 0.8372\n",
      "Epoch 27/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4704 - accuracy: 0.8178 - val_loss: 0.4757 - val_accuracy: 0.8217\n",
      "Epoch 28/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4651 - accuracy: 0.8004 - val_loss: 0.4564 - val_accuracy: 0.7984\n",
      "Epoch 29/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4512 - accuracy: 0.8159 - val_loss: 0.4630 - val_accuracy: 0.8217\n",
      "Epoch 30/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4463 - accuracy: 0.8217 - val_loss: 0.4246 - val_accuracy: 0.8062\n",
      "Epoch 31/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4548 - accuracy: 0.8178 - val_loss: 0.5014 - val_accuracy: 0.7907\n",
      "Epoch 32/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4545 - accuracy: 0.8256 - val_loss: 0.4939 - val_accuracy: 0.8217\n",
      "Epoch 33/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4891 - accuracy: 0.8062 - val_loss: 0.5423 - val_accuracy: 0.7829\n",
      "Epoch 34/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4665 - accuracy: 0.8023 - val_loss: 0.4443 - val_accuracy: 0.7907\n",
      "Epoch 35/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4461 - accuracy: 0.8159 - val_loss: 0.4321 - val_accuracy: 0.8295\n",
      "Epoch 36/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4345 - accuracy: 0.8275 - val_loss: 0.4408 - val_accuracy: 0.8372\n",
      "Epoch 37/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4448 - accuracy: 0.8236 - val_loss: 0.4269 - val_accuracy: 0.7829\n",
      "Epoch 38/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4697 - accuracy: 0.8081 - val_loss: 0.4474 - val_accuracy: 0.7907\n",
      "Epoch 39/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4592 - accuracy: 0.7984 - val_loss: 0.4436 - val_accuracy: 0.7907\n",
      "Epoch 40/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4399 - accuracy: 0.8120 - val_loss: 0.4297 - val_accuracy: 0.7907\n",
      "Epoch 41/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4594 - accuracy: 0.8062 - val_loss: 0.4390 - val_accuracy: 0.7829\n",
      "Epoch 42/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4342 - accuracy: 0.8314 - val_loss: 0.4320 - val_accuracy: 0.7984\n",
      "Epoch 43/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4333 - accuracy: 0.8159 - val_loss: 0.4259 - val_accuracy: 0.8372\n",
      "Epoch 44/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4252 - accuracy: 0.8295 - val_loss: 0.4209 - val_accuracy: 0.7829\n",
      "Epoch 45/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4392 - accuracy: 0.8159 - val_loss: 0.4335 - val_accuracy: 0.8372\n",
      "Epoch 46/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.5130 - accuracy: 0.7946 - val_loss: 0.4550 - val_accuracy: 0.7829\n",
      "Epoch 47/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4632 - accuracy: 0.8120 - val_loss: 0.4456 - val_accuracy: 0.8295\n",
      "Epoch 48/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4408 - accuracy: 0.8295 - val_loss: 0.4311 - val_accuracy: 0.7907\n",
      "Epoch 49/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4407 - accuracy: 0.8236 - val_loss: 0.4204 - val_accuracy: 0.7907\n",
      "Epoch 50/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4268 - accuracy: 0.8333 - val_loss: 0.4197 - val_accuracy: 0.8217\n",
      "Epoch 51/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4215 - accuracy: 0.8469 - val_loss: 0.4187 - val_accuracy: 0.8295\n",
      "Epoch 52/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4244 - accuracy: 0.8353 - val_loss: 0.4535 - val_accuracy: 0.8217\n",
      "Epoch 53/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4197 - accuracy: 0.8391 - val_loss: 0.4325 - val_accuracy: 0.8372\n",
      "Epoch 54/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4399 - accuracy: 0.8198 - val_loss: 0.4862 - val_accuracy: 0.8217\n",
      "Epoch 55/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4041 - accuracy: 0.8372 - val_loss: 0.4643 - val_accuracy: 0.7907\n",
      "Epoch 56/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4602 - accuracy: 0.8101 - val_loss: 0.4599 - val_accuracy: 0.8295\n",
      "Epoch 57/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4235 - accuracy: 0.8333 - val_loss: 0.4204 - val_accuracy: 0.8140\n",
      "Epoch 58/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4127 - accuracy: 0.8411 - val_loss: 0.4178 - val_accuracy: 0.8295\n",
      "Epoch 59/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4175 - accuracy: 0.8353 - val_loss: 0.4231 - val_accuracy: 0.8062\n",
      "Epoch 60/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4227 - accuracy: 0.8314 - val_loss: 0.4437 - val_accuracy: 0.8450\n",
      "Epoch 61/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4472 - accuracy: 0.8140 - val_loss: 0.4895 - val_accuracy: 0.7829\n",
      "Epoch 62/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4866 - accuracy: 0.7888 - val_loss: 0.4471 - val_accuracy: 0.7907\n",
      "Epoch 63/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4449 - accuracy: 0.8217 - val_loss: 0.4574 - val_accuracy: 0.8527\n",
      "Epoch 64/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4340 - accuracy: 0.8101 - val_loss: 0.4324 - val_accuracy: 0.8372\n",
      "Epoch 65/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4140 - accuracy: 0.8353 - val_loss: 0.4148 - val_accuracy: 0.8295\n",
      "Epoch 66/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4436 - accuracy: 0.8043 - val_loss: 0.4768 - val_accuracy: 0.7829\n",
      "Epoch 67/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4478 - accuracy: 0.8023 - val_loss: 0.4347 - val_accuracy: 0.7984\n",
      "Epoch 68/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4463 - accuracy: 0.8120 - val_loss: 0.4418 - val_accuracy: 0.8295\n",
      "Epoch 69/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4845 - accuracy: 0.8081 - val_loss: 0.4460 - val_accuracy: 0.7984\n",
      "Epoch 70/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4326 - accuracy: 0.8314 - val_loss: 0.4340 - val_accuracy: 0.7907\n",
      "Epoch 71/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4159 - accuracy: 0.8411 - val_loss: 0.4307 - val_accuracy: 0.7907\n",
      "Epoch 72/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4508 - accuracy: 0.8159 - val_loss: 0.4265 - val_accuracy: 0.8140\n",
      "Epoch 73/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4259 - accuracy: 0.8275 - val_loss: 0.4435 - val_accuracy: 0.8372\n",
      "Epoch 74/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4416 - accuracy: 0.8295 - val_loss: 0.4538 - val_accuracy: 0.8295\n",
      "Epoch 75/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4155 - accuracy: 0.8256 - val_loss: 0.4236 - val_accuracy: 0.7984\n",
      "Epoch 76/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4046 - accuracy: 0.8314 - val_loss: 0.4247 - val_accuracy: 0.8295\n",
      "Epoch 77/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4069 - accuracy: 0.8353 - val_loss: 0.4206 - val_accuracy: 0.8217\n",
      "Epoch 78/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4200 - accuracy: 0.8391 - val_loss: 0.4288 - val_accuracy: 0.8062\n",
      "Epoch 79/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4012 - accuracy: 0.8391 - val_loss: 0.4666 - val_accuracy: 0.7829\n",
      "Epoch 80/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4219 - accuracy: 0.8353 - val_loss: 0.4855 - val_accuracy: 0.8217\n",
      "Epoch 81/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4781 - accuracy: 0.8023 - val_loss: 0.5266 - val_accuracy: 0.7752\n",
      "Epoch 82/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4266 - accuracy: 0.8236 - val_loss: 0.4338 - val_accuracy: 0.8295\n",
      "Epoch 83/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4169 - accuracy: 0.8217 - val_loss: 0.4229 - val_accuracy: 0.8295\n",
      "Epoch 84/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4294 - accuracy: 0.8178 - val_loss: 0.4320 - val_accuracy: 0.8295\n",
      "Epoch 85/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4262 - accuracy: 0.8275 - val_loss: 0.4230 - val_accuracy: 0.8295\n",
      "Epoch 86/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4243 - accuracy: 0.8256 - val_loss: 0.4236 - val_accuracy: 0.8140\n",
      "Epoch 87/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4401 - accuracy: 0.8140 - val_loss: 0.4316 - val_accuracy: 0.8062\n",
      "Epoch 88/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4228 - accuracy: 0.8333 - val_loss: 0.4253 - val_accuracy: 0.8062\n",
      "Epoch 89/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4189 - accuracy: 0.8256 - val_loss: 0.4239 - val_accuracy: 0.8295\n",
      "Epoch 90/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4046 - accuracy: 0.8295 - val_loss: 0.4478 - val_accuracy: 0.8295\n",
      "Epoch 91/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4194 - accuracy: 0.8256 - val_loss: 0.5056 - val_accuracy: 0.7907\n",
      "Epoch 92/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4199 - accuracy: 0.8236 - val_loss: 0.4340 - val_accuracy: 0.8062\n",
      "Epoch 93/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4120 - accuracy: 0.8333 - val_loss: 0.4706 - val_accuracy: 0.8217\n",
      "Epoch 94/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.3908 - accuracy: 0.8566 - val_loss: 0.4698 - val_accuracy: 0.7829\n",
      "Epoch 95/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4224 - accuracy: 0.8217 - val_loss: 0.4313 - val_accuracy: 0.8295\n",
      "Epoch 96/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.3985 - accuracy: 0.8353 - val_loss: 0.4538 - val_accuracy: 0.8295\n",
      "Epoch 97/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4182 - accuracy: 0.8120 - val_loss: 0.4285 - val_accuracy: 0.8295\n",
      "Epoch 98/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3936 - accuracy: 0.8353 - val_loss: 0.4317 - val_accuracy: 0.8140\n",
      "Epoch 99/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4327 - accuracy: 0.8314 - val_loss: 0.4493 - val_accuracy: 0.8372\n",
      "Epoch 100/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.3913 - accuracy: 0.8411 - val_loss: 0.4420 - val_accuracy: 0.8372\n",
      "Epoch 101/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3935 - accuracy: 0.8391 - val_loss: 0.4304 - val_accuracy: 0.8062\n",
      "Epoch 102/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.3935 - accuracy: 0.8333 - val_loss: 0.5723 - val_accuracy: 0.7752\n",
      "Epoch 103/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4843 - accuracy: 0.8217 - val_loss: 0.5301 - val_accuracy: 0.7907\n",
      "Epoch 104/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4410 - accuracy: 0.8295 - val_loss: 0.4439 - val_accuracy: 0.7907\n",
      "Epoch 105/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4094 - accuracy: 0.8333 - val_loss: 0.4572 - val_accuracy: 0.7907\n",
      "Epoch 106/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4454 - accuracy: 0.8081 - val_loss: 0.4410 - val_accuracy: 0.8450\n",
      "Epoch 107/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4160 - accuracy: 0.8217 - val_loss: 0.4550 - val_accuracy: 0.8217\n",
      "Epoch 108/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4421 - accuracy: 0.8101 - val_loss: 0.5087 - val_accuracy: 0.8217\n",
      "Epoch 109/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4026 - accuracy: 0.8275 - val_loss: 0.4528 - val_accuracy: 0.8295\n",
      "Epoch 110/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4177 - accuracy: 0.8314 - val_loss: 0.6209 - val_accuracy: 0.7364\n",
      "Epoch 111/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4550 - accuracy: 0.8140 - val_loss: 0.4366 - val_accuracy: 0.8295\n",
      "Epoch 112/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4090 - accuracy: 0.8469 - val_loss: 0.4352 - val_accuracy: 0.8217\n",
      "Epoch 113/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4252 - accuracy: 0.8159 - val_loss: 0.4616 - val_accuracy: 0.8140\n",
      "Epoch 114/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4038 - accuracy: 0.8372 - val_loss: 0.4346 - val_accuracy: 0.8217\n",
      "Epoch 115/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4028 - accuracy: 0.8256 - val_loss: 0.5391 - val_accuracy: 0.7752\n",
      "Epoch 116/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4216 - accuracy: 0.8178 - val_loss: 0.4577 - val_accuracy: 0.8295\n",
      "Epoch 117/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4097 - accuracy: 0.8217 - val_loss: 0.4361 - val_accuracy: 0.8295\n",
      "Epoch 118/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4046 - accuracy: 0.8236 - val_loss: 0.4574 - val_accuracy: 0.8295\n",
      "Epoch 119/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3931 - accuracy: 0.8372 - val_loss: 0.4304 - val_accuracy: 0.8295\n",
      "Epoch 120/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.3899 - accuracy: 0.8295 - val_loss: 0.4271 - val_accuracy: 0.8217\n",
      "Epoch 121/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4184 - accuracy: 0.8275 - val_loss: 0.4376 - val_accuracy: 0.8062\n",
      "Epoch 122/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4052 - accuracy: 0.8198 - val_loss: 0.4488 - val_accuracy: 0.8295\n",
      "Epoch 123/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.3933 - accuracy: 0.8372 - val_loss: 0.4444 - val_accuracy: 0.8295\n",
      "Epoch 124/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4217 - accuracy: 0.8217 - val_loss: 0.4331 - val_accuracy: 0.8062\n",
      "Epoch 125/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4394 - accuracy: 0.8217 - val_loss: 0.4329 - val_accuracy: 0.8217\n",
      "Epoch 126/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4018 - accuracy: 0.8295 - val_loss: 0.4303 - val_accuracy: 0.8295\n",
      "Epoch 127/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4106 - accuracy: 0.8391 - val_loss: 0.4882 - val_accuracy: 0.7752\n",
      "Epoch 128/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4192 - accuracy: 0.8178 - val_loss: 0.5103 - val_accuracy: 0.7907\n",
      "Epoch 129/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4106 - accuracy: 0.8372 - val_loss: 0.4743 - val_accuracy: 0.7829\n",
      "Epoch 130/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4254 - accuracy: 0.8353 - val_loss: 0.4316 - val_accuracy: 0.8295\n",
      "Epoch 131/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3931 - accuracy: 0.8391 - val_loss: 0.4292 - val_accuracy: 0.8295\n",
      "Epoch 132/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3893 - accuracy: 0.8450 - val_loss: 0.4344 - val_accuracy: 0.8140\n",
      "Epoch 133/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4257 - accuracy: 0.8275 - val_loss: 0.4489 - val_accuracy: 0.8062\n",
      "Epoch 134/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.3937 - accuracy: 0.8217 - val_loss: 0.4268 - val_accuracy: 0.8217\n",
      "Epoch 135/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4114 - accuracy: 0.8217 - val_loss: 0.4283 - val_accuracy: 0.8062\n",
      "Epoch 136/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4368 - accuracy: 0.8178 - val_loss: 0.5097 - val_accuracy: 0.8140\n",
      "Epoch 137/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4614 - accuracy: 0.8140 - val_loss: 0.4579 - val_accuracy: 0.8372\n",
      "Epoch 138/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4119 - accuracy: 0.8353 - val_loss: 0.5452 - val_accuracy: 0.7829\n",
      "Epoch 139/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4323 - accuracy: 0.8217 - val_loss: 0.4530 - val_accuracy: 0.8450\n",
      "Epoch 140/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4009 - accuracy: 0.8411 - val_loss: 0.4378 - val_accuracy: 0.8062\n",
      "Epoch 141/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4004 - accuracy: 0.8372 - val_loss: 0.4304 - val_accuracy: 0.8295\n",
      "Epoch 142/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3900 - accuracy: 0.8469 - val_loss: 0.4551 - val_accuracy: 0.8295\n",
      "Epoch 143/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.3875 - accuracy: 0.8314 - val_loss: 0.4843 - val_accuracy: 0.8217\n",
      "Epoch 144/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3854 - accuracy: 0.8353 - val_loss: 0.4431 - val_accuracy: 0.8372\n",
      "Epoch 145/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4044 - accuracy: 0.8236 - val_loss: 0.4816 - val_accuracy: 0.7829\n",
      "Epoch 146/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4083 - accuracy: 0.8198 - val_loss: 0.4329 - val_accuracy: 0.8295\n",
      "Epoch 147/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.3965 - accuracy: 0.8450 - val_loss: 0.4670 - val_accuracy: 0.8217\n",
      "Epoch 148/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3863 - accuracy: 0.8333 - val_loss: 0.4453 - val_accuracy: 0.8372\n",
      "Epoch 149/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.3992 - accuracy: 0.8372 - val_loss: 0.4354 - val_accuracy: 0.8140\n",
      "Epoch 150/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3709 - accuracy: 0.8450 - val_loss: 0.5542 - val_accuracy: 0.7829\n",
      "Epoch 151/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3946 - accuracy: 0.8333 - val_loss: 0.4380 - val_accuracy: 0.8372\n",
      "Epoch 152/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3882 - accuracy: 0.8295 - val_loss: 0.4652 - val_accuracy: 0.8295\n",
      "Epoch 153/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3825 - accuracy: 0.8411 - val_loss: 0.4345 - val_accuracy: 0.8217\n",
      "Epoch 154/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3948 - accuracy: 0.8295 - val_loss: 0.4592 - val_accuracy: 0.7907\n",
      "Epoch 155/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4076 - accuracy: 0.8178 - val_loss: 0.4721 - val_accuracy: 0.7907\n",
      "Epoch 156/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4094 - accuracy: 0.8256 - val_loss: 0.4718 - val_accuracy: 0.8062\n",
      "Epoch 157/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.3960 - accuracy: 0.8353 - val_loss: 0.4619 - val_accuracy: 0.8217\n",
      "Epoch 158/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4081 - accuracy: 0.8275 - val_loss: 0.4303 - val_accuracy: 0.8217\n",
      "Epoch 159/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3824 - accuracy: 0.8372 - val_loss: 0.4310 - val_accuracy: 0.8217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3698 - accuracy: 0.8411 - val_loss: 0.4342 - val_accuracy: 0.8295\n",
      "Epoch 161/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3707 - accuracy: 0.8527 - val_loss: 0.4431 - val_accuracy: 0.8372\n",
      "Epoch 162/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3715 - accuracy: 0.8488 - val_loss: 0.4678 - val_accuracy: 0.8295\n",
      "Epoch 163/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3724 - accuracy: 0.8391 - val_loss: 0.4573 - val_accuracy: 0.7984\n",
      "Epoch 164/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3845 - accuracy: 0.8411 - val_loss: 0.4402 - val_accuracy: 0.8140\n",
      "Epoch 165/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4030 - accuracy: 0.8353 - val_loss: 0.4657 - val_accuracy: 0.8295\n",
      "Epoch 166/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3810 - accuracy: 0.8275 - val_loss: 0.4240 - val_accuracy: 0.8295\n",
      "Epoch 167/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3923 - accuracy: 0.8353 - val_loss: 0.4700 - val_accuracy: 0.7907\n",
      "Epoch 168/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3988 - accuracy: 0.8411 - val_loss: 0.4261 - val_accuracy: 0.8295\n",
      "Epoch 169/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3656 - accuracy: 0.8411 - val_loss: 0.4362 - val_accuracy: 0.7984\n",
      "Epoch 170/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3917 - accuracy: 0.8372 - val_loss: 0.4449 - val_accuracy: 0.8372\n",
      "Epoch 171/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3657 - accuracy: 0.8469 - val_loss: 0.4614 - val_accuracy: 0.8140\n",
      "Epoch 172/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3727 - accuracy: 0.8450 - val_loss: 0.4323 - val_accuracy: 0.8062\n",
      "Epoch 173/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3739 - accuracy: 0.8353 - val_loss: 0.4444 - val_accuracy: 0.8217\n",
      "Epoch 174/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3592 - accuracy: 0.8527 - val_loss: 0.4555 - val_accuracy: 0.8062\n",
      "Epoch 175/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.3667 - accuracy: 0.8450 - val_loss: 0.4601 - val_accuracy: 0.7984\n",
      "Epoch 176/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3972 - accuracy: 0.8256 - val_loss: 0.4958 - val_accuracy: 0.7829\n",
      "Epoch 177/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4409 - accuracy: 0.8120 - val_loss: 0.4204 - val_accuracy: 0.8295\n",
      "Epoch 178/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.3958 - accuracy: 0.8295 - val_loss: 0.4693 - val_accuracy: 0.7829\n",
      "Epoch 179/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.3795 - accuracy: 0.8372 - val_loss: 0.4849 - val_accuracy: 0.8062\n",
      "Epoch 180/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3784 - accuracy: 0.8430 - val_loss: 0.4218 - val_accuracy: 0.8295\n",
      "Epoch 181/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.3722 - accuracy: 0.8391 - val_loss: 0.4409 - val_accuracy: 0.8140\n",
      "Epoch 182/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.3820 - accuracy: 0.8488 - val_loss: 0.4381 - val_accuracy: 0.8372\n",
      "Epoch 183/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.3647 - accuracy: 0.8411 - val_loss: 0.4849 - val_accuracy: 0.7984\n",
      "Epoch 184/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.3744 - accuracy: 0.8469 - val_loss: 0.4527 - val_accuracy: 0.8062\n",
      "Epoch 185/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.3835 - accuracy: 0.8430 - val_loss: 0.4595 - val_accuracy: 0.8295\n",
      "Epoch 186/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.3834 - accuracy: 0.8450 - val_loss: 0.4972 - val_accuracy: 0.8140\n",
      "Epoch 187/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3930 - accuracy: 0.8372 - val_loss: 0.4520 - val_accuracy: 0.7984\n",
      "Epoch 188/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.3878 - accuracy: 0.8430 - val_loss: 0.4319 - val_accuracy: 0.8062\n",
      "Epoch 189/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.3816 - accuracy: 0.8353 - val_loss: 0.5913 - val_accuracy: 0.7674\n",
      "Epoch 190/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4400 - accuracy: 0.8178 - val_loss: 0.4906 - val_accuracy: 0.7984\n",
      "Epoch 191/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.3822 - accuracy: 0.8430 - val_loss: 0.4584 - val_accuracy: 0.8140\n",
      "Epoch 192/200\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.3933 - accuracy: 0.8198 - val_loss: 0.4383 - val_accuracy: 0.8062\n",
      "Epoch 193/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3877 - accuracy: 0.8411 - val_loss: 0.4520 - val_accuracy: 0.8372\n",
      "Epoch 194/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3723 - accuracy: 0.8353 - val_loss: 0.4467 - val_accuracy: 0.8295\n",
      "Epoch 195/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4012 - accuracy: 0.8527 - val_loss: 0.4366 - val_accuracy: 0.8140\n",
      "Epoch 196/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4063 - accuracy: 0.8391 - val_loss: 0.4479 - val_accuracy: 0.8217\n",
      "Epoch 197/200\n",
      "172/172 [==============================] - 1s 5ms/sample - loss: 0.3924 - accuracy: 0.8333 - val_loss: 0.4611 - val_accuracy: 0.7907\n",
      "Epoch 198/200\n",
      "172/172 [==============================] - 1s 5ms/sample - loss: 0.3617 - accuracy: 0.8469 - val_loss: 0.4445 - val_accuracy: 0.8140\n",
      "Epoch 199/200\n",
      "172/172 [==============================] - 1s 5ms/sample - loss: 0.3896 - accuracy: 0.8314 - val_loss: 0.4628 - val_accuracy: 0.7907\n",
      "Epoch 200/200\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3633 - accuracy: 0.8469 - val_loss: 0.4355 - val_accuracy: 0.8295\n"
     ]
    }
   ],
   "source": [
    "dropout_rates = [0.001]\n",
    "reg_types = ['l2']\n",
    "reg_coeffs = [0.001]\n",
    "activations = ['tanh']\n",
    "units=[10, 200]\n",
    "num_layers = [2, 3, 4]\n",
    "\n",
    "pbar = functools.partial(tqdm, leave=True, ncols='70%')\n",
    "pbars = [pbar() for _ in range(3)]\n",
    "\n",
    "grid_search_df3 = grid_search(dropout_rates=dropout_rates, reg_coeffs=reg_coeffs, reg_types=reg_types, \n",
    "                             pbars=pbars, activations=activations, num_epochs=200, units=units, num_layers=num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_c4c0b42e_8dbe_11ea_a150_a683e795f3a1row0_col0 {\n",
       "            background-color:  #000004;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_c4c0b42e_8dbe_11ea_a150_a683e795f3a1row1_col0 {\n",
       "            background-color:  #fd9266;\n",
       "            color:  #000000;\n",
       "        }    #T_c4c0b42e_8dbe_11ea_a150_a683e795f3a1row2_col0 {\n",
       "            background-color:  #fb8761;\n",
       "            color:  #000000;\n",
       "        }    #T_c4c0b42e_8dbe_11ea_a150_a683e795f3a1row3_col0 {\n",
       "            background-color:  #fc9065;\n",
       "            color:  #000000;\n",
       "        }    #T_c4c0b42e_8dbe_11ea_a150_a683e795f3a1row4_col0 {\n",
       "            background-color:  #fea36f;\n",
       "            color:  #000000;\n",
       "        }    #T_c4c0b42e_8dbe_11ea_a150_a683e795f3a1row5_col0 {\n",
       "            background-color:  #fcfdbf;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_c4c0b42e_8dbe_11ea_a150_a683e795f3a1\" ><thead>    <tr>        <th class=\"blank\" ></th>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >validation loss</th>    </tr>    <tr>        <th class=\"blank\" ></th>        <th class=\"index_name level1\" >lambda</th>        <th class=\"col_heading level1 col0\" >0.001</th>    </tr>    <tr>        <th class=\"index_name level0\" >num_layers</th>        <th class=\"index_name level1\" >units</th>        <th class=\"blank\" ></th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_c4c0b42e_8dbe_11ea_a150_a683e795f3a1level0_row0\" class=\"row_heading level0 row0\" rowspan=2>2</th>\n",
       "                        <th id=\"T_c4c0b42e_8dbe_11ea_a150_a683e795f3a1level1_row0\" class=\"row_heading level1 row0\" >10</th>\n",
       "                        <td id=\"T_c4c0b42e_8dbe_11ea_a150_a683e795f3a1row0_col0\" class=\"data row0 col0\" >0.436</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_c4c0b42e_8dbe_11ea_a150_a683e795f3a1level1_row1\" class=\"row_heading level1 row1\" >200</th>\n",
       "                        <td id=\"T_c4c0b42e_8dbe_11ea_a150_a683e795f3a1row1_col0\" class=\"data row1 col0\" >0.420</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c4c0b42e_8dbe_11ea_a150_a683e795f3a1level0_row2\" class=\"row_heading level0 row2\" rowspan=2>3</th>\n",
       "                        <th id=\"T_c4c0b42e_8dbe_11ea_a150_a683e795f3a1level1_row2\" class=\"row_heading level1 row2\" >10</th>\n",
       "                        <td id=\"T_c4c0b42e_8dbe_11ea_a150_a683e795f3a1row2_col0\" class=\"data row2 col0\" >0.420</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_c4c0b42e_8dbe_11ea_a150_a683e795f3a1level1_row3\" class=\"row_heading level1 row3\" >200</th>\n",
       "                        <td id=\"T_c4c0b42e_8dbe_11ea_a150_a683e795f3a1row3_col0\" class=\"data row3 col0\" >0.420</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c4c0b42e_8dbe_11ea_a150_a683e795f3a1level0_row4\" class=\"row_heading level0 row4\" rowspan=2>4</th>\n",
       "                        <th id=\"T_c4c0b42e_8dbe_11ea_a150_a683e795f3a1level1_row4\" class=\"row_heading level1 row4\" >10</th>\n",
       "                        <td id=\"T_c4c0b42e_8dbe_11ea_a150_a683e795f3a1row4_col0\" class=\"data row4 col0\" >0.419</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_c4c0b42e_8dbe_11ea_a150_a683e795f3a1level1_row5\" class=\"row_heading level1 row5\" >200</th>\n",
       "                        <td id=\"T_c4c0b42e_8dbe_11ea_a150_a683e795f3a1row5_col0\" class=\"data row5 col0\" >0.415</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x19a1df610>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_pivot3 = (grid_search_df3\n",
    "                     .pivot_table(values=['validation loss'],\n",
    "                                  columns=['lambda'],\n",
    "                                  index=['num_layers', 'units']))\n",
    "grid_search_pivot3.style.format('{:.3f}').background_gradient(cmap='magma_r',\n",
    "                                                             axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: activation: tanh, reg type: l2, lambda: 0.001, dropout rate: 0.001, units: 200, layers: 4\n"
     ]
    }
   ],
   "source": [
    "print('Best parameters: activation: {}, reg type: {}, lambda: {}, ' \n",
    "      'dropout rate: {}, units: {}, layers: {}'.format('tanh', 'l2', 0.001, 0.001, 200, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_2(dropout_rate=0.001, \n",
    "                 input_shape=(5637,), \n",
    "                 reg_coeff=0.001,\n",
    "                 reg_type='l2',\n",
    "                 activation='relu',\n",
    "                 num_epochs=300,\n",
    "                 units=200,\n",
    "                 num_layers=2):\n",
    "    model = K.Sequential()\n",
    "    if reg_type == 'l2':\n",
    "        reg = K.regularizers.l2(l=reg_coeff)\n",
    "    elif reg_type == 'l1':\n",
    "        reg = K.regularizers.l1(l=reg_coeff)\n",
    "    model.add(K.layers.Dense(units=units, activation=activation, input_shape=input_shape, \n",
    "                             kernel_regularizer=reg))\n",
    "    model.add(K.layers.Dropout(rate=dropout_rate))\n",
    "#     model.add(K.layers.Dense(units=units, activation=activation, kernel_regularizer=reg))\n",
    "\n",
    "    for i in range(num_layers-1):\n",
    "        model.add(K.layers.Dense(units=units, activation=activation, kernel_regularizer=reg))\n",
    "        model.add(K.layers.Dropout(rate=dropout_rate))\n",
    "    \n",
    "    model.add(K.layers.Dense(units=3, activation='softmax'))\n",
    "    history = History()\n",
    "    mcp_save = ModelCheckpoint('weights/best_model.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'], callbacks=[history, mcp_save])\n",
    "    \n",
    "    hist = model.fit(X_train, y_train, epochs=num_epochs, batch_size=10, validation_split=0.2)\n",
    "    \n",
    "    best_loss = min(hist.history['val_loss'])\n",
    "    \n",
    "    return best_loss, model, hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 172 samples, validate on 43 samples\n",
      "Epoch 1/300\n",
      "172/172 [==============================] - 2s 13ms/sample - loss: 1.2499 - accuracy: 0.7364 - val_loss: 0.9745 - val_accuracy: 0.7829\n",
      "Epoch 2/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.9117 - accuracy: 0.7791 - val_loss: 0.8247 - val_accuracy: 0.7829\n",
      "Epoch 3/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.8065 - accuracy: 0.7791 - val_loss: 0.7534 - val_accuracy: 0.7829\n",
      "Epoch 4/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.7323 - accuracy: 0.7791 - val_loss: 0.6895 - val_accuracy: 0.7829\n",
      "Epoch 5/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.6815 - accuracy: 0.7791 - val_loss: 0.6467 - val_accuracy: 0.7829\n",
      "Epoch 6/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.6416 - accuracy: 0.7791 - val_loss: 0.6160 - val_accuracy: 0.7829\n",
      "Epoch 7/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.6093 - accuracy: 0.7810 - val_loss: 0.5784 - val_accuracy: 0.7829\n",
      "Epoch 8/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.5873 - accuracy: 0.7752 - val_loss: 0.5479 - val_accuracy: 0.7907\n",
      "Epoch 9/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.5775 - accuracy: 0.7888 - val_loss: 0.5904 - val_accuracy: 0.8140\n",
      "Epoch 10/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.5664 - accuracy: 0.7926 - val_loss: 0.5220 - val_accuracy: 0.7907\n",
      "Epoch 11/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.5332 - accuracy: 0.7771 - val_loss: 0.4927 - val_accuracy: 0.7984\n",
      "Epoch 12/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.5344 - accuracy: 0.7907 - val_loss: 0.4959 - val_accuracy: 0.7907\n",
      "Epoch 13/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.5145 - accuracy: 0.7965 - val_loss: 0.4936 - val_accuracy: 0.7984\n",
      "Epoch 14/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.5193 - accuracy: 0.7849 - val_loss: 0.4857 - val_accuracy: 0.7984\n",
      "Epoch 15/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4988 - accuracy: 0.8023 - val_loss: 0.4897 - val_accuracy: 0.7907\n",
      "Epoch 16/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4875 - accuracy: 0.8081 - val_loss: 0.4841 - val_accuracy: 0.8217\n",
      "Epoch 17/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4924 - accuracy: 0.8004 - val_loss: 0.4856 - val_accuracy: 0.8295\n",
      "Epoch 18/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4693 - accuracy: 0.8023 - val_loss: 0.4503 - val_accuracy: 0.8062\n",
      "Epoch 19/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4959 - accuracy: 0.8062 - val_loss: 0.5271 - val_accuracy: 0.8062\n",
      "Epoch 20/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4695 - accuracy: 0.8140 - val_loss: 0.4458 - val_accuracy: 0.8062\n",
      "Epoch 21/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4934 - accuracy: 0.8140 - val_loss: 0.5477 - val_accuracy: 0.7829\n",
      "Epoch 22/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4795 - accuracy: 0.7849 - val_loss: 0.4993 - val_accuracy: 0.8217\n",
      "Epoch 23/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.5014 - accuracy: 0.7868 - val_loss: 0.4592 - val_accuracy: 0.7907\n",
      "Epoch 24/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4616 - accuracy: 0.8178 - val_loss: 0.4509 - val_accuracy: 0.8062\n",
      "Epoch 25/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4688 - accuracy: 0.8004 - val_loss: 0.5072 - val_accuracy: 0.7829\n",
      "Epoch 26/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4985 - accuracy: 0.8043 - val_loss: 0.4574 - val_accuracy: 0.7984\n",
      "Epoch 27/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4908 - accuracy: 0.8023 - val_loss: 0.4422 - val_accuracy: 0.7907\n",
      "Epoch 28/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4725 - accuracy: 0.8062 - val_loss: 0.4466 - val_accuracy: 0.8062\n",
      "Epoch 29/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4459 - accuracy: 0.8159 - val_loss: 0.4366 - val_accuracy: 0.8062\n",
      "Epoch 30/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4725 - accuracy: 0.8062 - val_loss: 0.5015 - val_accuracy: 0.7829\n",
      "Epoch 31/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4520 - accuracy: 0.8198 - val_loss: 0.4547 - val_accuracy: 0.8372\n",
      "Epoch 32/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4460 - accuracy: 0.8140 - val_loss: 0.4307 - val_accuracy: 0.8062\n",
      "Epoch 33/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4690 - accuracy: 0.8004 - val_loss: 0.4795 - val_accuracy: 0.7752\n",
      "Epoch 34/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.5207 - accuracy: 0.7946 - val_loss: 0.4556 - val_accuracy: 0.7907\n",
      "Epoch 35/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4883 - accuracy: 0.7946 - val_loss: 0.4647 - val_accuracy: 0.8372\n",
      "Epoch 36/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4512 - accuracy: 0.8159 - val_loss: 0.4369 - val_accuracy: 0.8217\n",
      "Epoch 37/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4521 - accuracy: 0.8178 - val_loss: 0.4379 - val_accuracy: 0.8295\n",
      "Epoch 38/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4450 - accuracy: 0.8140 - val_loss: 0.4402 - val_accuracy: 0.8372\n",
      "Epoch 39/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4465 - accuracy: 0.8314 - val_loss: 0.4396 - val_accuracy: 0.8372\n",
      "Epoch 40/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4356 - accuracy: 0.8256 - val_loss: 0.4284 - val_accuracy: 0.8295\n",
      "Epoch 41/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4238 - accuracy: 0.8198 - val_loss: 0.4297 - val_accuracy: 0.7829\n",
      "Epoch 42/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4458 - accuracy: 0.8081 - val_loss: 0.5324 - val_accuracy: 0.7907\n",
      "Epoch 43/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4571 - accuracy: 0.8275 - val_loss: 0.4323 - val_accuracy: 0.7984\n",
      "Epoch 44/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4271 - accuracy: 0.8159 - val_loss: 0.5229 - val_accuracy: 0.7984\n",
      "Epoch 45/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4418 - accuracy: 0.8217 - val_loss: 0.4554 - val_accuracy: 0.8372\n",
      "Epoch 46/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4305 - accuracy: 0.8198 - val_loss: 0.4267 - val_accuracy: 0.8217\n",
      "Epoch 47/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4301 - accuracy: 0.8275 - val_loss: 0.4254 - val_accuracy: 0.7907\n",
      "Epoch 48/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4200 - accuracy: 0.8275 - val_loss: 0.4351 - val_accuracy: 0.7984\n",
      "Epoch 49/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4218 - accuracy: 0.8256 - val_loss: 0.4779 - val_accuracy: 0.7829\n",
      "Epoch 50/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4308 - accuracy: 0.8236 - val_loss: 0.4486 - val_accuracy: 0.8372\n",
      "Epoch 51/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4491 - accuracy: 0.8120 - val_loss: 0.4261 - val_accuracy: 0.8217\n",
      "Epoch 52/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4271 - accuracy: 0.8236 - val_loss: 0.4306 - val_accuracy: 0.8295\n",
      "Epoch 53/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4246 - accuracy: 0.8314 - val_loss: 0.4613 - val_accuracy: 0.8295\n",
      "Epoch 54/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4203 - accuracy: 0.8120 - val_loss: 0.4241 - val_accuracy: 0.8217\n",
      "Epoch 55/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4224 - accuracy: 0.8314 - val_loss: 0.4524 - val_accuracy: 0.8372\n",
      "Epoch 56/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4600 - accuracy: 0.8120 - val_loss: 0.4409 - val_accuracy: 0.7984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4529 - accuracy: 0.8198 - val_loss: 0.4729 - val_accuracy: 0.7984\n",
      "Epoch 58/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4161 - accuracy: 0.8353 - val_loss: 0.4559 - val_accuracy: 0.7907\n",
      "Epoch 59/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4360 - accuracy: 0.8101 - val_loss: 0.4287 - val_accuracy: 0.7907\n",
      "Epoch 60/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4197 - accuracy: 0.8391 - val_loss: 0.4262 - val_accuracy: 0.8217\n",
      "Epoch 61/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4364 - accuracy: 0.8101 - val_loss: 0.4459 - val_accuracy: 0.8295\n",
      "Epoch 62/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4756 - accuracy: 0.8023 - val_loss: 0.4589 - val_accuracy: 0.8295\n",
      "Epoch 63/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4221 - accuracy: 0.8391 - val_loss: 0.4246 - val_accuracy: 0.7829\n",
      "Epoch 64/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4515 - accuracy: 0.8101 - val_loss: 0.4341 - val_accuracy: 0.7984\n",
      "Epoch 65/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4515 - accuracy: 0.8120 - val_loss: 0.4461 - val_accuracy: 0.8295\n",
      "Epoch 66/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4206 - accuracy: 0.8372 - val_loss: 0.4261 - val_accuracy: 0.7984\n",
      "Epoch 67/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4158 - accuracy: 0.8450 - val_loss: 0.4634 - val_accuracy: 0.8295\n",
      "Epoch 68/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4117 - accuracy: 0.8411 - val_loss: 0.4324 - val_accuracy: 0.8372\n",
      "Epoch 69/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4054 - accuracy: 0.8333 - val_loss: 0.4259 - val_accuracy: 0.8062\n",
      "Epoch 70/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4120 - accuracy: 0.8295 - val_loss: 0.4552 - val_accuracy: 0.8295\n",
      "Epoch 71/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4285 - accuracy: 0.8275 - val_loss: 0.4327 - val_accuracy: 0.8295\n",
      "Epoch 72/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4170 - accuracy: 0.8217 - val_loss: 0.4412 - val_accuracy: 0.7907\n",
      "Epoch 73/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4368 - accuracy: 0.8159 - val_loss: 0.4343 - val_accuracy: 0.7907\n",
      "Epoch 74/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4081 - accuracy: 0.8391 - val_loss: 0.4832 - val_accuracy: 0.8217\n",
      "Epoch 75/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4637 - accuracy: 0.8178 - val_loss: 0.4322 - val_accuracy: 0.7907\n",
      "Epoch 76/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4389 - accuracy: 0.8198 - val_loss: 0.4314 - val_accuracy: 0.7984\n",
      "Epoch 77/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4067 - accuracy: 0.8314 - val_loss: 0.4576 - val_accuracy: 0.7907\n",
      "Epoch 78/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4381 - accuracy: 0.8217 - val_loss: 0.5191 - val_accuracy: 0.8062\n",
      "Epoch 79/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4462 - accuracy: 0.8178 - val_loss: 0.4399 - val_accuracy: 0.8372\n",
      "Epoch 80/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4541 - accuracy: 0.8178 - val_loss: 0.4476 - val_accuracy: 0.8062\n",
      "Epoch 81/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4572 - accuracy: 0.8023 - val_loss: 0.4357 - val_accuracy: 0.7984\n",
      "Epoch 82/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4260 - accuracy: 0.8256 - val_loss: 0.4462 - val_accuracy: 0.8450\n",
      "Epoch 83/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4194 - accuracy: 0.8275 - val_loss: 0.4897 - val_accuracy: 0.8217\n",
      "Epoch 84/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4486 - accuracy: 0.8236 - val_loss: 0.4693 - val_accuracy: 0.8217\n",
      "Epoch 85/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4357 - accuracy: 0.8391 - val_loss: 0.6038 - val_accuracy: 0.7519\n",
      "Epoch 86/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4474 - accuracy: 0.8120 - val_loss: 0.4849 - val_accuracy: 0.8295\n",
      "Epoch 87/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4459 - accuracy: 0.8140 - val_loss: 0.4815 - val_accuracy: 0.8217\n",
      "Epoch 88/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4310 - accuracy: 0.8256 - val_loss: 0.4298 - val_accuracy: 0.7984\n",
      "Epoch 89/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4117 - accuracy: 0.8275 - val_loss: 0.4892 - val_accuracy: 0.7984\n",
      "Epoch 90/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4094 - accuracy: 0.8314 - val_loss: 0.4255 - val_accuracy: 0.8140\n",
      "Epoch 91/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4170 - accuracy: 0.8275 - val_loss: 0.4224 - val_accuracy: 0.8140\n",
      "Epoch 92/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.3981 - accuracy: 0.8333 - val_loss: 0.4255 - val_accuracy: 0.8295\n",
      "Epoch 93/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4017 - accuracy: 0.8391 - val_loss: 0.4434 - val_accuracy: 0.8062\n",
      "Epoch 94/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4098 - accuracy: 0.8314 - val_loss: 0.5018 - val_accuracy: 0.8140\n",
      "Epoch 95/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4232 - accuracy: 0.8236 - val_loss: 0.4395 - val_accuracy: 0.8372\n",
      "Epoch 96/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3958 - accuracy: 0.8411 - val_loss: 0.4431 - val_accuracy: 0.8217\n",
      "Epoch 97/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4024 - accuracy: 0.8450 - val_loss: 0.5925 - val_accuracy: 0.7519\n",
      "Epoch 98/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4271 - accuracy: 0.8217 - val_loss: 0.4927 - val_accuracy: 0.8140\n",
      "Epoch 99/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4408 - accuracy: 0.8101 - val_loss: 0.5476 - val_accuracy: 0.7829\n",
      "Epoch 100/300\n",
      "172/172 [==============================] - 1s 5ms/sample - loss: 0.4337 - accuracy: 0.8295 - val_loss: 0.4356 - val_accuracy: 0.8372\n",
      "Epoch 101/300\n",
      "172/172 [==============================] - 1s 5ms/sample - loss: 0.4246 - accuracy: 0.8198 - val_loss: 0.4297 - val_accuracy: 0.7984\n",
      "Epoch 102/300\n",
      "172/172 [==============================] - 1s 5ms/sample - loss: 0.4287 - accuracy: 0.8236 - val_loss: 0.4302 - val_accuracy: 0.8062\n",
      "Epoch 103/300\n",
      "172/172 [==============================] - 1s 5ms/sample - loss: 0.3999 - accuracy: 0.8411 - val_loss: 0.4273 - val_accuracy: 0.8295\n",
      "Epoch 104/300\n",
      "172/172 [==============================] - 1s 6ms/sample - loss: 0.3928 - accuracy: 0.8333 - val_loss: 0.4399 - val_accuracy: 0.8062\n",
      "Epoch 105/300\n",
      "172/172 [==============================] - 1s 7ms/sample - loss: 0.3975 - accuracy: 0.8353 - val_loss: 0.4608 - val_accuracy: 0.8140\n",
      "Epoch 106/300\n",
      "172/172 [==============================] - 1s 7ms/sample - loss: 0.3962 - accuracy: 0.8411 - val_loss: 0.4664 - val_accuracy: 0.8140\n",
      "Epoch 107/300\n",
      "172/172 [==============================] - 1s 7ms/sample - loss: 0.4018 - accuracy: 0.8275 - val_loss: 0.5007 - val_accuracy: 0.7984\n",
      "Epoch 108/300\n",
      "172/172 [==============================] - 1s 8ms/sample - loss: 0.4548 - accuracy: 0.7965 - val_loss: 0.4511 - val_accuracy: 0.7907\n",
      "Epoch 109/300\n",
      "172/172 [==============================] - 1s 7ms/sample - loss: 0.4013 - accuracy: 0.8372 - val_loss: 0.4269 - val_accuracy: 0.8217\n",
      "Epoch 110/300\n",
      "172/172 [==============================] - 1s 6ms/sample - loss: 0.4106 - accuracy: 0.8256 - val_loss: 0.5029 - val_accuracy: 0.8140\n",
      "Epoch 111/300\n",
      "172/172 [==============================] - 1s 6ms/sample - loss: 0.4350 - accuracy: 0.8178 - val_loss: 0.4463 - val_accuracy: 0.8372\n",
      "Epoch 112/300\n",
      "172/172 [==============================] - 1s 6ms/sample - loss: 0.3875 - accuracy: 0.8411 - val_loss: 0.4432 - val_accuracy: 0.8372\n",
      "Epoch 113/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 1s 5ms/sample - loss: 0.3987 - accuracy: 0.8353 - val_loss: 0.4697 - val_accuracy: 0.7829\n",
      "Epoch 114/300\n",
      "172/172 [==============================] - 1s 5ms/sample - loss: 0.4021 - accuracy: 0.8256 - val_loss: 0.4490 - val_accuracy: 0.8372\n",
      "Epoch 115/300\n",
      "172/172 [==============================] - 1s 5ms/sample - loss: 0.4059 - accuracy: 0.8391 - val_loss: 0.4307 - val_accuracy: 0.8372\n",
      "Epoch 116/300\n",
      "172/172 [==============================] - 1s 5ms/sample - loss: 0.4007 - accuracy: 0.8314 - val_loss: 0.4253 - val_accuracy: 0.8217\n",
      "Epoch 117/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3899 - accuracy: 0.8469 - val_loss: 0.4353 - val_accuracy: 0.8062\n",
      "Epoch 118/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3877 - accuracy: 0.8372 - val_loss: 0.5089 - val_accuracy: 0.8217\n",
      "Epoch 119/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3953 - accuracy: 0.8372 - val_loss: 0.4310 - val_accuracy: 0.8140\n",
      "Epoch 120/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4120 - accuracy: 0.8275 - val_loss: 0.4421 - val_accuracy: 0.7984\n",
      "Epoch 121/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4153 - accuracy: 0.8159 - val_loss: 0.4666 - val_accuracy: 0.8217\n",
      "Epoch 122/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3953 - accuracy: 0.8411 - val_loss: 0.4342 - val_accuracy: 0.8140\n",
      "Epoch 123/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4172 - accuracy: 0.8295 - val_loss: 0.4795 - val_accuracy: 0.8217\n",
      "Epoch 124/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3852 - accuracy: 0.8391 - val_loss: 0.4331 - val_accuracy: 0.8372\n",
      "Epoch 125/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3846 - accuracy: 0.8430 - val_loss: 0.5302 - val_accuracy: 0.7907\n",
      "Epoch 126/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3918 - accuracy: 0.8314 - val_loss: 0.4377 - val_accuracy: 0.8217\n",
      "Epoch 127/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4438 - accuracy: 0.8217 - val_loss: 0.4713 - val_accuracy: 0.7829\n",
      "Epoch 128/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4050 - accuracy: 0.8372 - val_loss: 0.4873 - val_accuracy: 0.8217\n",
      "Epoch 129/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4237 - accuracy: 0.8314 - val_loss: 0.4286 - val_accuracy: 0.8295\n",
      "Epoch 130/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4240 - accuracy: 0.8295 - val_loss: 0.4368 - val_accuracy: 0.8372\n",
      "Epoch 131/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4289 - accuracy: 0.8333 - val_loss: 0.4402 - val_accuracy: 0.8295\n",
      "Epoch 132/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4030 - accuracy: 0.8353 - val_loss: 0.4407 - val_accuracy: 0.7984\n",
      "Epoch 133/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3872 - accuracy: 0.8430 - val_loss: 0.4268 - val_accuracy: 0.8217\n",
      "Epoch 134/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3767 - accuracy: 0.8372 - val_loss: 0.4294 - val_accuracy: 0.8295\n",
      "Epoch 135/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3934 - accuracy: 0.8430 - val_loss: 0.4356 - val_accuracy: 0.8217\n",
      "Epoch 136/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4310 - accuracy: 0.8101 - val_loss: 0.5973 - val_accuracy: 0.7519\n",
      "Epoch 137/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4068 - accuracy: 0.8353 - val_loss: 0.4488 - val_accuracy: 0.8217\n",
      "Epoch 138/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3895 - accuracy: 0.8333 - val_loss: 0.4467 - val_accuracy: 0.8217\n",
      "Epoch 139/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4369 - accuracy: 0.8198 - val_loss: 0.4347 - val_accuracy: 0.8140\n",
      "Epoch 140/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4020 - accuracy: 0.8353 - val_loss: 0.5300 - val_accuracy: 0.7907\n",
      "Epoch 141/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4578 - accuracy: 0.7829 - val_loss: 0.4372 - val_accuracy: 0.8372\n",
      "Epoch 142/300\n",
      "172/172 [==============================] - 1s 5ms/sample - loss: 0.4172 - accuracy: 0.8333 - val_loss: 0.4332 - val_accuracy: 0.8295\n",
      "Epoch 143/300\n",
      "172/172 [==============================] - 1s 5ms/sample - loss: 0.3870 - accuracy: 0.8333 - val_loss: 0.4488 - val_accuracy: 0.8217\n",
      "Epoch 144/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4354 - accuracy: 0.8198 - val_loss: 0.5409 - val_accuracy: 0.7674\n",
      "Epoch 145/300\n",
      "172/172 [==============================] - 1s 5ms/sample - loss: 0.4191 - accuracy: 0.8236 - val_loss: 0.5063 - val_accuracy: 0.8062\n",
      "Epoch 146/300\n",
      "172/172 [==============================] - 1s 5ms/sample - loss: 0.4002 - accuracy: 0.8256 - val_loss: 0.4445 - val_accuracy: 0.8217\n",
      "Epoch 147/300\n",
      "172/172 [==============================] - 1s 5ms/sample - loss: 0.3817 - accuracy: 0.8450 - val_loss: 0.4393 - val_accuracy: 0.8140\n",
      "Epoch 148/300\n",
      "172/172 [==============================] - 1s 5ms/sample - loss: 0.3898 - accuracy: 0.8391 - val_loss: 0.4341 - val_accuracy: 0.8295\n",
      "Epoch 149/300\n",
      "172/172 [==============================] - 1s 5ms/sample - loss: 0.3997 - accuracy: 0.8295 - val_loss: 0.4324 - val_accuracy: 0.8062\n",
      "Epoch 150/300\n",
      "172/172 [==============================] - 1s 5ms/sample - loss: 0.3767 - accuracy: 0.8488 - val_loss: 0.4328 - val_accuracy: 0.8372\n",
      "Epoch 151/300\n",
      "172/172 [==============================] - 1s 5ms/sample - loss: 0.4174 - accuracy: 0.8333 - val_loss: 0.4252 - val_accuracy: 0.8140\n",
      "Epoch 152/300\n",
      "172/172 [==============================] - 1s 5ms/sample - loss: 0.3808 - accuracy: 0.8450 - val_loss: 0.4225 - val_accuracy: 0.8217\n",
      "Epoch 153/300\n",
      "172/172 [==============================] - 1s 5ms/sample - loss: 0.3801 - accuracy: 0.8372 - val_loss: 0.4324 - val_accuracy: 0.8217\n",
      "Epoch 154/300\n",
      "172/172 [==============================] - 1s 5ms/sample - loss: 0.4689 - accuracy: 0.8256 - val_loss: 0.4933 - val_accuracy: 0.7984\n",
      "Epoch 155/300\n",
      "172/172 [==============================] - 1s 5ms/sample - loss: 0.4530 - accuracy: 0.8023 - val_loss: 0.4922 - val_accuracy: 0.8217\n",
      "Epoch 156/300\n",
      "172/172 [==============================] - 1s 5ms/sample - loss: 0.3914 - accuracy: 0.8508 - val_loss: 0.4418 - val_accuracy: 0.8062\n",
      "Epoch 157/300\n",
      "172/172 [==============================] - 1s 5ms/sample - loss: 0.3994 - accuracy: 0.8430 - val_loss: 0.5307 - val_accuracy: 0.8062\n",
      "Epoch 158/300\n",
      "172/172 [==============================] - 1s 5ms/sample - loss: 0.4227 - accuracy: 0.8256 - val_loss: 0.4991 - val_accuracy: 0.7907\n",
      "Epoch 159/300\n",
      "172/172 [==============================] - 1s 5ms/sample - loss: 0.4031 - accuracy: 0.8372 - val_loss: 0.4222 - val_accuracy: 0.8295\n",
      "Epoch 160/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4202 - accuracy: 0.8256 - val_loss: 0.4420 - val_accuracy: 0.7984\n",
      "Epoch 161/300\n",
      "172/172 [==============================] - 1s 5ms/sample - loss: 0.3932 - accuracy: 0.8333 - val_loss: 0.4201 - val_accuracy: 0.8295\n",
      "Epoch 162/300\n",
      "172/172 [==============================] - 1s 5ms/sample - loss: 0.3809 - accuracy: 0.8391 - val_loss: 0.4690 - val_accuracy: 0.8295\n",
      "Epoch 163/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3834 - accuracy: 0.8333 - val_loss: 0.4303 - val_accuracy: 0.8217\n",
      "Epoch 164/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4041 - accuracy: 0.8275 - val_loss: 0.4323 - val_accuracy: 0.8372\n",
      "Epoch 165/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3723 - accuracy: 0.8488 - val_loss: 0.4494 - val_accuracy: 0.8295\n",
      "Epoch 166/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3668 - accuracy: 0.8450 - val_loss: 0.4525 - val_accuracy: 0.8062\n",
      "Epoch 167/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3962 - accuracy: 0.8314 - val_loss: 0.4316 - val_accuracy: 0.8295\n",
      "Epoch 168/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3754 - accuracy: 0.8391 - val_loss: 0.4463 - val_accuracy: 0.8372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3769 - accuracy: 0.8411 - val_loss: 0.5272 - val_accuracy: 0.7984\n",
      "Epoch 170/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3784 - accuracy: 0.8411 - val_loss: 0.4738 - val_accuracy: 0.7907\n",
      "Epoch 171/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3774 - accuracy: 0.8353 - val_loss: 0.4300 - val_accuracy: 0.8217\n",
      "Epoch 172/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3784 - accuracy: 0.8391 - val_loss: 0.4319 - val_accuracy: 0.8372\n",
      "Epoch 173/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3814 - accuracy: 0.8391 - val_loss: 0.4341 - val_accuracy: 0.8295\n",
      "Epoch 174/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3612 - accuracy: 0.8372 - val_loss: 0.4457 - val_accuracy: 0.8372\n",
      "Epoch 175/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3684 - accuracy: 0.8391 - val_loss: 0.4501 - val_accuracy: 0.8295\n",
      "Epoch 176/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3658 - accuracy: 0.8488 - val_loss: 0.4396 - val_accuracy: 0.8295\n",
      "Epoch 177/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3885 - accuracy: 0.8236 - val_loss: 0.4954 - val_accuracy: 0.8140\n",
      "Epoch 178/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3699 - accuracy: 0.8391 - val_loss: 0.4801 - val_accuracy: 0.8140\n",
      "Epoch 179/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3898 - accuracy: 0.8295 - val_loss: 0.5183 - val_accuracy: 0.7984\n",
      "Epoch 180/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4342 - accuracy: 0.8178 - val_loss: 0.5389 - val_accuracy: 0.7829\n",
      "Epoch 181/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3768 - accuracy: 0.8566 - val_loss: 0.4482 - val_accuracy: 0.7907\n",
      "Epoch 182/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3945 - accuracy: 0.8275 - val_loss: 0.4287 - val_accuracy: 0.8140\n",
      "Epoch 183/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3913 - accuracy: 0.8450 - val_loss: 0.4824 - val_accuracy: 0.7984\n",
      "Epoch 184/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3790 - accuracy: 0.8256 - val_loss: 0.4430 - val_accuracy: 0.8372\n",
      "Epoch 185/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3623 - accuracy: 0.8430 - val_loss: 0.5141 - val_accuracy: 0.8062\n",
      "Epoch 186/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3783 - accuracy: 0.8430 - val_loss: 0.4399 - val_accuracy: 0.8450\n",
      "Epoch 187/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3597 - accuracy: 0.8411 - val_loss: 0.4262 - val_accuracy: 0.8372\n",
      "Epoch 188/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3751 - accuracy: 0.8391 - val_loss: 0.4472 - val_accuracy: 0.7984\n",
      "Epoch 189/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3909 - accuracy: 0.8391 - val_loss: 0.4633 - val_accuracy: 0.7907\n",
      "Epoch 190/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3677 - accuracy: 0.8391 - val_loss: 0.4590 - val_accuracy: 0.8140\n",
      "Epoch 191/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3591 - accuracy: 0.8430 - val_loss: 0.4695 - val_accuracy: 0.8140\n",
      "Epoch 192/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3616 - accuracy: 0.8411 - val_loss: 0.4955 - val_accuracy: 0.7984\n",
      "Epoch 193/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3656 - accuracy: 0.8488 - val_loss: 0.4483 - val_accuracy: 0.8295\n",
      "Epoch 194/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3523 - accuracy: 0.8488 - val_loss: 0.4358 - val_accuracy: 0.8372\n",
      "Epoch 195/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3684 - accuracy: 0.8430 - val_loss: 0.4450 - val_accuracy: 0.8372\n",
      "Epoch 196/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3495 - accuracy: 0.8430 - val_loss: 0.4464 - val_accuracy: 0.8217\n",
      "Epoch 197/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3700 - accuracy: 0.8353 - val_loss: 0.4518 - val_accuracy: 0.8140\n",
      "Epoch 198/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3521 - accuracy: 0.8372 - val_loss: 0.4831 - val_accuracy: 0.8140\n",
      "Epoch 199/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3580 - accuracy: 0.8411 - val_loss: 0.4577 - val_accuracy: 0.8217\n",
      "Epoch 200/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.5097 - accuracy: 0.7926 - val_loss: 0.5639 - val_accuracy: 0.7674\n",
      "Epoch 201/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4561 - accuracy: 0.8217 - val_loss: 0.4492 - val_accuracy: 0.7984\n",
      "Epoch 202/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3868 - accuracy: 0.8391 - val_loss: 0.4506 - val_accuracy: 0.7984\n",
      "Epoch 203/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3731 - accuracy: 0.8450 - val_loss: 0.4275 - val_accuracy: 0.8140\n",
      "Epoch 204/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3733 - accuracy: 0.8450 - val_loss: 0.4471 - val_accuracy: 0.7907\n",
      "Epoch 205/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3717 - accuracy: 0.8508 - val_loss: 0.4339 - val_accuracy: 0.8450\n",
      "Epoch 206/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3544 - accuracy: 0.8314 - val_loss: 0.4393 - val_accuracy: 0.8295\n",
      "Epoch 207/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3727 - accuracy: 0.8391 - val_loss: 0.4944 - val_accuracy: 0.7829\n",
      "Epoch 208/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3906 - accuracy: 0.8295 - val_loss: 0.5027 - val_accuracy: 0.7829\n",
      "Epoch 209/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3964 - accuracy: 0.8333 - val_loss: 0.4637 - val_accuracy: 0.8295\n",
      "Epoch 210/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3592 - accuracy: 0.8469 - val_loss: 0.5135 - val_accuracy: 0.7984\n",
      "Epoch 211/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3960 - accuracy: 0.8275 - val_loss: 0.4350 - val_accuracy: 0.8295\n",
      "Epoch 212/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3640 - accuracy: 0.8411 - val_loss: 0.4347 - val_accuracy: 0.8372\n",
      "Epoch 213/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3592 - accuracy: 0.8411 - val_loss: 0.4869 - val_accuracy: 0.8062\n",
      "Epoch 214/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3887 - accuracy: 0.8353 - val_loss: 0.4487 - val_accuracy: 0.8295\n",
      "Epoch 215/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3667 - accuracy: 0.8450 - val_loss: 0.4293 - val_accuracy: 0.8372\n",
      "Epoch 216/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3679 - accuracy: 0.8547 - val_loss: 0.4628 - val_accuracy: 0.8062\n",
      "Epoch 217/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3639 - accuracy: 0.8566 - val_loss: 0.6113 - val_accuracy: 0.7597\n",
      "Epoch 218/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3943 - accuracy: 0.8488 - val_loss: 0.4320 - val_accuracy: 0.8140\n",
      "Epoch 219/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3624 - accuracy: 0.8450 - val_loss: 0.4467 - val_accuracy: 0.7984\n",
      "Epoch 220/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3554 - accuracy: 0.8430 - val_loss: 0.4414 - val_accuracy: 0.8217\n",
      "Epoch 221/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3608 - accuracy: 0.8372 - val_loss: 0.4528 - val_accuracy: 0.7907\n",
      "Epoch 222/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3595 - accuracy: 0.8488 - val_loss: 0.4547 - val_accuracy: 0.7984\n",
      "Epoch 223/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3913 - accuracy: 0.8372 - val_loss: 0.4296 - val_accuracy: 0.7984\n",
      "Epoch 224/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3663 - accuracy: 0.8391 - val_loss: 0.4929 - val_accuracy: 0.7984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/300\n",
      "172/172 [==============================] - 1s 5ms/sample - loss: 0.3991 - accuracy: 0.8275 - val_loss: 0.4666 - val_accuracy: 0.7907\n",
      "Epoch 226/300\n",
      "172/172 [==============================] - 1s 5ms/sample - loss: 0.3694 - accuracy: 0.8411 - val_loss: 0.4556 - val_accuracy: 0.7907\n",
      "Epoch 227/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3578 - accuracy: 0.8508 - val_loss: 0.4542 - val_accuracy: 0.7829\n",
      "Epoch 228/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3657 - accuracy: 0.8508 - val_loss: 0.4408 - val_accuracy: 0.8062\n",
      "Epoch 229/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3654 - accuracy: 0.8411 - val_loss: 0.4334 - val_accuracy: 0.8062\n",
      "Epoch 230/300\n",
      "172/172 [==============================] - 1s 5ms/sample - loss: 0.3753 - accuracy: 0.8450 - val_loss: 0.4901 - val_accuracy: 0.8140\n",
      "Epoch 231/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3610 - accuracy: 0.8372 - val_loss: 0.4349 - val_accuracy: 0.8295\n",
      "Epoch 232/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.3651 - accuracy: 0.8469 - val_loss: 0.4937 - val_accuracy: 0.7984\n",
      "Epoch 233/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3524 - accuracy: 0.8469 - val_loss: 0.4481 - val_accuracy: 0.8217\n",
      "Epoch 234/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3535 - accuracy: 0.8353 - val_loss: 0.4437 - val_accuracy: 0.8295\n",
      "Epoch 235/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3540 - accuracy: 0.8295 - val_loss: 0.4413 - val_accuracy: 0.8217\n",
      "Epoch 236/300\n",
      "172/172 [==============================] - 1s 5ms/sample - loss: 0.3525 - accuracy: 0.8372 - val_loss: 0.5207 - val_accuracy: 0.7829\n",
      "Epoch 237/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3579 - accuracy: 0.8391 - val_loss: 0.4618 - val_accuracy: 0.7829\n",
      "Epoch 238/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3537 - accuracy: 0.8508 - val_loss: 0.4427 - val_accuracy: 0.8295\n",
      "Epoch 239/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3511 - accuracy: 0.8488 - val_loss: 0.4749 - val_accuracy: 0.7907\n",
      "Epoch 240/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4386 - accuracy: 0.8159 - val_loss: 0.5168 - val_accuracy: 0.7752\n",
      "Epoch 241/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4318 - accuracy: 0.8488 - val_loss: 0.4413 - val_accuracy: 0.8372\n",
      "Epoch 242/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3754 - accuracy: 0.8450 - val_loss: 0.4965 - val_accuracy: 0.7829\n",
      "Epoch 243/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.3983 - accuracy: 0.8295 - val_loss: 0.4353 - val_accuracy: 0.8295\n",
      "Epoch 244/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4327 - accuracy: 0.8333 - val_loss: 0.5412 - val_accuracy: 0.7829\n",
      "Epoch 245/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4161 - accuracy: 0.8295 - val_loss: 0.4504 - val_accuracy: 0.8140\n",
      "Epoch 246/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3650 - accuracy: 0.8488 - val_loss: 0.4441 - val_accuracy: 0.8140\n",
      "Epoch 247/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3613 - accuracy: 0.8469 - val_loss: 0.4367 - val_accuracy: 0.8140\n",
      "Epoch 248/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3710 - accuracy: 0.8353 - val_loss: 0.5340 - val_accuracy: 0.7829\n",
      "Epoch 249/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3673 - accuracy: 0.8508 - val_loss: 0.4700 - val_accuracy: 0.7907\n",
      "Epoch 250/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3523 - accuracy: 0.8469 - val_loss: 0.4870 - val_accuracy: 0.7907\n",
      "Epoch 251/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3834 - accuracy: 0.8391 - val_loss: 0.5666 - val_accuracy: 0.7674\n",
      "Epoch 252/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3589 - accuracy: 0.8488 - val_loss: 0.4711 - val_accuracy: 0.7984\n",
      "Epoch 253/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3489 - accuracy: 0.8547 - val_loss: 0.4543 - val_accuracy: 0.8140\n",
      "Epoch 254/300\n",
      "172/172 [==============================] - 1s 5ms/sample - loss: 0.3604 - accuracy: 0.8430 - val_loss: 0.4738 - val_accuracy: 0.7829\n",
      "Epoch 255/300\n",
      "172/172 [==============================] - 1s 5ms/sample - loss: 0.3748 - accuracy: 0.8547 - val_loss: 0.4693 - val_accuracy: 0.7907\n",
      "Epoch 256/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3785 - accuracy: 0.8508 - val_loss: 0.4437 - val_accuracy: 0.8217\n",
      "Epoch 257/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3819 - accuracy: 0.8411 - val_loss: 0.6758 - val_accuracy: 0.7054\n",
      "Epoch 258/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3964 - accuracy: 0.8469 - val_loss: 0.4439 - val_accuracy: 0.8140\n",
      "Epoch 259/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3759 - accuracy: 0.8314 - val_loss: 0.4308 - val_accuracy: 0.8372\n",
      "Epoch 260/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3504 - accuracy: 0.8430 - val_loss: 0.5189 - val_accuracy: 0.7984\n",
      "Epoch 261/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3677 - accuracy: 0.8275 - val_loss: 0.4523 - val_accuracy: 0.8295\n",
      "Epoch 262/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3517 - accuracy: 0.8411 - val_loss: 0.4471 - val_accuracy: 0.8217\n",
      "Epoch 263/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3440 - accuracy: 0.8547 - val_loss: 0.4507 - val_accuracy: 0.8140\n",
      "Epoch 264/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3442 - accuracy: 0.8450 - val_loss: 0.4797 - val_accuracy: 0.8140\n",
      "Epoch 265/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3430 - accuracy: 0.8411 - val_loss: 0.4673 - val_accuracy: 0.8217\n",
      "Epoch 266/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3535 - accuracy: 0.8430 - val_loss: 0.4517 - val_accuracy: 0.7984\n",
      "Epoch 267/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3921 - accuracy: 0.8353 - val_loss: 0.4354 - val_accuracy: 0.8295\n",
      "Epoch 268/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3761 - accuracy: 0.8469 - val_loss: 0.5194 - val_accuracy: 0.7674\n",
      "Epoch 269/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3517 - accuracy: 0.8353 - val_loss: 0.4661 - val_accuracy: 0.8140\n",
      "Epoch 270/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3358 - accuracy: 0.8508 - val_loss: 0.4468 - val_accuracy: 0.8140\n",
      "Epoch 271/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3349 - accuracy: 0.8450 - val_loss: 0.4626 - val_accuracy: 0.7984\n",
      "Epoch 272/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3406 - accuracy: 0.8488 - val_loss: 0.4442 - val_accuracy: 0.8372\n",
      "Epoch 273/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.3432 - accuracy: 0.8527 - val_loss: 0.4381 - val_accuracy: 0.8217\n",
      "Epoch 274/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3777 - accuracy: 0.8450 - val_loss: 0.4521 - val_accuracy: 0.7907\n",
      "Epoch 275/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3977 - accuracy: 0.8411 - val_loss: 0.4357 - val_accuracy: 0.8062\n",
      "Epoch 276/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3543 - accuracy: 0.8391 - val_loss: 0.4626 - val_accuracy: 0.7829\n",
      "Epoch 277/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3698 - accuracy: 0.8469 - val_loss: 0.4436 - val_accuracy: 0.7984\n",
      "Epoch 278/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3691 - accuracy: 0.8430 - val_loss: 0.4558 - val_accuracy: 0.7829\n",
      "Epoch 279/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3466 - accuracy: 0.8488 - val_loss: 0.5710 - val_accuracy: 0.7829\n",
      "Epoch 280/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4363 - accuracy: 0.8236 - val_loss: 0.5337 - val_accuracy: 0.7907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3852 - accuracy: 0.8275 - val_loss: 0.5292 - val_accuracy: 0.7674\n",
      "Epoch 282/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3955 - accuracy: 0.8488 - val_loss: 0.4653 - val_accuracy: 0.7829\n",
      "Epoch 283/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.3746 - accuracy: 0.8411 - val_loss: 0.4315 - val_accuracy: 0.8295\n",
      "Epoch 284/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.3568 - accuracy: 0.8527 - val_loss: 0.5623 - val_accuracy: 0.7907\n",
      "Epoch 285/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.4179 - accuracy: 0.8333 - val_loss: 0.4463 - val_accuracy: 0.8140\n",
      "Epoch 286/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.3812 - accuracy: 0.8488 - val_loss: 0.5254 - val_accuracy: 0.7984\n",
      "Epoch 287/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.3592 - accuracy: 0.8391 - val_loss: 0.4793 - val_accuracy: 0.7907\n",
      "Epoch 288/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3472 - accuracy: 0.8547 - val_loss: 0.4586 - val_accuracy: 0.7829\n",
      "Epoch 289/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.3579 - accuracy: 0.8469 - val_loss: 0.4825 - val_accuracy: 0.7752\n",
      "Epoch 290/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.3426 - accuracy: 0.8488 - val_loss: 0.4769 - val_accuracy: 0.7752\n",
      "Epoch 291/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3923 - accuracy: 0.8547 - val_loss: 0.5342 - val_accuracy: 0.7674\n",
      "Epoch 292/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.3501 - accuracy: 0.8488 - val_loss: 0.4335 - val_accuracy: 0.8217\n",
      "Epoch 293/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.3880 - accuracy: 0.8236 - val_loss: 0.5705 - val_accuracy: 0.7752\n",
      "Epoch 294/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.3906 - accuracy: 0.8391 - val_loss: 0.4244 - val_accuracy: 0.8217\n",
      "Epoch 295/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3397 - accuracy: 0.8547 - val_loss: 0.4971 - val_accuracy: 0.7829\n",
      "Epoch 296/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.3482 - accuracy: 0.8488 - val_loss: 0.4458 - val_accuracy: 0.8140\n",
      "Epoch 297/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.3382 - accuracy: 0.8585 - val_loss: 0.4772 - val_accuracy: 0.7752\n",
      "Epoch 298/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.3845 - accuracy: 0.8333 - val_loss: 0.4899 - val_accuracy: 0.7984\n",
      "Epoch 299/300\n",
      "172/172 [==============================] - 1s 3ms/sample - loss: 0.3968 - accuracy: 0.8411 - val_loss: 0.4272 - val_accuracy: 0.8295\n",
      "Epoch 300/300\n",
      "172/172 [==============================] - 1s 4ms/sample - loss: 0.4034 - accuracy: 0.8353 - val_loss: 0.4327 - val_accuracy: 0.7907\n"
     ]
    }
   ],
   "source": [
    "best_loss, model, hist = create_model_2(activation='tanh', num_layers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 84.735\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Accuracy: {:.3f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.36088562e-01, 4.45545614e-02, 1.93568356e-02],\n",
       "       [9.94117737e-01, 4.44727484e-03, 1.43499661e-03],\n",
       "       [8.95959914e-01, 7.10962713e-02, 3.29439081e-02],\n",
       "       [2.43527889e-02, 5.04469693e-01, 4.71177429e-01],\n",
       "       [6.37589037e-01, 2.32117206e-01, 1.30293638e-01],\n",
       "       [5.93575120e-01, 2.58221805e-01, 1.48203105e-01],\n",
       "       [9.83527899e-01, 1.20554809e-02, 4.41662408e-03],\n",
       "       [9.50288057e-01, 3.49910334e-02, 1.47209596e-02],\n",
       "       [9.94565368e-01, 4.11818363e-03, 1.31640746e-03],\n",
       "       [8.84192765e-01, 7.87732899e-02, 3.70339639e-02],\n",
       "       [5.95999837e-01, 2.56789714e-01, 1.47210479e-01],\n",
       "       [6.67805910e-01, 2.13986233e-01, 1.18207768e-01],\n",
       "       [4.15619969e-01, 3.59434515e-01, 2.24945545e-01],\n",
       "       [3.12694937e-01, 4.13957417e-01, 2.73347706e-01],\n",
       "       [9.34488833e-01, 4.56240512e-02, 1.98870469e-02],\n",
       "       [9.03044462e-01, 6.64572790e-02, 3.04982327e-02],\n",
       "       [4.60122496e-01, 3.34832639e-01, 2.05044940e-01],\n",
       "       [4.44338381e-01, 3.43619883e-01, 2.12041721e-01],\n",
       "       [9.77536142e-01, 1.62697602e-02, 6.19414914e-03],\n",
       "       [9.80377853e-01, 1.42772188e-02, 5.34494733e-03],\n",
       "       [9.82848644e-01, 1.25358170e-02, 4.61558765e-03],\n",
       "       [5.72777152e-01, 2.70413786e-01, 1.56809017e-01],\n",
       "       [9.77475166e-01, 1.63121596e-02, 6.21261075e-03],\n",
       "       [3.50932181e-01, 3.94143552e-01, 2.54924268e-01],\n",
       "       [9.87986147e-01, 8.88368208e-03, 3.13012768e-03],\n",
       "       [9.17614460e-01, 5.68502434e-02, 2.55353078e-02],\n",
       "       [8.80575061e-01, 8.11218768e-02, 3.83030400e-02],\n",
       "       [2.66710460e-01, 4.36936677e-01, 2.96352804e-01],\n",
       "       [9.60354805e-01, 2.81411782e-02, 1.15039861e-02],\n",
       "       [9.81759906e-01, 1.33040892e-02, 4.93604271e-03],\n",
       "       [9.81185496e-01, 1.37085924e-02, 5.10594947e-03],\n",
       "       [7.11738527e-01, 1.87327310e-01, 1.00934111e-01],\n",
       "       [2.40799353e-01, 4.49355066e-01, 3.09845567e-01],\n",
       "       [9.91877556e-01, 6.08064048e-03, 2.04175478e-03],\n",
       "       [9.44490880e-02, 5.06555021e-01, 3.98995847e-01],\n",
       "       [6.34081841e-01, 2.34219506e-01, 1.31698608e-01],\n",
       "       [6.31677270e-01, 2.35653028e-01, 1.32669672e-01],\n",
       "       [2.40009248e-01, 4.49725777e-01, 3.10264945e-01],\n",
       "       [6.73173070e-01, 2.10761964e-01, 1.16064996e-01],\n",
       "       [9.75356460e-01, 1.77919809e-02, 6.85158093e-03],\n",
       "       [8.83785307e-01, 7.90383518e-02, 3.71763110e-02],\n",
       "       [7.51532137e-01, 1.62844881e-01, 8.56230408e-02],\n",
       "       [8.16709340e-01, 1.22052997e-01, 6.12377562e-02],\n",
       "       [7.57086039e-01, 1.59400642e-01, 8.35133791e-02],\n",
       "       [9.97574151e-01, 1.88114552e-03, 5.44638664e-04],\n",
       "       [6.32360518e-01, 2.35246241e-01, 1.32393226e-01],\n",
       "       [2.74824142e-01, 4.32949215e-01, 2.92226583e-01],\n",
       "       [8.23957503e-01, 1.17449127e-01, 5.85933849e-02],\n",
       "       [9.54922497e-01, 3.18462625e-02, 1.32312328e-02],\n",
       "       [8.69930744e-01, 8.80182162e-02, 4.20510322e-02],\n",
       "       [6.19506657e-01, 2.42891446e-01, 1.37601912e-01],\n",
       "       [7.86055326e-01, 1.41344637e-01, 7.26000741e-02],\n",
       "       [7.41390347e-01, 1.69121489e-01, 8.94881263e-02],\n",
       "       [6.04216754e-01, 2.51962870e-01, 1.43820345e-01],\n",
       "       [5.74674189e-01, 2.69316852e-01, 1.56008929e-01],\n",
       "       [4.49088633e-01, 3.40995073e-01, 2.09916309e-01],\n",
       "       [7.44710386e-01, 1.67064548e-01, 8.82250220e-02],\n",
       "       [1.88048020e-01, 4.73157704e-01, 3.38794351e-01],\n",
       "       [6.65817857e-01, 2.15205058e-01, 1.18976995e-01],\n",
       "       [3.51999164e-01, 3.93576503e-01, 2.54424274e-01],\n",
       "       [9.98950601e-01, 8.32075253e-04, 2.17355308e-04],\n",
       "       [8.55304122e-01, 9.74418074e-02, 4.72540259e-02],\n",
       "       [2.39151835e-01, 4.50138271e-01, 3.10709953e-01],\n",
       "       [9.15658176e-01, 5.81471249e-02, 2.61946451e-02],\n",
       "       [3.77185673e-01, 3.80219012e-01, 2.42595315e-01],\n",
       "       [9.93617296e-01, 4.81363386e-03, 1.56906305e-03],\n",
       "       [6.18827879e-01, 2.43288606e-01, 1.37883544e-01],\n",
       "       [9.08027649e-01, 6.31745234e-02, 2.87977569e-02],\n",
       "       [9.77999508e-01, 1.59456301e-02, 6.05480047e-03],\n",
       "       [8.48551095e-01, 1.01771414e-01, 4.96775471e-02],\n",
       "       [9.81467664e-01, 1.35102775e-02, 5.02212439e-03],\n",
       "       [9.99904394e-01, 8.00381968e-05, 1.55743455e-05],\n",
       "       [9.57710683e-01, 2.99463216e-02, 1.23429159e-02],\n",
       "       [9.84534860e-01, 1.13374665e-02, 4.12765937e-03],\n",
       "       [1.19217947e-01, 4.99442786e-01, 3.81339312e-01],\n",
       "       [3.22205633e-01, 4.09065068e-01, 2.68729270e-01],\n",
       "       [9.49889064e-01, 3.52614671e-02, 1.48495203e-02],\n",
       "       [4.85173106e-01, 3.20757300e-01, 1.94069609e-01],\n",
       "       [5.25473773e-01, 2.97815681e-01, 1.76710561e-01],\n",
       "       [9.46068227e-01, 3.78435962e-02, 1.60882361e-02],\n",
       "       [9.15036321e-01, 5.85554205e-02, 2.64081955e-02],\n",
       "       [8.05575609e-01, 1.29077926e-01, 6.53464571e-02],\n",
       "       [9.97903466e-01, 1.63228798e-03, 4.64309880e-04],\n",
       "       [9.79938745e-01, 1.45854009e-02, 5.47585590e-03],\n",
       "       [9.62395430e-01, 2.67441794e-02, 1.08603872e-02],\n",
       "       [9.76534247e-01, 1.69694480e-02, 6.49619801e-03],\n",
       "       [8.89867961e-01, 7.50748217e-02, 3.50571983e-02],\n",
       "       [5.73191047e-01, 2.70179302e-01, 1.56629711e-01],\n",
       "       [9.40483332e-01, 4.16064002e-02, 1.79102737e-02],\n",
       "       [9.93149698e-01, 5.15533658e-03, 1.69503968e-03],\n",
       "       [3.14571410e-01, 4.13004518e-01, 2.72424012e-01],\n",
       "       [9.84048247e-01, 1.16873104e-02, 4.26441012e-03],\n",
       "       [9.60881650e-01, 2.77809761e-02, 1.13373920e-02],\n",
       "       [2.34791636e-01, 4.52184141e-01, 3.13024133e-01],\n",
       "       [9.91616428e-01, 6.26990339e-03, 2.11368455e-03],\n",
       "       [9.98648345e-01, 1.06471579e-03, 2.86926981e-04],\n",
       "       [9.94600415e-01, 4.09264211e-03, 1.30697049e-03],\n",
       "       [8.48038018e-01, 1.02104798e-01, 4.98571210e-02],\n",
       "       [7.12374508e-01, 1.86936438e-01, 1.00689054e-01],\n",
       "       [9.68640208e-01, 2.24479828e-02, 8.91184434e-03],\n",
       "       [9.68741179e-01, 2.23791767e-02, 8.87963548e-03],\n",
       "       [9.82826054e-01, 1.25518106e-02, 4.62213531e-03],\n",
       "       [7.06111133e-01, 1.90752253e-01, 1.03136577e-01],\n",
       "       [9.62602377e-01, 2.66022310e-02, 1.07954079e-02],\n",
       "       [8.06466401e-01, 1.28519163e-01, 6.50145113e-02],\n",
       "       [9.45931971e-01, 3.79345566e-02, 1.61334369e-02],\n",
       "       [9.63616788e-01, 2.59067211e-02, 1.04763927e-02]], dtype=float32)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = preds\n",
    "a = (a == a.max(axis=1)[:,None]).astype(float)\n",
    "a = np.argmax(a, axis=1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.argmax(y_test, axis=1)\n",
    "arr[arr == 2] = 1\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(arr, a)\n",
    "auc_keras = auc(fpr_keras, tpr_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_keras, tpr_keras, label='Keras (area = {:.3f})'.format(auc_keras))\n",
    "# plt.plot(fpr_rf, tpr_rf, label='RF (area = {:.3f})'.format(auc_rf))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ps2-env",
   "language": "python",
   "name": "ps2-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
