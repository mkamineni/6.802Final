{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting utilities\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as K\n",
    "\n",
    "\n",
    "# data-science & processing tools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics\n",
    "import h5py\n",
    "import pygmnormalize as gmn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('raw_data.tsv', sep='\\t', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_ID = df['Gene ID']\n",
    "gene_names = df['Gene Name']\n",
    "\n",
    "df.drop('Gene ID', axis=1, inplace=True)\n",
    "df.drop('Gene Name', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_df = gmn.total_count_normalization(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = normal_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65217, 322)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54914, 322)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## indices where values are greater than zero\n",
    "idx2 = np.where(X.any(axis=1))[0]\n",
    "newX = X[idx2]\n",
    "newX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5637, 322)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get rows where a value is greater than 0.0001\n",
    "rows = np.unique(np.where(newX > 0.0001)[0])\n",
    "newerX = newX[rows]\n",
    "newerX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = gene_names[idx2].values[rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(322, 5637)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "by_patient = newerX.T\n",
    "by_patient.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = open('classifications.txt', 'r').read()\n",
    "classes = eval(classes)\n",
    "y = np.array(list(classes.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 2, 0, 0, 0, 0, 2, 2, 0, 0,\n",
       "       0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 2, 2, 2, 2, 0, 2, 2, 0, 2, 2, 0, 2,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0,\n",
       "       2, 0, 0, 0, 0, 2, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 2, 2, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0,\n",
       "       0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_enc = LabelEncoder()\n",
    "labels = label_enc.fit_transform(y)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = labels.reshape(len(labels), 1)\n",
    "one_hot = enc.fit_transform(labels)\n",
    "one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(by_patient, one_hot, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(215, 5637)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = K.Sequential()\n",
    "model.add(K.layers.Dense(units=10, activation='relu', input_shape=(5637,), \n",
    "                         kernel_regularizer=K.regularizers.l2(l=0.001)))\n",
    "model.add(K.layers.Dropout(rate=0.001))\n",
    "model.add(K.layers.Dense(units=200, activation='relu', kernel_regularizer=K.regularizers.l2(l=0.001)))\n",
    "model.add(K.layers.Dense(units=3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_28 (Dense)             (None, 10)                56380     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 200)               2200      \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 3)                 603       \n",
      "=================================================================\n",
      "Total params: 59,183\n",
      "Trainable params: 59,183\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 215 samples\n",
      "Epoch 1/100\n",
      "215/215 [==============================] - 1s 5ms/sample - loss: 0.6416 - accuracy: 0.6667\n",
      "Epoch 2/100\n",
      "215/215 [==============================] - 0s 417us/sample - loss: 0.5758 - accuracy: 0.6915\n",
      "Epoch 3/100\n",
      "215/215 [==============================] - 0s 412us/sample - loss: 0.5290 - accuracy: 0.7798\n",
      "Epoch 4/100\n",
      "215/215 [==============================] - 0s 406us/sample - loss: 0.5164 - accuracy: 0.7798\n",
      "Epoch 5/100\n",
      "215/215 [==============================] - 0s 403us/sample - loss: 0.5166 - accuracy: 0.7798\n",
      "Epoch 6/100\n",
      "215/215 [==============================] - 0s 402us/sample - loss: 0.5119 - accuracy: 0.7798\n",
      "Epoch 7/100\n",
      "215/215 [==============================] - 0s 403us/sample - loss: 0.5102 - accuracy: 0.7798\n",
      "Epoch 8/100\n",
      "215/215 [==============================] - 0s 406us/sample - loss: 0.5098 - accuracy: 0.7798\n",
      "Epoch 9/100\n",
      "215/215 [==============================] - 0s 403us/sample - loss: 0.5089 - accuracy: 0.7798\n",
      "Epoch 10/100\n",
      "215/215 [==============================] - 0s 407us/sample - loss: 0.5089 - accuracy: 0.7798\n",
      "Epoch 11/100\n",
      "215/215 [==============================] - 0s 403us/sample - loss: 0.5083 - accuracy: 0.7798\n",
      "Epoch 12/100\n",
      "215/215 [==============================] - 0s 409us/sample - loss: 0.5078 - accuracy: 0.7798\n",
      "Epoch 13/100\n",
      "215/215 [==============================] - 0s 402us/sample - loss: 0.5082 - accuracy: 0.7798\n",
      "Epoch 14/100\n",
      "215/215 [==============================] - 0s 406us/sample - loss: 0.5086 - accuracy: 0.7798\n",
      "Epoch 15/100\n",
      "215/215 [==============================] - 0s 434us/sample - loss: 0.5085 - accuracy: 0.7798\n",
      "Epoch 16/100\n",
      "215/215 [==============================] - 0s 427us/sample - loss: 0.5061 - accuracy: 0.7798\n",
      "Epoch 17/100\n",
      "215/215 [==============================] - 0s 426us/sample - loss: 0.5069 - accuracy: 0.7798\n",
      "Epoch 18/100\n",
      "215/215 [==============================] - 0s 423us/sample - loss: 0.5066 - accuracy: 0.7798\n",
      "Epoch 19/100\n",
      "215/215 [==============================] - 0s 447us/sample - loss: 0.5068 - accuracy: 0.7798\n",
      "Epoch 20/100\n",
      "215/215 [==============================] - 0s 428us/sample - loss: 0.5062 - accuracy: 0.7798\n",
      "Epoch 21/100\n",
      "215/215 [==============================] - 0s 432us/sample - loss: 0.5065 - accuracy: 0.7798\n",
      "Epoch 22/100\n",
      "215/215 [==============================] - 0s 431us/sample - loss: 0.5058 - accuracy: 0.7798\n",
      "Epoch 23/100\n",
      "215/215 [==============================] - 0s 403us/sample - loss: 0.5074 - accuracy: 0.7798\n",
      "Epoch 24/100\n",
      "215/215 [==============================] - 0s 405us/sample - loss: 0.5055 - accuracy: 0.7798\n",
      "Epoch 25/100\n",
      "215/215 [==============================] - 0s 408us/sample - loss: 0.5054 - accuracy: 0.7798\n",
      "Epoch 26/100\n",
      "215/215 [==============================] - 0s 404us/sample - loss: 0.5072 - accuracy: 0.7798\n",
      "Epoch 27/100\n",
      "215/215 [==============================] - 0s 403us/sample - loss: 0.5053 - accuracy: 0.7798\n",
      "Epoch 28/100\n",
      "215/215 [==============================] - 0s 408us/sample - loss: 0.5040 - accuracy: 0.7798\n",
      "Epoch 29/100\n",
      "215/215 [==============================] - 0s 406us/sample - loss: 0.5042 - accuracy: 0.7798\n",
      "Epoch 30/100\n",
      "215/215 [==============================] - 0s 431us/sample - loss: 0.5037 - accuracy: 0.7798\n",
      "Epoch 31/100\n",
      "215/215 [==============================] - 0s 421us/sample - loss: 0.5034 - accuracy: 0.7798\n",
      "Epoch 32/100\n",
      "215/215 [==============================] - 0s 423us/sample - loss: 0.5039 - accuracy: 0.7798\n",
      "Epoch 33/100\n",
      "215/215 [==============================] - 0s 410us/sample - loss: 0.5027 - accuracy: 0.7798\n",
      "Epoch 34/100\n",
      "215/215 [==============================] - 0s 412us/sample - loss: 0.5016 - accuracy: 0.7798\n",
      "Epoch 35/100\n",
      "215/215 [==============================] - 0s 459us/sample - loss: 0.5021 - accuracy: 0.7798\n",
      "Epoch 36/100\n",
      "215/215 [==============================] - 0s 452us/sample - loss: 0.5030 - accuracy: 0.7798\n",
      "Epoch 37/100\n",
      "215/215 [==============================] - 0s 481us/sample - loss: 0.5009 - accuracy: 0.7798\n",
      "Epoch 38/100\n",
      "215/215 [==============================] - 0s 447us/sample - loss: 0.5003 - accuracy: 0.7798\n",
      "Epoch 39/100\n",
      "215/215 [==============================] - 0s 449us/sample - loss: 0.4995 - accuracy: 0.7798\n",
      "Epoch 40/100\n",
      "215/215 [==============================] - 0s 559us/sample - loss: 0.5009 - accuracy: 0.7798\n",
      "Epoch 41/100\n",
      "215/215 [==============================] - 0s 461us/sample - loss: 0.4994 - accuracy: 0.7798\n",
      "Epoch 42/100\n",
      "215/215 [==============================] - 0s 491us/sample - loss: 0.4978 - accuracy: 0.7798\n",
      "Epoch 43/100\n",
      "215/215 [==============================] - 0s 466us/sample - loss: 0.4972 - accuracy: 0.7798\n",
      "Epoch 44/100\n",
      "215/215 [==============================] - 0s 490us/sample - loss: 0.4979 - accuracy: 0.7798\n",
      "Epoch 45/100\n",
      "215/215 [==============================] - 0s 432us/sample - loss: 0.4941 - accuracy: 0.7798\n",
      "Epoch 46/100\n",
      "215/215 [==============================] - 0s 425us/sample - loss: 0.4957 - accuracy: 0.7798\n",
      "Epoch 47/100\n",
      "215/215 [==============================] - 0s 421us/sample - loss: 0.4934 - accuracy: 0.7798\n",
      "Epoch 48/100\n",
      "215/215 [==============================] - 0s 458us/sample - loss: 0.4910 - accuracy: 0.7798\n",
      "Epoch 49/100\n",
      "215/215 [==============================] - 0s 480us/sample - loss: 0.4920 - accuracy: 0.7798\n",
      "Epoch 50/100\n",
      "215/215 [==============================] - 0s 606us/sample - loss: 0.4948 - accuracy: 0.7798\n",
      "Epoch 51/100\n",
      "215/215 [==============================] - 0s 488us/sample - loss: 0.4882 - accuracy: 0.7798\n",
      "Epoch 52/100\n",
      "215/215 [==============================] - 0s 486us/sample - loss: 0.4882 - accuracy: 0.7829\n",
      "Epoch 53/100\n",
      "215/215 [==============================] - 0s 496us/sample - loss: 0.4862 - accuracy: 0.7798\n",
      "Epoch 54/100\n",
      "215/215 [==============================] - 0s 511us/sample - loss: 0.4841 - accuracy: 0.7860\n",
      "Epoch 55/100\n",
      "215/215 [==============================] - 0s 538us/sample - loss: 0.4845 - accuracy: 0.7845\n",
      "Epoch 56/100\n",
      "215/215 [==============================] - 0s 618us/sample - loss: 0.4835 - accuracy: 0.7860\n",
      "Epoch 57/100\n",
      "215/215 [==============================] - 0s 574us/sample - loss: 0.4826 - accuracy: 0.7891\n",
      "Epoch 58/100\n",
      "215/215 [==============================] - 0s 554us/sample - loss: 0.4785 - accuracy: 0.7860\n",
      "Epoch 59/100\n",
      "215/215 [==============================] - 0s 577us/sample - loss: 0.4789 - accuracy: 0.7907\n",
      "Epoch 60/100\n",
      "215/215 [==============================] - 0s 572us/sample - loss: 0.4799 - accuracy: 0.7876\n",
      "Epoch 61/100\n",
      "215/215 [==============================] - 0s 572us/sample - loss: 0.4778 - accuracy: 0.7891\n",
      "Epoch 62/100\n",
      "215/215 [==============================] - 0s 584us/sample - loss: 0.4791 - accuracy: 0.7938\n",
      "Epoch 63/100\n",
      "215/215 [==============================] - 0s 545us/sample - loss: 0.4744 - accuracy: 0.7876\n",
      "Epoch 64/100\n",
      "215/215 [==============================] - 0s 511us/sample - loss: 0.4696 - accuracy: 0.7953\n",
      "Epoch 65/100\n",
      "215/215 [==============================] - 0s 548us/sample - loss: 0.4731 - accuracy: 0.7907\n",
      "Epoch 66/100\n",
      "215/215 [==============================] - 0s 503us/sample - loss: 0.4704 - accuracy: 0.7922\n",
      "Epoch 67/100\n",
      "215/215 [==============================] - 0s 559us/sample - loss: 0.4718 - accuracy: 0.7922\n",
      "Epoch 68/100\n",
      "215/215 [==============================] - 0s 562us/sample - loss: 0.4658 - accuracy: 0.7969\n",
      "Epoch 69/100\n",
      "215/215 [==============================] - 0s 561us/sample - loss: 0.4684 - accuracy: 0.7953\n",
      "Epoch 70/100\n",
      "215/215 [==============================] - 0s 513us/sample - loss: 0.4723 - accuracy: 0.7938\n",
      "Epoch 71/100\n",
      "215/215 [==============================] - 0s 498us/sample - loss: 0.4630 - accuracy: 0.7907\n",
      "Epoch 72/100\n",
      "215/215 [==============================] - 0s 522us/sample - loss: 0.4637 - accuracy: 0.8062\n",
      "Epoch 73/100\n",
      "215/215 [==============================] - 0s 548us/sample - loss: 0.4609 - accuracy: 0.7953\n",
      "Epoch 74/100\n",
      "215/215 [==============================] - 0s 548us/sample - loss: 0.4649 - accuracy: 0.7984\n",
      "Epoch 75/100\n",
      "215/215 [==============================] - 0s 762us/sample - loss: 0.4613 - accuracy: 0.8031\n",
      "Epoch 76/100\n",
      "215/215 [==============================] - 0s 583us/sample - loss: 0.4624 - accuracy: 0.7969\n",
      "Epoch 77/100\n",
      "215/215 [==============================] - 0s 564us/sample - loss: 0.4605 - accuracy: 0.8093\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215/215 [==============================] - 0s 549us/sample - loss: 0.4587 - accuracy: 0.8016\n",
      "Epoch 79/100\n",
      "215/215 [==============================] - 0s 517us/sample - loss: 0.4626 - accuracy: 0.8109\n",
      "Epoch 80/100\n",
      "215/215 [==============================] - 0s 478us/sample - loss: 0.4576 - accuracy: 0.8062\n",
      "Epoch 81/100\n",
      "215/215 [==============================] - 0s 477us/sample - loss: 0.4545 - accuracy: 0.8031\n",
      "Epoch 82/100\n",
      "215/215 [==============================] - 0s 465us/sample - loss: 0.4562 - accuracy: 0.8000\n",
      "Epoch 83/100\n",
      "215/215 [==============================] - 0s 463us/sample - loss: 0.4546 - accuracy: 0.8186\n",
      "Epoch 84/100\n",
      "215/215 [==============================] - 0s 465us/sample - loss: 0.4538 - accuracy: 0.8031\n",
      "Epoch 85/100\n",
      "215/215 [==============================] - 0s 469us/sample - loss: 0.4565 - accuracy: 0.8155\n",
      "Epoch 86/100\n",
      "215/215 [==============================] - 0s 481us/sample - loss: 0.4514 - accuracy: 0.8124\n",
      "Epoch 87/100\n",
      "215/215 [==============================] - 0s 474us/sample - loss: 0.4565 - accuracy: 0.7984\n",
      "Epoch 88/100\n",
      "215/215 [==============================] - 0s 468us/sample - loss: 0.4585 - accuracy: 0.8109\n",
      "Epoch 89/100\n",
      "215/215 [==============================] - 0s 467us/sample - loss: 0.4552 - accuracy: 0.8093\n",
      "Epoch 90/100\n",
      "215/215 [==============================] - 0s 484us/sample - loss: 0.4504 - accuracy: 0.8171\n",
      "Epoch 91/100\n",
      "215/215 [==============================] - 0s 505us/sample - loss: 0.4491 - accuracy: 0.8124\n",
      "Epoch 92/100\n",
      "215/215 [==============================] - 0s 504us/sample - loss: 0.4539 - accuracy: 0.7922\n",
      "Epoch 93/100\n",
      "215/215 [==============================] - 0s 519us/sample - loss: 0.4560 - accuracy: 0.8109\n",
      "Epoch 94/100\n",
      "215/215 [==============================] - 0s 546us/sample - loss: 0.4508 - accuracy: 0.8140\n",
      "Epoch 95/100\n",
      "215/215 [==============================] - 0s 540us/sample - loss: 0.4487 - accuracy: 0.8093\n",
      "Epoch 96/100\n",
      "215/215 [==============================] - 0s 716us/sample - loss: 0.4535 - accuracy: 0.8109\n",
      "Epoch 97/100\n",
      "215/215 [==============================] - 0s 540us/sample - loss: 0.4494 - accuracy: 0.8031\n",
      "Epoch 98/100\n",
      "215/215 [==============================] - 0s 501us/sample - loss: 0.4475 - accuracy: 0.8264\n",
      "Epoch 99/100\n",
      "215/215 [==============================] - 0s 493us/sample - loss: 0.4494 - accuracy: 0.8062\n",
      "Epoch 100/100\n",
      "215/215 [==============================] - 0s 488us/sample - loss: 0.4475 - accuracy: 0.8124\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14a1bcbd0>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ps2-env",
   "language": "python",
   "name": "ps2-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
