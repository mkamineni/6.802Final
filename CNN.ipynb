{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REPLACE CELL BELOW WITH GETTING REAL DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322\n",
      "322\n"
     ]
    }
   ],
   "source": [
    "#split into test and train directories\n",
    "source1 = \"images/small\"\n",
    "dest11 = \"cnn_images/test\"\n",
    "dest12 = \"cnn_images/training\"\n",
    "classes = {0:\"/crohns\", 1: \"/bowel\", 2:\"/none\"}\n",
    "files = os.listdir(source1)\n",
    "print(len(files))\n",
    "import numpy as np\n",
    "\n",
    "f = open('classifications.txt', 'r').read()\n",
    "samples_to_label = eval(f)\n",
    "print(len(samples_to_label))\n",
    "\n",
    "for f in files:\n",
    "    sample = f[:-4]\n",
    "    classification = samples_to_label[sample]\n",
    "    if np.random.rand(1) < 0.2:\n",
    "        shutil.copyfile(source1 + '/'+ f, dest11 + classes[classification]+'/'+ f)\n",
    "    else:\n",
    "        shutil.copyfile(source1 + '/'+ f, dest12 + classes[classification]+'/'+ f)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 245 images belonging to 3 classes.\n",
      "Found 77 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "#load images\n",
    "train_data_dir = 'cnn_images/training/'\n",
    "test_data_dir = 'cnn_images/test/'\n",
    "\n",
    "train_gen = ImageDataGenerator(rescale = 1.0/255)\n",
    "\n",
    "test_gen = ImageDataGenerator(rescale = 1.0/255)\n",
    "\n",
    "train_generator = train_gen.flow_from_directory(train_data_dir,\n",
    "                                        classes = ['crohns', 'bowel', 'none'],\n",
    "                                        batch_size = 20,\n",
    "                                        class_mode = \"categorical\",\n",
    "                                        target_size = (150, 150))\n",
    "\n",
    "test_generator = test_gen.flow_from_directory(test_data_dir,\n",
    "                                        classes = ['crohns', 'bowel', 'none'],\n",
    "                                        batch_size = 20,\n",
    "                                        class_mode = \"categorical\",\n",
    "                                        target_size = (150, 150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Build CNN model with multiple layers.\n",
    "'''\n",
    "def build_cnn(dropout_rate):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation = 'relu', input_shape=(150, 150, 3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), dim_ordering=\"th\"))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), dim_ordering=\"th\"))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), dim_ordering=\"th\"))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in order to save model with best weights in multiple epochs\n",
    "early_stopping_monitor = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0,\n",
    "    patience=0,\n",
    "    verbose=0,\n",
    "    mode='auto',\n",
    "    baseline=None,\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define set of options for hyperparameters\n",
    "dropout_rates = [0.2,  0.5, 0.8]\n",
    "learning_rates = [0.1, 0.01, 1e-3]\n",
    "accs = np.zeros((len(dropout_rates), len(learning_rates)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\")`\n",
      "  import sys\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\")`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\")`\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      " 35/100 [=========>....................] - ETA: 24s - loss: 7711348.7553 - accuracy: 0.6000"
     ]
    }
   ],
   "source": [
    "for i in range(len(dropout_rates)):\n",
    "    dropout_rate = dropout_rates[i]\n",
    "    for j in range(len(learning_rates)):\n",
    "        learning_rate = learning_rates[j]\n",
    "        model = build_cnn(dropout_rate)\n",
    "        #compile thee model\n",
    "        model.compile(optimizer=RMSprop(lr = learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        history = model.fit_generator(train_generator,\n",
    "                                      validation_data = test_generator,\n",
    "                                      steps_per_epoch = 100,\n",
    "                                      epochs = 15,\n",
    "                                      validation_steps = 50,\n",
    "                                      callbacks = [early_stopping_monitor],\n",
    "                                      verbose = 1)        \n",
    "        accs[i][j] = max(history.history[\"val_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the accuracy and parameters for which we have best accuracy\n",
    "accuracy_df = pd.DataFrame(data=accs, index=dropout_rates, columns=learning_rates)  \n",
    "accuracy_df.to_csv(\"CNN_all_results.csv\")\n",
    "\n",
    "ind = np.unravel_index(np.argmax(accs, axis=None), accs.shape) \n",
    "dropout_rate = dropout_rates[ind[0]]\n",
    "learning_rate = learning_rates[ind[1]]\n",
    "\n",
    "with open(\"CNN_best_result.txt\", \"a+\") as f:\n",
    "    f.write(\"Best Model Dropout Rate: %f\" %dropout_rate)\n",
    "    f.write(\"Best Model Learning Rate: %f\" %learning_rate)\n",
    "    f.write(\"Best Model Loss: %f\" %accs[ind[0]][ind[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and save model with best hyperparameters\n",
    "model.compile(optimizer=RMSprop(lr = learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit_generator(train_generator,\n",
    "                              validation_data = test_generator,\n",
    "                              steps_per_epoch = 100,\n",
    "                              epochs = 1,\n",
    "                              validation_steps = 50,\n",
    "                              callbacks = [early_stopping_monitor],\n",
    "                              verbose = 1)\n",
    "model.save('best_CNN_model.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
